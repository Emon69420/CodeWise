Directory structure:
└── emon69420-navigit/
    ├── README.md
    ├── AI_PROJECT_ANALYZER_SETUP.md
    ├── app.py
    ├── debug_github.py
    ├── ingest.py
    ├── package.json
    ├── rag_repo.py
    ├── requirements.txt
    ├── .env.example
    ├── gitingest_outputs/
    │   ├── Emon69420_HazMapApp_20250908_165923.txt
    │   └── Emon69420_NaviGit_20250908_025846.txt
    ├── indexes/
    │   ├── MedMint/
    │   │   └── graph.pkl
    │   └── NaviGit/
    │       ├── chunks.json
    │       ├── graph.pkl
    │       └── repo.index
    ├── services/
    │   ├── __init__.py
    │   ├── code_analyzer.py
    │   ├── config.py
    │   ├── gitingest_processor.py
    │   ├── rag_service.py
    │   └── rag_system.py
    ├── static/
    │   └── index.css
    ├── templates/
    │   ├── index.html
    │   ├── loading.html
    │   └── workspace.html
    ├── test_files/
    │   ├── quick_test.py
    │   ├── quick_token_test.py
    │   ├── streamlit_app.py
    │   ├── suppress_warnings.py
    │   ├── test_api.py
    │   ├── test_clone.py
    │   ├── test_consistent_indexing.py
    │   ├── test_deep_analysis.py
    │   ├── test_final.py
    │   ├── test_find_functions.py
    │   ├── test_find_functions_clean.py
    │   ├── test_github_auth.py
    │   ├── test_gitingest.py
    │   ├── test_gitingest_simple.py
    │   ├── test_gitingest_with_output.py
    │   ├── test_hazmap.py
    │   ├── test_hazmap_rag.py
    │   ├── test_rag_simple.py
    │   ├── test_rag_system.py
    │   ├── test_silent.py
    │   ├── test_timing_small.py
    │   ├── test_token.py
    │   └── test_with_token.py
    └── .kiro/
        └── specs/
            ├── ai-project-analyzer/
            │   ├── design.md
            │   ├── requirements.md
            │   └── tasks.md
            ├── gitingest-integration/
            │   ├── design.md
            │   ├── requirements.md
            │   └── tasks.md
            ├── self-configuring-ai-agents/
            │   └── requirements.md
            └── streamlit-frontend/
                ├── design.md
                ├── requirements.md
                └── tasks.md

================================================
FILE: README.md
================================================
Error reading file with 'cp1252': 'charmap' codec can't decode byte 0x81 in position 3880: character maps to <undefined>


================================================
FILE: AI_PROJECT_ANALYZER_SETUP.md
================================================
Error reading file with 'cp1252': 'charmap' codec can't decode byte 0x8f in position 3078: character maps to <undefined>


================================================
FILE: app.py
================================================
Error reading file with 'cp1252': 'charmap' codec can't decode byte 0x8f in position 1271: character maps to <undefined>


================================================
FILE: debug_github.py
================================================
#!/usr/bin/env python3
"""
Debug script to check GitHub API status and rate limits
"""

import requests
import json

def check_github_api():
    """Check GitHub API status and rate limits"""
    print("🔍 Debugging GitHub API access...")
    print("=" * 50)
    
    # Check API rate limit status
    print("1. Checking GitHub API rate limits...")
    try:
        response = requests.get("https://api.github.com/rate_limit")
        print(f"Status: {response.status_code}")
        
        if response.status_code == 200:
            rate_data = response.json()
            core = rate_data['resources']['core']
            print(f"✅ Rate limit status:")
            print(f"   Limit: {core['limit']}")
            print(f"   Used: {core['used']}")
            print(f"   Remaining: {core['remaining']}")
            print(f"   Reset time: {core['reset']}")
            
            if core['remaining'] == 0:
                print("❌ RATE LIMIT EXCEEDED! This is the issue.")
                import datetime
                reset_time = datetime.datetime.fromtimestamp(core['reset'])
                print(f"   Rate limit resets at: {reset_time}")
            else:
                print("✅ Rate limit OK")
        else:
            print(f"❌ Failed to check rate limits: {response.status_code}")
    except Exception as e:
        print(f"❌ Error checking rate limits: {e}")
    
    print()
    
    # Test direct repository access
    print("2. Testing direct repository access...")
    try:
        repo_url = "https://api.github.com/repos/Emon69420/HazMapApp"
        response = requests.get(repo_url)
        print(f"Status: {response.status_code}")
        
        if response.status_code == 200:
            repo_data = response.json()
            print(f"✅ Repository accessible:")
            print(f"   Name: {repo_data['full_name']}")
            print(f"   Private: {repo_data['private']}")
            print(f"   Size: {repo_data['size']} KB")
        elif response.status_code == 403:
            print("❌ 403 Forbidden - Likely rate limited")
            print("Response headers:")
            for header, value in response.headers.items():
                if 'rate' in header.lower() or 'limit' in header.lower():
                    print(f"   {header}: {value}")
        elif response.status_code == 404:
            print("❌ 404 Not Found - Repository doesn't exist or is private")
        else:
            print(f"❌ Unexpected status: {response.status_code}")
            print(f"Response: {response.text[:200]}")
    except Exception as e:
        print(f"❌ Error testing repository: {e}")
    
    print()
    
    # Test with a known public repository
    print("3. Testing with known public repository (octocat/Hello-World)...")
    try:
        repo_url = "https://api.github.com/repos/octocat/Hello-World"
        response = requests.get(repo_url)
        print(f"Status: {response.status_code}")
        
        if response.status_code == 200:
            print("✅ Known public repo accessible - API is working")
        elif response.status_code == 403:
            print("❌ Even known public repo is forbidden - definitely rate limited")
        else:
            print(f"❌ Unexpected status for known repo: {response.status_code}")
    except Exception as e:
        print(f"❌ Error testing known repo: {e}")

def check_flask_server():
    """Check if Flask server is responding"""
    print("\n4. Testing Flask server...")
    try:
        response = requests.get("http://localhost:5000/auth/status")
        print(f"Flask server status: {response.status_code}")
        if response.status_code == 200:
            print("✅ Flask server is running")
        else:
            print("❌ Flask server issue")
    except requests.exceptions.ConnectionError:
        print("❌ Flask server not running - start with: python app.py")
    except Exception as e:
        print(f"❌ Flask server error: {e}")

if __name__ == "__main__":
    check_github_api()
    check_flask_server()
    
    print("\n💡 Solutions:")
    print("1. If rate limited: Wait for reset time or use GitHub token")
    print("2. If server not running: python app.py")
    print("3. If repo changed: Check repository URL and permissions")


================================================
FILE: ingest.py
================================================
Error reading file with 'cp1252': 'charmap' codec can't decode byte 0x9d in position 1111: character maps to <undefined>


================================================
FILE: package.json
================================================
{
  "name": "workflow-automation",
  "version": "1.0.0",
  "description": "Complete workflow automation platform with visual builder",
  "main": "server.js",
  "scripts": {
    "start": "node server.js",
    "dev": "nodemon server.js",
    "build": "cd client && npm run build",
    "install:all": "npm install && cd client && npm install"
  },
  "dependencies": {
    "@huggingface/inference": "^4.7.1",
    "@octokit/rest": "^22.0.0",
    "cors": "^2.8.5",
    "d3": "^7.9.0",
    "dotenv": "^17.2.1",
    "express": "^4.18.2",
    "redis": "^5.8.2"
  },
  "devDependencies": {
    "nodemon": "^3.0.1"
  }
}



================================================
FILE: rag_repo.py
================================================
Error reading file with 'cp1252': 'charmap' codec can't decode byte 0x8f in position 4869: character maps to <undefined>


================================================
FILE: requirements.txt
================================================
# Streamlit Frontend Dependencies
streamlit>=1.28.0
requests>=2.31.0
pandas>=2.0.0
numpy>=1.24.0

# Gitingest Integration
gitingest>=0.1.0

# Additional utilities
python-dateutil>=2.8.2
urllib3>=2.0.0

# Development and testing (optional)
pytest>=7.4.0
pytest-mock>=3.11.0


================================================
FILE: .env.example
================================================
# Flask Configuration
SECRET_KEY=your-secret-key-here
FLASK_ENV=development

# GitHub OAuth Configuration (optional - for OAuth flow)
GITHUB_CLIENT_ID=your-github-client-id
GITHUB_CLIENT_SECRET=your-github-client-secret
GITHUB_REDIRECT_URI=http://localhost:5000/auth/github/callback

# Redis Configuration (for caching)
REDIS_URL=redis://localhost:6379/0

# Gitingest Configuration
GITINGEST_MAX_FILE_SIZE=10485760
GITINGEST_TIMEOUT=300
GITINGEST_TEMP_DIR=/tmp/gitingest
GITINGEST_INCLUDE_PATTERNS=*.py,*.js,*.ts,*.jsx,*.tsx,*.md,*.json,*.yaml,*.yml,README*,LICENSE*,*.txt,*.html,*.css,*.scss
GITINGEST_EXCLUDE_PATTERNS=node_modules,__pycache__,.git,*.pyc,*.log


================================================
FILE: gitingest_outputs/Emon69420_HazMapApp_20250908_165923.txt
================================================
[Binary file]


================================================
FILE: gitingest_outputs/Emon69420_NaviGit_20250908_025846.txt
================================================
Error reading file with 'cp1252': 'charmap' codec can't decode byte 0x8d in position 59637: character maps to <undefined>


================================================
FILE: indexes/MedMint/graph.pkl
================================================
[Binary file]


================================================
FILE: indexes/NaviGit/chunks.json
================================================
[{"id": "Directory structure:_0", "file": "Directory structure:", "content": "\u2514\u2500\u2500 emon69420-navigit/\n    \u251c\u2500\u2500 README.md\n    \u251c\u2500\u2500 AI_PROJECT_ANALYZER_SETUP.md\n    \u251c\u2500\u2500 app.py\n    \u251c\u2500\u2500 debug_github.py\n    \u251c\u2500\u2500 package.json\n    \u251c\u2500\u2500 rag_repo.py\n    \u251c\u2500\u2500 requirements.txt\n    \u251c\u2500\u2500 simple_gitingest_integration.py\n    \u251c\u2500\u2500 .env.example\n    \u251c\u2500\u2500 gitingest_outputs/\n    \u2502   \u251c\u2500\u2500 Emon69420_HazMapApp_20250905_194000.txt\n    \u2502   \u251c\u2500\u2500 Emon69420_Navigit_20250906_111750.txt\n    \u2502   \u251c\u2500\u2500 github_gitignore_20250905_193039.txt\n    \u2502   \u251c\u2500\u2500 github_gitignore_20250905_194008.txt\n    \u2502   \u251c\u2500\u2500 gitignore_raw_20250905_192308.txt\n    \u2502   \u251c\u2500\u2500 gitignore_structured_20250905_192308.json\n    \u2502   \u251c\u2500\u2500 Hello-World_raw_20250905_192258.txt\n    \u2502   \u251c\u2500\u2500 Hello-World_structured_20250905_192258.json\n    \u2502   \u251c\u2500\u2500 octocat_Hello-World_20250905_193031.txt\n    \u2502   \u251c\u2500\u2500 Samay1011_Project_ecommerce_React_20250906_104832.txt"}, {"id": "Directory structure:_1", "file": "Directory structure:", "content": "\u2502   \u251c\u2500\u2500 Samay1011_Project_ecommerce_React_20250906_104832.txt\n    \u2502   \u251c\u2500\u2500 tree_main_20250907_182050.txt\n    \u2502   \u251c\u2500\u2500 urvashixo_land_registry_20250906_162438.txt\n    \u2502   \u251c\u2500\u2500 urvashixo_land_registry_20250906_164238.txt\n    \u2502   \u251c\u2500\u2500 gitignore_files_20250905_192308/\n    \u2502   \u2502   \u251c\u2500\u2500 README.md.txt\n    \u2502   \u2502   \u251c\u2500\u2500 CONTRIBUTING.md.txt\n    \u2502   \u2502   \u251c\u2500\u2500 Global_README.md.txt\n    \u2502   \u2502   \u251c\u2500\u2500 LICENSE.txt\n    \u2502   \u2502   \u251c\u2500\u2500 .github_PULL_REQUEST_TEMPLATE.md.txt\n    \u2502   \u2502   \u2514\u2500\u2500 .github_workflows_stale.yml.txt\n    \u2502   \u2514\u2500\u2500 Hello-World_files_20250905_192258/\n    \u2502       \u2514\u2500\u2500 README.txt\n    \u251c\u2500\u2500 services/\n    \u2502   \u251c\u2500\u2500 __init__.py\n    \u2502   \u251c\u2500\u2500 code_analyzer.py\n    \u2502   \u251c\u2500\u2500 config.py\n    \u2502   \u251c\u2500\u2500 gitingest_processor.py\n    \u2502   \u251c\u2500\u2500 rag_service.py\n    \u2502   \u2514\u2500\u2500 rag_system.py\n    \u251c\u2500\u2500 templates/\n    \u2502   \u251c\u2500\u2500 index.html"}, {"id": "Directory structure:_2", "file": "Directory structure:", "content": "\u2502   \u251c\u2500\u2500 rag_service.py\n    \u2502   \u2514\u2500\u2500 rag_system.py\n    \u251c\u2500\u2500 templates/\n    \u2502   \u251c\u2500\u2500 index.html\n    \u2502   \u251c\u2500\u2500 loading.html\n    \u2502   \u2514\u2500\u2500 workspace.html\n    \u251c\u2500\u2500 test_files/\n    \u2502   \u251c\u2500\u2500 quick_test.py\n    \u2502   \u251c\u2500\u2500 quick_token_test.py\n    \u2502   \u251c\u2500\u2500 streamlit_app.py\n    \u2502   \u251c\u2500\u2500 suppress_warnings.py\n    \u2502   \u251c\u2500\u2500 test_api.py\n    \u2502   \u251c\u2500\u2500 test_clone.py\n    \u2502   \u251c\u2500\u2500 test_consistent_indexing.py\n    \u2502   \u251c\u2500\u2500 test_deep_analysis.py\n    \u2502   \u251c\u2500\u2500 test_final.py\n    \u2502   \u251c\u2500\u2500 test_find_functions.py\n    \u2502   \u251c\u2500\u2500 test_find_functions_clean.py\n    \u2502   \u251c\u2500\u2500 test_github_auth.py\n    \u2502   \u251c\u2500\u2500 test_gitingest.py\n    \u2502   \u251c\u2500\u2500 test_gitingest_simple.py\n    \u2502   \u251c\u2500\u2500 test_gitingest_with_output.py\n    \u2502   \u251c\u2500\u2500 test_hazmap.py\n    \u2502   \u251c\u2500\u2500 test_hazmap_rag.py\n    \u2502   \u251c\u2500\u2500 test_rag_simple.py\n    \u2502   \u251c\u2500\u2500 test_rag_system.py"}, {"id": "Directory structure:_3", "file": "Directory structure:", "content": "\u2502   \u251c\u2500\u2500 test_hazmap_rag.py\n    \u2502   \u251c\u2500\u2500 test_rag_simple.py\n    \u2502   \u251c\u2500\u2500 test_rag_system.py\n    \u2502   \u251c\u2500\u2500 test_silent.py\n    \u2502   \u2514\u2500\u2500 test_timing_small.py\n    \u2514\u2500\u2500 .kiro/\n        \u2514\u2500\u2500 specs/\n            \u251c\u2500\u2500 ai-project-analyzer/\n            \u2502   \u251c\u2500\u2500 design.md\n            \u2502   \u251c\u2500\u2500 requirements.md\n            \u2502   \u2514\u2500\u2500 tasks.md\n            \u251c\u2500\u2500 gitingest-integration/\n            \u2502   \u251c\u2500\u2500 design.md\n            \u2502   \u251c\u2500\u2500 requirements.md\n            \u2502   \u2514\u2500\u2500 tasks.md\n            \u251c\u2500\u2500 self-configuring-ai-agents/\n            \u2502   \u2514\u2500\u2500 requirements.md\n            \u2514\u2500\u2500 streamlit-frontend/\n                \u251c\u2500\u2500 design.md\n                \u251c\u2500\u2500 requirements.md\n                \u2514\u2500\u2500 tasks.md"}, {"id": "README.md_0", "file": "README.md", "content": "================================================\nError reading file with 'cp1252': 'charmap' codec can't decode byte 0x81 in position 3880: character maps to <undefined>"}, {"id": "AI_PROJECT_ANALYZER_SETUP.md_0", "file": "AI_PROJECT_ANALYZER_SETUP.md", "content": "================================================\nError reading file with 'cp1252': 'charmap' codec can't decode byte 0x8f in position 3078: character maps to <undefined>"}, {"id": "app.py_0", "file": "app.py", "content": "================================================\nfrom flask import Flask, request, jsonify, session\nfrom flask_cors import CORS\nimport os\nimport requests\nfrom datetime import datetime\nimport logging\nimport re\nfrom urllib.parse import urlparse\nimport subprocess\nimport shutil\nfrom pathlib import Path\nimport tempfile\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\napp = Flask(__name__)\napp.secret_key = os.environ.get('SECRET_KEY', 'dev-secret-key-change-in-production')\n\n# Enable CORS for frontend integration\nCORS(app, supports_credentials=True)\n\n# GitHub OAuth configuration\nGITHUB_CLIENT_ID = os.environ.get('GITHUB_CLIENT_ID')\nGITHUB_CLIENT_SECRET = os.environ.get('GITHUB_CLIENT_SECRET')"}, {"id": "app.py_1", "file": "app.py", "content": "GITHUB_CLIENT_SECRET = os.environ.get('GITHUB_CLIENT_SECRET')\nGITHUB_REDIRECT_URI = os.environ.get('GITHUB_REDIRECT_URI', 'http://localhost:5000/auth/github/callback')"}, {"id": "app.py_2", "file": "app.py", "content": "class GitHubService:\n    \"\"\"Service for handling GitHub authentication and repository access\"\"\"\n    \n    def __init__(self):\n        self.base_url = \"https://api.github.com\"\n        \n    def validate_token(self, token):\n        \"\"\"Validate GitHub personal access token\"\"\"\n        try:\n            headers = {\n                'Authorization': f'token {token}',\n                'Accept': 'application/vnd.github.v3+json'\n            }\n            \n            response = requests.get(f'{self.base_url}/user', headers=headers)\n            \n            if response.status_code == 200:\n                user_data = response.json()\n                return {\n                    'valid': True,\n                    'user': {\n                        'login': user_data.get('login'),"}, {"id": "app.py_3", "file": "app.py", "content": "'user': {\n                        'login': user_data.get('login'),\n                        'id': user_data.get('id'),\n                        'name': user_data.get('name'),\n                        'email': user_data.get('email')\n                    },\n                    'scopes': response.headers.get('X-OAuth-Scopes', '').split(', ')\n                }\n            else:\n                return {\n                    'valid': False,\n                    'error': 'Invalid token or insufficient permissions'\n                }\n                \n        except requests.RequestException as e:\n            logger.error(f\"GitHub API error: {str(e)}\")\n            return {\n                'valid': False,\n                'error': 'Failed to validate token with GitHub API'\n            }"}, {"id": "app.py_4", "file": "app.py", "content": "'error': 'Failed to validate token with GitHub API'\n            }\n    \n    def get_oauth_url(self, state=None):\n        \"\"\"Generate GitHub OAuth authorization URL\"\"\"\n        if not GITHUB_CLIENT_ID:\n            raise ValueError(\"GitHub Client ID not configured\")\n            \n        params = {\n            'client_id': GITHUB_CLIENT_ID,\n            'redirect_uri': GITHUB_REDIRECT_URI,\n            'scope': 'repo,user:email',\n            'state': state or 'default'\n        }\n        \n        query_string = '&'.join([f\"{k}={v}\" for k, v in params.items()])\n        return f\"https://github.com/login/oauth/authorize?{query_string}\"\n    \n    def exchange_code_for_token(self, code, state):\n        \"\"\"Exchange OAuth code for access token\"\"\"\n        try:\n            data = {"}, {"id": "app.py_5", "file": "app.py", "content": "\"\"\"Exchange OAuth code for access token\"\"\"\n        try:\n            data = {\n                'client_id': GITHUB_CLIENT_ID,\n                'client_secret': GITHUB_CLIENT_SECRET,\n                'code': code,\n                'redirect_uri': GITHUB_REDIRECT_URI,\n                'state': state\n            }\n            \n            headers = {\n                'Accept': 'application/json'\n            }\n            \n            response = requests.post(\n                'https://github.com/login/oauth/access_token',\n                data=data,\n                headers=headers\n            )\n            \n            if response.status_code == 200:\n                token_data = response.json()\n                if 'access_token' in token_data:\n                    return {"}, {"id": "app.py_6", "file": "app.py", "content": "if 'access_token' in token_data:\n                    return {\n                        'success': True,\n                        'access_token': token_data['access_token'],\n                        'token_type': token_data.get('token_type', 'bearer'),\n                        'scope': token_data.get('scope', '')\n                    }\n                else:\n                    return {\n                        'success': False,\n                        'error': token_data.get('error_description', 'Failed to get access token')\n                    }\n            else:\n                return {\n                    'success': False,\n                    'error': 'GitHub OAuth server error'\n                }\n                \n        except requests.RequestException as e:"}, {"id": "app.py_7", "file": "app.py", "content": "}\n                \n        except requests.RequestException as e:\n            logger.error(f\"OAuth token exchange error: {str(e)}\")\n            return {\n                'success': False,\n                'error': 'Failed to exchange code for token'\n            }\n    \n    def parse_github_url(self, url):\n        \"\"\"Parse GitHub repository URL to extract owner and repo name\"\"\"\n        try:\n            # Handle different GitHub URL formats\n            patterns = [\n                r'github\\.com[:/]([^/]+)/([^/]+?)(?:\\.git)?/?$',\n                r'github\\.com/([^/]+)/([^/]+?)(?:/.*)?$'\n            ]\n            \n            for pattern in patterns:\n                match = re.search(pattern, url)\n                if match:\n                    owner, repo = match.groups()"}, {"id": "app.py_8", "file": "app.py", "content": "if match:\n                    owner, repo = match.groups()\n                    # Remove .git suffix if present\n                    repo = repo.replace('.git', '')\n                    return {'owner': owner, 'repo': repo}\n            \n            return None\n        except Exception as e:\n            logger.error(f\"URL parsing error: {str(e)}\")\n            return None\n    \n    def validate_repository_access(self, owner, repo, token=None):\n        \"\"\"Validate repository exists and check access permissions\"\"\"\n        try:\n            headers = {\n                'Accept': 'application/vnd.github.v3+json',\n                'User-Agent': 'AI-Project-Analyzer/1.0'\n            }\n            \n            if token:\n                headers['Authorization'] = f'token {token}'"}, {"id": "app.py_9", "file": "app.py", "content": "if token:\n                headers['Authorization'] = f'token {token}'\n            \n            # Check repository existence and basic info\n            response = requests.get(\n                f'{self.base_url}/repos/{owner}/{repo}',\n                headers=headers\n            )\n            \n            if response.status_code == 200:\n                repo_data = response.json()\n                return {\n                    'accessible': True,\n                    'repo_info': {\n                        'name': repo_data.get('name'),\n                        'full_name': repo_data.get('full_name'),\n                        'description': repo_data.get('description'),\n                        'private': repo_data.get('private', False),"}, {"id": "app.py_10", "file": "app.py", "content": "'private': repo_data.get('private', False),\n                        'size': repo_data.get('size', 0),\n                        'language': repo_data.get('language'),\n                        'languages_url': repo_data.get('languages_url'),\n                        'default_branch': repo_data.get('default_branch', 'main'),\n                        'clone_url': repo_data.get('clone_url'),\n                        'html_url': repo_data.get('html_url'),\n                        'created_at': repo_data.get('created_at'),\n                        'updated_at': repo_data.get('updated_at'),\n                        'stargazers_count': repo_data.get('stargazers_count', 0),\n                        'forks_count': repo_data.get('forks_count', 0)\n                    }\n                }"}, {"id": "app.py_11", "file": "app.py", "content": "}\n                }\n            elif response.status_code == 404:\n                return {\n                    'accessible': False,\n                    'error': 'Repository not found or not accessible'\n                }\n            elif response.status_code == 403:\n                return {\n                    'accessible': False,\n                    'error': 'Access forbidden - repository may be private or rate limited'\n                }\n            else:\n                return {\n                    'accessible': False,\n                    'error': f'GitHub API error: {response.status_code}'\n                }\n                \n        except requests.RequestException as e:\n            logger.error(f\"Repository validation error: {str(e)}\")\n            return {"}, {"id": "app.py_12", "file": "app.py", "content": "logger.error(f\"Repository validation error: {str(e)}\")\n            return {\n                'accessible': False,\n                'error': 'Failed to connect to GitHub API'\n            }\n    \n    def get_repository_tree(self, owner, repo, token=None, branch=None):\n        \"\"\"Get repository file tree structure\"\"\"\n        try:\n            headers = {\n                'Accept': 'application/vnd.github.v3+json',\n                'User-Agent': 'AI-Project-Analyzer/1.0'\n            }\n            \n            if token:\n                headers['Authorization'] = f'token {token}'\n            \n            # Get default branch if not specified\n            if not branch:\n                repo_info = self.validate_repository_access(owner, repo, token)"}, {"id": "app.py_13", "file": "app.py", "content": "repo_info = self.validate_repository_access(owner, repo, token)\n                if repo_info['accessible']:\n                    branch = repo_info['repo_info']['default_branch']\n                else:\n                    return repo_info\n            \n            # Get repository tree\n            response = requests.get(\n                f'{self.base_url}/repos/{owner}/{repo}/git/trees/{branch}?recursive=1',\n                headers=headers\n            )\n            \n            if response.status_code == 200:\n                tree_data = response.json()\n                \n                # Process tree data\n                files = []\n                directories = []\n                \n                for item in tree_data.get('tree', []):"}, {"id": "app.py_14", "file": "app.py", "content": "for item in tree_data.get('tree', []):\n                    if item['type'] == 'blob':  # File\n                        files.append({\n                            'path': item['path'],\n                            'sha': item['sha'],\n                            'size': item.get('size', 0),\n                            'url': item.get('url')\n                        })\n                    elif item['type'] == 'tree':  # Directory\n                        directories.append({\n                            'path': item['path'],\n                            'sha': item['sha']\n                        })\n                \n                return {\n                    'success': True,\n                    'tree': {\n                        'files': files,"}, {"id": "app.py_15", "file": "app.py", "content": "'tree': {\n                        'files': files,\n                        'directories': directories,\n                        'total_files': len(files),\n                        'total_directories': len(directories),\n                        'sha': tree_data.get('sha'),\n                        'truncated': tree_data.get('truncated', False)\n                    }\n                }\n            else:\n                return {\n                    'success': False,\n                    'error': f'Failed to get repository tree: {response.status_code}'\n                }\n                \n        except requests.RequestException as e:\n            logger.error(f\"Repository tree error: {str(e)}\")\n            return {\n                'success': False,"}, {"id": "app.py_16", "file": "app.py", "content": "return {\n                'success': False,\n                'error': 'Failed to fetch repository tree'\n            }\n    \n    def get_file_content(self, owner, repo, file_path, token=None, branch=None):\n        \"\"\"Get content of a specific file from repository\"\"\"\n        try:\n            headers = {\n                'Accept': 'application/vnd.github.v3+json',\n                'User-Agent': 'AI-Project-Analyzer/1.0'\n            }\n            \n            if token:\n                headers['Authorization'] = f'token {token}'\n            \n            # Build URL with branch if specified\n            url = f'{self.base_url}/repos/{owner}/{repo}/contents/{file_path}'\n            if branch:\n                url += f'?ref={branch}'"}, {"id": "app.py_17", "file": "app.py", "content": "if branch:\n                url += f'?ref={branch}'\n            \n            response = requests.get(url, headers=headers)\n            \n            if response.status_code == 200:\n                file_data = response.json()\n                \n                # Handle file vs directory\n                if isinstance(file_data, list):\n                    return {\n                        'success': False,\n                        'error': 'Path is a directory, not a file'\n                    }\n                \n                return {\n                    'success': True,\n                    'file': {\n                        'name': file_data.get('name'),\n                        'path': file_data.get('path'),\n                        'sha': file_data.get('sha'),"}, {"id": "app.py_18", "file": "app.py", "content": "'sha': file_data.get('sha'),\n                        'size': file_data.get('size'),\n                        'content': file_data.get('content'),  # Base64 encoded\n                        'encoding': file_data.get('encoding'),\n                        'download_url': file_data.get('download_url'),\n                        'html_url': file_data.get('html_url')\n                    }\n                }\n            elif response.status_code == 404:\n                return {\n                    'success': False,\n                    'error': 'File not found'\n                }\n            else:\n                return {\n                    'success': False,\n                    'error': f'Failed to get file content: {response.status_code}'\n                }"}, {"id": "app.py_19", "file": "app.py", "content": "}\n                \n        except requests.RequestException as e:\n            logger.error(f\"File content error: {str(e)}\")\n            return {\n                'success': False,\n                'error': 'Failed to fetch file content'\n            }\n    \n    def deep_analyze_repository(self, owner, repo, token=None, max_file_size=1024*1024):\n        \"\"\"\n        Perform deep analysis of repository - fetch all files with content\n        Returns complete repository structure with file contents\n        \"\"\"\n        import time\n        start_time = time.time()\n        \n        try:\n            # First get repository info and tree\n            repo_info = self.validate_repository_access(owner, repo, token)\n            if not repo_info['accessible']:\n                return repo_info"}, {"id": "app.py_20", "file": "app.py", "content": "if not repo_info['accessible']:\n                return repo_info\n            \n            tree_result = self.get_repository_tree(owner, repo, token)\n            if not tree_result['success']:\n                return tree_result\n            \n            # Initialize result structure\n            deep_analysis = {\n                'repository_info': repo_info['repo_info'],\n                'structure': {\n                    'total_files': tree_result['tree']['total_files'],\n                    'total_directories': tree_result['tree']['total_directories'],\n                    'directories': tree_result['tree']['directories'],\n                    'files_with_content': [],\n                    'skipped_files': [],\n                    'processing_stats': {"}, {"id": "app.py_21", "file": "app.py", "content": "'skipped_files': [],\n                    'processing_stats': {\n                        'processed': 0,\n                        'skipped_large': 0,\n                        'skipped_binary': 0,\n                        'errors': 0,\n                        'start_time': datetime.utcnow().isoformat(),\n                        'files_per_second': 0\n                    }\n                }\n            }\n            \n            # Define file extensions to skip (binary files)\n            binary_extensions = {\n                '.png', '.jpg', '.jpeg', '.gif', '.bmp', '.ico', '.svg',\n                '.pdf', '.zip', '.tar', '.gz', '.rar', '.7z',\n                '.exe', '.dll', '.so', '.dylib',\n                '.mp4', '.avi', '.mov', '.wmv', '.flv',"}, {"id": "app.py_22", "file": "app.py", "content": "'.mp4', '.avi', '.mov', '.wmv', '.flv',\n                '.mp3', '.wav', '.ogg', '.flac',\n                '.woff', '.woff2', '.ttf', '.eot',\n                '.bin', '.dat', '.db', '.sqlite'\n            }\n            \n            # Process each file\n            for file_info in tree_result['tree']['files']:\n                file_path = file_info['path']\n                file_size = file_info.get('size', 0)\n                \n                # Skip large files\n                if file_size > max_file_size:\n                    deep_analysis['structure']['skipped_files'].append({\n                        'path': file_path,\n                        'reason': 'file_too_large',\n                        'size': file_size,\n                        'max_size': max_file_size"}, {"id": "app.py_23", "file": "app.py", "content": "'size': file_size,\n                        'max_size': max_file_size\n                    })\n                    deep_analysis['structure']['processing_stats']['skipped_large'] += 1\n                    continue\n                \n                # Skip binary files based on extension\n                file_ext = '.' + file_path.split('.')[-1].lower() if '.' in file_path else ''\n                if file_ext in binary_extensions:\n                    deep_analysis['structure']['skipped_files'].append({\n                        'path': file_path,\n                        'reason': 'binary_file',\n                        'extension': file_ext\n                    })\n                    deep_analysis['structure']['processing_stats']['skipped_binary'] += 1"}, {"id": "app.py_24", "file": "app.py", "content": "deep_analysis['structure']['processing_stats']['skipped_binary'] += 1\n                    continue\n                \n                # Fetch file content\n                try:\n                    file_result = self.get_file_content(owner, repo, file_path, token)\n                    \n                    if file_result['success']:\n                        file_data = file_result['file']\n                        \n                        # Decode content if it's base64 encoded\n                        content = file_data.get('content', '')\n                        if content and file_data.get('encoding') == 'base64':\n                            try:\n                                import base64"}, {"id": "app.py_25", "file": "app.py", "content": "try:\n                                import base64\n                                decoded_content = base64.b64decode(content).decode('utf-8')\n                                content = decoded_content\n                            except (UnicodeDecodeError, Exception):\n                                # If decoding fails, treat as binary\n                                deep_analysis['structure']['skipped_files'].append({\n                                    'path': file_path,\n                                    'reason': 'decode_error',\n                                    'size': file_size\n                                })\n                                deep_analysis['structure']['processing_stats']['skipped_binary'] += 1\n                                continue"}, {"id": "app.py_26", "file": "app.py", "content": "continue\n                        \n                        # Add file with content to results\n                        deep_analysis['structure']['files_with_content'].append({\n                            'path': file_path,\n                            'name': file_data['name'],\n                            'size': file_data['size'],\n                            'sha': file_data['sha'],\n                            'content': content,\n                            'download_url': file_data.get('download_url'),\n                            'html_url': file_data.get('html_url'),\n                            'lines': len(content.split('\\n')) if content else 0,\n                            'extension': file_ext\n                        })"}, {"id": "app.py_27", "file": "app.py", "content": "})\n                        \n                        deep_analysis['structure']['processing_stats']['processed'] += 1\n                        \n                    else:\n                        deep_analysis['structure']['skipped_files'].append({\n                            'path': file_path,\n                            'reason': 'fetch_error',\n                            'error': file_result.get('error')\n                        })\n                        deep_analysis['structure']['processing_stats']['errors'] += 1\n                        \n                except Exception as e:\n                    logger.error(f\"Error processing file {file_path}: {str(e)}\")\n                    deep_analysis['structure']['skipped_files'].append({"}, {"id": "app.py_28", "file": "app.py", "content": "deep_analysis['structure']['skipped_files'].append({\n                        'path': file_path,\n                        'reason': 'processing_error',\n                        'error': str(e)\n                    })\n                    deep_analysis['structure']['processing_stats']['errors'] += 1\n            \n            end_time = time.time()\n            processing_time = end_time - start_time\n            \n            # Update processing stats with timing info\n            total_files_processed = deep_analysis['structure']['processing_stats']['processed']\n            files_per_second = total_files_processed / processing_time if processing_time > 0 else 0\n            deep_analysis['structure']['processing_stats']['files_per_second'] = round(files_per_second, 2)"}, {"id": "app.py_29", "file": "app.py", "content": "deep_analysis['structure']['processing_stats']['end_time'] = datetime.utcnow().isoformat()\n            deep_analysis['structure']['processing_stats']['total_processing_time_seconds'] = round(processing_time, 2)\n            \n            return {\n                'success': True,\n                'deep_analysis': deep_analysis,\n                'analyzed_at': datetime.utcnow().isoformat(),\n                'processing_time': {\n                    'seconds': round(processing_time, 2),\n                    'minutes': round(processing_time / 60, 2),\n                    'formatted': f\"{int(processing_time // 60)}m {int(processing_time % 60)}s\"\n                }\n            }\n            \n        except Exception as e:\n            logger.error(f\"Deep analysis error: {str(e)}\")"}, {"id": "app.py_30", "file": "app.py", "content": "except Exception as e:\n            logger.error(f\"Deep analysis error: {str(e)}\")\n            return {\n                'success': False,\n                'error': f'Deep analysis failed: {str(e)}'\n            }\n    \n    def clone_repository(self, owner, repo, token=None, target_dir=\"./my_repos\"):\n        \"\"\"\n        Clone a GitHub repository to local directory\n        Returns path to cloned repository and metadata\n        \"\"\"\n        try:\n            # Create target directory if it doesn't exist\n            repos_dir = Path(target_dir)\n            repos_dir.mkdir(exist_ok=True)\n            \n            # Create owner directory\n            owner_dir = repos_dir / owner\n            owner_dir.mkdir(exist_ok=True)\n            \n            # Repository path"}, {"id": "app.py_31", "file": "app.py", "content": "owner_dir.mkdir(exist_ok=True)\n            \n            # Repository path\n            repo_path = owner_dir / repo\n            \n            # If repository already exists, remove it for fresh clone\n            if repo_path.exists():\n                logger.info(f\"Removing existing repository at {repo_path}\")\n                shutil.rmtree(repo_path)\n            \n            # Build clone URL\n            if token:\n                # Use token for authentication (works for both public and private repos)\n                clone_url = f\"https://{token}@github.com/{owner}/{repo}.git\"\n            else:\n                # Public repository clone\n                clone_url = f\"https://github.com/{owner}/{repo}.git\"\n            \n            logger.info(f\"Cloning repository: {owner}/{repo}\")"}, {"id": "app.py_32", "file": "app.py", "content": "logger.info(f\"Cloning repository: {owner}/{repo}\")\n            \n            # Clone the repository\n            result = subprocess.run([\n                'git', 'clone', \n                '--depth', '1',  # Shallow clone for faster operation\n                clone_url, \n                str(repo_path)\n            ], capture_output=True, text=True, timeout=300)  # 5 minute timeout\n            \n            if result.returncode == 0:\n                # Get repository statistics\n                stats = self._get_local_repo_stats(repo_path)\n                \n                return {\n                    'success': True,\n                    'clone_path': str(repo_path),\n                    'clone_url': clone_url.replace(token, '***') if token else clone_url,"}, {"id": "app.py_33", "file": "app.py", "content": "'clone_url': clone_url.replace(token, '***') if token else clone_url,\n                    'stats': stats,\n                    'cloned_at': datetime.utcnow().isoformat()\n                }\n            else:\n                error_msg = result.stderr.strip() if result.stderr else \"Unknown git error\"\n                # Don't expose token in error messages\n                if token:\n                    error_msg = error_msg.replace(token, '***')\n                \n                return {\n                    'success': False,\n                    'error': f'Git clone failed: {error_msg}'\n                }\n                \n        except subprocess.TimeoutExpired:\n            return {\n                'success': False,"}, {"id": "app.py_34", "file": "app.py", "content": "except subprocess.TimeoutExpired:\n            return {\n                'success': False,\n                'error': 'Repository clone timed out (5 minutes)'\n            }\n        except FileNotFoundError:\n            return {\n                'success': False,\n                'error': 'Git is not installed or not in PATH'\n            }\n        except Exception as e:\n            logger.error(f\"Clone error: {str(e)}\")\n            return {\n                'success': False,\n                'error': f'Clone failed: {str(e)}'\n            }\n    \n    def _get_local_repo_stats(self, repo_path):\n        \"\"\"Get statistics from locally cloned repository\"\"\"\n        try:\n            stats = {\n                'total_files': 0,\n                'total_directories': 0,"}, {"id": "app.py_35", "file": "app.py", "content": "stats = {\n                'total_files': 0,\n                'total_directories': 0,\n                'file_types': {},\n                'size_bytes': 0,\n                'languages': {}\n            }\n            \n            # Walk through all files\n            for root, dirs, files in os.walk(repo_path):\n                # Skip .git directory\n                if '.git' in dirs:\n                    dirs.remove('.git')\n                \n                stats['total_directories'] += len(dirs)\n                \n                for file in files:\n                    file_path = Path(root) / file\n                    \n                    # Count files\n                    stats['total_files'] += 1\n                    \n                    # Get file size\n                    try:"}, {"id": "app.py_36", "file": "app.py", "content": "# Get file size\n                    try:\n                        stats['size_bytes'] += file_path.stat().st_size\n                    except:\n                        pass\n                    \n                    # Count file extensions\n                    ext = file_path.suffix.lower()\n                    if ext:\n                        stats['file_types'][ext] = stats['file_types'].get(ext, 0) + 1\n                    \n                    # Detect languages by extension\n                    language = self._detect_language_by_extension(ext)\n                    if language:\n                        stats['languages'][language] = stats['languages'].get(language, 0) + 1\n            \n            return stats\n            \n        except Exception as e:"}, {"id": "app.py_37", "file": "app.py", "content": "return stats\n            \n        except Exception as e:\n            logger.error(f\"Stats error: {str(e)}\")\n            return {'error': str(e)}\n    \n    def _detect_language_by_extension(self, ext):\n        \"\"\"Detect programming language by file extension\"\"\"\n        language_map = {\n            '.js': 'JavaScript',\n            '.jsx': 'JavaScript',\n            '.ts': 'TypeScript',\n            '.tsx': 'TypeScript',\n            '.py': 'Python',\n            '.java': 'Java',\n            '.kt': 'Kotlin',\n            '.cs': 'C#',\n            '.go': 'Go',\n            '.rs': 'Rust',\n            '.cpp': 'C++',\n            '.cc': 'C++',\n            '.cxx': 'C++',\n            '.c': 'C',\n            '.h': 'C/C++',\n            '.hpp': 'C++',\n            '.swift': 'Swift',"}, {"id": "app.py_38", "file": "app.py", "content": "'.h': 'C/C++',\n            '.hpp': 'C++',\n            '.swift': 'Swift',\n            '.php': 'PHP',\n            '.rb': 'Ruby',\n            '.scala': 'Scala',\n            '.sh': 'Shell',\n            '.bash': 'Shell',\n            '.ps1': 'PowerShell',\n            '.html': 'HTML',\n            '.css': 'CSS',\n            '.scss': 'SCSS',\n            '.sass': 'Sass',\n            '.less': 'Less',\n            '.vue': 'Vue',\n            '.svelte': 'Svelte',\n            '.sql': 'SQL',\n            '.json': 'JSON',\n            '.xml': 'XML',\n            '.yaml': 'YAML',\n            '.yml': 'YAML',\n            '.toml': 'TOML',\n            '.md': 'Markdown',\n            '.dockerfile': 'Docker',\n            '.r': 'R',\n            '.m': 'Objective-C',\n            '.mm': 'Objective-C++',"}, {"id": "app.py_39", "file": "app.py", "content": "'.r': 'R',\n            '.m': 'Objective-C',\n            '.mm': 'Objective-C++',\n            '.dart': 'Dart',\n            '.lua': 'Lua',\n            '.pl': 'Perl',\n            '.clj': 'Clojure',\n            '.ex': 'Elixir',\n            '.exs': 'Elixir',\n            '.erl': 'Erlang',\n            '.hrl': 'Erlang',\n            '.fs': 'F#',\n            '.fsx': 'F#',\n            '.ml': 'OCaml',\n            '.mli': 'OCaml',\n            '.hs': 'Haskell',\n            '.elm': 'Elm',\n            '.jl': 'Julia',\n            '.nim': 'Nim',\n            '.zig': 'Zig'\n        }\n        return language_map.get(ext)\n    \n    def analyze_local_repository(self, repo_path, max_file_size=1024*1024):\n        \"\"\"\n        Analyze locally cloned repository - much faster than API approach\n        \"\"\""}, {"id": "app.py_40", "file": "app.py", "content": "\"\"\"\n        Analyze locally cloned repository - much faster than API approach\n        \"\"\"\n        try:\n            repo_path = Path(repo_path)\n            if not repo_path.exists():\n                return {\n                    'success': False,\n                    'error': 'Repository path does not exist'\n                }\n            \n            # Get repository stats\n            stats = self._get_local_repo_stats(repo_path)\n            \n            # Initialize analysis result\n            analysis = {\n                'repository_path': str(repo_path),\n                'stats': stats,\n                'files_with_content': [],\n                'skipped_files': [],\n                'processing_stats': {\n                    'processed': 0,\n                    'skipped_large': 0,"}, {"id": "app.py_41", "file": "app.py", "content": "'processed': 0,\n                    'skipped_large': 0,\n                    'skipped_binary': 0,\n                    'errors': 0\n                }\n            }\n            \n            # Binary file extensions to skip\n            binary_extensions = {\n                '.png', '.jpg', '.jpeg', '.gif', '.bmp', '.ico', '.svg',\n                '.pdf', '.zip', '.tar', '.gz', '.rar', '.7z',\n                '.exe', '.dll', '.so', '.dylib',\n                '.mp4', '.avi', '.mov', '.wmv', '.flv',\n                '.mp3', '.wav', '.ogg', '.flac',\n                '.woff', '.woff2', '.ttf', '.eot',\n                '.bin', '.dat', '.db', '.sqlite',\n                '.node', '.pyc', '.class', '.jar'\n            }\n            \n            # Process all files"}, {"id": "app.py_42", "file": "app.py", "content": "}\n            \n            # Process all files\n            for root, dirs, files in os.walk(repo_path):\n                # Skip .git directory\n                if '.git' in dirs:\n                    dirs.remove('.git')\n                \n                # Skip node_modules and other common build directories\n                skip_dirs = {'.git', 'node_modules', '__pycache__', '.venv', 'venv', \n                           'build', 'dist', 'target', '.gradle', '.idea', '.vscode'}\n                dirs[:] = [d for d in dirs if d not in skip_dirs]\n                \n                for file in files:\n                    file_path = Path(root) / file\n                    relative_path = file_path.relative_to(repo_path)\n                    \n                    try:"}, {"id": "app.py_43", "file": "app.py", "content": "try:\n                        # Get file size\n                        file_size = file_path.stat().st_size\n                        \n                        # Skip large files\n                        if file_size > max_file_size:\n                            analysis['skipped_files'].append({\n                                'path': str(relative_path),\n                                'reason': 'file_too_large',\n                                'size': file_size\n                            })\n                            analysis['processing_stats']['skipped_large'] += 1\n                            continue\n                        \n                        # Skip binary files\n                        file_ext = file_path.suffix.lower()"}, {"id": "app.py_44", "file": "app.py", "content": "file_ext = file_path.suffix.lower()\n                        if file_ext in binary_extensions:\n                            analysis['skipped_files'].append({\n                                'path': str(relative_path),\n                                'reason': 'binary_file',\n                                'extension': file_ext\n                            })\n                            analysis['processing_stats']['skipped_binary'] += 1\n                            continue\n                        \n                        # Read file content\n                        try:\n                            with open(file_path, 'r', encoding='utf-8') as f:\n                                content = f.read()"}, {"id": "app.py_45", "file": "app.py", "content": "content = f.read()\n                            \n                            # Add to analysis\n                            analysis['files_with_content'].append({\n                                'path': str(relative_path),\n                                'name': file_path.name,\n                                'size': file_size,\n                                'content': content,\n                                'lines': len(content.split('\\n')),\n                                'extension': file_ext,\n                                'language': self._detect_language_by_extension(file_ext)\n                            })\n                            \n                            analysis['processing_stats']['processed'] += 1"}, {"id": "app.py_46", "file": "app.py", "content": "except UnicodeDecodeError:\n                            # File is likely binary\n                            analysis['skipped_files'].append({\n                                'path': str(relative_path),\n                                'reason': 'encoding_error',\n                                'size': file_size\n                            })\n                            analysis['processing_stats']['skipped_binary'] += 1\n                            \n                    except Exception as e:\n                        analysis['skipped_files'].append({\n                            'path': str(relative_path),\n                            'reason': 'processing_error',\n                            'error': str(e)\n                        })"}, {"id": "app.py_47", "file": "app.py", "content": "'error': str(e)\n                        })\n                        analysis['processing_stats']['errors'] += 1\n            \n            return {\n                'success': True,\n                'analysis': analysis,\n                'analyzed_at': datetime.utcnow().isoformat()\n            }\n            \n        except Exception as e:\n            logger.error(f\"Local analysis error: {str(e)}\")\n            return {\n                'success': False,\n                'error': f'Local analysis failed: {str(e)}'\n            }\n\n# Initialize services\ngithub_service = GitHubService()\n\n@app.route('/auth/github/login', methods=['POST'])"}, {"id": "app.py_48", "file": "app.py", "content": "def github_login():\n    \"\"\"Initiate GitHub OAuth login or validate personal access token\"\"\"\n    try:\n        # Better JSON parsing with error handling\n        if not request.is_json:\n            return jsonify({'error': 'Content-Type must be application/json'}), 415\n        \n        try:\n            data = request.get_json(force=True)\n        except Exception as json_error:\n            logger.error(f\"JSON parsing error: {str(json_error)}\")\n            return jsonify({'error': 'Invalid JSON format'}), 400\n        \n        if not data:\n            return jsonify({'error': 'Request body required'}), 400\n        \n        # Handle personal access token authentication\n        if 'token' in data:\n            token = data['token'].strip()\n            \n            if not token:"}, {"id": "app.py_49", "file": "app.py", "content": "token = data['token'].strip()\n            \n            if not token:\n                return jsonify({'error': 'Token cannot be empty'}), 400\n            \n            # Validate the token\n            validation_result = github_service.validate_token(token)\n            \n            if validation_result['valid']:\n                # Store token in session (in-memory only)\n                session['github_token'] = token\n                session['github_user'] = validation_result['user']\n                session['login_time'] = datetime.utcnow().isoformat()\n                \n                return jsonify({\n                    'success': True,\n                    'user': validation_result['user'],\n                    'scopes': validation_result['scopes'],"}, {"id": "app.py_50", "file": "app.py", "content": "'scopes': validation_result['scopes'],\n                    'auth_method': 'token'\n                })\n            else:\n                return jsonify({\n                    'success': False,\n                    'error': validation_result['error']\n                }), 401\n        \n        # Handle OAuth flow initiation\n        elif 'oauth' in data and data['oauth']:\n            try:\n                state = data.get('state', 'default')\n                oauth_url = github_service.get_oauth_url(state)\n                \n                return jsonify({\n                    'success': True,\n                    'oauth_url': oauth_url,\n                    'auth_method': 'oauth'\n                })\n            except ValueError as e:\n                return jsonify({"}, {"id": "app.py_51", "file": "app.py", "content": "})\n            except ValueError as e:\n                return jsonify({\n                    'success': False,\n                    'error': str(e)\n                }), 500\n        \n        else:\n            return jsonify({\n                'error': 'Either \"token\" or \"oauth\": true must be provided'\n            }), 400\n            \n    except Exception as e:\n        logger.error(f\"Login error: {str(e)}\")\n        return jsonify({'error': 'Internal server error'}), 500\n\n@app.route('/auth/github/callback', methods=['GET'])"}, {"id": "app.py_52", "file": "app.py", "content": "def github_callback():\n    \"\"\"Handle GitHub OAuth callback\"\"\"\n    try:\n        code = request.args.get('code')\n        state = request.args.get('state')\n        error = request.args.get('error')\n        \n        if error:\n            return jsonify({\n                'success': False,\n                'error': f'GitHub OAuth error: {error}'\n            }), 400\n        \n        if not code:\n            return jsonify({\n                'success': False,\n                'error': 'Authorization code not provided'\n            }), 400\n        \n        # Exchange code for token\n        token_result = github_service.exchange_code_for_token(code, state)\n        \n        if token_result['success']:\n            # Validate the received token"}, {"id": "app.py_53", "file": "app.py", "content": "if token_result['success']:\n            # Validate the received token\n            validation_result = github_service.validate_token(token_result['access_token'])\n            \n            if validation_result['valid']:\n                # Store token in session\n                session['github_token'] = token_result['access_token']\n                session['github_user'] = validation_result['user']\n                session['login_time'] = datetime.utcnow().isoformat()\n                \n                return jsonify({\n                    'success': True,\n                    'user': validation_result['user'],\n                    'scopes': validation_result['scopes'],\n                    'auth_method': 'oauth'\n                })\n            else:\n                return jsonify({"}, {"id": "app.py_54", "file": "app.py", "content": "})\n            else:\n                return jsonify({\n                    'success': False,\n                    'error': 'Failed to validate received token'\n                }), 401\n        else:\n            return jsonify({\n                'success': False,\n                'error': token_result['error']\n            }), 400\n            \n    except Exception as e:\n        logger.error(f\"OAuth callback error: {str(e)}\")\n        return jsonify({'error': 'Internal server error'}), 500\n\n@app.route('/auth/status', methods=['GET'])"}, {"id": "app.py_55", "file": "app.py", "content": "def auth_status():\n    \"\"\"Check current authentication status\"\"\"\n    try:\n        if 'github_token' in session and 'github_user' in session:\n            return jsonify({\n                'authenticated': True,\n                'user': session['github_user'],\n                'login_time': session.get('login_time')\n            })\n        else:\n            return jsonify({\n                'authenticated': False\n            })\n    except Exception as e:\n        logger.error(f\"Auth status error: {str(e)}\")\n        return jsonify({'error': 'Internal server error'}), 500\n\n@app.route('/auth/logout', methods=['POST'])"}, {"id": "app.py_56", "file": "app.py", "content": "def logout():\n    \"\"\"Clear authentication session\"\"\"\n    try:\n        # Clear all authentication data from session\n        session.pop('github_token', None)\n        session.pop('github_user', None)\n        session.pop('login_time', None)\n        \n        return jsonify({\n            'success': True,\n            'message': 'Successfully logged out'\n        })\n    except Exception as e:\n        logger.error(f\"Logout error: {str(e)}\")\n        return jsonify({'error': 'Internal server error'}), 500\n\n# Repository endpoints\n@app.route('/api/repositories/validate', methods=['POST'])"}, {"id": "app.py_57", "file": "app.py", "content": "def validate_repository():\n    \"\"\"Validate repository URL and check access\"\"\"\n    try:\n        # Better JSON parsing with error handling\n        if not request.is_json:\n            return jsonify({'error': 'Content-Type must be application/json'}), 415\n        \n        try:\n            data = request.get_json(force=True)\n        except Exception as json_error:\n            logger.error(f\"JSON parsing error: {str(json_error)}\")\n            return jsonify({'error': 'Invalid JSON format'}), 400\n        \n        if not data or 'url' not in data:\n            return jsonify({'error': 'Repository URL is required'}), 400\n        \n        repo_url = data['url'].strip()\n        if not repo_url:\n            return jsonify({'error': 'Repository URL cannot be empty'}), 400"}, {"id": "app.py_58", "file": "app.py", "content": "return jsonify({'error': 'Repository URL cannot be empty'}), 400\n        \n        # Parse GitHub URL\n        parsed = github_service.parse_github_url(repo_url)\n        if not parsed:\n            return jsonify({\n                'error': 'Invalid GitHub repository URL format'\n            }), 400\n        \n        owner, repo = parsed['owner'], parsed['repo']\n        \n        # Get token from session if available\n        token = session.get('github_token')\n        \n        # Validate repository access\n        validation_result = github_service.validate_repository_access(owner, repo, token)\n        \n        if validation_result['accessible']:\n            return jsonify({\n                'success': True,\n                'repository': validation_result['repo_info'],"}, {"id": "app.py_59", "file": "app.py", "content": "'success': True,\n                'repository': validation_result['repo_info'],\n                'parsed': {'owner': owner, 'repo': repo}\n            })\n        else:\n            return jsonify({\n                'success': False,\n                'error': validation_result['error']\n            }), 404\n            \n    except Exception as e:\n        logger.error(f\"Repository validation error: {str(e)}\")\n        return jsonify({'error': 'Internal server error'}), 500\n\n@app.route('/api/repositories/<owner>/<repo>/tree', methods=['GET'])"}, {"id": "app.py_60", "file": "app.py", "content": "def get_repository_tree(owner, repo):\n    \"\"\"Get repository file tree structure\"\"\"\n    try:\n        # Get optional branch parameter\n        branch = request.args.get('branch')\n        \n        # Get token from session if available\n        token = session.get('github_token')\n        \n        # Get repository tree\n        tree_result = github_service.get_repository_tree(owner, repo, token, branch)\n        \n        if tree_result.get('success'):\n            return jsonify(tree_result)\n        else:\n            return jsonify({\n                'error': tree_result.get('error', 'Failed to get repository tree')\n            }), 400\n            \n    except Exception as e:\n        logger.error(f\"Repository tree error: {str(e)}\")\n        return jsonify({'error': 'Internal server error'}), 500"}, {"id": "app.py_61", "file": "app.py", "content": "return jsonify({'error': 'Internal server error'}), 500\n\n@app.route('/api/repositories/<owner>/<repo>/files/<path:file_path>', methods=['GET'])"}, {"id": "app.py_62", "file": "app.py", "content": "def get_file_content(owner, repo, file_path):\n    \"\"\"Get content of a specific file from repository\"\"\"\n    try:\n        # Get optional branch parameter\n        branch = request.args.get('branch')\n        \n        # Get token from session if available\n        token = session.get('github_token')\n        \n        # Get file content\n        file_result = github_service.get_file_content(owner, repo, file_path, token, branch)\n        \n        if file_result.get('success'):\n            return jsonify(file_result)\n        else:\n            return jsonify({\n                'error': file_result.get('error', 'Failed to get file content')\n            }), 404\n            \n    except Exception as e:\n        logger.error(f\"File content error: {str(e)}\")"}, {"id": "app.py_63", "file": "app.py", "content": "except Exception as e:\n        logger.error(f\"File content error: {str(e)}\")\n        return jsonify({'error': 'Internal server error'}), 500\n\n@app.route('/api/repositories/analyze', methods=['POST'])"}, {"id": "app.py_64", "file": "app.py", "content": "def analyze_repository():\n    \"\"\"Start repository analysis process\"\"\"\n    try:\n        # Better JSON parsing with error handling\n        if not request.is_json:\n            return jsonify({'error': 'Content-Type must be application/json'}), 415\n        \n        try:\n            data = request.get_json(force=True)\n        except Exception as json_error:\n            logger.error(f\"JSON parsing error: {str(json_error)}\")\n            return jsonify({'error': 'Invalid JSON format'}), 400\n        \n        if not data or 'url' not in data:\n            return jsonify({'error': 'Repository URL is required'}), 400\n        \n        repo_url = data['url'].strip()\n        \n        # Parse GitHub URL\n        parsed = github_service.parse_github_url(repo_url)\n        if not parsed:"}, {"id": "app.py_65", "file": "app.py", "content": "parsed = github_service.parse_github_url(repo_url)\n        if not parsed:\n            return jsonify({\n                'error': 'Invalid GitHub repository URL format'\n            }), 400\n        \n        owner, repo = parsed['owner'], parsed['repo']\n        \n        # Get token from session if available\n        token = session.get('github_token')\n        \n        # First validate repository access\n        validation_result = github_service.validate_repository_access(owner, repo, token)\n        \n        if not validation_result['accessible']:\n            return jsonify({\n                'success': False,\n                'error': validation_result['error']\n            }), 404\n        \n        # Get repository structure"}, {"id": "app.py_66", "file": "app.py", "content": "}), 404\n        \n        # Get repository structure\n        tree_result = github_service.get_repository_tree(owner, repo, token)\n        \n        if not tree_result.get('success'):\n            return jsonify({\n                'success': False,\n                'error': tree_result.get('error', 'Failed to analyze repository structure')\n            }), 400\n        \n        # Return analysis results\n        return jsonify({\n            'success': True,\n            'analysis': {\n                'repository': validation_result['repo_info'],\n                'structure': tree_result['tree'],\n                'parsed': {'owner': owner, 'repo': repo},\n                'analyzed_at': datetime.utcnow().isoformat()\n            }\n        })\n        \n    except Exception as e:"}, {"id": "app.py_67", "file": "app.py", "content": "}\n        })\n        \n    except Exception as e:\n        logger.error(f\"Repository analysis error: {str(e)}\")\n        return jsonify({'error': 'Internal server error'}), 500\n\n@app.route('/api/repositories/deep-analyze', methods=['POST'])"}, {"id": "app.py_68", "file": "app.py", "content": "def deep_analyze_repository():\n    \"\"\"Perform deep analysis of repository - fetch all files with their content\"\"\"\n    try:\n        # Better JSON parsing with error handling\n        if not request.is_json:\n            return jsonify({'error': 'Content-Type must be application/json'}), 415\n        \n        try:\n            data = request.get_json(force=True)\n        except Exception as json_error:\n            logger.error(f\"JSON parsing error: {str(json_error)}\")\n            return jsonify({'error': 'Invalid JSON format'}), 400\n        \n        if not data or 'url' not in data:\n            return jsonify({'error': 'Repository URL is required'}), 400\n        \n        repo_url = data['url'].strip()\n        max_file_size = data.get('max_file_size', 1024*1024)  # Default 1MB limit"}, {"id": "app.py_69", "file": "app.py", "content": "max_file_size = data.get('max_file_size', 1024*1024)  # Default 1MB limit\n        \n        # Parse GitHub URL\n        parsed = github_service.parse_github_url(repo_url)\n        if not parsed:\n            return jsonify({\n                'error': 'Invalid GitHub repository URL format'\n            }), 400\n        \n        owner, repo = parsed['owner'], parsed['repo']\n        \n        # Get token from session if available\n        token = session.get('github_token')\n        \n        # Perform deep analysis\n        logger.info(f\"Starting deep analysis of {owner}/{repo}\")\n        analysis_result = github_service.deep_analyze_repository(owner, repo, token, max_file_size)\n        \n        if analysis_result.get('success'):"}, {"id": "app.py_70", "file": "app.py", "content": "if analysis_result.get('success'):\n            logger.info(f\"Deep analysis completed for {owner}/{repo}\")\n            return jsonify(analysis_result)\n        else:\n            return jsonify({\n                'success': False,\n                'error': analysis_result.get('error', 'Deep analysis failed')\n            }), 400\n            \n    except Exception as e:\n        logger.error(f\"Deep analysis endpoint error: {str(e)}\")\n        return jsonify({'error': 'Internal server error'}), 500\n\n@app.route('/api/repositories/<owner>/<repo>/explore', methods=['GET'])"}, {"id": "app.py_71", "file": "app.py", "content": "def explore_repository_structure(owner, repo):\n    \"\"\"Get detailed repository structure with file contents (alternative endpoint)\"\"\"\n    try:\n        # Get optional parameters\n        max_file_size = request.args.get('max_file_size', 1024*1024, type=int)\n        \n        # Get token from session if available\n        token = session.get('github_token')\n        \n        # Perform deep analysis\n        logger.info(f\"Exploring repository structure: {owner}/{repo}\")\n        analysis_result = github_service.deep_analyze_repository(owner, repo, token, max_file_size)\n        \n        if analysis_result.get('success'):\n            return jsonify(analysis_result)\n        else:\n            return jsonify({\n                'error': analysis_result.get('error', 'Repository exploration failed')"}, {"id": "app.py_72", "file": "app.py", "content": "'error': analysis_result.get('error', 'Repository exploration failed')\n            }), 400\n            \n    except Exception as e:\n        logger.error(f\"Repository exploration error: {str(e)}\")\n        return jsonify({'error': 'Internal server error'}), 500\n\n@app.route('/api/repositories/clone', methods=['POST'])"}, {"id": "app.py_73", "file": "app.py", "content": "def clone_repository():\n    \"\"\"Clone a GitHub repository to local storage\"\"\"\n    try:\n        # Better JSON parsing with error handling\n        if not request.is_json:\n            return jsonify({'error': 'Content-Type must be application/json'}), 415\n        \n        try:\n            data = request.get_json(force=True)\n        except Exception as json_error:\n            logger.error(f\"JSON parsing error: {str(json_error)}\")\n            return jsonify({'error': 'Invalid JSON format'}), 400\n        \n        if not data or 'url' not in data:\n            return jsonify({'error': 'Repository URL is required'}), 400\n        \n        repo_url = data['url'].strip()\n        target_dir = data.get('target_dir', './my_repos')\n        \n        # Parse GitHub URL"}, {"id": "app.py_74", "file": "app.py", "content": "target_dir = data.get('target_dir', './my_repos')\n        \n        # Parse GitHub URL\n        parsed = github_service.parse_github_url(repo_url)\n        if not parsed:\n            return jsonify({\n                'error': 'Invalid GitHub repository URL format'\n            }), 400\n        \n        owner, repo = parsed['owner'], parsed['repo']\n        \n        # Get token from session if available\n        token = session.get('github_token')\n        \n        # Clone repository\n        logger.info(f\"Cloning repository: {owner}/{repo}\")\n        clone_result = github_service.clone_repository(owner, repo, token, target_dir)\n        \n        if clone_result.get('success'):\n            logger.info(f\"Repository cloned successfully: {clone_result['clone_path']}\")"}, {"id": "app.py_75", "file": "app.py", "content": "logger.info(f\"Repository cloned successfully: {clone_result['clone_path']}\")\n            return jsonify(clone_result)\n        else:\n            return jsonify({\n                'success': False,\n                'error': clone_result.get('error', 'Clone failed')\n            }), 400\n            \n    except Exception as e:\n        logger.error(f\"Clone endpoint error: {str(e)}\")\n        return jsonify({'error': 'Internal server error'}), 500\n\n@app.route('/api/repositories/clone-and-analyze', methods=['POST'])"}, {"id": "app.py_76", "file": "app.py", "content": "def clone_and_analyze_repository():\n    \"\"\"Clone repository and perform local analysis - much faster than API approach\"\"\"\n    try:\n        # Better JSON parsing with error handling\n        if not request.is_json:\n            return jsonify({'error': 'Content-Type must be application/json'}), 415\n        \n        try:\n            data = request.get_json(force=True)\n        except Exception as json_error:\n            logger.error(f\"JSON parsing error: {str(json_error)}\")\n            return jsonify({'error': 'Invalid JSON format'}), 400\n        \n        if not data or 'url' not in data:\n            return jsonify({'error': 'Repository URL is required'}), 400\n        \n        repo_url = data['url'].strip()\n        target_dir = data.get('target_dir', './my_repos')"}, {"id": "app.py_77", "file": "app.py", "content": "repo_url = data['url'].strip()\n        target_dir = data.get('target_dir', './my_repos')\n        max_file_size = data.get('max_file_size', 1024*1024)  # Default 1MB\n        cleanup_after = data.get('cleanup_after', False)  # Whether to delete after analysis\n        \n        # Parse GitHub URL\n        parsed = github_service.parse_github_url(repo_url)\n        if not parsed:\n            return jsonify({\n                'error': 'Invalid GitHub repository URL format'\n            }), 400\n        \n        owner, repo = parsed['owner'], parsed['repo']\n        \n        # Get token from session if available\n        token = session.get('github_token')\n        \n        # Step 1: Clone repository\n        logger.info(f\"Cloning repository: {owner}/{repo}\")"}, {"id": "app.py_78", "file": "app.py", "content": "# Step 1: Clone repository\n        logger.info(f\"Cloning repository: {owner}/{repo}\")\n        clone_result = github_service.clone_repository(owner, repo, token, target_dir)\n        \n        if not clone_result.get('success'):\n            return jsonify({\n                'success': False,\n                'error': clone_result.get('error', 'Clone failed')\n            }), 400\n        \n        repo_path = clone_result['clone_path']\n        \n        try:\n            # Step 2: Analyze local repository\n            logger.info(f\"Analyzing local repository: {repo_path}\")\n            analysis_result = github_service.analyze_local_repository(repo_path, max_file_size)\n            \n            if analysis_result.get('success'):\n                # Combine clone and analysis results"}, {"id": "app.py_79", "file": "app.py", "content": "if analysis_result.get('success'):\n                # Combine clone and analysis results\n                combined_result = {\n                    'success': True,\n                    'clone_info': clone_result,\n                    'analysis': analysis_result['analysis'],\n                    'analyzed_at': analysis_result['analyzed_at']\n                }\n                \n                # Cleanup if requested\n                if cleanup_after:\n                    try:\n                        shutil.rmtree(repo_path)\n                        combined_result['cleanup'] = 'Repository deleted after analysis'\n                        logger.info(f\"Cleaned up repository: {repo_path}\")\n                    except Exception as cleanup_error:"}, {"id": "app.py_80", "file": "app.py", "content": "except Exception as cleanup_error:\n                        combined_result['cleanup_error'] = str(cleanup_error)\n                        logger.warning(f\"Failed to cleanup {repo_path}: {cleanup_error}\")\n                \n                logger.info(f\"Clone and analysis completed for {owner}/{repo}\")\n                return jsonify(combined_result)\n            else:\n                return jsonify({\n                    'success': False,\n                    'error': analysis_result.get('error', 'Analysis failed'),\n                    'clone_info': clone_result\n                }), 400\n                \n        except Exception as analysis_error:\n            logger.error(f\"Analysis error: {str(analysis_error)}\")\n            return jsonify({\n                'success': False,"}, {"id": "app.py_81", "file": "app.py", "content": "return jsonify({\n                'success': False,\n                'error': f'Analysis failed: {str(analysis_error)}',\n                'clone_info': clone_result\n            }), 500\n            \n    except Exception as e:\n        logger.error(f\"Clone and analyze endpoint error: {str(e)}\")\n        return jsonify({'error': 'Internal server error'}), 500\n\nif __name__ == '__main__':\n    app.run(debug=True, host='0.0.0.0', port=5000)"}, {"id": "debug_github.py_0", "file": "debug_github.py", "content": "================================================\n#!/usr/bin/env python3\n\"\"\"\nDebug script to check GitHub API status and rate limits\n\"\"\"\n\nimport requests\nimport json"}, {"id": "debug_github.py_1", "file": "debug_github.py", "content": "def check_github_api():\n    \"\"\"Check GitHub API status and rate limits\"\"\"\n    print(\"\ud83d\udd0d Debugging GitHub API access...\")\n    print(\"=\" * 50)\n    \n    # Check API rate limit status\n    print(\"1. Checking GitHub API rate limits...\")\n    try:\n        response = requests.get(\"https://api.github.com/rate_limit\")\n        print(f\"Status: {response.status_code}\")\n        \n        if response.status_code == 200:\n            rate_data = response.json()\n            core = rate_data['resources']['core']\n            print(f\"\u2705 Rate limit status:\")\n            print(f\"   Limit: {core['limit']}\")\n            print(f\"   Used: {core['used']}\")\n            print(f\"   Remaining: {core['remaining']}\")\n            print(f\"   Reset time: {core['reset']}\")\n            \n            if core['remaining'] == 0:"}, {"id": "debug_github.py_2", "file": "debug_github.py", "content": "if core['remaining'] == 0:\n                print(\"\u274c RATE LIMIT EXCEEDED! This is the issue.\")\n                import datetime\n                reset_time = datetime.datetime.fromtimestamp(core['reset'])\n                print(f\"   Rate limit resets at: {reset_time}\")\n            else:\n                print(\"\u2705 Rate limit OK\")\n        else:\n            print(f\"\u274c Failed to check rate limits: {response.status_code}\")\n    except Exception as e:\n        print(f\"\u274c Error checking rate limits: {e}\")\n    \n    print()\n    \n    # Test direct repository access\n    print(\"2. Testing direct repository access...\")\n    try:\n        repo_url = \"https://api.github.com/repos/Emon69420/HazMapApp\"\n        response = requests.get(repo_url)\n        print(f\"Status: {response.status_code}\")"}, {"id": "debug_github.py_3", "file": "debug_github.py", "content": "response = requests.get(repo_url)\n        print(f\"Status: {response.status_code}\")\n        \n        if response.status_code == 200:\n            repo_data = response.json()\n            print(f\"\u2705 Repository accessible:\")\n            print(f\"   Name: {repo_data['full_name']}\")\n            print(f\"   Private: {repo_data['private']}\")\n            print(f\"   Size: {repo_data['size']} KB\")\n        elif response.status_code == 403:\n            print(\"\u274c 403 Forbidden - Likely rate limited\")\n            print(\"Response headers:\")\n            for header, value in response.headers.items():\n                if 'rate' in header.lower() or 'limit' in header.lower():\n                    print(f\"   {header}: {value}\")\n        elif response.status_code == 404:"}, {"id": "debug_github.py_4", "file": "debug_github.py", "content": "print(f\"   {header}: {value}\")\n        elif response.status_code == 404:\n            print(\"\u274c 404 Not Found - Repository doesn't exist or is private\")\n        else:\n            print(f\"\u274c Unexpected status: {response.status_code}\")\n            print(f\"Response: {response.text[:200]}\")\n    except Exception as e:\n        print(f\"\u274c Error testing repository: {e}\")\n    \n    print()\n    \n    # Test with a known public repository\n    print(\"3. Testing with known public repository (octocat/Hello-World)...\")\n    try:\n        repo_url = \"https://api.github.com/repos/octocat/Hello-World\"\n        response = requests.get(repo_url)\n        print(f\"Status: {response.status_code}\")\n        \n        if response.status_code == 200:"}, {"id": "debug_github.py_5", "file": "debug_github.py", "content": "print(f\"Status: {response.status_code}\")\n        \n        if response.status_code == 200:\n            print(\"\u2705 Known public repo accessible - API is working\")\n        elif response.status_code == 403:\n            print(\"\u274c Even known public repo is forbidden - definitely rate limited\")\n        else:\n            print(f\"\u274c Unexpected status for known repo: {response.status_code}\")\n    except Exception as e:\n        print(f\"\u274c Error testing known repo: {e}\")"}, {"id": "debug_github.py_6", "file": "debug_github.py", "content": "def check_flask_server():\n    \"\"\"Check if Flask server is responding\"\"\"\n    print(\"\\n4. Testing Flask server...\")\n    try:\n        response = requests.get(\"http://localhost:5000/auth/status\")\n        print(f\"Flask server status: {response.status_code}\")\n        if response.status_code == 200:\n            print(\"\u2705 Flask server is running\")\n        else:\n            print(\"\u274c Flask server issue\")\n    except requests.exceptions.ConnectionError:\n        print(\"\u274c Flask server not running - start with: python app.py\")\n    except Exception as e:\n        print(f\"\u274c Flask server error: {e}\")\n\nif __name__ == \"__main__\":\n    check_github_api()\n    check_flask_server()\n    \n    print(\"\\n\ud83d\udca1 Solutions:\")\n    print(\"1. If rate limited: Wait for reset time or use GitHub token\")"}, {"id": "debug_github.py_7", "file": "debug_github.py", "content": "print(\"1. If rate limited: Wait for reset time or use GitHub token\")\n    print(\"2. If server not running: python app.py\")\n    print(\"3. If repo changed: Check repository URL and permissions\")"}, {"id": "package.json_0", "file": "package.json", "content": "================================================\n{\n  \"name\": \"workflow-automation\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Complete workflow automation platform with visual builder\",\n  \"main\": \"server.js\",\n  \"scripts\": {\n    \"start\": \"node server.js\",\n    \"dev\": \"nodemon server.js\",\n    \"build\": \"cd client && npm run build\",\n    \"install:all\": \"npm install && cd client && npm install\"\n  },\n  \"dependencies\": {\n    \"@huggingface/inference\": \"^4.7.1\",\n    \"@octokit/rest\": \"^22.0.0\",\n    \"cors\": \"^2.8.5\",\n    \"d3\": \"^7.9.0\",\n    \"dotenv\": \"^17.2.1\",\n    \"express\": \"^4.18.2\",\n    \"redis\": \"^5.8.2\"\n  },\n  \"devDependencies\": {\n    \"nodemon\": \"^3.0.1\"\n  }\n}"}, {"id": "rag_repo.py_0", "file": "rag_repo.py", "content": "================================================\nError reading file with 'cp1252': 'charmap' codec can't decode byte 0x8f in position 4865: character maps to <undefined>"}, {"id": "requirements.txt_0", "file": "requirements.txt", "content": "================================================\n# Streamlit Frontend Dependencies\nstreamlit>=1.28.0\nrequests>=2.31.0\npandas>=2.0.0\nnumpy>=1.24.0\n\n# Gitingest Integration\ngitingest>=0.1.0\n\n# Additional utilities\npython-dateutil>=2.8.2\nurllib3>=2.0.0\n\n# Development and testing (optional)\npytest>=7.4.0\npytest-mock>=3.11.0"}, {"id": "simple_gitingest_integration.py_0", "file": "simple_gitingest_integration.py", "content": "================================================\nError reading file with 'cp1252': 'charmap' codec can't decode byte 0x81 in position 7715: character maps to <undefined>"}, {"id": ".env.example_0", "file": ".env.example", "content": "================================================\n# Flask Configuration\nSECRET_KEY=your-secret-key-here\nFLASK_ENV=development\n\n# GitHub OAuth Configuration (optional - for OAuth flow)\nGITHUB_CLIENT_ID=your-github-client-id\nGITHUB_CLIENT_SECRET=your-github-client-secret\nGITHUB_REDIRECT_URI=http://localhost:5000/auth/github/callback\n\n# Redis Configuration (for caching)\nREDIS_URL=redis://localhost:6379/0\n\n# Gitingest Configuration\nGITINGEST_MAX_FILE_SIZE=10485760\nGITINGEST_TIMEOUT=300\nGITINGEST_TEMP_DIR=/tmp/gitingest\nGITINGEST_INCLUDE_PATTERNS=*.py,*.js,*.ts,*.jsx,*.tsx,*.md,*.json,*.yaml,*.yml,README*,LICENSE*,*.txt,*.html,*.css,*.scss\nGITINGEST_EXCLUDE_PATTERNS=node_modules,__pycache__,.git,*.pyc,*.log"}, {"id": "gitingest_outputs/Emon69420_HazMapApp_20250905_194000.txt_0", "file": "gitingest_outputs/Emon69420_HazMapApp_20250905_194000.txt", "content": "================================================\n[Binary file]"}, {"id": "gitingest_outputs/Emon69420_Navigit_20250906_111750.txt_0", "file": "gitingest_outputs/Emon69420_Navigit_20250906_111750.txt", "content": "================================================\nError reading file with 'cp1252': 'charmap' codec can't decode byte 0x8d in position 60842: character maps to <undefined>"}, {"id": "gitingest_outputs/github_gitignore_20250905_193039.txt_0", "file": "gitingest_outputs/github_gitignore_20250905_193039.txt", "content": "================================================\nDirectory structure:\n\u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac github-gitignore/\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac README.md\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Actionscript.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Ada.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac AdventureGameStudio.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Agda.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac AL.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Android.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Angular.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac AppceleratorTitanium.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac AppEngine.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac ArchLinuxPackages.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Autotools.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Ballerina.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac C++.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac C.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CakePHP.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CFWheels.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac ChefCookbook.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Clojure.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CMake.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CodeIgniter.gitignore"}, {"id": "gitingest_outputs/github_gitignore_20250905_193039.txt_1", "file": "gitingest_outputs/github_gitignore_20250905_193039.txt", "content": "\u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Clojure.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CMake.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CodeIgniter.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CommonLisp.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Composer.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Concrete5.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CONTRIBUTING.md\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Coq.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CraftCMS.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CUDA.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac D.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Dart.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Delphi.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac DM.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Dotnet.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Drupal.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Eagle.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac ecu.test.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Elisp.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Elixir.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Elm.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac EPiServer.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Erlang.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac ExpressionEngine.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac ExtJs.gitignore"}, {"id": "gitingest_outputs/github_gitignore_20250905_193039.txt_2", "file": "gitingest_outputs/github_gitignore_20250905_193039.txt", "content": "\u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac ExpressionEngine.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac ExtJs.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Fancy.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Finale.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Firebase.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac FlaxEngine.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Flutter.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac ForceDotCom.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Fortran.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac FuelPHP.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Gcov.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac GitBook.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac GitHubPages.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Gleam.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Go.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Godot.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Gradle.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Grails.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac GWT.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Haskell.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Haxe.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac HIP.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac IAR.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Idris.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac IGORPro.gitignore"}, {"id": "gitingest_outputs/github_gitignore_20250905_193039.txt_3", "file": "gitingest_outputs/github_gitignore_20250905_193039.txt", "content": "\u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac IAR.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Idris.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac IGORPro.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Java.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac JBoss.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Jekyll.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac JENKINS_HOME.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Joomla.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Julia.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Katalon.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac KiCad.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Kohana.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Kotlin.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac LabVIEW.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac LangChain.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Laravel.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Leiningen.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac LemonStand.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac LICENSE\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Lilypond.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Lithium.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Lua.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Luau.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Magento.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Maven.gitignore"}, {"id": "gitingest_outputs/github_gitignore_20250905_193039.txt_4", "file": "gitingest_outputs/github_gitignore_20250905_193039.txt", "content": "\u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Luau.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Magento.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Maven.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Mercury.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac MetaProgrammingSystem.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Modelica.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac ModelSim.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Nanoc.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Nestjs.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Nextjs.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Nim.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Nix.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Node.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Objective-C.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac OCaml.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Opa.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac OpenCart.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac OracleForms.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Packer.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Perl.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Phalcon.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac PlayFramework.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Plone.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Prestashop.gitignore"}, {"id": "gitingest_outputs/github_gitignore_20250905_193039.txt_5", "file": "gitingest_outputs/github_gitignore_20250905_193039.txt", "content": "\u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Plone.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Prestashop.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Processing.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac PureScript.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Python.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Qooxdoo.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Qt.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac R.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Racket.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Rails.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Raku.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac ReScript.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac RhodesRhomobile.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac ROS.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Ruby.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Rust.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Salesforce.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Sass.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Scala.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Scheme.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac SCons.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Scrivener.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Sdcc.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac SeamGen.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac SketchUp.gitignore"}, {"id": "gitingest_outputs/github_gitignore_20250905_193039.txt_6", "file": "gitingest_outputs/github_gitignore_20250905_193039.txt", "content": "\u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Sdcc.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac SeamGen.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac SketchUp.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Smalltalk.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Solidity-Remix.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac SSDT-sqlproj.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Stella.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac SugarCRM.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Swift.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Symfony.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac SymphonyCMS.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Terraform.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac TestComplete.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac TeX.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Textpattern.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac TurboGears2.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac TwinCAT3.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Typo3.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Unity.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac UnrealEngine.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac VBA.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac VisualStudio.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac VVVV.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Waf.gitignore"}, {"id": "gitingest_outputs/github_gitignore_20250905_193039.txt_7", "file": "gitingest_outputs/github_gitignore_20250905_193039.txt", "content": "\u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac VisualStudio.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac VVVV.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Waf.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac WordPress.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Xojo.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Yeoman.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Yii.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac ZendFramework.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Zephir.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Zig.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac community/\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Alteryx.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac AltiumDesigner.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac AutoIt.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac AutomationStudio.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac B4X.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Bazel.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Beef.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Dotter.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Exercism.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Gretl.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Hexo.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac LensStudio.gitignore"}, {"id": "gitingest_outputs/github_gitignore_20250905_193039.txt_8", "file": "gitingest_outputs/github_gitignore_20250905_193039.txt", "content": "\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Hexo.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac LensStudio.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac libogc.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Logtalk.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac MetaTrader5.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Move.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac NasaSpecsIntact.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac OpenSSL.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac OpenTofu.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Puppet.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Racket.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Red.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac ROS2.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac SPFx.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Splunk.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Strapi.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Terragrunt.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Toit.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac UiPath.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac UTAU.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac V.gitignore"}, {"id": "gitingest_outputs/github_gitignore_20250905_193039.txt_9", "file": "gitingest_outputs/github_gitignore_20250905_193039.txt", "content": "\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac UTAU.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac V.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Xilinx.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac AWS/\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CDK.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac SAM.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac BoxLang/\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac ColdBox.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CFML/\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac ColdBox.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac DotNet/\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac core.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac InforCMS.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Kentico.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac Umbraco.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Elixir/\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac Phoenix.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac embedded/\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac AtmelStudio.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac esp-idf.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac IAR_EWARM.gitignore"}, {"id": "gitingest_outputs/github_gitignore_20250905_193039.txt_10", "file": "gitingest_outputs/github_gitignore_20250905_193039.txt", "content": "\u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac esp-idf.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac IAR_EWARM.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac uVision.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac GNOME/\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac GNOMEShellExtension.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Golang/\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Go.AllowList.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac Hugo.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Java/\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac JBoss4.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac JBoss6.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac JavaScript/\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Cordova.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Expo.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Meteor.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac NWjs.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac Vue.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Linux/\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac Snap.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Obsidian/"}, {"id": "gitingest_outputs/github_gitignore_20250905_193039.txt_11", "file": "gitingest_outputs/github_gitignore_20250905_193039.txt", "content": "\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Linux/\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac Snap.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Obsidian/\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac NotesAndCoreConfiguration.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac NotesAndExtendedConfiguration.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac NotesOnly.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac PHP/\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Bitrix.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CodeSniffer.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Drupal7.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Jigsaw.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Magento1.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Magento2.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Pimcore.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac ThinkPHP.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac Python/\n    \u00e2\u201d\u201a       \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac JupyterNotebooks.gitignore\n    \u00e2\u201d\u201a       \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac Nikola.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Global/"}, {"id": "gitingest_outputs/github_gitignore_20250905_193039.txt_12", "file": "gitingest_outputs/github_gitignore_20250905_193039.txt", "content": "\u00e2\u201d\u201a       \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac Nikola.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Global/\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac README.md\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac AL.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Anjuta.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Ansible.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Archives.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Backup.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Bazaar.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac BricxCC.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Calabash.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Cloud9.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CodeKit.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Cursor.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CVS.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac DartEditor.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Diff.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Dreamweaver.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Dropbox.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Eclipse.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac EiffelStudio.gitignore"}, {"id": "gitingest_outputs/github_gitignore_20250905_193039.txt_13", "file": "gitingest_outputs/github_gitignore_20250905_193039.txt", "content": "\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Eclipse.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac EiffelStudio.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Emacs.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Ensime.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Espresso.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac FlexBuilder.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac GPG.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Images.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac JDeveloper.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac JEnv.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac JetBrains.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Kate.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac KDevelop4.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Lazarus.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Lefthook.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac LibreOffice.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Linux.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac LyX.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac macOS.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac MATLAB.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Mercurial.gitignore"}, {"id": "gitingest_outputs/github_gitignore_20250905_193039.txt_14", "file": "gitingest_outputs/github_gitignore_20250905_193039.txt", "content": "\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac MATLAB.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Mercurial.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Metals.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac MicrosoftOffice.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac mise.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Momentics.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac MonoDevelop.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac NetBeans.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Ninja.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac NotepadPP.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Octave.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Otto.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Patch.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac PlatformIO.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac PSoCCreator.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac PuTTY.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Redcar.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Redis.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac SBT.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac SlickEdit.gitignore"}, {"id": "gitingest_outputs/github_gitignore_20250905_193039.txt_15", "file": "gitingest_outputs/github_gitignore_20250905_193039.txt", "content": "\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac SBT.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac SlickEdit.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Stata.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac SublimeText.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac SVN.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Syncthing.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac SynopsysVCS.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Tags.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac TextMate.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac TortoiseGit.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Vagrant.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Vim.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac VirtualEnv.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Virtuoso.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac VisualStudioCode.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac WebMethods.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Windows.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Xcode.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac XilinxISE.gitignore\n    \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac .github/\n        \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CODEOWNERS"}, {"id": "gitingest_outputs/github_gitignore_20250905_193039.txt_16", "file": "gitingest_outputs/github_gitignore_20250905_193039.txt", "content": "\u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac XilinxISE.gitignore\n    \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac .github/\n        \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CODEOWNERS\n        \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac PULL_REQUEST_TEMPLATE.md\n        \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac workflows/\n            \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac stale.yml"}, {"id": "README.md_0", "file": "README.md", "content": "================================================\n# A collection of `.gitignore` templates\n\nThis is GitHub\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s collection of [`.gitignore`][man] file templates.\nWe use this list to populate the `.gitignore` template choosers available\nin the GitHub.com interface when creating new repositories and files.\n\nFor more information about how `.gitignore` files work, and how to use them,\nthe following resources are a great place to start:\n\n- The [Ignoring Files chapter][chapter] of the [Pro Git][progit] book.\n- The [Ignoring Files article][help] on the GitHub Help site.\n- The [gitignore(5)][man] manual page.\n\n[man]: https://git-scm.com/docs/gitignore\n[help]: https://help.github.com/articles/ignoring-files"}, {"id": "README.md_1", "file": "README.md", "content": "[man]: https://git-scm.com/docs/gitignore\n[help]: https://help.github.com/articles/ignoring-files\n[chapter]: https://git-scm.com/book/en/v2/Git-Basics-Recording-Changes-to-the-Repository#_ignoring\n[progit]: https://git-scm.com/book"}, {"id": "README.md_2", "file": "README.md", "content": "## Folder structure\n\nWe support a collection of templates, organized in this way:\n\n- The root folder contains templates in common use, to help people get started\n  with popular programming languages and technologies. These define a meaningful\n  set of rules to help get started, and ensure you are not committing\n  unimportant files into your repository.\n- [`Global`](./Global) contains templates for various editors, tools and\n  operating systems that can be used in different situations. It is recommended\n  that you either [add these to your global template](https://docs.github.com/en/get-started/getting-started-with-git/ignoring-files#configuring-ignored-files-for-all-repositories-on-your-computer)\n  or merge these rules into your project-specific templates if you want to use"}, {"id": "README.md_3", "file": "README.md", "content": "or merge these rules into your project-specific templates if you want to use\n  them permanently.\n- [`community`](./community) contains specialized templates for other popular\n  languages, tools and project, which don't currently belong in the mainstream\n  templates. These should be added to your project-specific templates when you\n  decide to adopt the framework or tool."}, {"id": "README.md_4", "file": "README.md", "content": "## What makes a good template?\n\nA template should contain a set of rules to help Git repositories work with a\nspecific programming language, framework, tool or environment.\n\nIf it's not possible to curate a small set of useful rules for this situation,\nthen the template is not a good fit for this collection.\n\nIf a template is mostly a list of files installed by a particular version of\nsome software (e.g. a PHP framework), it could live under the `community`\ndirectory. See [versioned templates](#versioned-templates) for more details.\n\nIf you have a small set of rules, or want to support a technology that is not\nwidely in use, and still believe this will be helpful to others, please read the\nsection about [specialized templates](#specialized-templates) for more details."}, {"id": "README.md_5", "file": "README.md", "content": "section about [specialized templates](#specialized-templates) for more details.\n\nInclude details when opening pull request if the template is important and visible. We\nmay not accept it immediately, but we can promote it to the root at a later date\nbased on interest.\n\nPlease also understand that we can\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2t list every tool that ever existed.\nOur aim is to curate a collection of the _most common and helpful_ templates,\nnot to make sure we cover every project possible. If we choose not to\ninclude your language, tool, or project, it\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s not because it\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s not awesome."}, {"id": "README.md_6", "file": "README.md", "content": "## Contributing guidelines\n\nWe\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2d love for you to help us improve this project. To help us keep this collection\nhigh quality, we request that contributions adhere to the following guidelines.\n\n- **Provide a link to the application or project\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s homepage**. Unless it\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s\n  extremely popular, there\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s a chance the maintainers don\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2t know about or use\n  the language, framework, editor, app, or project your change applies to.\n\n- **Provide links to documentation** supporting the change you\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2re making.\n  Current, canonical documentation mentioning the files being ignored is best.\n  If documentation isn\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2t available to support your change, do the best you can\n  to explain what the files being ignored are for."}, {"id": "README.md_7", "file": "README.md", "content": "to explain what the files being ignored are for.\n\n- **Explain why you\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2re making a change**. Even if it seems self-evident, please\n  take a sentence or two to tell us why your change or addition should happen.\n  It\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s especially helpful to articulate why this change applies to _everyone_\n  who works with the applicable technology, rather than just you or your team.\n\n- **Please consider the scope of your change**. If your change is specific to a\n  certain language or framework, then make sure the change is made to the\n  template for that language or framework, rather than to the template for an\n  editor, tool, or operating system.\n\n- **Please only modify _one template_ per pull request**. This helps keep pull"}, {"id": "README.md_8", "file": "README.md", "content": "- **Please only modify _one template_ per pull request**. This helps keep pull\n  requests and feedback focused on a specific project or technology.\n\nIn general, the more you can do to help us understand the change you\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2re making,\nthe more likely we\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2ll be to accept your contribution quickly."}, {"id": "README.md_9", "file": "README.md", "content": "## Versioned templates\n\nSome templates can change greatly between versions, and if you wish to contribute\nto this repository we need to follow this specific flow:\n\n- the template at the root should be the current supported version\n- the template at the root should not have a version in the filename (i.e.\n  \"evergreen\")\n- previous versions of templates should live under `community/`\n- previous versions of the template should embed the version in the filename,\n  for readability\n\nThis helps ensure users get the latest version (because they'll use whatever is\nat the root) but helps maintainers support older versions still in the wild."}, {"id": "README.md_10", "file": "README.md", "content": "## Specialized templates\n\nIf you have a template that you would like to contribute, but it isn't quite\nmainstream, please consider adding this to the `community` directory under a\nfolder that best suits where it belongs.\n\nThe rules in your specialized template should be specific to the framework or\ntool, and any additional templates should be mentioned in a comment in the\nheader of the template.\n\nFor example, this template might live at `community/DotNet/InforCRM.gitignore`:\n\n```gitignore\n# gitignore template for InforCRM (formerly SalesLogix)\n# website: https://www.infor.com/product-summary/cx/infor-crm/\n#\n# Recommended: VisualStudio.gitignore\n\n# Ignore model files that are auto-generated\nModelIndex.xml\nExportedFiles.xml\n\n# Ignore deployment files\n[Mm]odel/[Dd]eployment"}, {"id": "README.md_11", "file": "README.md", "content": "ModelIndex.xml\nExportedFiles.xml\n\n# Ignore deployment files\n[Mm]odel/[Dd]eployment\n\n# Force include portal SupportFiles\n!Model/Portal/*/SupportFiles/[Bb]in/\n!Model/Portal/PortalTemplates/*/SupportFiles/[Bb]in\n```"}, {"id": "README.md_12", "file": "README.md", "content": "## Contributing workflow\n\nHere\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s how we suggest you go about proposing a change to this project:\n\n1. [Fork this project][fork] to your account.\n2. [Create a branch][branch] for the change you intend to make.\n3. Make your changes to your fork.\n4. [Send a pull request][pr] from your fork\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s branch to our `main` branch.\n\nUsing the web-based interface to make changes is fine too, and will help you\nby automatically forking the project and prompting to send a pull request too.\n\n[fork]: https://help.github.com/articles/fork-a-repo/\n[branch]: https://help.github.com/articles/creating-and-deleting-branches-within-your-repository\n[pr]: https://help.github.com/articles/using-pull-requests/\n\n## License\n\n[CC0-1.0](./LICENSE)."}, {"id": "Actionscript.gitignore_0", "file": "Actionscript.gitignore", "content": "================================================\n# Build and Release Folders\nbin-debug/\nbin-release/\n[Oo]bj/\n[Bb]in/\n\n# Other files and folders\n.settings/\n\n# Executables\n*.swf\n*.air\n*.ipa\n*.apk\n\n# Project files, i.e. `.project`, `.actionScriptProperties` and `.flexProperties`\n# should NOT be excluded as they contain compiler settings and other important\n# information for Eclipse / Flash Builder."}, {"id": "Ada.gitignore_0", "file": "Ada.gitignore", "content": "================================================\n# Object file\n*.o\n\n# Ada Library Information\n*.ali"}, {"id": "AdventureGameStudio.gitignore_0", "file": "AdventureGameStudio.gitignore", "content": "================================================\n# Built things\n_Debug/\nCompiled/\n\n# AudioCache can be rebuilt from sources\nAudioCache/\n\n# Lockfile\n_OpenInEditor.lock\n\n# User settings\nGame.agf.user\n*.crm.user\n\n# Backups\nGame.agf.bak\nbackup_acsprset.spr\n\n# Memory dumps\n*.dmp\n\n# Temporary files\n# temporarily created during sprite or room background compression\n~aclzw.tmp\n# temporary, main game data, before getting packed into exe\ngame28.dta\n# temporary build of the game before being moved to Compiled/ folder\n*.exe\n\n# Log files\nwarnings.log"}, {"id": "Agda.gitignore_0", "file": "Agda.gitignore", "content": "================================================\n*.agdai\nMAlonzo/**"}, {"id": "AL.gitignore_0", "file": "AL.gitignore", "content": "================================================\n### AL ###\n#Template for AL projects for Dynamics 365 Business Central\n#launch.json folder\n.vscode/\n#Cache folder\n.alcache/\n#Symbols folder\n.alpackages/\n#Snapshots folder\n.snapshots/\n#Testing Output folder\n.output/\n#Extension App-file\n*.app\n#Rapid Application Development File\nrad.json\n#Translation Base-file\n*.g.xlf\n#License-file\n*.flf\n#Test results file\nTestResults.xml"}, {"id": "Android.gitignore_0", "file": "Android.gitignore", "content": "================================================\n# Gradle files\n.gradle/\nbuild/\n\n# Local configuration file (sdk path, etc)\nlocal.properties\n\n# Log/OS Files\n*.log\n\n# Android Studio generated files and folders\ncaptures/\n.externalNativeBuild/\n.cxx/\n*.aab\n*.apk\noutput-metadata.json\n\n# IntelliJ\n*.iml\n.idea/\nmisc.xml\ndeploymentTargetDropDown.xml\nrender.experimental.xml\n\n# Keystore files\n*.jks\n*.keystore\n\n# Google Services (e.g. APIs or Firebase)\ngoogle-services.json\n\n# Android Profiling\n*.hprof"}, {"id": "Angular.gitignore_0", "file": "Angular.gitignore", "content": "================================================\n# Angular specific\n/dist/\n/out-tsc/\n/tmp/\n/coverage/\n/e2e/test-output/\n/.angular/\n.angular/\n\n# Node modules and dependency files\n/node_modules/\n/package-lock.json\n/yarn.lock\n\n# Environment files\n/.env\n\n# Angular CLI and build artefacts\n/.angular-cli.json\n/.ng/\n\n# TypeScript cache\n*.tsbuildinfo\n\n# Logs\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*"}, {"id": "AppceleratorTitanium.gitignore_0", "file": "AppceleratorTitanium.gitignore", "content": "================================================\n# Build folder and log file\nbuild/\nbuild.log"}, {"id": "AppEngine.gitignore_0", "file": "AppEngine.gitignore", "content": "================================================\n# Google App Engine generated folder\nappengine-generated/"}, {"id": "ArchLinuxPackages.gitignore_0", "file": "ArchLinuxPackages.gitignore", "content": "================================================\n*.tar\n*.tar.*\n*.jar\n*.exe\n*.msi\n*.deb\n*.zip\n*.tgz\n*.log\n*.log.*\n*.sig\n\npkg/\nsrc/"}, {"id": "Autotools.gitignore_0", "file": "Autotools.gitignore", "content": "================================================\n# http://www.gnu.org/software/automake\n\nMakefile.in\n/ar-lib\n/mdate-sh\n/py-compile\n/test-driver\n/ylwrap\n.deps/\n.dirstamp\n\n# http://www.gnu.org/software/autoconf\n\nautom4te.cache\n/autoscan.log\n/autoscan-*.log\n/aclocal.m4\n/compile\n/config.cache\n/config.guess\n/config.h.in\n/config.log\n/config.status\n/config.sub\n/configure\n/configure.scan\n/depcomp\n/install-sh\n/missing\n/stamp-h1\n\n# https://www.gnu.org/software/libtool/\n\n/libtool\n/ltmain.sh\n.libs/\n\n# http://www.gnu.org/software/texinfo\n\n/texinfo.tex\n\n# http://www.gnu.org/software/m4/\n\nm4/libtool.m4\nm4/ltoptions.m4\nm4/ltsugar.m4\nm4/ltversion.m4\nm4/lt~obsolete.m4\n\n# Generated Makefile\n# (meta build system like autotools,\n# can automatically generate from config.status script"}, {"id": "Autotools.gitignore_1", "file": "Autotools.gitignore", "content": "# (meta build system like autotools,\n# can automatically generate from config.status script\n# (which is called by configure script))\nMakefile"}, {"id": "Ballerina.gitignore_0", "file": "Ballerina.gitignore", "content": "================================================\n# generated files\ntarget/\ngenerated/\n\n# dependencies\nDependencies.toml\n\n# config files\nConfig.toml\n# the config files used for testing, Uncomment the following line if you want to commit the test config files\n#!**/tests/Config.toml"}, {"id": "C++.gitignore_0", "file": "C++.gitignore", "content": "================================================\n# Prerequisites\n*.d\n\n# Compiled Object files\n*.slo\n*.lo\n*.o\n*.obj\n\n# Precompiled Headers\n*.gch\n*.pch\n\n# Linker files\n*.ilk\n\n# Debugger Files\n*.pdb\n\n# Compiled Dynamic libraries\n*.so\n*.dylib\n*.dll\n\n# Fortran module files\n*.mod\n*.smod\n\n# Compiled Static libraries\n*.lai\n*.la\n*.a\n*.lib\n\n# Executables\n*.exe\n*.out\n*.app\n\n# debug information files\n*.dwo"}, {"id": "C.gitignore_0", "file": "C.gitignore", "content": "================================================\n# Prerequisites\n*.d\n\n# Object files\n*.o\n*.ko\n*.obj\n*.elf\n\n# Linker output\n*.ilk\n*.map\n*.exp\n\n# Precompiled Headers\n*.gch\n*.pch\n\n# Libraries\n*.lib\n*.a\n*.la\n*.lo\n\n# Shared objects (inc. Windows DLLs)\n*.dll\n*.so\n*.so.*\n*.dylib\n\n# Executables\n*.exe\n*.out\n*.app\n*.i*86\n*.x86_64\n*.hex\n\n# Debug files\n*.dSYM/\n*.su\n*.idb\n*.pdb\n\n# Kernel Module Compile Results\n*.mod*\n*.cmd\n.tmp_versions/\nmodules.order\nModule.symvers\nMkfile.old\ndkms.conf\n\n# debug information files\n*.dwo"}, {"id": "CakePHP.gitignore_0", "file": "CakePHP.gitignore", "content": "================================================\n# CakePHP 3\n\n/vendor/*\n/config/app.php\n\n/tmp/cache/models/*\n!/tmp/cache/models/empty\n/tmp/cache/persistent/*\n!/tmp/cache/persistent/empty\n/tmp/cache/views/*\n!/tmp/cache/views/empty\n/tmp/sessions/*\n!/tmp/sessions/empty\n/tmp/tests/*\n!/tmp/tests/empty\n\n/logs/*\n!/logs/empty\n\n# CakePHP 2\n\n/app/tmp/*\n/app/Config/core.php\n/app/Config/database.php\n/vendors/*"}, {"id": "CFWheels.gitignore_0", "file": "CFWheels.gitignore", "content": "================================================\n# unpacked plugin folders\nplugins/**/*\n\n# files directory where uploads go\nfiles\n\n# DBMigrate plugin: generated SQL\ndb/sql\n\n# AssetBundler plugin: generated bundles\njavascripts/bundles\nstylesheets/bundles"}, {"id": "ChefCookbook.gitignore_0", "file": "ChefCookbook.gitignore", "content": "================================================\n.vagrant\n/cookbooks\n\n# Bundler\nbin/*\n.bundle/*\n\n.kitchen/\n.kitchen.local.yml"}, {"id": "Clojure.gitignore_0", "file": "Clojure.gitignore", "content": "================================================\nLeiningen.gitignore"}, {"id": "CMake.gitignore_0", "file": "CMake.gitignore", "content": "================================================\nCMakeLists.txt.user\nCMakeCache.txt\nCMakeFiles\nCMakeScripts\nTesting\nMakefile\ncmake_install.cmake\ninstall_manifest.txt\ncompile_commands.json\nCTestTestfile.cmake\n_deps\nCMakeUserPresets.json\n\n# CLion\n#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can\n#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore\n#  and can be added to the global gitignore or merged into this file.  For a more nuclear\n#  option (not recommended) you can uncomment the following to ignore the entire idea folder.\n#cmake-build-*"}, {"id": "CodeIgniter.gitignore_0", "file": "CodeIgniter.gitignore", "content": "================================================\n*/config/development\n*/logs/log-*.php\n!*/logs/index.html\n*/cache/*\n!system/cache/*\n!*/cache/index.html\n!*/cache/.htaccess\n\nuser_guide_src/build/*\nuser_guide_src/cilexer/build/*\nuser_guide_src/cilexer/dist/*\nuser_guide_src/cilexer/pycilexer.egg-info/*\n\n#codeigniter 3\napplication/logs/*\n!application/logs/index.html\n!application/logs/.htaccess\n/vendor/"}, {"id": "CommonLisp.gitignore_0", "file": "CommonLisp.gitignore", "content": "================================================\n*.FASL\n*.fasl\n*.lisp-temp\n*.dfsl\n*.pfsl\n*.d64fsl\n*.p64fsl\n*.lx64fsl\n*.lx32fsl\n*.dx64fsl\n*.dx32fsl\n*.fx64fsl\n*.fx32fsl\n*.sx64fsl\n*.sx32fsl\n*.wx64fsl\n*.wx32fsl"}, {"id": "Composer.gitignore_0", "file": "Composer.gitignore", "content": "================================================\ncomposer.phar\n/vendor/\n\n# Commit your application's lock file https://getcomposer.org/doc/01-basic-usage.md#commit-your-composer-lock-file-to-version-control\n# You may choose to ignore a library lock file http://getcomposer.org/doc/02-libraries.md#lock-file\n# composer.lock"}, {"id": "Concrete5.gitignore_0", "file": "Concrete5.gitignore", "content": "================================================\n# ignore the error log and .htaccess and others\nerror_log\n.htaccess\n\n# concrete5 5.6 specific\n\nconfig/site.php\nfiles/cache/*\nfiles/tmp/*\n\n# concrete5 5.7 specific\n\n# ignore everything but the index.html\n/application/files/*\n!/application/files/index.html\n\n# ignore updates folder\n/updates/*\n\n# ignore sitemap.xml\n/sitemap.xml"}, {"id": "CONTRIBUTING.md_0", "file": "CONTRIBUTING.md", "content": "================================================\n# Contributing guidelines\n\nWe\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2d love you to help us improve this project. To help us keep this collection\nhigh quality, we request that contributions adhere to the following guidelines.\n\n- **Provide a link to the application or project\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s homepage**. Unless it\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s\n  extremely popular, there\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s a chance the maintainers don\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2t know about or use\n  the language, framework, editor, app, or project your change applies to.\n\n- **Provide links to documentation** supporting the change you\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2re making.\n  Current, canonical documentation mentioning the files being ignored is best.\n  If documentation isn\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2t available to support your change, do the best you can\n  to explain what the files being ignored are for."}, {"id": "CONTRIBUTING.md_1", "file": "CONTRIBUTING.md", "content": "to explain what the files being ignored are for.\n\n- **Explain why you\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2re making a change**. Even if it seems self-evident, please\n  take a sentence or two to tell us why your change or addition should happen.\n  It\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s especially helpful to articulate why this change applies to *everyone*\n  who works with the applicable technology, rather than just you or your team.\n\n- **Please consider the scope of your change**. If your change specific to a\n  certain language or framework, then make sure the change is made to the\n  template for that language or framework, rather than to the template for an\n  editor, tool, or operating system.\n\n- **Please only modify *one template* per pull request**. This helps keep pull\n  requests and feedback focused on a specific project or technology."}, {"id": "CONTRIBUTING.md_2", "file": "CONTRIBUTING.md", "content": "requests and feedback focused on a specific project or technology.\n\nIn general, the more you can do to help us understand the change you\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2re making,\nthe more likely we\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2ll be to accept your contribution quickly.\n\nIf a template is mostly a list of files installed by a particular version of\nsome software (e.g. a PHP framework) then it's brittle and probably no more\nhelpful than a simple `ls`. If it's not possible to curate a small set of\nuseful rules, then the template might not be a good fit for this collection.\n\nPlease also understand that we can\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2t list every tool that ever existed.\nOur aim is to curate a collection of the *most common and helpful* templates,\nnot to make sure we cover every project possible. If we choose not to"}, {"id": "CONTRIBUTING.md_3", "file": "CONTRIBUTING.md", "content": "not to make sure we cover every project possible. If we choose not to\ninclude your language, tool, or project, it\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s not because it\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s not awesome."}, {"id": "Coq.gitignore_0", "file": "Coq.gitignore", "content": "================================================\n.*.aux\n.*.d\n*.a\n*.cma\n*.cmi\n*.cmo\n*.cmx\n*.cmxa\n*.cmxs\n*.glob\n*.ml.d\n*.ml4.d\n*.mlg.d\n*.mli.d\n*.mllib.d\n*.mlpack.d\n*.native\n*.o\n*.v.d\n*.vio\n*.vo\n*.vok\n*.vos\n.coq-native\n.csdp.cache\n.lia.cache\n.nia.cache\n.nlia.cache\n.nra.cache\ncsdp.cache\nlia.cache\nnia.cache\nnlia.cache\nnra.cache\nnative_compute_profile_*.data\n\n# generated timing files\n*.timing.diff\n*.v.after-timing\n*.v.before-timing\n*.v.timing\ntime-of-build-after.log\ntime-of-build-before.log\ntime-of-build-both.log\ntime-of-build-pretty.log"}, {"id": "CraftCMS.gitignore_0", "file": "CraftCMS.gitignore", "content": "================================================\n# Craft 2 Storage (https://craftcms.com/support/craft-storage-gitignore)\n# not necessary for Craft 3 (https://github.com/craftcms/craft/issues/26)\n/craft/storage/*\n!/craft/storage/rebrand"}, {"id": "CUDA.gitignore_0", "file": "CUDA.gitignore", "content": "================================================\n*.i\n*.ii\n*.gpu\n*.ptx\n*.cubin\n*.fatbin"}, {"id": "D.gitignore_0", "file": "D.gitignore", "content": "================================================\n# Compiled Object files\n*.o\n*.obj\n\n# Compiled Dynamic libraries\n*.so\n*.dylib\n*.dll\n\n# Compiled Static libraries\n*.a\n*.lib\n\n# Executables\n*.exe\n\n# DUB\n.dub\ndocs.json\n__dummy.html\ndocs/\n\n# Code coverage\n*.lst"}, {"id": "Dart.gitignore_0", "file": "Dart.gitignore", "content": "================================================\n# See https://www.dartlang.org/guides/libraries/private-files\n\n# Files and directories created by pub\n.dart_tool/\n.packages\nbuild/\n# If you're building an application, you may want to check-in your pubspec.lock\npubspec.lock\n\n# Directory created by dartdoc\n# If you don't generate documentation locally you can remove this line.\ndoc/api/\n\n# dotenv environment variables file\n.env*\n\n# Avoid committing generated Javascript files:\n*.dart.js\n# Produced by the --dump-info flag.\n*.info.json\n# When generated by dart2js. Don't specify *.js if your\n# project includes source files written in JavaScript.\n*.js\n*.js_\n*.js.deps\n*.js.map\n\n.flutter-plugins\n.flutter-plugins-dependencies"}, {"id": "Delphi.gitignore_0", "file": "Delphi.gitignore", "content": "================================================\n# Uncomment these types if you want even more clean repository. But be careful.\n# It can make harm to an existing project source. Read explanations below.\n#\n# Resource files are binaries containing manifest, project icon and version info.\n# They can not be viewed as text or compared by diff-tools. Consider replacing them with .rc files.\n#*.res\n#\n# Type library file (binary). In old Delphi versions it should be stored.\n# Since Delphi 2009 it is produced from .ridl file and can safely be ignored.\n#*.tlb\n#\n# Diagram Portfolio file. Used by the diagram editor up to Delphi 7.\n# Uncomment this if you are not using diagrams or use newer Delphi version.\n#*.ddp\n#\n# Visual LiveBindings file. Added in Delphi XE2."}, {"id": "Delphi.gitignore_1", "file": "Delphi.gitignore", "content": "#*.ddp\n#\n# Visual LiveBindings file. Added in Delphi XE2.\n# Uncomment this if you are not using LiveBindings Designer.\n#*.vlb\n#\n# Deployment Manager configuration file for your project. Added in Delphi XE2.\n# Uncomment this if it is not mobile development and you do not use remote debug feature.\n#*.deployproj\n#\n# C++ object files produced when C/C++ Output file generation is configured.\n# Uncomment this if you are not using external objects (zlib library for example).\n#*.obj\n#\n\n# Default Delphi compiler directories\n# Content of this directories are generated with each Compile/Construct of a project.\n# Most of the time, files here have not there place in a code repository.\n#Win32/\n#Win64/\n#OSX64/\n#OSXARM64/\n#Android/\n#Android64/\n#iOSDevice64/\n#Linux64/"}, {"id": "Delphi.gitignore_2", "file": "Delphi.gitignore", "content": "#Win32/\n#Win64/\n#OSX64/\n#OSXARM64/\n#Android/\n#Android64/\n#iOSDevice64/\n#Linux64/\n\n# Delphi compiler-generated binaries (safe to delete)\n*.exe\n*.dll\n*.bpl\n*.bpi\n*.dcp\n*.so\n*.apk\n*.drc\n*.map\n*.dres\n*.rsm\n*.tds\n*.dcu\n*.lib\n*.a\n*.o\n*.ocx\n\n# Delphi autogenerated files (duplicated info)\n*.cfg\n*.hpp\n*Resource.rc\n\n# Delphi local files (user-specific info)\n*.local\n*.identcache\n*.projdata\n*.tvsconfig\n*.dsk\n*.dsv\n\n# Delphi history and backups\n__history/\n__recovery/\n*.~*\n\n# Castalia statistics file (since XE7 Castalia is distributed with Delphi)\n*.stat\n\n# Boss dependency manager vendor folder https://github.com/HashLoad/boss\nmodules/"}, {"id": "DM.gitignore_0", "file": "DM.gitignore", "content": "================================================\n*.dmb\n*.rsc\n*.int\n*.lk\n*.zip"}, {"id": "Dotnet.gitignore_0", "file": "Dotnet.gitignore", "content": "================================================\n## A streamlined .gitignore for modern .NET projects\n## including temporary files, build results, and\n## files generated by popular .NET tools. If you are\n## developing with Visual Studio, the VS .gitignore\n## https://github.com/github/gitignore/blob/main/VisualStudio.gitignore\n## has more thorough IDE-specific entries.\n##"}, {"id": "Dotnet.gitignore_1", "file": "Dotnet.gitignore", "content": "## has more thorough IDE-specific entries.\n##\n## Get latest from https://github.com/github/gitignore/blob/main/Dotnet.gitignore\n\n# Build results\n[Dd]ebug/\n[Dd]ebugPublic/\n[Rr]elease/\n[Rr]eleases/\nx64/\nx86/\n[Ww][Ii][Nn]32/\n[Aa][Rr][Mm]/\n[Aa][Rr][Mm]64/\nbld/\n[Bb]in/\n[Oo]bj/\n[Ll]og/\n[Ll]ogs/\n\n# .NET Core\nproject.lock.json\nproject.fragment.lock.json\nartifacts/\n\n# ASP.NET Scaffolding\nScaffoldingReadMe.txt\n\n# NuGet Packages\n*.nupkg\n# NuGet Symbol Packages\n*.snupkg\n\n# Others\n~$*\n*~\nCodeCoverage/\n\n# MSBuild Binary and Structured Log\n*.binlog\n\n# MSTest test Results\n[Tt]est[Rr]esult*/\n[Bb]uild[Ll]og.*\n\n# NUnit\n*.VisualState.xml\nTestResult.xml\nnunit-*.xml"}, {"id": "Drupal.gitignore_0", "file": "Drupal.gitignore", "content": "================================================\n# gitignore template for Drupal 8 projects\n#\n# earlier versions of Drupal are tracked in `community/PHP/`\n#\n# follows official upstream conventions:\n# https://www.drupal.org/docs/develop/using-composer\n\n# Ignore configuration files that may contain sensitive information\n/web/sites/*/*settings*.php\n/web/sites/*/*services*.yml\n\n# Ignore paths that may contain user-generated content\n/web/sites/*/files\n/web/sites/*/public\n/web/sites/*/private\n/web/sites/*/files-public\n/web/sites/*/files-private\n\n# Ignore paths that may contain temporary files\n/web/sites/*/translations\n/web/sites/*/tmp\n/web/sites/*/cache\n\n# Ignore drupal core (if not versioning drupal sources)\n/web/vendor\n/web/core\n/web/modules/README.txt\n/web/modules/contrib"}, {"id": "Drupal.gitignore_1", "file": "Drupal.gitignore", "content": "/web/vendor\n/web/core\n/web/modules/README.txt\n/web/modules/contrib\n/web/profiles/README.txt\n/web/profiles/contrib\n/web/sites/development.services.yml\n/web/sites/example.settings.local.php\n/web/sites/example.sites.php\n/web/sites/README.txt\n/web/themes/README.txt\n/web/themes/contrib\n/web/.csslintrc\n/web/.editorconfig\n/web/.eslintignore\n/web/.eslintrc.json\n/web/.gitattributes\n/web/.htaccess\n/web/.ht.router.php\n/web/autoload.php\n/web/composer.json\n/web/composer.lock\n/web/example.gitignore\n/web/index.php\n/web/INSTALL.txt\n/web/LICENSE.txt\n/web/README.txt\n/web/robots.txt\n/web/update.php\n/web/web.config\n\n# Ignore vendor dependencies and scripts\n/vendor\n/composer.phar\n/composer\n/robo.phar\n/robo\n/drush.phar\n/drush\n/drupal.phar\n/drupal"}, {"id": "Eagle.gitignore_0", "file": "Eagle.gitignore", "content": "================================================\n# Ignore list for Eagle, a PCB layout tool\n\n# Backup files\n*.s#?\n*.b#?\n*.l#?\n*.b$?\n*.s$?\n*.l$?\n\n# Eagle project file\n# It contains a serial number and references to the file structure\n# on your computer.\n# comment the following line if you want to have your project file included.\neagle.epf\n\n# Autorouter files\n*.pro\n*.job\n\n# CAM files\n*.$$$\n*.cmp\n*.ly2\n*.l15\n*.sol\n*.plc\n*.stc\n*.sts\n*.crc\n*.crs\n\n*.dri\n*.drl\n*.gpi\n*.pls\n*.ger\n*.xln\n\n*.drd\n*.drd.*\n\n*.s#*\n*.b#*\n\n*.info\n\n*.eps\n\n# file locks introduced since 7.x\n*.lck"}, {"id": "ecu.test.gitignore_0", "file": "ecu.test.gitignore", "content": "================================================\n# gitignore template for ecu.test workspaces - by tracetronic https://tracetronic.com\n# website: https://www.ecu-test.com\n#   * all directories are related to the default directories, please adapt the .gitignore if you use customized directories\n\n# Dynamic workspace settings\n#   * We don't recommend to ignore the .workspace directory, because of important\n#     * project specific settings\n#     * local user settings\n.workspace/ETdrive.xml\n.workspace/favorites.xml\n.workspace/filters.xml\n.workspace/generators.xml\n.workspace/history.xml\n.workspace/parallelExecution.xml\n.workspace/signalviewer.xml\n.workspace/signalViewerHistory.json\n.workspace/signalviewer2layout.xml\n.workspace/testeditor.xml\n.workspace/tooladapter.xml\n.workspace/view.xml"}, {"id": "ecu.test.gitignore_1", "file": "ecu.test.gitignore", "content": ".workspace/testeditor.xml\n.workspace/tooladapter.xml\n.workspace/view.xml\n# optional, if your process depends on this file remove exclusion\n.workspace/attributeLists.xml\n.workspace/interactiveexecution.xml\n.workspace/protocol.xml\n.workspace/pythonlibrary.xml\n# deprecated, support for older versions\n.workspace/traceexplorer.xml\n\n# Custom file formats and test dependencies\n#  * you can manage your artifacts also with test.guide (https://www.test-guide.info) and reference them via Playbooks\n*.arxml\n*.a2l\n*.dbc\n*.hex\n*.s19\n[tT]estdata\n[tT]estdaten\n\n# Test results and test execution related content\n#   * Git is not intended to store and provide test results for all iterations\n#   * We recommend to use test.guide (https://www.test-guide.info) for the test report management\nTestReports"}, {"id": "ecu.test.gitignore_2", "file": "ecu.test.gitignore", "content": "TestReports\n\n# Report generators and templates\n#   * if you want to provide (f.e.) your own report generators exclude the directory here and ignore only the unnecessary subdirectories\nTemplates\n\n# optional, default for external Python libraries\nPyLibs\n\n# Exclude large binary artifacts\n#  * you can manage your artifacts also with test.guide (https://www.test-guide.info) and reference them via Playbooks\nOffline-FIUs\nOffline-Models\nOffline-SGBDs\n*.exe\n*.msi\n*.zip\n*.7z\n\n# Exclude default and custom temporary directories\nBackup_*\n\n# Python bytecode and cache files\n__pycache__/\n*.py[cod]"}, {"id": "Elisp.gitignore_0", "file": "Elisp.gitignore", "content": "================================================\n# Compiled\n*.elc\n\n# Packaging\n.cask/\n.eask/\n.eldev/\n.keg/\n\n# Built distribution\ndist/\n\n# Backup files\n*~\n\n# Undo-tree save-files\n*.~undo-tree"}, {"id": "Elixir.gitignore_0", "file": "Elixir.gitignore", "content": "================================================\n/_build\n/cover\n/deps\n/doc\n/.fetch\nerl_crash.dump\n*.ez\n*.beam\n/config/*.secret.exs\n.elixir_ls/"}, {"id": "Elm.gitignore_0", "file": "Elm.gitignore", "content": "================================================\n# elm-package generated files\nelm-stuff\n# elm-repl generated files\nrepl-temp-*"}, {"id": "EPiServer.gitignore_0", "file": "EPiServer.gitignore", "content": "================================================\n######################\n## EPiServer Files\n######################\n*License.config"}, {"id": "Erlang.gitignore_0", "file": "Erlang.gitignore", "content": "================================================\n.eunit\n*.o\n*.beam\n*.plt\nerl_crash.dump\n.concrete/DEV_MODE\n\n# rebar 2.x\n.rebar\nrel/example_project\nebin/*.beam\ndeps\n\n# rebar 3\n.rebar3\n_build/\n_checkouts/"}, {"id": "ExpressionEngine.gitignore_0", "file": "ExpressionEngine.gitignore", "content": "================================================\n.DS_Store\n\n# Images\nimages/avatars/\nimages/captchas/\nimages/smileys/\nimages/member_photos/\nimages/signature_attachments/\nimages/pm_attachments/\n\n# For security do not publish the following files\nsystem/expressionengine/config/database.php\nsystem/expressionengine/config/config.php\n\n# Caches\nsized/\nthumbs/\n_thumbs/\n*/expressionengine/cache/*"}, {"id": "ExtJs.gitignore_0", "file": "ExtJs.gitignore", "content": "================================================\n.architect\nbootstrap.css\nbootstrap.js\nbootstrap.json\nbootstrap.jsonp\nbuild/\nclassic.json\nclassic.jsonp\next/\nmodern.json\nmodern.jsonp\nresources/sass/.sass-cache/\nresources/.arch-internal-preview.css\n.arch-internal-preview.css"}, {"id": "Fancy.gitignore_0", "file": "Fancy.gitignore", "content": "================================================\n*.rbc\n*.fyc"}, {"id": "Finale.gitignore_0", "file": "Finale.gitignore", "content": "================================================\n*.bak\n*.db\n*.avi\n*.pdf\n*.ps\n*.mid\n*.midi\n*.mp3\n*.aif\n*.wav\n# Some versions of Finale have a bug and randomly save extra copies of\n# the music source as \"<Filename> copy.mus\"\n*copy.mus"}, {"id": "Firebase.gitignore_0", "file": "Firebase.gitignore", "content": "================================================\n# Firebase build and deployment files\n/firebase-debug.log\n/firebase-debug.*.log\n.firebaserc\n\n# Firebase Hosting\n/firebase.json\n*.cache\nhosting/.cache\n\n# Firebase Functions\n/functions/node_modules/\n/functions/.env\n/functions/package-lock.json\n\n# Firebase Emulators\n/firebase-*.zip\n/.firebase/\n/emulator-ui/\n\n# Logs\n*.log\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\n\n# Environment files (local configs)\n/.env.*"}, {"id": "FlaxEngine.gitignore_0", "file": "FlaxEngine.gitignore", "content": "================================================\n# Ignore Flax project files\nBinaries/\nCache/\nLogs/\nOutput/\nScreenshots/\n*.HotReload.*\n\n# Ignore Visual Studio project files (generated locally)\n*.csproj\n*.sln\n\n# Ignore thumbnails created by Windows\nThumbs.db\n\n# Ignore files built by Visual Studio\n*.obj\n*.exe\n*.pdb\n*.user\n*.aps\n*.pch\n*.vspscc\n*_i.c\n*_p.c\n*.ncb\n*.suo\n*.tlb\n*.tlh\n*.bak\n*.cache\n*.ilk\n*.log\n[Bb]in\n[Dd]ebug*/\n*.lib\n*.sbr\nobj/\n[Rr]elease*/\n_ReSharper*/\n[Tt]est[Rr]esult*\n.vs/\n\n# Ignore Nuget packages folder\npackages/"}, {"id": "Flutter.gitignore_0", "file": "Flutter.gitignore", "content": "================================================\n# Miscellaneous\n*.class\n*.lock\n*.log\n*.pyc\n*.swp\n.buildlog/\n.history\n\n\n\n# Flutter repo-specific\n/bin/cache/\n/bin/internal/bootstrap.bat\n/bin/internal/bootstrap.sh\n/bin/mingit/\n/dev/benchmarks/mega_gallery/\n/dev/bots/.recipe_deps\n/dev/bots/android_tools/\n/dev/devicelab/ABresults*.json\n/dev/docs/doc/\n/dev/docs/flutter.docs.zip\n/dev/docs/lib/\n/dev/docs/pubspec.yaml\n/dev/integration_tests/**/xcuserdata\n/dev/integration_tests/**/Pods\n/packages/flutter/coverage/\nversion\nanalysis_benchmark.json\n\n# packages file containing multi-root paths\n.packages.generated\n\n# Flutter/Dart/Pub related\n**/doc/api/\n.dart_tool/\n.flutter-plugins\n.flutter-plugins-dependencies\n**/generated_plugin_registrant.dart\n.packages\n.pub-preload-cache/\n.pub/\nbuild/\nflutter_*.png"}, {"id": "Flutter.gitignore_1", "file": "Flutter.gitignore", "content": "**/generated_plugin_registrant.dart\n.packages\n.pub-preload-cache/\n.pub/\nbuild/\nflutter_*.png\nlinked_*.ds\nunlinked.ds\nunlinked_spec.ds\n\n# Android related\n**/android/**/gradle-wrapper.jar\n.gradle/\n**/android/captures/\n**/android/gradlew\n**/android/gradlew.bat\n**/android/local.properties\n**/android/**/GeneratedPluginRegistrant.java\n**/android/key.properties\n*.jks\n\n# iOS/XCode related\n**/ios/**/*.mode1v3\n**/ios/**/*.mode2v3\n**/ios/**/*.moved-aside\n**/ios/**/*.pbxuser\n**/ios/**/*.perspectivev3\n**/ios/**/*sync/\n**/ios/**/.sconsign.dblite\n**/ios/**/.tags*\n**/ios/**/.vagrant/\n**/ios/**/DerivedData/\n**/ios/**/Icon?\n**/ios/**/Pods/\n**/ios/**/.symlinks/\n**/ios/**/profile\n**/ios/**/xcuserdata\n**/ios/.generated/\n**/ios/Flutter/.last_build_id\n**/ios/Flutter/App.framework"}, {"id": "Flutter.gitignore_2", "file": "Flutter.gitignore", "content": "**/ios/**/xcuserdata\n**/ios/.generated/\n**/ios/Flutter/.last_build_id\n**/ios/Flutter/App.framework\n**/ios/Flutter/Flutter.framework\n**/ios/Flutter/Flutter.podspec\n**/ios/Flutter/Generated.xcconfig\n**/ios/Flutter/ephemeral\n**/ios/Flutter/app.flx\n**/ios/Flutter/app.zip\n**/ios/Flutter/flutter_assets/\n**/ios/Flutter/flutter_export_environment.sh\n**/ios/ServiceDefinitions.json\n**/ios/Runner/GeneratedPluginRegistrant.*\n\n# macOS\n**/Flutter/ephemeral/\n**/Pods/\n**/macos/Flutter/GeneratedPluginRegistrant.swift\n**/macos/Flutter/ephemeral\n**/xcuserdata/\n\n# Windows\n**/windows/flutter/generated_plugin_registrant.cc\n**/windows/flutter/generated_plugin_registrant.h\n**/windows/flutter/generated_plugins.cmake\n\n# Linux\n**/linux/flutter/generated_plugin_registrant.cc"}, {"id": "Flutter.gitignore_3", "file": "Flutter.gitignore", "content": "**/windows/flutter/generated_plugins.cmake\n\n# Linux\n**/linux/flutter/generated_plugin_registrant.cc\n**/linux/flutter/generated_plugin_registrant.h\n**/linux/flutter/generated_plugins.cmake\n\n# Coverage\ncoverage/\n\n# Symbols\napp.*.symbols\n\n# Exceptions to above rules.\n!**/ios/**/default.mode1v3\n!**/ios/**/default.mode2v3\n!**/ios/**/default.pbxuser\n!**/ios/**/default.perspectivev3\n!/packages/flutter_tools/test/data/dart_dependencies_test/**/.packages\n!/dev/ci/**/Gemfile.lock"}, {"id": "ForceDotCom.gitignore_0", "file": "ForceDotCom.gitignore", "content": "================================================\n.project\n.settings\nsalesforce.schema\nReferenced Packages"}, {"id": "Fortran.gitignore_0", "file": "Fortran.gitignore", "content": "================================================\nC++.gitignore"}, {"id": "FuelPHP.gitignore_0", "file": "FuelPHP.gitignore", "content": "================================================\n# the composer package lock file and install directory\n# Commit your application's lock file http://getcomposer.org/doc/01-basic-usage.md#composer-lock-the-lock-file\n# You may choose to ignore a library lock file http://getcomposer.org/doc/02-libraries.md#lock-file\n# /composer.lock\n/fuel/vendor\n\n# the fuelphp document\n/docs/\n\n# you may install these packages with `oil package`.\n# http://fuelphp.com/docs/packages/oil/package.html\n# /fuel/packages/auth/\n# /fuel/packages/email/\n# /fuel/packages/oil/\n# /fuel/packages/orm/\n# /fuel/packages/parser/\n\n# dynamically generated files\n/fuel/app/logs/*/*/*\n/fuel/app/cache/*/*\n/fuel/app/config/crypt.php"}, {"id": "Gcov.gitignore_0", "file": "Gcov.gitignore", "content": "================================================\n# gcc coverage testing tool files\n\n*.gcno\n*.gcda\n*.gcov"}, {"id": "GitBook.gitignore_0", "file": "GitBook.gitignore", "content": "================================================\n# Node rules:\n## Grunt intermediate storage (http://gruntjs.com/creating-plugins#storing-task-files)\n.grunt\n\n## Dependency directory\n## Commenting this out is preferred by some people, see\n## https://docs.npmjs.com/misc/faq#should-i-check-my-node_modules-folder-into-git\nnode_modules\n\n# Book build output\n_book\n\n# eBook build output\n*.epub\n*.mobi\n*.pdf"}, {"id": "GitHubPages.gitignore_0", "file": "GitHubPages.gitignore", "content": "================================================\n# This .gitignore is appropriate for repositories deployed to GitHub Pages and using\n# a Gemfile as specified at https://github.com/github/pages-gem#conventional\n\n# Basic Jekyll gitignores (synchronize to Jekyll.gitignore)\n_site/\n.sass-cache/\n.jekyll-cache/\n.jekyll-metadata\n\n# Additional Ruby/bundler ignore for when you run: bundle install\n/vendor\n\n# Specific ignore for GitHub Pages\n# GitHub Pages will always use its own deployed version of pages-gem\n# This means GitHub Pages will NOT use your Gemfile.lock and therefore it is\n# counterproductive to check this file into the repository.\n# Details at https://github.com/github/pages-gem/issues/768\nGemfile.lock"}, {"id": "Gleam.gitignore_0", "file": "Gleam.gitignore", "content": "================================================\n*.beam\n*.ez\n/build\nerl_crash.dump"}, {"id": "Go.gitignore_0", "file": "Go.gitignore", "content": "================================================\n# If you prefer the allow list template instead of the deny list, see community template:\n# https://github.com/github/gitignore/blob/main/community/Golang/Go.AllowList.gitignore\n#\n# Binaries for programs and plugins\n*.exe\n*.exe~\n*.dll\n*.so\n*.dylib\n\n# Test binary, built with `go test -c`\n*.test\n\n# Code coverage profiles and other test artifacts\n*.out\ncoverage.*\n*.coverprofile\nprofile.cov\n\n# Dependency directories (remove the comment below to include it)\n# vendor/\n\n# Go workspace file\ngo.work\ngo.work.sum\n\n# env file\n.env\n\n# Editor/IDE\n# .idea/\n# .vscode/"}, {"id": "Godot.gitignore_0", "file": "Godot.gitignore", "content": "================================================\n# Godot 4+ specific ignores\n.godot/\n.nomedia\n\n# Godot-specific ignores\n.import/\nexport.cfg\nexport_credentials.cfg\n*.tmp\n\n# Imported translations (automatically generated from CSV files)\n*.translation\n\n# Mono-specific ignores\n.mono/\ndata_*/\nmono_crash.*.json"}, {"id": "Gradle.gitignore_0", "file": "Gradle.gitignore", "content": "================================================\n.gradle\n**/build/\n!**/src/**/build/\n\n# Ignore Gradle GUI config\ngradle-app.setting\n\n# Avoid ignoring Gradle wrapper jar file (.jar files are usually ignored)\n!gradle-wrapper.jar\n\n# Avoid ignore Gradle wrappper properties\n!gradle-wrapper.properties\n\n# Cache of project\n.gradletasknamecache\n\n# Eclipse Gradle plugin generated files\n# Eclipse Core\n.project\n# JDT-specific (Eclipse Java Development Tools)\n.classpath"}, {"id": "Grails.gitignore_0", "file": "Grails.gitignore", "content": "================================================\n# .gitignore for Grails 1.2 and 1.3\n# Although this should work for most versions of grails, it is\n# suggested that you use the \"grails integrate-with --git\" command\n# to generate your .gitignore file.\n\n# web application files\n/web-app/WEB-INF/classes\n\n# default HSQL database files for production mode\n/prodDb.*\n\n# general HSQL database files\n*Db.properties\n*Db.script\n\n# logs\n/stacktrace.log\n/test/reports\n/logs\n\n# project release file\n/*.war\n\n# plugin release files\n/*.zip\n/plugin.xml\n\n# older plugin install locations\n/plugins\n/web-app/plugins\n\n# \"temporary\" build files\n/target"}, {"id": "GWT.gitignore_0", "file": "GWT.gitignore", "content": "================================================\n*.class\n\n# Package Files #\n*.jar\n*.war\n\n# gwt caches and compiled units #\nwar/gwt_bree/\ngwt-unitCache/\n\n# boilerplate generated classes #\n.apt_generated/\n\n# more caches and things from deploy #\nwar/WEB-INF/deploy/\nwar/WEB-INF/classes/\n\n#compilation logs\n.gwt/\n\n#gwt junit compilation files\nwww-test/\n\n#old GWT (1.5) created this dir\n.gwt-tmp/"}, {"id": "Haskell.gitignore_0", "file": "Haskell.gitignore", "content": "================================================\ndist\ndist-*\ncabal-dev\n*.o\n*.hi\n*.hie\n*.chi\n*.chs.h\n*.dyn_o\n*.dyn_hi\n.hpc\n.hsenv\n.cabal-sandbox/\ncabal.sandbox.config\n*.prof\n*.aux\n*.hp\n*.eventlog\n.stack-work/\ncabal.project.local\ncabal.project.local~\n.HTF/\n.ghc.environment.*"}, {"id": "Haxe.gitignore_0", "file": "Haxe.gitignore", "content": "================================================\n.haxelib/\n.haxelsp/recording/\ndump/"}, {"id": "HIP.gitignore_0", "file": "HIP.gitignore", "content": "================================================\n# HIP.gitignore\n# GitHub gitignore template for AMD HIP (ROCm) projects\n#\n# Reference:\n#   Official AMD ROCm HIP .gitignore: https://github.com/ROCm/hip/blob/amd-staging/.gitignore\n\n# 1. Build directories and files\n/build/                          # common build directory\n/CMakeFiles/                     # CMake internal files\n/CMakeCache.txt                  # CMake cache file\n/Makefile                        # autogenerated Makefile\n/cmake_install.cmake             # install script\n/install_manifest.txt            # install manifest list\n*.ninja-dep                      # Ninja dependency files\n*.ninja_log                      # Ninja log files\nmeson-logs/                      # Meson log directory"}, {"id": "HIP.gitignore_1", "file": "HIP.gitignore", "content": "meson-logs/                      # Meson log directory\n\n# 2. Compilation outputs and intermediates\n*.o                              # object files\n*.obj                            # Windows object files\n*.so                             # shared libraries\n*.a                              # static librarie\n*.d                              # dependency files\n*.gch                            # precompiled headers\n*.ii                             # preprocessed output\n*.ii.cpp                         # C++ preprocessed output\n*.out                            # generic executable outputs\n*.exe                            # Windows executables\n\n# 3. HIP/ROCm specific binaries and intermediates\n*.hsaco                          # ROCm compiled binary"}, {"id": "HIP.gitignore_2", "file": "HIP.gitignore", "content": "*.hsaco                          # ROCm compiled binary\n*.s                              # assembly output\n*.kernels.cpp                    # autogenerated kernel sources\n*.hip.cpp.*                      # hipcc intermediate outputs\n\n# 4. Official sample binaries and tutorial outputs\nbin/hipInfo                      # sample binary\nbin/hipBusBandwidth              # sample binary\nbin/hipDispatchLatency           # sample binary\nbin/hipify-clang                 # sample tool\nsamples/**/*.out                 # tutorial outputs\nsamples/**/*.code                # ISA/code dumps\nsamples/**/*.hsaco               # compiled binaries\nsamples/**/*.co                  # kernel code outputs\n\n# 5. Tags, logs and test outputs\ntags                             # ctags index"}, {"id": "HIP.gitignore_3", "file": "HIP.gitignore", "content": "# 5. Tags, logs and test outputs\ntags                             # ctags index\n*.log                            # log files\n/tests_output/                   # custom test output directory\n/samples_output/                 # custom sample output directory"}, {"id": "IAR.gitignore_0", "file": "IAR.gitignore", "content": "================================================\n# Compiled binaries\n*.o\n*.bin\n*.elf\n*.hex\n*.map\n*.out\n*.obj\n\n# Trash\n*.bak\nthumbs.db\n*.~*\n\n# IAR Settings\n**/settings/*.crun\n**/settings/*.dbgdt\n**/settings/*.cspy\n**/settings/*.cspy.*\n**/settings/*.xcl\n**/settings/*.dni\n**/settings/*.wsdt\n**/settings/*.wspos\n\n# IAR Debug Exe\n**/Exe/*.sim\n\n# IAR Debug Obj\n**/Obj/*.pbd\n**/Obj/*.pbd.*\n**/Obj/*.pbi\n**/Obj/*.pbi.*\n\n# IAR project \"Debug\" directory\nDebug/\n\n# IAR project \"Release\" directory\nRelease/\n\n# IAR project settings directory\nsettings/\n\n# IAR backup files\nBackup*\n\n# IAR .dep files\n*.dep"}, {"id": "Idris.gitignore_0", "file": "Idris.gitignore", "content": "================================================\n# Idris 2\n*.ttc\n*.ttm\n\n# Idris 1\n*.ibc\n*.o"}, {"id": "IGORPro.gitignore_0", "file": "IGORPro.gitignore", "content": "================================================\n# Avoid including Experiment files: they can be created and edited locally to test the ipf files\n*.pxp\n*.pxt\n*.uxp\n*.uxt"}, {"id": "Java.gitignore_0", "file": "Java.gitignore", "content": "================================================\n# Compiled class file\n*.class\n\n# Log file\n*.log\n\n# BlueJ files\n*.ctxt\n\n# Mobile Tools for Java (J2ME)\n.mtj.tmp/\n\n# Package Files #\n*.jar\n*.war\n*.nar\n*.ear\n*.zip\n*.tar.gz\n*.rar\n\n# virtual machine crash logs, see http://www.java.com/en/download/help/error_hotspot.xml\nhs_err_pid*\nreplay_pid*"}, {"id": "JBoss.gitignore_0", "file": "JBoss.gitignore", "content": "================================================\njboss/server/all/deploy/project.ext\njboss/server/default/deploy/project.ext\njboss/server/minimal/deploy/project.ext\njboss/server/all/log/*.log\njboss/server/all/tmp/**/*\njboss/server/all/data/**/*\njboss/server/all/work/**/*\njboss/server/default/log/*.log\njboss/server/default/tmp/**/*\njboss/server/default/data/**/*\njboss/server/default/work/**/*\njboss/server/minimal/log/*.log\njboss/server/minimal/tmp/**/*\njboss/server/minimal/data/**/*\njboss/server/minimal/work/**/*\n\n# deployed package files #\n\n*.DEPLOYED"}, {"id": "Jekyll.gitignore_0", "file": "Jekyll.gitignore", "content": "================================================\n_site/\n.sass-cache/\n.jekyll-cache/\n.jekyll-metadata\n# Ignore folders generated by Bundler\n.bundle/\nvendor/"}, {"id": "JENKINS_HOME.gitignore_0", "file": "JENKINS_HOME.gitignore", "content": "================================================\n# Learn more about Jenkins and JENKINS_HOME directory for which this file is\n# intended.\n#\n#  http://jenkins-ci.org/\n#  https://wiki.jenkins-ci.org/display/JENKINS/Administering+Jenkins\n#\n# Note: secret.key is purposefully not tracked by git. This should be backed up\n# separately because configs may contain secrets which were encrypted using the\n# secret.key.  To back up secrets use 'tar -czf /tmp/secrets.tgz secret*' and\n# save the file separate from your repository.  If you want secrets backed up\n# with configuration, then see the bottom of this file for an example.\n\n# Ignore all JENKINS_HOME except jobs directory, root xml config, and\n# .gitignore file.\n/*\n!/jobs\n!/.gitignore\n!/*.xml"}, {"id": "JENKINS_HOME.gitignore_1", "file": "JENKINS_HOME.gitignore", "content": "# .gitignore file.\n/*\n!/jobs\n!/.gitignore\n!/*.xml\n\n# Ignore all files in jobs subdirectories except for folders.\n# Note: git doesn't track folders, only file content.\njobs/**\n!jobs/**/\n\n# Uncomment the following line to save next build numbers with config.\n\n#!jobs/**/nextBuildNumber\n\n# For performance reasons, we want to ignore builds in Jenkins jobs because it\n# contains many tiny files on large installations.  This can impact git\n# performance when running even basic commands like 'git status'.\nbuilds\nindexing\n\n# Exclude only config.xml files in repository subdirectories.\n!config.xml\n\n# Don't track workspaces (when users build on the master).\njobs/**/*workspace\n\n# Security warning: If secrets are included with your configuration, then an"}, {"id": "JENKINS_HOME.gitignore_2", "file": "JENKINS_HOME.gitignore", "content": "jobs/**/*workspace\n\n# Security warning: If secrets are included with your configuration, then an\n# adversary will be able to decrypt all encrypted secrets within Jenkins\n# config.  Including secrets is a bad practice, but the example is included in\n# case someone still wants it for convenience.  Uncomment the following line to\n# include secrets for decryption with repository configuration in Git.\n\n#!/secret*\n\n# As a result, only Jenkins settings and job config.xml files in JENKINS_HOME\n# will be tracked by git."}, {"id": "Joomla.gitignore_0", "file": "Joomla.gitignore", "content": "================================================\n/.htaccess\n/administrator/cache/*\n/administrator/components/com_actionlogs/*\n/administrator/components/com_admin/*\n/administrator/components/com_ajax/*\n/administrator/components/com_associations/*\n/administrator/components/com_banners/*\n/administrator/components/com_cache/*\n/administrator/components/com_categories/*\n/administrator/components/com_checkin/*\n/administrator/components/com_config/*\n/administrator/components/com_contact/*\n/administrator/components/com_content/*\n/administrator/components/com_contenthistory/*\n/administrator/components/com_cpanel/*\n/administrator/components/com_fields/*\n/administrator/components/com_finder/*\n/administrator/components/com_installer/*\n/administrator/components/com_joomlaupdate/*"}, {"id": "Joomla.gitignore_1", "file": "Joomla.gitignore", "content": "/administrator/components/com_installer/*\n/administrator/components/com_joomlaupdate/*\n/administrator/components/com_languages/*\n/administrator/components/com_login/*\n/administrator/components/com_media/*\n/administrator/components/com_menus/*\n/administrator/components/com_messages/*\n/administrator/components/com_modules/*\n/administrator/components/com_newsfeeds/*\n/administrator/components/com_plugins/*\n/administrator/components/com_postinstall/*\n/administrator/components/com_privacy/*\n/administrator/components/com_redirect/*\n/administrator/components/com_search/*\n/administrator/components/com_tags/*\n/administrator/components/com_templates/*\n/administrator/components/com_users/*\n/administrator/help/*\n/administrator/includes/*\n/administrator/index.php"}, {"id": "Joomla.gitignore_2", "file": "Joomla.gitignore", "content": "/administrator/help/*\n/administrator/includes/*\n/administrator/index.php\n/administrator/language/en-GB/en-GB.com_actionlogs.ini\n/administrator/language/en-GB/en-GB.com_actionlogs.sys.ini\n/administrator/language/en-GB/en-GB.com_admin.ini\n/administrator/language/en-GB/en-GB.com_admin.sys.ini\n/administrator/language/en-GB/en-GB.com_ajax.ini\n/administrator/language/en-GB/en-GB.com_ajax.sys.ini\n/administrator/language/en-GB/en-GB.com_associations.ini\n/administrator/language/en-GB/en-GB.com_associations.sys.ini\n/administrator/language/en-GB/en-GB.com_banners.ini\n/administrator/language/en-GB/en-GB.com_banners.sys.ini\n/administrator/language/en-GB/en-GB.com_cache.ini\n/administrator/language/en-GB/en-GB.com_cache.sys.ini\n/administrator/language/en-GB/en-GB.com_categories.ini"}, {"id": "Joomla.gitignore_3", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.com_categories.ini\n/administrator/language/en-GB/en-GB.com_categories.sys.ini\n/administrator/language/en-GB/en-GB.com_checkin.ini\n/administrator/language/en-GB/en-GB.com_checkin.sys.ini\n/administrator/language/en-GB/en-GB.com_config.ini\n/administrator/language/en-GB/en-GB.com_config.sys.ini\n/administrator/language/en-GB/en-GB.com_contact.ini\n/administrator/language/en-GB/en-GB.com_contact.sys.ini\n/administrator/language/en-GB/en-GB.com_content.ini\n/administrator/language/en-GB/en-GB.com_content.sys.ini\n/administrator/language/en-GB/en-GB.com_contenthistory.ini\n/administrator/language/en-GB/en-GB.com_contenthistory.sys.ini\n/administrator/language/en-GB/en-GB.com_cpanel.ini\n/administrator/language/en-GB/en-GB.com_cpanel.sys.ini"}, {"id": "Joomla.gitignore_4", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.com_cpanel.sys.ini\n/administrator/language/en-GB/en-GB.com_fields.ini\n/administrator/language/en-GB/en-GB.com_fields.sys.ini\n/administrator/language/en-GB/en-GB.com_finder.ini\n/administrator/language/en-GB/en-GB.com_finder.sys.ini\n/administrator/language/en-GB/en-GB.com_installer.ini\n/administrator/language/en-GB/en-GB.com_installer.sys.ini\n/administrator/language/en-GB/en-GB.com_joomlaupdate.ini\n/administrator/language/en-GB/en-GB.com_joomlaupdate.sys.ini\n/administrator/language/en-GB/en-GB.com_languages.ini\n/administrator/language/en-GB/en-GB.com_languages.sys.ini\n/administrator/language/en-GB/en-GB.com_login.ini\n/administrator/language/en-GB/en-GB.com_login.sys.ini\n/administrator/language/en-GB/en-GB.com_mailto.sys.ini"}, {"id": "Joomla.gitignore_5", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.com_mailto.sys.ini\n/administrator/language/en-GB/en-GB.com_media.ini\n/administrator/language/en-GB/en-GB.com_media.sys.ini\n/administrator/language/en-GB/en-GB.com_menus.ini\n/administrator/language/en-GB/en-GB.com_menus.sys.ini\n/administrator/language/en-GB/en-GB.com_messages.ini\n/administrator/language/en-GB/en-GB.com_messages.sys.ini\n/administrator/language/en-GB/en-GB.com_modules.ini\n/administrator/language/en-GB/en-GB.com_modules.sys.ini\n/administrator/language/en-GB/en-GB.com_newsfeeds.ini\n/administrator/language/en-GB/en-GB.com_newsfeeds.sys.ini\n/administrator/language/en-GB/en-GB.com_plugins.ini\n/administrator/language/en-GB/en-GB.com_plugins.sys.ini\n/administrator/language/en-GB/en-GB.com_postinstall.ini"}, {"id": "Joomla.gitignore_6", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.com_postinstall.ini\n/administrator/language/en-GB/en-GB.com_postinstall.sys.ini\n/administrator/language/en-GB/en-GB.com_privacy.ini\n/administrator/language/en-GB/en-GB.com_privacy.sys.ini\n/administrator/language/en-GB/en-GB.com_redirect.ini\n/administrator/language/en-GB/en-GB.com_redirect.sys.ini\n/administrator/language/en-GB/en-GB.com_search.ini\n/administrator/language/en-GB/en-GB.com_search.sys.ini\n/administrator/language/en-GB/en-GB.com_tags.ini\n/administrator/language/en-GB/en-GB.com_tags.sys.ini\n/administrator/language/en-GB/en-GB.com_templates.ini\n/administrator/language/en-GB/en-GB.com_templates.sys.ini\n/administrator/language/en-GB/en-GB.com_users.ini\n/administrator/language/en-GB/en-GB.com_users.sys.ini"}, {"id": "Joomla.gitignore_7", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.com_users.sys.ini\n/administrator/language/en-GB/en-GB.com_weblinks.ini\n/administrator/language/en-GB/en-GB.com_weblinks.sys.ini\n/administrator/language/en-GB/en-GB.com_wrapper.ini\n/administrator/language/en-GB/en-GB.com_wrapper.sys.ini\n/administrator/language/en-GB/en-GB.ini\n/administrator/language/en-GB/en-GB.lib_joomla.ini\n/administrator/language/en-GB/en-GB.localise.php\n/administrator/language/en-GB/en-GB.mod_custom.ini\n/administrator/language/en-GB/en-GB.mod_custom.sys.ini\n/administrator/language/en-GB/en-GB.mod_feed.ini\n/administrator/language/en-GB/en-GB.mod_feed.sys.ini\n/administrator/language/en-GB/en-GB.mod_latest.ini\n/administrator/language/en-GB/en-GB.mod_latest.sys.ini\n/administrator/language/en-GB/en-GB.mod_latestactions.ini"}, {"id": "Joomla.gitignore_8", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.mod_latestactions.ini\n/administrator/language/en-GB/en-GB.mod_latestactions.sys.ini\n/administrator/language/en-GB/en-GB.mod_logged.ini\n/administrator/language/en-GB/en-GB.mod_logged.sys.ini\n/administrator/language/en-GB/en-GB.mod_login.ini\n/administrator/language/en-GB/en-GB.mod_login.sys.ini\n/administrator/language/en-GB/en-GB.mod_menu.ini\n/administrator/language/en-GB/en-GB.mod_menu.sys.ini\n/administrator/language/en-GB/en-GB.mod_multilangstatus.ini\n/administrator/language/en-GB/en-GB.mod_multilangstatus.sys.ini\n/administrator/language/en-GB/en-GB.mod_online.ini\n/administrator/language/en-GB/en-GB.mod_online.sys.ini\n/administrator/language/en-GB/en-GB.mod_popular.ini\n/administrator/language/en-GB/en-GB.mod_popular.sys.ini"}, {"id": "Joomla.gitignore_9", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.mod_popular.sys.ini\n/administrator/language/en-GB/en-GB.mod_privacy_dashboard.ini\n/administrator/language/en-GB/en-GB.mod_privacy_dashboard.sys.ini\n/administrator/language/en-GB/en-GB.mod_quickicon.ini\n/administrator/language/en-GB/en-GB.mod_quickicon.sys.ini\n/administrator/language/en-GB/en-GB.mod_sampledata.ini\n/administrator/language/en-GB/en-GB.mod_sampledata.sys.ini\n/administrator/language/en-GB/en-GB.mod_stats_admin.ini\n/administrator/language/en-GB/en-GB.mod_stats_admin.sys.ini\n/administrator/language/en-GB/en-GB.mod_status.ini\n/administrator/language/en-GB/en-GB.mod_status.sys.ini\n/administrator/language/en-GB/en-GB.mod_submenu.ini\n/administrator/language/en-GB/en-GB.mod_submenu.sys.ini\n/administrator/language/en-GB/en-GB.mod_title.ini"}, {"id": "Joomla.gitignore_10", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.mod_title.ini\n/administrator/language/en-GB/en-GB.mod_title.sys.ini\n/administrator/language/en-GB/en-GB.mod_toolbar.ini\n/administrator/language/en-GB/en-GB.mod_toolbar.sys.ini\n/administrator/language/en-GB/en-GB.mod_unread.ini\n/administrator/language/en-GB/en-GB.mod_unread.sys.ini\n/administrator/language/en-GB/en-GB.mod_version.ini\n/administrator/language/en-GB/en-GB.mod_version.sys.ini\n/administrator/language/en-GB/en-GB.plg_actionlog_joomla.ini\n/administrator/language/en-GB/en-GB.plg_actionlog_joomla.sys.ini\n/administrator/language/en-GB/en-GB.plg_authentication_cookie.ini\n/administrator/language/en-GB/en-GB.plg_authentication_cookie.sys.ini\n/administrator/language/en-GB/en-GB.plg_authentication_example.ini"}, {"id": "Joomla.gitignore_11", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_authentication_example.ini\n/administrator/language/en-GB/en-GB.plg_authentication_example.sys.ini\n/administrator/language/en-GB/en-GB.plg_authentication_gmail.ini\n/administrator/language/en-GB/en-GB.plg_authentication_gmail.sys.ini\n/administrator/language/en-GB/en-GB.plg_authentication_joomla.ini\n/administrator/language/en-GB/en-GB.plg_authentication_joomla.sys.ini\n/administrator/language/en-GB/en-GB.plg_authentication_ldap.ini\n/administrator/language/en-GB/en-GB.plg_authentication_ldap.sys.ini\n/administrator/language/en-GB/en-GB.plg_captcha_recaptcha.ini\n/administrator/language/en-GB/en-GB.plg_captcha_recaptcha.sys.ini\n/administrator/language/en-GB/en-GB.plg_captcha_recaptcha_invisible.ini"}, {"id": "Joomla.gitignore_12", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_captcha_recaptcha_invisible.ini\n/administrator/language/en-GB/en-GB.plg_captcha_recaptcha_invisible.sys.ini\n/administrator/language/en-GB/en-GB.plg_content_confirmconsent.ini\n/administrator/language/en-GB/en-GB.plg_content_confirmconsent.sys.ini\n/administrator/language/en-GB/en-GB.plg_content_contact.ini\n/administrator/language/en-GB/en-GB.plg_content_contact.sys.ini\n/administrator/language/en-GB/en-GB.plg_content_emailcloak.ini\n/administrator/language/en-GB/en-GB.plg_content_emailcloak.sys.ini\n/administrator/language/en-GB/en-GB.plg_content_fields.ini\n/administrator/language/en-GB/en-GB.plg_content_fields.sys.ini\n/administrator/language/en-GB/en-GB.plg_content_finder.ini\n/administrator/language/en-GB/en-GB.plg_content_finder.sys.ini"}, {"id": "Joomla.gitignore_13", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_content_finder.sys.ini\n/administrator/language/en-GB/en-GB.plg_content_geshi.ini\n/administrator/language/en-GB/en-GB.plg_content_geshi.sys.ini\n/administrator/language/en-GB/en-GB.plg_content_joomla.ini\n/administrator/language/en-GB/en-GB.plg_content_joomla.sys.ini\n/administrator/language/en-GB/en-GB.plg_content_loadmodule.ini\n/administrator/language/en-GB/en-GB.plg_content_loadmodule.sys.ini\n/administrator/language/en-GB/en-GB.plg_content_pagebreak.ini\n/administrator/language/en-GB/en-GB.plg_content_pagebreak.sys.ini\n/administrator/language/en-GB/en-GB.plg_content_pagenavigation.ini\n/administrator/language/en-GB/en-GB.plg_content_pagenavigation.sys.ini\n/administrator/language/en-GB/en-GB.plg_content_vote.ini"}, {"id": "Joomla.gitignore_14", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_content_vote.ini\n/administrator/language/en-GB/en-GB.plg_content_vote.sys.ini\n/administrator/language/en-GB/en-GB.plg_editors-xtd_article.ini\n/administrator/language/en-GB/en-GB.plg_editors-xtd_article.sys.ini\n/administrator/language/en-GB/en-GB.plg_editors-xtd_contact.ini\n/administrator/language/en-GB/en-GB.plg_editors-xtd_contact.sys.ini\n/administrator/language/en-GB/en-GB.plg_editors-xtd_fields.ini\n/administrator/language/en-GB/en-GB.plg_editors-xtd_fields.sys.ini\n/administrator/language/en-GB/en-GB.plg_editors-xtd_image.ini\n/administrator/language/en-GB/en-GB.plg_editors-xtd_image.sys.ini\n/administrator/language/en-GB/en-GB.plg_editors-xtd_menu.ini\n/administrator/language/en-GB/en-GB.plg_editors-xtd_menu.sys.ini"}, {"id": "Joomla.gitignore_15", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_editors-xtd_menu.sys.ini\n/administrator/language/en-GB/en-GB.plg_editors-xtd_module.ini\n/administrator/language/en-GB/en-GB.plg_editors-xtd_module.sys.ini\n/administrator/language/en-GB/en-GB.plg_editors-xtd_pagebreak.ini\n/administrator/language/en-GB/en-GB.plg_editors-xtd_pagebreak.sys.ini\n/administrator/language/en-GB/en-GB.plg_editors-xtd_readmore.ini\n/administrator/language/en-GB/en-GB.plg_editors-xtd_readmore.sys.ini\n/administrator/language/en-GB/en-GB.plg_editors_codemirror.ini\n/administrator/language/en-GB/en-GB.plg_editors_codemirror.sys.ini\n/administrator/language/en-GB/en-GB.plg_editors_none.ini\n/administrator/language/en-GB/en-GB.plg_editors_none.sys.ini\n/administrator/language/en-GB/en-GB.plg_editors_tinymce.ini"}, {"id": "Joomla.gitignore_16", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_editors_tinymce.ini\n/administrator/language/en-GB/en-GB.plg_editors_tinymce.sys.ini\n/administrator/language/en-GB/en-GB.plg_extension_joomla.ini\n/administrator/language/en-GB/en-GB.plg_extension_joomla.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_calendar.ini\n/administrator/language/en-GB/en-GB.plg_fields_calendar.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_checkboxes.ini\n/administrator/language/en-GB/en-GB.plg_fields_checkboxes.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_color.ini\n/administrator/language/en-GB/en-GB.plg_fields_color.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_editor.ini\n/administrator/language/en-GB/en-GB.plg_fields_editor.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_image.ini"}, {"id": "Joomla.gitignore_17", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_fields_image.ini\n/administrator/language/en-GB/en-GB.plg_fields_image.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_imagelist.ini\n/administrator/language/en-GB/en-GB.plg_fields_imagelist.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_integer.ini\n/administrator/language/en-GB/en-GB.plg_fields_integer.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_list.ini\n/administrator/language/en-GB/en-GB.plg_fields_list.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_media.ini\n/administrator/language/en-GB/en-GB.plg_fields_media.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_radio.ini\n/administrator/language/en-GB/en-GB.plg_fields_radio.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_repeatable.ini"}, {"id": "Joomla.gitignore_18", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_fields_repeatable.ini\n/administrator/language/en-GB/en-GB.plg_fields_repeatable.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_sql.ini\n/administrator/language/en-GB/en-GB.plg_fields_sql.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_text.ini\n/administrator/language/en-GB/en-GB.plg_fields_text.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_textarea.ini\n/administrator/language/en-GB/en-GB.plg_fields_textarea.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_url.ini\n/administrator/language/en-GB/en-GB.plg_fields_url.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_user.ini\n/administrator/language/en-GB/en-GB.plg_fields_user.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_usergrouplist.ini"}, {"id": "Joomla.gitignore_19", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_fields_usergrouplist.ini\n/administrator/language/en-GB/en-GB.plg_fields_usergrouplist.sys.ini\n/administrator/language/en-GB/en-GB.plg_finder_categories.ini\n/administrator/language/en-GB/en-GB.plg_finder_categories.sys.ini\n/administrator/language/en-GB/en-GB.plg_finder_contacts.ini\n/administrator/language/en-GB/en-GB.plg_finder_contacts.sys.ini\n/administrator/language/en-GB/en-GB.plg_finder_content.ini\n/administrator/language/en-GB/en-GB.plg_finder_content.sys.ini\n/administrator/language/en-GB/en-GB.plg_finder_newsfeeds.ini\n/administrator/language/en-GB/en-GB.plg_finder_newsfeeds.sys.ini\n/administrator/language/en-GB/en-GB.plg_finder_tags.ini\n/administrator/language/en-GB/en-GB.plg_finder_tags.sys.ini"}, {"id": "Joomla.gitignore_20", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_finder_tags.sys.ini\n/administrator/language/en-GB/en-GB.plg_finder_weblinks.ini\n/administrator/language/en-GB/en-GB.plg_finder_weblinks.sys.ini\n/administrator/language/en-GB/en-GB.plg_installer_folderinstaller.ini\n/administrator/language/en-GB/en-GB.plg_installer_folderinstaller.sys.ini\n/administrator/language/en-GB/en-GB.plg_installer_packageinstaller.ini\n/administrator/language/en-GB/en-GB.plg_installer_packageinstaller.sys.ini\n/administrator/language/en-GB/en-GB.plg_installer_urlinstaller.ini\n/administrator/language/en-GB/en-GB.plg_installer_urlinstaller.sys.ini\n/administrator/language/en-GB/en-GB.plg_installer_webinstaller.ini\n/administrator/language/en-GB/en-GB.plg_installer_webinstaller.sys.ini"}, {"id": "Joomla.gitignore_21", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_installer_webinstaller.sys.ini\n/administrator/language/en-GB/en-GB.plg_privacy_actionlogs.ini\n/administrator/language/en-GB/en-GB.plg_privacy_actionlogs.sys.ini\n/administrator/language/en-GB/en-GB.plg_privacy_consents.ini\n/administrator/language/en-GB/en-GB.plg_privacy_consents.sys.ini\n/administrator/language/en-GB/en-GB.plg_privacy_contact.ini\n/administrator/language/en-GB/en-GB.plg_privacy_contact.sys.ini\n/administrator/language/en-GB/en-GB.plg_privacy_content.ini\n/administrator/language/en-GB/en-GB.plg_privacy_content.sys.ini\n/administrator/language/en-GB/en-GB.plg_privacy_message.ini\n/administrator/language/en-GB/en-GB.plg_privacy_message.sys.ini\n/administrator/language/en-GB/en-GB.plg_privacy_user.ini"}, {"id": "Joomla.gitignore_22", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_privacy_user.ini\n/administrator/language/en-GB/en-GB.plg_privacy_user.sys.ini\n/administrator/language/en-GB/en-GB.plg_quickicon_extensionupdate.ini\n/administrator/language/en-GB/en-GB.plg_quickicon_extensionupdate.sys.ini\n/administrator/language/en-GB/en-GB.plg_quickicon_joomlaupdate.ini\n/administrator/language/en-GB/en-GB.plg_quickicon_joomlaupdate.sys.ini\n/administrator/language/en-GB/en-GB.plg_quickicon_phpversioncheck.ini\n/administrator/language/en-GB/en-GB.plg_quickicon_phpversioncheck.sys.ini\n/administrator/language/en-GB/en-GB.plg_quickicon_privacycheck.ini\n/administrator/language/en-GB/en-GB.plg_quickicon_privacycheck.sys.ini\n/administrator/language/en-GB/en-GB.plg_sampledata_blog.ini"}, {"id": "Joomla.gitignore_23", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_sampledata_blog.ini\n/administrator/language/en-GB/en-GB.plg_sampledata_blog.sys.ini\n/administrator/language/en-GB/en-GB.plg_search_categories.ini\n/administrator/language/en-GB/en-GB.plg_search_categories.sys.ini\n/administrator/language/en-GB/en-GB.plg_search_contacts.ini\n/administrator/language/en-GB/en-GB.plg_search_contacts.sys.ini\n/administrator/language/en-GB/en-GB.plg_search_content.ini\n/administrator/language/en-GB/en-GB.plg_search_content.sys.ini\n/administrator/language/en-GB/en-GB.plg_search_newsfeeds.ini\n/administrator/language/en-GB/en-GB.plg_search_newsfeeds.sys.ini\n/administrator/language/en-GB/en-GB.plg_search_tags.ini\n/administrator/language/en-GB/en-GB.plg_search_tags.sys.ini\n/administrator/language/en-GB/en-GB.plg_search_weblinks.ini"}, {"id": "Joomla.gitignore_24", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_search_weblinks.ini\n/administrator/language/en-GB/en-GB.plg_search_weblinks.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_actionlogs.ini\n/administrator/language/en-GB/en-GB.plg_system_actionlogs.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_cache.ini\n/administrator/language/en-GB/en-GB.plg_system_cache.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_debug.ini\n/administrator/language/en-GB/en-GB.plg_system_debug.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_fields.ini\n/administrator/language/en-GB/en-GB.plg_system_fields.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_highlight.ini\n/administrator/language/en-GB/en-GB.plg_system_highlight.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_languagecode.ini"}, {"id": "Joomla.gitignore_25", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_system_languagecode.ini\n/administrator/language/en-GB/en-GB.plg_system_languagecode.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_languagefilter.ini\n/administrator/language/en-GB/en-GB.plg_system_languagefilter.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_log.ini\n/administrator/language/en-GB/en-GB.plg_system_log.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_logout.ini\n/administrator/language/en-GB/en-GB.plg_system_logout.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_logrotation.ini\n/administrator/language/en-GB/en-GB.plg_system_logrotation.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_p3p.ini\n/administrator/language/en-GB/en-GB.plg_system_p3p.sys.ini"}, {"id": "Joomla.gitignore_26", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_system_p3p.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_privacyconsent.ini\n/administrator/language/en-GB/en-GB.plg_system_privacyconsent.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_redirect.ini\n/administrator/language/en-GB/en-GB.plg_system_redirect.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_remember.ini\n/administrator/language/en-GB/en-GB.plg_system_remember.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_sef.ini\n/administrator/language/en-GB/en-GB.plg_system_sef.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_sessiongc.ini\n/administrator/language/en-GB/en-GB.plg_system_sessiongc.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_stats.ini"}, {"id": "Joomla.gitignore_27", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_system_stats.ini\n/administrator/language/en-GB/en-GB.plg_system_stats.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_updatenotification.ini\n/administrator/language/en-GB/en-GB.plg_system_updatenotification.sys.ini\n/administrator/language/en-GB/en-GB.plg_twofactorauth_totp.ini\n/administrator/language/en-GB/en-GB.plg_twofactorauth_totp.sys.ini\n/administrator/language/en-GB/en-GB.plg_twofactorauth_yubikey.ini\n/administrator/language/en-GB/en-GB.plg_twofactorauth_yubikey.sys.ini\n/administrator/language/en-GB/en-GB.plg_user_contactcreator.ini\n/administrator/language/en-GB/en-GB.plg_user_contactcreator.sys.ini\n/administrator/language/en-GB/en-GB.plg_user_joomla.ini\n/administrator/language/en-GB/en-GB.plg_user_joomla.sys.ini"}, {"id": "Joomla.gitignore_28", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_user_joomla.sys.ini\n/administrator/language/en-GB/en-GB.plg_user_profile.ini\n/administrator/language/en-GB/en-GB.plg_user_profile.sys.ini\n/administrator/language/en-GB/en-GB.plg_user_terms.ini\n/administrator/language/en-GB/en-GB.plg_user_terms.sys.ini\n/administrator/language/en-GB/en-GB.tpl_hathor.ini\n/administrator/language/en-GB/en-GB.tpl_hathor.sys.ini\n/administrator/language/en-GB/en-GB.tpl_isis.ini\n/administrator/language/en-GB/en-GB.tpl_isis.sys.ini\n/administrator/language/en-GB/en-GB.xml\n/administrator/language/en-GB/install.xml\n/administrator/language/overrides/*\n/administrator/language/index.html\n/administrator/logs/*\n/administrator/manifests/files/joomla.xml\n/administrator/manifests/libraries/fof.xml"}, {"id": "Joomla.gitignore_29", "file": "Joomla.gitignore", "content": "/administrator/manifests/files/joomla.xml\n/administrator/manifests/libraries/fof.xml\n/administrator/manifests/libraries/idna_convert.xml\n/administrator/manifests/libraries/joomla.xml\n/administrator/manifests/libraries/phpass.xml\n/administrator/manifests/libraries/phputf8.xml\n/administrator/manifests/packages/pkg_en-GB.xml\n/administrator/manifests/packages/index.html\n/administrator/modules/mod_custom/*\n/administrator/modules/mod_feed/*\n/administrator/modules/mod_latest/*\n/administrator/modules/mod_latestactions/*\n/administrator/modules/mod_logged/*\n/administrator/modules/mod_login/*\n/administrator/modules/mod_menu/*\n/administrator/modules/mod_multilangstatus/*\n/administrator/modules/mod_online/*\n/administrator/modules/mod_popular/*\n/administrator/modules/mod_privacy_dashboard/*"}, {"id": "Joomla.gitignore_30", "file": "Joomla.gitignore", "content": "/administrator/modules/mod_popular/*\n/administrator/modules/mod_privacy_dashboard/*\n/administrator/modules/mod_quickicon/*\n/administrator/modules/mod_sampledata/*\n/administrator/modules/mod_stats_admin/*\n/administrator/modules/mod_status/*\n/administrator/modules/mod_submenu/*\n/administrator/modules/mod_title/*\n/administrator/modules/mod_toolbar/*\n/administrator/modules/mod_unread/*\n/administrator/modules/mod_version/*\n/administrator/templates/hathor/*\n/administrator/templates/isis/*\n/administrator/templates/system/*\n/bin/*\n/cache/*\n/cli/*\n/components/com_ajax/*\n/components/com_banners/*\n/components/com_config/*\n/components/com_contact/*\n/components/com_content/*\n/components/com_contenthistory/*\n/components/com_fields/*\n/components/com_finder/*\n/components/com_mailto/*"}, {"id": "Joomla.gitignore_31", "file": "Joomla.gitignore", "content": "/components/com_fields/*\n/components/com_finder/*\n/components/com_mailto/*\n/components/com_media/*\n/components/com_menus/*\n/components/com_modules/*\n/components/com_newsfeeds/*\n/components/com_privacy/*\n/components/com_search/*\n/components/com_tags/*\n/components/com_users/*\n/components/com_wrapper/*\n/components/index.html\n/images/banners/*\n/images/headers/*\n/images/sampledata/*\n/images/index.html\n/images/joomla*\n/images/powered_by.png\n/includes/*\n/installation/*\n/language/en-GB/en-GB.com_ajax.ini\n/language/en-GB/en-GB.com_config.ini\n/language/en-GB/en-GB.com_contact.ini\n/language/en-GB/en-GB.com_content.ini\n/language/en-GB/en-GB.com_finder.ini\n/language/en-GB/en-GB.com_mailto.ini\n/language/en-GB/en-GB.com_media.ini\n/language/en-GB/en-GB.com_messages.ini"}, {"id": "Joomla.gitignore_32", "file": "Joomla.gitignore", "content": "/language/en-GB/en-GB.com_media.ini\n/language/en-GB/en-GB.com_messages.ini\n/language/en-GB/en-GB.com_newsfeeds.ini\n/language/en-GB/en-GB.com_privacy.ini\n/language/en-GB/en-GB.com_search.ini\n/language/en-GB/en-GB.com_tags.ini\n/language/en-GB/en-GB.com_users.ini\n/language/en-GB/en-GB.com_weblinks.ini\n/language/en-GB/en-GB.com_wrapper.ini\n/language/en-GB/en-GB.files_joomla.sys.ini\n/language/en-GB/en-GB.finder_cli.ini\n/language/en-GB/en-GB.ini\n/language/en-GB/en-GB.lib_fof.ini\n/language/en-GB/en-GB.lib_fof.sys.ini\n/language/en-GB/en-GB.lib_idna_convert.sys.ini\n/language/en-GB/en-GB.lib_joomla.ini\n/language/en-GB/en-GB.lib_joomla.sys.ini\n/language/en-GB/en-GB.lib_phpass.sys.ini\n/language/en-GB/en-GB.lib_phpmailer.sys.ini\n/language/en-GB/en-GB.lib_phputf8.sys.ini"}, {"id": "Joomla.gitignore_33", "file": "Joomla.gitignore", "content": "/language/en-GB/en-GB.lib_phpmailer.sys.ini\n/language/en-GB/en-GB.lib_phputf8.sys.ini\n/language/en-GB/en-GB.lib_simplepie.sys.ini\n/language/en-GB/en-GB.localise.php\n/language/en-GB/en-GB.mod_articles_archive.ini\n/language/en-GB/en-GB.mod_articles_archive.sys.ini\n/language/en-GB/en-GB.mod_articles_categories.ini\n/language/en-GB/en-GB.mod_articles_categories.sys.ini\n/language/en-GB/en-GB.mod_articles_category.ini\n/language/en-GB/en-GB.mod_articles_category.sys.ini\n/language/en-GB/en-GB.mod_articles_latest.ini\n/language/en-GB/en-GB.mod_articles_latest.sys.ini\n/language/en-GB/en-GB.mod_articles_news.ini\n/language/en-GB/en-GB.mod_articles_news.sys.ini\n/language/en-GB/en-GB.mod_articles_popular.ini\n/language/en-GB/en-GB.mod_articles_popular.sys.ini\n/language/en-GB/en-GB.mod_banners.ini"}, {"id": "Joomla.gitignore_34", "file": "Joomla.gitignore", "content": "/language/en-GB/en-GB.mod_articles_popular.sys.ini\n/language/en-GB/en-GB.mod_banners.ini\n/language/en-GB/en-GB.mod_banners.sys.ini\n/language/en-GB/en-GB.mod_breadcrumbs.ini\n/language/en-GB/en-GB.mod_breadcrumbs.sys.ini\n/language/en-GB/en-GB.mod_custom.ini\n/language/en-GB/en-GB.mod_custom.sys.ini\n/language/en-GB/en-GB.mod_feed.ini\n/language/en-GB/en-GB.mod_feed.sys.ini\n/language/en-GB/en-GB.mod_finder.ini\n/language/en-GB/en-GB.mod_finder.sys.ini\n/language/en-GB/en-GB.mod_footer.ini\n/language/en-GB/en-GB.mod_footer.sys.ini\n/language/en-GB/en-GB.mod_languages.ini\n/language/en-GB/en-GB.mod_languages.sys.ini\n/language/en-GB/en-GB.mod_login.ini\n/language/en-GB/en-GB.mod_login.sys.ini\n/language/en-GB/en-GB.mod_menu.ini\n/language/en-GB/en-GB.mod_menu.sys.ini"}, {"id": "Joomla.gitignore_35", "file": "Joomla.gitignore", "content": "/language/en-GB/en-GB.mod_menu.ini\n/language/en-GB/en-GB.mod_menu.sys.ini\n/language/en-GB/en-GB.mod_random_image.ini\n/language/en-GB/en-GB.mod_random_image.sys.ini\n/language/en-GB/en-GB.mod_related_items.ini\n/language/en-GB/en-GB.mod_related_items.sys.ini\n/language/en-GB/en-GB.mod_search.ini\n/language/en-GB/en-GB.mod_search.sys.ini\n/language/en-GB/en-GB.mod_stats.ini\n/language/en-GB/en-GB.mod_stats.sys.ini\n/language/en-GB/en-GB.mod_syndicate.ini\n/language/en-GB/en-GB.mod_syndicate.sys.ini\n/language/en-GB/en-GB.mod_tags_popular.ini\n/language/en-GB/en-GB.mod_tags_popular.sys.ini\n/language/en-GB/en-GB.mod_tags_similar.ini\n/language/en-GB/en-GB.mod_tags_similar.sys.ini\n/language/en-GB/en-GB.mod_users_latest.ini\n/language/en-GB/en-GB.mod_users_latest.sys.ini"}, {"id": "Joomla.gitignore_36", "file": "Joomla.gitignore", "content": "/language/en-GB/en-GB.mod_users_latest.ini\n/language/en-GB/en-GB.mod_users_latest.sys.ini\n/language/en-GB/en-GB.mod_weblinks.ini\n/language/en-GB/en-GB.mod_weblinks.sys.ini\n/language/en-GB/en-GB.mod_whosonline.ini\n/language/en-GB/en-GB.mod_whosonline.sys.ini\n/language/en-GB/en-GB.mod_wrapper.ini\n/language/en-GB/en-GB.mod_wrapper.sys.ini\n/language/en-GB/en-GB.tpl_atomic.ini\n/language/en-GB/en-GB.tpl_atomic.sys.ini\n/language/en-GB/en-GB.tpl_beez3.ini\n/language/en-GB/en-GB.tpl_beez3.sys.ini\n/language/en-GB/en-GB.tpl_beez5.ini\n/language/en-GB/en-GB.tpl_beez5.sys.ini\n/language/en-GB/en-GB.tpl_beez_20.ini\n/language/en-GB/en-GB.tpl_beez_20.sys.ini\n/language/en-GB/en-GB.tpl_protostar.ini\n/language/en-GB/en-GB.tpl_protostar.sys.ini\n/language/en-GB/en-GB.xml\n/language/en-GB/install.xml"}, {"id": "Joomla.gitignore_37", "file": "Joomla.gitignore", "content": "/language/en-GB/en-GB.tpl_protostar.sys.ini\n/language/en-GB/en-GB.xml\n/language/en-GB/install.xml\n/language/overrides/*\n/language/index.html\n/layouts/joomla/*\n/layouts/libraries/*\n/layouts/plugins/*\n/layouts/index.html\n/libraries/cms/*\n/libraries/fof/*\n/libraries/idna_convert/*\n/libraries/joomla/*\n/libraries/legacy/*\n/libraries/php-encryption/*\n/libraries/phpass/*\n/libraries/phpmailer/*\n/libraries/phputf8/*\n/libraries/simplepie/*\n/libraries/src/*\n/libraries/vendor/*\n/libraries/classmap.php\n/libraries/cms.php\n/libraries/import.legacy.php\n/libraries/import.php\n/libraries/index.html\n/libraries/loader.php\n/media/cms/*\n/media/com_associations/*\n/media/com_contact/*\n/media/com_content/*\n/media/com_contenthistory/*\n/media/com_fields/*\n/media/com_finder/*\n/media/com_joomlaupdate/*"}, {"id": "Joomla.gitignore_38", "file": "Joomla.gitignore", "content": "/media/com_contenthistory/*\n/media/com_fields/*\n/media/com_finder/*\n/media/com_joomlaupdate/*\n/media/com_menus/*\n/media/com_modules/*\n/media/com_wrapper/*\n/media/contacts/*\n/media/editors/*\n/media/jui/*\n/media/mailto/*\n/media/media/*\n/media/mod_languages/*\n/media/mod_sampledata/*\n/media/overrider/*\n/media/plg_captcha_recaptcha/*\n/media/plg_captcha_recaptcha_invisible/*\n/media/plg_quickicon_extensionupdate/*\n/media/plg_quickicon_joomlaupdate/*\n/media/plg_quickicon_privacycheck/*\n/media/plg_system_highlight/*\n/media/plg_system_stats/*\n/media/plg_twofactorauth_totp/*\n/media/system/*\n/media/index.html\n/modules/mod_articles_archive/*\n/modules/mod_articles_categories/*\n/modules/mod_articles_category/*\n/modules/mod_articles_latest/*\n/modules/mod_articles_news/*\n/modules/mod_articles_popular/*"}, {"id": "Joomla.gitignore_39", "file": "Joomla.gitignore", "content": "/modules/mod_articles_latest/*\n/modules/mod_articles_news/*\n/modules/mod_articles_popular/*\n/modules/mod_banners/*\n/modules/mod_breadcrumbs/*\n/modules/mod_custom/*\n/modules/mod_feed/*\n/modules/mod_finder/*\n/modules/mod_footer/*\n/modules/mod_languages/*\n/modules/mod_login/*\n/modules/mod_menu/*\n/modules/mod_random_image/*\n/modules/mod_related_items/*\n/modules/mod_search/*\n/modules/mod_stats/*\n/modules/mod_syndicate/*\n/modules/mod_tags_popular/*\n/modules/mod_tags_similar/*\n/modules/mod_users_latest/*\n/modules/mod_whosonline/*\n/modules/mod_wrapper/*\n/modules/index.html\n/plugins/actionlog/joomla/*\n/plugins/authentication/cookie/*\n/plugins/authentication/example/*\n/plugins/authentication/gmail/*\n/plugins/authentication/joomla/*\n/plugins/authentication/ldap/*\n/plugins/captcha/recaptcha/*"}, {"id": "Joomla.gitignore_40", "file": "Joomla.gitignore", "content": "/plugins/authentication/joomla/*\n/plugins/authentication/ldap/*\n/plugins/captcha/recaptcha/*\n/plugins/captcha/recaptcha_invisible/*\n/plugins/content/confirmconsent/*\n/plugins/content/contact/*\n/plugins/content/emailcloak/*\n/plugins/content/example/*\n/plugins/content/fields/*\n/plugins/content/finder/*\n/plugins/content/geshi/*\n/plugins/content/joomla/*\n/plugins/content/loadmodule/*\n/plugins/content/pagebreak/*\n/plugins/content/pagenavigation/*\n/plugins/content/vote/*\n/plugins/editors/codemirror/*\n/plugins/editors/none/*\n/plugins/editors/tinymce/*\n/plugins/editors-xtd/article/*\n/plugins/editors-xtd/contact/*\n/plugins/editors-xtd/fields/*\n/plugins/editors-xtd/image/*\n/plugins/editors-xtd/menu/*\n/plugins/editors-xtd/module/*\n/plugins/editors-xtd/pagebreak/*\n/plugins/editors-xtd/readmore/*"}, {"id": "Joomla.gitignore_41", "file": "Joomla.gitignore", "content": "/plugins/editors-xtd/module/*\n/plugins/editors-xtd/pagebreak/*\n/plugins/editors-xtd/readmore/*\n/plugins/extension/example/*\n/plugins/extension/joomla/*\n/plugins/fields/calendar/*\n/plugins/fields/checkboxes/*\n/plugins/fields/color/*\n/plugins/fields/editor/*\n/plugins/fields/imagelist/*\n/plugins/fields/integer/*\n/plugins/fields/list/*\n/plugins/fields/media/*\n/plugins/fields/radio/*\n/plugins/fields/repeatable/*\n/plugins/fields/sql/*\n/plugins/fields/text/*\n/plugins/fields/textarea/*\n/plugins/fields/url/*\n/plugins/fields/user/*\n/plugins/fields/usergrouplist/*\n/plugins/finder/categories/*\n/plugins/finder/contacts/*\n/plugins/finder/content/*\n/plugins/finder/newsfeeds/*\n/plugins/finder/tags/*\n/plugins/installer/folderinstaller/*\n/plugins/installer/packageinstaller/*"}, {"id": "Joomla.gitignore_42", "file": "Joomla.gitignore", "content": "/plugins/finder/tags/*\n/plugins/installer/folderinstaller/*\n/plugins/installer/packageinstaller/*\n/plugins/installer/urlinstaller/*\n/plugins/privacy/actionlogs/*\n/plugins/privacy/consents/*\n/plugins/privacy/contact/*\n/plugins/privacy/content/*\n/plugins/privacy/message/*\n/plugins/privacy/user/*\n/plugins/quickicon/extensionupdate/*\n/plugins/quickicon/joomlaupdate/*\n/plugins/quickicon/phpversioncheck/*\n/plugins/quickicon/privacycheck/*\n/plugins/quickicon/index.html\n/plugins/sampledata/blog/*\n/plugins/search/categories/*\n/plugins/search/contacts/*\n/plugins/search/content/*\n/plugins/search/newsfeeds/*\n/plugins/search/tags/*\n/plugins/search/weblinks/*\n/plugins/search/index.html\n/plugins/system/actionlogs/*\n/plugins/system/cache/*\n/plugins/system/debug/*\n/plugins/system/fields/*"}, {"id": "Joomla.gitignore_43", "file": "Joomla.gitignore", "content": "/plugins/system/cache/*\n/plugins/system/debug/*\n/plugins/system/fields/*\n/plugins/system/highlight/*\n/plugins/system/languagecode/*\n/plugins/system/languagefilter/*\n/plugins/system/log/*\n/plugins/system/logout/*\n/plugins/system/logrotation/*\n/plugins/system/p3p/*\n/plugins/system/privacyconsent/*\n/plugins/system/redirect/*\n/plugins/system/remember/*\n/plugins/system/sef/*\n/plugins/system/sessiongc/*\n/plugins/system/stats/*\n/plugins/system/updatenotification/*\n/plugins/system/index.html\n/plugins/twofactorauth/totp/*\n/plugins/twofactorauth/yubikey/*\n/plugins/user/contactcreator/*\n/plugins/user/example/*\n/plugins/user/joomla/*\n/plugins/user/profile/*\n/plugins/user/terms/*\n/plugins/user/index.html\n/plugins/index.html\n/templates/beez3/*\n/templates/protostar/*\n/templates/system/*"}, {"id": "Joomla.gitignore_44", "file": "Joomla.gitignore", "content": "/plugins/index.html\n/templates/beez3/*\n/templates/protostar/*\n/templates/system/*\n/templates/index.html\n/tmp/*\n/configuration.php\n/htaccess.txt\n/index.php\n/joomla.xml\n/LICENSE.txt\n/README.txt\n/robots.txt.dist\n/web.config.txt"}, {"id": "Julia.gitignore_0", "file": "Julia.gitignore", "content": "================================================\n# Files generated by invoking Julia with --code-coverage\n*.jl.cov\n*.jl.*.cov\n\n# Files generated by invoking Julia with --track-allocation\n*.jl.mem\n\n# System-specific files and directories generated by the BinaryProvider and BinDeps packages\n# They contain absolute paths specific to the host computer, and so should not be committed\ndeps/deps.jl\ndeps/build.log\ndeps/downloads/\ndeps/usr/\ndeps/src/\n\n# Build artifacts for creating documentation generated by the Documenter package\ndocs/build/\ndocs/site/\n\n# File generated by Pkg, the package manager, based on a corresponding Project.toml\n# It records a fixed state of all packages used by the project. As such, it should not be"}, {"id": "Julia.gitignore_1", "file": "Julia.gitignore", "content": "# It records a fixed state of all packages used by the project. As such, it should not be\n# committed for packages, but should be committed for applications that require a static\n# environment.\nManifest*.toml\n\n# File generated by the Preferences package to store local preferences\nLocalPreferences.toml\nJuliaLocalPreferences.toml"}, {"id": "Katalon.gitignore_0", "file": "Katalon.gitignore", "content": "================================================\n# Katalon Test Suite\n# Compiled class file\n*.class\n*.swp\noutput\n!output/.gitkeep\nbuild\n\nLibs/TempTestCase*\nLibs/TempTestSuite*\nbin/lib/TempTestCase*\nReports/\n\\.classpath\n\\.project\n\\.settings/\nbin/lib/\nLibs/\n.svn/\n.gradle\n\n\n# Log file\n*.log\n\n# BlueJ files\n*.ctxt\n\n# Mobile Tools for Java (J2ME)\n.mtj.tmp/\n\n# Package Files #\n*.jar\n*.war\n*.ear\n*.zip\n*.tar.gz\n*.rar\n\n# virtual machine crash logs, see http://www.java.com/en/download/help/error_hotspot.xml\nhs_err_pid*"}, {"id": "KiCad.gitignore_0", "file": "KiCad.gitignore", "content": "================================================\n# For PCBs designed using KiCad: https://www.kicad.org/\n# Format documentation: https://kicad.org/help/file-formats/\n\n# Temporary files\n*.000\n*.bak\n*.bck\n*.kicad_pcb-bak\n*.kicad_sch-bak\n*-backups\n*-cache*\n*-bak\n*-bak*\n*~\n~*\n_autosave-*\n\\#auto_saved_files\\#\n*.tmp\n*-save.pro\n*-save.kicad_pcb\nfp-info-cache\n~*.lck\n\\#auto_saved_files#\n\n# Netlist files (exported from Eeschema)\n*.net\n\n# Autorouter files (exported from Pcbnew)\n*.dsn\n*.ses\n\n# Exported BOM files\n*.xml\n*.csv\n\n# Archived Backups (KiCad 6.0)\n**/*-backups/*.zip\n\n# Local project settings\n*.kicad_prl"}, {"id": "Kohana.gitignore_0", "file": "Kohana.gitignore", "content": "================================================\napplication/cache/*\napplication/logs/*"}, {"id": "Kotlin.gitignore_0", "file": "Kotlin.gitignore", "content": "================================================\n# Compiled class file\n*.class\n\n# Log file\n*.log\n\n# BlueJ files\n*.ctxt\n\n# Mobile Tools for Java (J2ME)\n.mtj.tmp/\n\n# Package Files #\n*.jar\n*.war\n*.nar\n*.ear\n*.zip\n*.tar.gz\n*.rar\n\n# virtual machine crash logs, see http://www.java.com/en/download/help/error_hotspot.xml\nhs_err_pid*\nreplay_pid*\n\n# Kotlin Gradle plugin data, see https://kotlinlang.org/docs/whatsnew20.html#new-directory-for-kotlin-data-in-gradle-projects\n.kotlin/"}, {"id": "LabVIEW.gitignore_0", "file": "LabVIEW.gitignore", "content": "================================================\n# Libraries\n*.lvlibp\n*.llb\n\n# Shared objects (inc. Windows DLLs)\n*.dll\n*.so\n*.so.*\n*.dylib\n\n# Executables\n*.exe\n\n# Metadata\n*.aliases\n*.lvlps\n.cache/"}, {"id": "LangChain.gitignore_0", "file": "LangChain.gitignore", "content": "================================================\n# gitignore template for LangChain products, e.g., LangGraph, LangSmith\n# website: https://www.langchain.com/\n# website: https://www.langchain.com/langgraph\n\n# LangGraph\n.langgraph_api/"}, {"id": "Laravel.gitignore_0", "file": "Laravel.gitignore", "content": "================================================\n/vendor/\nnode_modules/\nnpm-debug.log\nyarn-error.log\n\n# Laravel 4 specific\nbootstrap/compiled.php\napp/storage/\n\n# Laravel 5 & Lumen specific\npublic/storage\npublic/hot\n\n# Laravel 5 & Lumen specific with changed public path\npublic_html/storage\npublic_html/hot\n\nstorage/*.key\n.env\nHomestead.yaml\nHomestead.json\n/.vagrant\n.phpunit.result.cache\n\n/public/build\n/storage/pail\n.env.backup\n.env.production\n.phpactor.json\nauth.json"}, {"id": "Leiningen.gitignore_0", "file": "Leiningen.gitignore", "content": "================================================\npom.xml\npom.xml.asc\n*.jar\n*.class\n/lib/\n/classes/\n/target/\n/checkouts/\n.lein-deps-sum\n.lein-repl-history\n.lein-plugins/\n.lein-failures\n.nrepl-port\n.cpcache/"}, {"id": "LemonStand.gitignore_0", "file": "LemonStand.gitignore", "content": "================================================\nboot.php\nindex.php\ninstall.php\n/config/*\n!/config/config.php\n/controllers/*\n/init/*\n/logs/*\n/phproad/*\n/temp/*\n/uploaded/*\n/installer_files/*\n/modules/backend/*\n/modules/blog/*\n/modules/cms/*\n/modules/core/*\n/modules/session/*\n/modules/shop/*\n/modules/system/*\n/modules/users/*\n# add content_*.php if you don't want erase client changes to content"}, {"id": "LICENSE_0", "file": "LICENSE", "content": "================================================\nCC0 1.0 Universal\n\nStatement of Purpose\n\nThe laws of most jurisdictions throughout the world automatically confer\nexclusive Copyright and Related Rights (defined below) upon the creator and\nsubsequent owner(s) (each and all, an \"owner\") of an original work of\nauthorship and/or a database (each, a \"Work\").\n\nCertain owners wish to permanently relinquish those rights to a Work for the\npurpose of contributing to a commons of creative, cultural and scientific\nworks (\"Commons\") that the public can reliably and without fear of later\nclaims of infringement build upon, modify, incorporate in other works, reuse\nand redistribute as freely as possible in any form whatsoever and for any"}, {"id": "LICENSE_1", "file": "LICENSE", "content": "and redistribute as freely as possible in any form whatsoever and for any\npurposes, including without limitation commercial purposes. These owners may\ncontribute to the Commons to promote the ideal of a free culture and the\nfurther production of creative, cultural and scientific works, or to gain\nreputation or greater distribution for their Work in part through the use and\nefforts of others.\n\nFor these and/or other purposes and motivations, and without any expectation\nof additional consideration or compensation, the person associating CC0 with a\nWork (the \"Affirmer\"), to the extent that he or she is an owner of Copyright\nand Related Rights in the Work, voluntarily elects to apply CC0 to the Work\nand publicly distribute the Work under its terms, with knowledge of his or her"}, {"id": "LICENSE_2", "file": "LICENSE", "content": "and publicly distribute the Work under its terms, with knowledge of his or her\nCopyright and Related Rights in the Work and the meaning and intended legal\neffect of CC0 on those rights.\n\n1. Copyright and Related Rights. A Work made available under CC0 may be\nprotected by copyright and related or neighboring rights (\"Copyright and\nRelated Rights\"). Copyright and Related Rights include, but are not limited\nto, the following:\n\n  i. the right to reproduce, adapt, distribute, perform, display, communicate,\n  and translate a Work;\n\n  ii. moral rights retained by the original author(s) and/or performer(s);\n\n  iii. publicity and privacy rights pertaining to a person's image or likeness\n  depicted in a Work;\n\n  iv. rights protecting against unfair competition in regards to a Work,"}, {"id": "LICENSE_3", "file": "LICENSE", "content": "depicted in a Work;\n\n  iv. rights protecting against unfair competition in regards to a Work,\n  subject to the limitations in paragraph 4(a), below;\n\n  v. rights protecting the extraction, dissemination, use and reuse of data in\n  a Work;\n\n  vi. database rights (such as those arising under Directive 96/9/EC of the\n  European Parliament and of the Council of 11 March 1996 on the legal\n  protection of databases, and under any national implementation thereof,\n  including any amended or successor version of such directive); and\n\n  vii. other similar, equivalent or corresponding rights throughout the world\n  based on applicable law or treaty, and any national implementations thereof.\n\n2. Waiver. To the greatest extent permitted by, but not in contravention of,"}, {"id": "LICENSE_4", "file": "LICENSE", "content": "2. Waiver. To the greatest extent permitted by, but not in contravention of,\napplicable law, Affirmer hereby overtly, fully, permanently, irrevocably and\nunconditionally waives, abandons, and surrenders all of Affirmer's Copyright\nand Related Rights and associated claims and causes of action, whether now\nknown or unknown (including existing as well as future claims and causes of\naction), in the Work (i) in all territories worldwide, (ii) for the maximum\nduration provided by applicable law or treaty (including future time\nextensions), (iii) in any current or future medium and for any number of\ncopies, and (iv) for any purpose whatsoever, including without limitation\ncommercial, advertising or promotional purposes (the \"Waiver\"). Affirmer makes"}, {"id": "LICENSE_5", "file": "LICENSE", "content": "commercial, advertising or promotional purposes (the \"Waiver\"). Affirmer makes\nthe Waiver for the benefit of each member of the public at large and to the\ndetriment of Affirmer's heirs and successors, fully intending that such Waiver\nshall not be subject to revocation, rescission, cancellation, termination, or\nany other legal or equitable action to disrupt the quiet enjoyment of the Work\nby the public as contemplated by Affirmer's express Statement of Purpose.\n\n3. Public License Fallback. Should any part of the Waiver for any reason be\njudged legally invalid or ineffective under applicable law, then the Waiver\nshall be preserved to the maximum extent permitted taking into account\nAffirmer's express Statement of Purpose. In addition, to the extent the Waiver"}, {"id": "LICENSE_6", "file": "LICENSE", "content": "Affirmer's express Statement of Purpose. In addition, to the extent the Waiver\nis so judged Affirmer hereby grants to each affected person a royalty-free,\nnon transferable, non sublicensable, non exclusive, irrevocable and\nunconditional license to exercise Affirmer's Copyright and Related Rights in\nthe Work (i) in all territories worldwide, (ii) for the maximum duration\nprovided by applicable law or treaty (including future time extensions), (iii)\nin any current or future medium and for any number of copies, and (iv) for any\npurpose whatsoever, including without limitation commercial, advertising or\npromotional purposes (the \"License\"). The License shall be deemed effective as\nof the date CC0 was applied by Affirmer to the Work. Should any part of the"}, {"id": "LICENSE_7", "file": "LICENSE", "content": "of the date CC0 was applied by Affirmer to the Work. Should any part of the\nLicense for any reason be judged legally invalid or ineffective under\napplicable law, such partial invalidity or ineffectiveness shall not\ninvalidate the remainder of the License, and in such case Affirmer hereby\naffirms that he or she will not (i) exercise any of his or her remaining\nCopyright and Related Rights in the Work or (ii) assert any associated claims\nand causes of action with respect to the Work, in either case contrary to\nAffirmer's express Statement of Purpose.\n\n4. Limitations and Disclaimers.\n\n  a. No trademark or patent rights held by Affirmer are waived, abandoned,\n  surrendered, licensed or otherwise affected by this document."}, {"id": "LICENSE_8", "file": "LICENSE", "content": "surrendered, licensed or otherwise affected by this document.\n\n  b. Affirmer offers the Work as-is and makes no representations or warranties\n  of any kind concerning the Work, express, implied, statutory or otherwise,\n  including without limitation warranties of title, merchantability, fitness\n  for a particular purpose, non infringement, or the absence of latent or\n  other defects, accuracy, or the present or absence of errors, whether or not\n  discoverable, all to the greatest extent permissible under applicable law.\n\n  c. Affirmer disclaims responsibility for clearing rights of other persons\n  that may apply to the Work or any use thereof, including without limitation\n  any person's Copyright and Related Rights in the Work. Further, Affirmer"}, {"id": "LICENSE_9", "file": "LICENSE", "content": "any person's Copyright and Related Rights in the Work. Further, Affirmer\n  disclaims responsibility for obtaining any necessary consents, permissions\n  or other rights required for any use of the Work.\n\n  d. Affirmer understands and acknowledges that Creative Commons is not a\n  party to this document and has no duty or obligation with respect to this\n  CC0 or use of the Work.\n\nFor more information, please see\n<http://creativecommons.org/publicdomain/zero/1.0/>"}, {"id": "Lilypond.gitignore_0", "file": "Lilypond.gitignore", "content": "================================================\n*.pdf\n*.ps\n*.midi\n*.mid\n*.log\n*~"}, {"id": "Lithium.gitignore_0", "file": "Lithium.gitignore", "content": "================================================\nlibraries/*\nresources/tmp/*"}, {"id": "Lua.gitignore_0", "file": "Lua.gitignore", "content": "================================================\n# Compiled Lua sources\nluac.out\n\n# luarocks build files\n*.src.rock\n*.zip\n*.tar.gz\n\n# Object files\n*.o\n*.os\n*.ko\n*.obj\n*.elf\n\n# Precompiled Headers\n*.gch\n*.pch\n\n# Libraries\n*.lib\n*.a\n*.la\n*.lo\n*.def\n*.exp\n\n# Shared objects (inc. Windows DLLs)\n*.dll\n*.so\n*.so.*\n*.dylib\n\n# Executables\n*.exe\n*.out\n*.app\n*.i*86\n*.x86_64\n*.hex"}, {"id": "Luau.gitignore_0", "file": "Luau.gitignore", "content": "================================================\n# A fast, small, safe, gradually typed embeddable scripting language derived from Lua\n#\n# https://github.com/luau-lang/luau\n# https://luau.org/\n\n# Code coverage\ncoverage.out\n\n# Profiling\nprofile.out\nprofile.svg\n\n# Time trace\ntrace.json"}, {"id": "Magento.gitignore_0", "file": "Magento.gitignore", "content": "================================================\n#--------------------------#\n# Magento Default Files    #\n#--------------------------#\n\n/PATCH_*.sh\n\n/app/etc/local.xml\n\n/media/*\n!/media/.htaccess\n\n!/media/customer\n/media/customer/*\n!/media/customer/.htaccess\n\n!/media/dhl\n/media/dhl/*\n!/media/dhl/logo.jpg\n\n!/media/downloadable\n/media/downloadable/*\n!/media/downloadable/.htaccess\n\n!/media/xmlconnect\n/media/xmlconnect/*\n\n!/media/xmlconnect/custom\n/media/xmlconnect/custom/*\n!/media/xmlconnect/custom/ok.gif\n\n!/media/xmlconnect/original\n/media/xmlconnect/original/*\n!/media/xmlconnect/original/ok.gif\n\n!/media/xmlconnect/system\n/media/xmlconnect/system/*\n!/media/xmlconnect/system/ok.gif\n\n/var/*\n!/var/.htaccess\n\n!/var/package\n/var/package/*\n!/var/package/*.xml"}, {"id": "Maven.gitignore_0", "file": "Maven.gitignore", "content": "================================================\ntarget/\npom.xml.tag\npom.xml.releaseBackup\npom.xml.versionsBackup\npom.xml.next\nrelease.properties\ndependency-reduced-pom.xml\nbuildNumber.properties\n.mvn/timing.properties\n# https://maven.apache.org/wrapper/#usage-without-binary-jar\n.mvn/wrapper/maven-wrapper.jar\n\n# Eclipse m2e generated files\n# Eclipse Core\n.project\n# JDT-specific (Eclipse Java Development Tools)\n.classpath"}, {"id": "Mercury.gitignore_0", "file": "Mercury.gitignore", "content": "================================================\nMercury/\nMercury.modules\n*.mh\n*.err\n*.init\n*.dll\n*.exe\n*.a\n*.so\n*.dylib\n*.beams\n*.d\n*.c_date"}, {"id": "MetaProgrammingSystem.gitignore_0", "file": "MetaProgrammingSystem.gitignore", "content": "================================================\nworkspace.xml\njunitvmwatcher*.properties\nbuild.properties\n\n# generated java classes and java source files\n#   manually add any custom artifacts that can't be generated from the models\n#   http://confluence.jetbrains.com/display/MPSD25/HowTo+--+MPS+and+Git\nclasses_gen\nsource_gen\nsource_gen.caches\n\n# generated test code and test results\ntest_gen\ntest_gen.caches\nTEST-*.xml\njunit*.properties"}, {"id": "Modelica.gitignore_0", "file": "Modelica.gitignore", "content": "================================================\n# Modelica - an object-oriented language for modeling of cyber-physical systems\n# https://modelica.org/\n# Ignore temporary files, build results, simulation files\n\n## Modelica-specific files\n*~\n*.bak\n*.bak-mo\n*.mof\n\\#*\\#\n*.moe\n*.mol\n\n## Build artefacts\n*.exe\n*.exp\n*.o\n*.pyc\n\n## Simulation files\n*.mat\n\n## Package files\n*.gz\n*.rar\n*.tar\n*.zip\n\n## Dymola-specific files\nbuildlog.txt\ndsfinal.txt\ndsin.txt\ndslog.txt\ndsmodel*\ndsres.txt\ndymosim*\nrequest\nstat\nstatus\nstop\nsuccess\n*."}, {"id": "ModelSim.gitignore_0", "file": "ModelSim.gitignore", "content": "================================================\n# ignore ModelSim generated files and directories (temp files and so on)\n[_@]*\n\n# ignore compilation output of ModelSim\n*.mti\n*.dat\n*.dbs\n*.psm\n*.bak\n*.cmp\n*.jpg\n*.html\n*.bsf\n\n# ignore simulation output of ModelSim\nwlf*\n*.wlf\n*.vstf\n*.ucdb\ncov*/\ntranscript*\nsc_dpiheader.h\nvsim.dbg"}, {"id": "Nanoc.gitignore_0", "file": "Nanoc.gitignore", "content": "================================================\n# For projects using Nanoc (http://nanoc.ws/)\n\n# Default location for output (needs to match output_dir's value found in nanoc.yaml)\noutput/\n\n# Temporary file directory\ntmp/nanoc/\n\n# Crash Log\ncrash.log"}, {"id": "Nestjs.gitignore_0", "file": "Nestjs.gitignore", "content": "================================================\n# Nestjs specific\n/dist\n/node_modules\n/build\n/tmp\n\n# Logs\nlogs\n*.log\nnpm-debug.log*\npnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\nlerna-debug.log*\n\n# dotenv environment variable files\n.env\n.env.development\n.env.test\n.env.production\n\n# temp directory\n.temp\n.tmp"}, {"id": "Nextjs.gitignore_0", "file": "Nextjs.gitignore", "content": "================================================\n# See https://help.github.com/articles/ignoring-files/ for more about ignoring files.\n\n# dependencies\n/node_modules\n/.pnp\n.pnp.js\n\n# testing\n/coverage\n\n# next.js\n/.next/\n/out/\n\n# production\n/build\n\n# misc\n.DS_Store\n*.pem\n\n# debug\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\n\n# local env files\n.env*.local\n.env\n\n# vercel\n.vercel\n\n# typescript\n*.tsbuildinfo\nnext-env.d.ts"}, {"id": "Nim.gitignore_0", "file": "Nim.gitignore", "content": "================================================\nnimcache/\nnimblecache/\nhtmldocs/"}, {"id": "Nix.gitignore_0", "file": "Nix.gitignore", "content": "================================================\n# Ignore build outputs from performing a nix-build or `nix build` command\nresult\nresult-*\n\n# Ignore automatically generated direnv output\n.direnv"}, {"id": "Node.gitignore_0", "file": "Node.gitignore", "content": "================================================\n# Logs\nlogs\n*.log\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\nlerna-debug.log*\n\n# Diagnostic reports (https://nodejs.org/api/report.html)\nreport.[0-9]*.[0-9]*.[0-9]*.[0-9]*.json\n\n# Runtime data\npids\n*.pid\n*.seed\n*.pid.lock\n\n# Directory for instrumented libs generated by jscoverage/JSCover\nlib-cov\n\n# Coverage directory used by tools like istanbul\ncoverage\n*.lcov\n\n# nyc test coverage\n.nyc_output\n\n# Grunt intermediate storage (https://gruntjs.com/creating-plugins#storing-task-files)\n.grunt\n\n# Bower dependency directory (https://bower.io/)\nbower_components\n\n# node-waf configuration\n.lock-wscript\n\n# Compiled binary addons (https://nodejs.org/api/addons.html)\nbuild/Release\n\n# Dependency directories\nnode_modules/\njspm_packages/"}, {"id": "Node.gitignore_1", "file": "Node.gitignore", "content": "build/Release\n\n# Dependency directories\nnode_modules/\njspm_packages/\n\n# Snowpack dependency directory (https://snowpack.dev/)\nweb_modules/\n\n# TypeScript cache\n*.tsbuildinfo\n\n# Optional npm cache directory\n.npm\n\n# Optional eslint cache\n.eslintcache\n\n# Optional stylelint cache\n.stylelintcache\n\n# Optional REPL history\n.node_repl_history\n\n# Output of 'npm pack'\n*.tgz\n\n# Yarn Integrity file\n.yarn-integrity\n\n# dotenv environment variable files\n.env\n.env.*\n!.env.example\n\n# parcel-bundler cache (https://parceljs.org/)\n.cache\n.parcel-cache\n\n# Next.js build output\n.next\nout\n\n# Nuxt.js build / generate output\n.nuxt\ndist\n.output\n\n# Gatsby files\n.cache/\n# Comment in the public line in if your project uses Gatsby and not Next.js\n# https://nextjs.org/blog/next-9-1#public-directory-support\n# public"}, {"id": "Node.gitignore_2", "file": "Node.gitignore", "content": "# https://nextjs.org/blog/next-9-1#public-directory-support\n# public\n\n# vuepress build output\n.vuepress/dist\n\n# vuepress v2.x temp and cache directory\n.temp\n.cache\n\n# Sveltekit cache directory\n.svelte-kit/\n\n# vitepress build output\n**/.vitepress/dist\n\n# vitepress cache directory\n**/.vitepress/cache\n\n# Docusaurus cache and generated files\n.docusaurus\n\n# Serverless directories\n.serverless/\n\n# FuseBox cache\n.fusebox/\n\n# DynamoDB Local files\n.dynamodb/\n\n# Firebase cache directory\n.firebase/\n\n# TernJS port file\n.tern-port\n\n# Stores VSCode versions used for testing VSCode extensions\n.vscode-test\n\n# yarn v3\n.pnp.*\n.yarn/*\n!.yarn/patches\n!.yarn/plugins\n!.yarn/releases\n!.yarn/sdks\n!.yarn/versions\n\n# Vite files\nvite.config.js.timestamp-*\nvite.config.ts.timestamp-*\n.vite/"}, {"id": "Objective-C.gitignore_0", "file": "Objective-C.gitignore", "content": "================================================\n# Xcode\n#\n# gitignore contributors: remember to update Global/Xcode.gitignore, Objective-C.gitignore & Swift.gitignore\n\n## User settings\nxcuserdata/\n\n## Obj-C/Swift specific\n*.hmap"}, {"id": "Objective-C.gitignore_1", "file": "Objective-C.gitignore", "content": "## App packaging\n*.ipa\n*.dSYM.zip\n*.dSYM\n\n# CocoaPods\n#\n# We recommend against adding the Pods directory to your .gitignore. However\n# you should judge for yourself, the pros and cons are mentioned at:\n# https://guides.cocoapods.org/using/using-cocoapods.html#should-i-check-the-pods-directory-into-source-control\n#\n# Pods/\n#\n# Add this line if you want to avoid checking in source code from the Xcode workspace\n# *.xcworkspace\n\n# Carthage\n#\n# Add this line if you want to avoid checking in source code from Carthage dependencies.\n# Carthage/Checkouts\n\nCarthage/Build/\n\n# fastlane\n#\n# It is recommended to not store the screenshots in the git repo.\n# Instead, use fastlane to re-generate the screenshots whenever they are needed.\n# For more information about the recommended setup visit:"}, {"id": "Objective-C.gitignore_2", "file": "Objective-C.gitignore", "content": "# For more information about the recommended setup visit:\n# https://docs.fastlane.tools/best-practices/source-control/#source-control\n\nfastlane/report.xml\nfastlane/Preview.html\nfastlane/screenshots/**/*.png\nfastlane/test_output"}, {"id": "OCaml.gitignore_0", "file": "OCaml.gitignore", "content": "================================================\n*.annot\n*.cmo\n*.cma\n*.cmi\n*.a\n*.o\n*.cmx\n*.cmxs\n*.cmxa\n\n# Files containing detailed information about the compilation (generated\n# by `ocamlc`/`ocamlopt` when invoked using the option `-bin-annot`).\n# These files are typically useful for code inspection tools\n# (e.g. Merlin).\n*.cmt\n*.cmti\n\n# ocamlbuild and Dune default working directory\n_build/\n\n# ocamlbuild targets\n*.byte\n*.native\n\n# oasis generated files\nsetup.data\nsetup.log\n\n# Merlin configuring file for Vim and Emacs\n.merlin\n\n# Dune generated files\n*.install\n\n# Local OPAM switch\n_opam/"}, {"id": "Opa.gitignore_0", "file": "Opa.gitignore", "content": "================================================\n_build\n_tracks\n\nopa-debug-js\n\n*.opp\n*.opx\n*.opx.broken\n*.dump\n*.api\n*.api-txt\n*.exe\n*.log"}, {"id": "OpenCart.gitignore_0", "file": "OpenCart.gitignore", "content": "================================================\n.htaccess\n/config.php\nadmin/config.php\n\n!index.html\n\ndownload/\nimage/data/\nimage/cache/\nsystem/cache/\nsystem/logs/\n\nsystem/storage/\n\n# vQmod log files\nvqmod/logs/*\n# vQmod cache files\nvqmod/vqcache/*\nvqmod/checked.cache\nvqmod/mods.cache"}, {"id": "OracleForms.gitignore_0", "file": "OracleForms.gitignore", "content": "================================================\n# Compiled Form Modules\n*.fmx\n\n# Compiled Menu Modules\n*.mmx\n\n# Compiled Pre-Linked Libraries\n*.plx"}, {"id": "Packer.gitignore_0", "file": "Packer.gitignore", "content": "================================================\n# Cache objects\npacker_cache/\n\n# Crash log\ncrash.log\n\n# https://www.packer.io/guides/hcl/variables\n# Exclude all .pkrvars.hcl files, which are likely to contain sensitive data,\n# such as password, private keys, and other secrets. These should not be part of\n# version control as they are data points which are potentially sensitive and\n# subject to change depending on the environment.\n#\n*.pkrvars.hcl\n\n# For built boxes\n*.box"}, {"id": "Perl.gitignore_0", "file": "Perl.gitignore", "content": "================================================\n!Build/\n.last_cover_stats\n/META.yml\n/META.json\n/MYMETA.*\n*.o\n*.pm.tdy\n*.bs\n\n# Devel::Cover\ncover_db/\n\n# Devel::NYTProf\nnytprof.out\n\n# Dist::Zilla\n/.build/\n\n# Module::Build\n_build/\nBuild\nBuild.bat\n\n# Module::Install\ninc/\n\n# ExtUtils::MakeMaker\n/blib/\n/_eumm/\n/*.gz\n/Makefile\n/Makefile.old\n/MANIFEST.bak\n/pm_to_blib\n/*.zip\n\n# Carton/Carmel\n/local/\n/.carmel/\n# cpanfile.snapshot should generally be ignored for library code, otherwise included\n# cpanfile.snapshot"}, {"id": "Phalcon.gitignore_0", "file": "Phalcon.gitignore", "content": "================================================\n/cache/\n/config/development/"}, {"id": "PlayFramework.gitignore_0", "file": "PlayFramework.gitignore", "content": "================================================\n# Ignore Play! working directory #\nbin/\n/db\n.eclipse\n/lib/\n/logs/\n/modules\n/project/project\n/project/target\n/target\ntmp/\ntest-result\nserver.pid\n*.eml\n/dist/\n.cache"}, {"id": "Plone.gitignore_0", "file": "Plone.gitignore", "content": "================================================\n*.pyc\n*.pyo\n*.tmp*\n*.mo\n*.egg\n*.EGG\n*.egg-info\n*.EGG-INFO\n.*.cfg\nbin/\nbuild/\ndevelop-eggs/\ndownloads/\neggs/\nfake-eggs/\nparts/\ndist/\nvar/"}, {"id": "Prestashop.gitignore_0", "file": "Prestashop.gitignore", "content": "================================================\n# Cache, temp and personal files\n\n/.htaccess\n*.log\n\n# Cache\n/cache/*\n!/cache/.htaccess\n!/cache/cachefs/index.php\n!/cache/deprecated.txt\n!/cache/index.php\n!/cache/purifier/index.php\n!/cache/push/activity\n!/cache/push/index.php\n!/cache/push/trends\n!/cache/sandbox/index.php\n!/cache/smarty/cache/index.php\n!/cache/smarty/compile/index.php\n!/cache/smarty/index.php\n!/cache/tcpdf/index.php\n\n# Download\n/download/*\n!/download/.htaccess\n!/download/index.php\n\n# Images\n/img/*\n!/img/.htaccess\n!/img/index.php\n!/img/404.gif\n!/img/bg_500.png\n!/img/bg_loader.png\n!/img/favicon.ico\n!/img/loader.gif\n!/img/loadingAnimation.gif\n!/img/logo.jpg\n!/img/logo.png\n!/img/logo_invoice.jpg\n!/img/logo_stores.png\n!/img/macFFBgHack.png\n!/img/prestashop-avatar.png"}, {"id": "Prestashop.gitignore_1", "file": "Prestashop.gitignore", "content": "!/img/logo_invoice.jpg\n!/img/logo_stores.png\n!/img/macFFBgHack.png\n!/img/prestashop-avatar.png\n!/img/prestashop@2x.png\n!/img/preston-login-wink@2x.png\n!/img/preston-login@2x.png\n!/img/questionmark.png\n!/img/genders/index.php\n!/img/admin/index.php\n!/img/c/index.php\n!/img/cms/index.php\n!/img/co/index.php\n!/img/jquery-ui\n!/img/l/index.php\n!/img/m/index.php\n!/img/os/index.php\n!/img/p/index.php\n!/img/s/index.php\n!/img/scenes\n!/img/st/index.php\n!/img/su/index.php\n!/img/t/index.php\n!/img/tmp/index.php\n\n# Upload\n/upload/*\n!/upload/.htaccess\n\n/vendor/*\n/docs/phpdoc-sf/\n/composer.lock\n*.hot-update.js\n*.hot-update.json\n\n\n/admin-dev/autoupgrade/*\n!/admin-dev/autoupgrade/index.php\n!/admin-dev/autoupgrade/backup/index.php\n\n/admin-dev/backups/*\n!/admin-dev/backups/.htaccess\n\n/admin-dev/import/*"}, {"id": "Prestashop.gitignore_2", "file": "Prestashop.gitignore", "content": "/admin-dev/backups/*\n!/admin-dev/backups/.htaccess\n\n/admin-dev/import/*\n!/admin-dev/import/.htaccess\n!/admin-dev/import/index.php\n\n/admin-dev/export/*\n!/admin-dev/export/.htaccess\n!/admin-dev/export/index.php\n\n# Downloaded RTL files\n/admin-dev/themes/default/css/bundle/default_rtl.css\n/admin-dev/themes/default/css/bundle/shared_rtl.css\n/admin-dev/themes/default/css/font_rtl.css\n/admin-dev/themes/default/css/overrides_rtl.css\n/admin-dev/themes/default/css/vendor/font-awesome/font-awesome_rtl.css\n/admin-dev/themes/default/css/vendor/nv.d3_rtl.css\n/admin-dev/themes/default/css/vendor/titatoggle-min_rtl.css\n/admin-dev/themes/default/public/theme_rtl.css\n/admin-dev/themes/new-theme/css/module/drop_rtl.css\n/admin-dev/themes/new-theme/css/right-sidebar_rtl.css\n\nthemes/*/cache/*\n\n# Config"}, {"id": "Prestashop.gitignore_3", "file": "Prestashop.gitignore", "content": "/admin-dev/themes/new-theme/css/right-sidebar_rtl.css\n\nthemes/*/cache/*\n\n# Config\n\nconfig/settings.inc.php\nconfig/settings.old.php\nconfig/xml/*\nconfig/themes/*\n!config/xml/themes/default.xml\nthemes/*/config/settings_*.json\napp/config/parameters.old.yml\napp/config/config.php\n\n# Themes, modules and overrides\n\nmodules/*\noverride/*\nthemes/*/\n!themes/classic\n!themes/_core\n!themes/_libraries\n\n# Vendors and dependencies\n\nbower_components/\nnode_modules/\ncomposer.phar\nphp-cs-fixer\n.grunt/*\n\n# Translations and emails templates\n\ntranslations/*\nmails/*\n!mails/themes/\n!mails/_partials/\nthemes/default-bootstrap/lang/*\nthemes/default-bootstrap/modules/*/translations/*.php\nthemes/default-bootstrap/mails/*\n!themes/default-bootstrap/mails/en/\nthemes/default-bootstrap/modules/*/mails/*"}, {"id": "Prestashop.gitignore_4", "file": "Prestashop.gitignore", "content": "!themes/default-bootstrap/mails/en/\nthemes/default-bootstrap/modules/*/mails/*\n!themes/default-bootstrap/modules/*/mails/en\n\n# MISC\n\n*sitemap.xml\n/robots.txt\n\n# Symfony\n\n/bin/\n/app/Resources/geoip/GeoLite2-City.mmdb\n/app/Resources/translations/*\n!/app/Resources/translations/default\n/app/config/parameters.yml\n/app/config/parameters.php\n/build/\n/phpunit.xml\n/var/*\n!/var/cache\n/var/cache/*\n!var/cache/.gitkeep\n!/var/logs\n/var/logs/*\n!var/logs/.gitkeep\n!/var/sessions\n/var/sessions/*\n!var/sessions/.gitkeep\n!var/SymfonyRequirements.php\n/vendor/\n/web/bundles/"}, {"id": "Processing.gitignore_0", "file": "Processing.gitignore", "content": "================================================\n.DS_Store\napplet\napplication.linux-arm64\napplication.linux-armv6hf\napplication.linux32\napplication.linux64\napplication.windows32\napplication.windows64\napplication.macosx\nout"}, {"id": "PureScript.gitignore_0", "file": "PureScript.gitignore", "content": "================================================\n# Dependencies\n.psci_modules\n.spago\nbower_components\nnode_modules\n\n# Generated files\n.psci\noutput"}, {"id": "Python.gitignore_0", "file": "Python.gitignore", "content": "================================================\n# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[codz]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py.cover\n.hypothesis/\n.pytest_cache/\ncover/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log"}, {"id": "Python.gitignore_1", "file": "Python.gitignore", "content": "*.py.cover\n.hypothesis/\n.pytest_cache/\ncover/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\n.pybuilder/\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n#   For a library or package, you might want to ignore these files since the code is\n#   intended to run in multiple environments; otherwise, check them in:\n# .python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies"}, {"id": "Python.gitignore_2", "file": "Python.gitignore", "content": "#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\n#Pipfile.lock\n\n# UV\n#   Similar to Pipfile.lock, it is generally recommended to include uv.lock in version control.\n#   This is especially recommended for binary packages to ensure reproducibility, and is more\n#   commonly ignored for libraries.\n#uv.lock\n\n# poetry\n#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.\n#   This is especially recommended for binary packages to ensure reproducibility, and is more\n#   commonly ignored for libraries."}, {"id": "Python.gitignore_3", "file": "Python.gitignore", "content": "#   commonly ignored for libraries.\n#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control\n#poetry.lock\n#poetry.toml\n\n# pdm\n#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.\n#   pdm recommends including project-wide configuration in pdm.toml, but excluding .pdm-python.\n#   https://pdm-project.org/en/latest/usage/project/#working-with-version-control\n#pdm.lock\n#pdm.toml\n.pdm-python\n.pdm-build/\n\n# pixi\n#   Similar to Pipfile.lock, it is generally recommended to include pixi.lock in version control.\n#pixi.lock\n#   Pixi creates a virtual environment in the .pixi directory, just like venv module creates one\n#   in the .venv directory. It is recommended not to include this directory in version control.\n.pixi"}, {"id": "Python.gitignore_4", "file": "Python.gitignore", "content": ".pixi\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# Redis\n*.rdb\n*.aof\n*.pid\n\n# RabbitMQ\nmnesia/\nrabbitmq/\nrabbitmq-data/\n\n# ActiveMQ\nactivemq-data/\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.envrc\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n# pytype static type analyzer\n.pytype/\n\n# Cython debug symbols\ncython_debug/\n\n# PyCharm\n#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can"}, {"id": "Python.gitignore_5", "file": "Python.gitignore", "content": "# PyCharm\n#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can\n#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore\n#  and can be added to the global gitignore or merged into this file.  For a more nuclear\n#  option (not recommended) you can uncomment the following to ignore the entire idea folder.\n#.idea/\n\n# Abstra\n# Abstra is an AI-powered process automation framework.\n# Ignore directories containing user credentials, local state, and settings.\n# Learn more at https://abstra.io/docs\n.abstra/\n\n# Visual Studio Code\n#  Visual Studio Code specific template is maintained in a separate VisualStudioCode.gitignore\n#  that can be found at https://github.com/github/gitignore/blob/main/Global/VisualStudioCode.gitignore"}, {"id": "Python.gitignore_6", "file": "Python.gitignore", "content": "#  and can be added to the global gitignore or merged into this file. However, if you prefer,\n#  you could uncomment the following to ignore the entire vscode folder\n# .vscode/\n\n# Ruff stuff:\n.ruff_cache/\n\n# PyPI configuration file\n.pypirc\n\n# Marimo\nmarimo/_static/\nmarimo/_lsp/\n__marimo__/\n\n# Streamlit\n.streamlit/secrets.toml"}, {"id": "Qooxdoo.gitignore_0", "file": "Qooxdoo.gitignore", "content": "================================================\ncache\ncache-downloads\ninspector\napi\nsource/inspector.html"}, {"id": "Qt.gitignore_0", "file": "Qt.gitignore", "content": "================================================\n# C++ objects and libs\n*.slo\n*.lo\n*.o\n*.a\n*.la\n*.lai\n*.so\n*.so.*\n*.dll\n*.dylib\n\n# Qt-es\nobject_script.*.Release\nobject_script.*.Debug\n*_plugin_import.cpp\n/.qmake.cache\n/.qmake.stash\n*.pro.user\n*.pro.user.*\n*.qbs.user\n*.qbs.user.*\n*.moc\nmoc_*.cpp\nmoc_*.h\nqrc_*.cpp\nui_*.h\n*.qmlc\n*.jsc\nMakefile*\n*build-*\n*.qm\n*.prl\n\n# Qt unit tests\ntarget_wrapper.*\n\n# QtCreator\n*.autosave\n\n# QtCreator Qml\n*.qmlproject.user\n*.qmlproject.user.*\n\n# QtCreator CMake\nCMakeLists.txt.user*\n\n# QtCreator 4.8< compilation database\ncompile_commands.json\n\n# QtCreator local machine specific files for imported projects\n*creator.user*\n\n*_qmlcache.qrc"}, {"id": "R.gitignore_0", "file": "R.gitignore", "content": "================================================\n# History files\n.Rhistory\n.Rapp.history\n\n# Session Data files\n.RData\n.RDataTmp\n\n# User-specific files\n.Ruserdata\n\n# Example code in package build process\n*-Ex.R\n\n# Output files from R CMD build\n/*.tar.gz\n\n# Output files from R CMD check\n/*.Rcheck/\n\n# RStudio files\n.Rproj.user/\n\n# produced vignettes\nvignettes/*.html\nvignettes/*.pdf\n\n# OAuth2 token, see https://github.com/hadley/httr/releases/tag/v0.3\n.httr-oauth\n\n# knitr and R markdown default cache directories\n*_cache/\n/cache/\n\n# Temporary files created by R markdown\n*.utf8.md\n*.knit.md\n\n# R Environment Variables\n.Renviron\n\n# pkgdown site\ndocs/\n\n# translation temp files\npo/*~\n\n# RStudio Connect folder\nrsconnect/"}, {"id": "Racket.gitignore_0", "file": "Racket.gitignore", "content": "================================================\n.DS_Store\ncompiled/\n/doc/\n*~\n*.bak\n\\#*\n.\\#*"}, {"id": "Rails.gitignore_0", "file": "Rails.gitignore", "content": "================================================\n*.rbc\ncapybara-*.html\n.rspec\n/db/*.sqlite3\n/db/*.sqlite3-journal\n/db/*.sqlite3-[0-9]*\n/public/system\n/coverage/\n/spec/tmp\n*.orig\nrerun.txt\npickle-email-*.html\n\n# Ignore all logfiles and tempfiles.\n/log/*\n/tmp/*\n!/log/.keep\n!/tmp/.keep\n\n# TODO Comment out this rule if you are OK with secrets being uploaded to the repo\nconfig/initializers/secret_token.rb\nconfig/master.key\n\n# Only include if you have production secrets in this file, which is no longer a Rails default\n# config/secrets.yml\n\n# dotenv, dotenv-rails\n# TODO Comment out these rules if environment variables can be committed\n.env\n.env*.local"}, {"id": "Rails.gitignore_1", "file": "Rails.gitignore", "content": "## Environment normalization:\n/.bundle\n/vendor/bundle\n\n# these should all be checked in to normalize the environment:\n# Gemfile.lock, .ruby-version, .ruby-gemset\n\n# unless supporting rvm < 1.11.0 or doing something fancy, ignore this:\n.rvmrc\n\n# if using bower-rails ignore default bower_components path bower.json files\n/vendor/assets/bower_components\n*.bowerrc\nbower.json\n\n# Ignore pow environment settings\n.powenv\n\n# Ignore Byebug command history file.\n.byebug_history\n\n# Ignore node_modules\nnode_modules/\n\n# Ignore precompiled javascript packs\n/public/packs\n/public/packs-test\n/public/assets\n\n# Ignore yarn files\n/yarn-error.log\nyarn-debug.log*\n.yarn-integrity\n\n# Ignore uploaded files in development\n/storage/*\n!/storage/.keep\n/public/uploads"}, {"id": "Raku.gitignore_0", "file": "Raku.gitignore", "content": "================================================\n# Gitignore for Raku (https://raku.org)\n# As part of https://github.com/github/gitignore\n\n# precompiled files\n.precomp\nlib/.precomp"}, {"id": "ReScript.gitignore_0", "file": "ReScript.gitignore", "content": "================================================\n/node_modules/\n/lib/\n.bsb.lock"}, {"id": "RhodesRhomobile.gitignore_0", "file": "RhodesRhomobile.gitignore", "content": "================================================\nrholog-*\nsim-*\nbin/libs\nbin/RhoBundle\nbin/tmp\nbin/target\nbin/*.ap_\n*.o\n*.jar"}, {"id": "ROS.gitignore_0", "file": "ROS.gitignore", "content": "================================================\ndevel/\nlogs/\nbuild/\nbin/\nlib/\nmsg_gen/\nsrv_gen/\nmsg/*Action.msg\nmsg/*ActionFeedback.msg\nmsg/*ActionGoal.msg\nmsg/*ActionResult.msg\nmsg/*Feedback.msg\nmsg/*Goal.msg\nmsg/*Result.msg\nmsg/_*.py\nbuild_isolated/\ndevel_isolated/\n\n# Generated by dynamic reconfigure\n*.cfgc\n/cfg/cpp/\n/cfg/*.py\n\n# Ignore generated docs\n*.dox\n*.wikidoc\n\n# eclipse stuff\n.project\n.cproject\n\n# qcreator stuff\nCMakeLists.txt.user\n\nsrv/_*.py\n*.pcd\n*.pyc\nqtcreator-*\n*.user\n\n/planning/cfg\n/planning/docs\n/planning/src\n\n*~\n\n# Emacs\n.#*\n\n# Catkin custom files\nCATKIN_IGNORE"}, {"id": "Ruby.gitignore_0", "file": "Ruby.gitignore", "content": "================================================\n*.gem\n*.rbc\n/.config\n/coverage/\n/InstalledFiles\n/pkg/\n/spec/reports/\n/spec/examples.txt\n/test/tmp/\n/test/version_tmp/\n/tmp/\n\n# Used by dotenv library to load environment variables.\n# .env\n\n# Ignore Byebug command history file.\n.byebug_history\n\n## Specific to RubyMotion:\n.dat*\n.repl_history\nbuild/\n*.bridgesupport\nbuild-iPhoneOS/\nbuild-iPhoneSimulator/\n\n## Specific to RubyMotion (use of CocoaPods):\n#\n# We recommend against adding the Pods directory to your .gitignore. However\n# you should judge for yourself, the pros and cons are mentioned at:\n# https://guides.cocoapods.org/using/using-cocoapods.html#should-i-check-the-pods-directory-into-source-control\n#\n# vendor/Pods/"}, {"id": "Ruby.gitignore_1", "file": "Ruby.gitignore", "content": "## Documentation cache and generated files:\n/.yardoc/\n/_yardoc/\n/doc/\n/rdoc/\n\n## Environment normalization:\n/.bundle/\n/vendor/bundle\n/lib/bundler/man/\n\n# for a library or gem, you might want to ignore these files since the code is\n# intended to run in multiple environments; otherwise, check them in:\n# Gemfile.lock\n# .ruby-version\n# .ruby-gemset\n\n# unless supporting rvm < 1.11.0 or doing something fancy, ignore this:\n.rvmrc\n\n# Used by RuboCop. Remote config files pulled in from inherit_from directive.\n# .rubocop-https?--*"}, {"id": "Rust.gitignore_0", "file": "Rust.gitignore", "content": "================================================\n# Generated by Cargo\n# will have compiled files and executables\ndebug\ntarget\n\n# These are backup files generated by rustfmt\n**/*.rs.bk\n\n# MSVC Windows builds of rustc generate these, which store debugging information\n*.pdb\n\n# Generated by cargo mutants\n# Contains mutation testing data\n**/mutants.out*/\n\n# RustRover\n#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can\n#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore\n#  and can be added to the global gitignore or merged into this file.  For a more nuclear\n#  option (not recommended) you can uncomment the following to ignore the entire idea folder.\n#.idea/"}, {"id": "Salesforce.gitignore_0", "file": "Salesforce.gitignore", "content": "================================================\n# This file is used for Git repositories to specify intentionally untracked files that Git should ignore. \n# If you are not using git, you can delete this file. For more information see: https://git-scm.com/docs/gitignore\n# For useful gitignore templates see: https://github.com/github/gitignore\n\n# Salesforce cache\n.sf/\n.sfdx/\n.localdevserver/\ndeploy-options.json\n.localdev\n\n# LWC VSCode autocomplete\n**/lwc/jsconfig.json\n\n# LWC Jest coverage reports\ncoverage/\n\n# Logs\nlogs\n*.log\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\n\n# Eslint cache\n.eslintcache\n\n# Windows system files\nThumbs.db\nehthumbs.db\n[Dd]esktop.ini\n$RECYCLE.BIN/\n\n# Salesforce Analyzer results\nsca-results.csv\nsfca_results.json\n\n# Local environment variables\n.env"}, {"id": "Sass.gitignore_0", "file": "Sass.gitignore", "content": "================================================\n.sass-cache/\n*.css.map\n*.sass.map\n*.scss.map"}, {"id": "Scala.gitignore_0", "file": "Scala.gitignore", "content": "================================================\n*.class\n*.log\n\n# virtual machine crash logs, see http://www.java.com/en/download/help/error_hotspot.xml\nhs_err_pid*"}, {"id": "Scheme.gitignore_0", "file": "Scheme.gitignore", "content": "================================================\n*.ss~\n*.ss#*\n.#*.ss\n\n*.scm~\n*.scm#*\n.#*.scm"}, {"id": "SCons.gitignore_0", "file": "SCons.gitignore", "content": "================================================\n# for projects that use SCons for building: http://http://www.scons.org/\n.sconsign.dblite\n\n# When configure fails, SCons outputs these\nconfig.log\n.sconf_temp"}, {"id": "Scrivener.gitignore_0", "file": "Scrivener.gitignore", "content": "================================================\n*/Files/binder.autosave\n*/Files/binder.backup\n*/Files/search.indexes\n*/Files/user.lock\n*/Files/Docs/docs.checksum\n*/Files/Data/docs.checksum\n*/QuickLook/\n*/Settings/ui.plist"}, {"id": "Sdcc.gitignore_0", "file": "Sdcc.gitignore", "content": "================================================\n# SDCC stuff\n*.lnk\n*.lst\n*.map\n*.mem\n*.rel\n*.rst\n*.sym"}, {"id": "SeamGen.gitignore_0", "file": "SeamGen.gitignore", "content": "================================================\n/bootstrap/data\n/bootstrap/tmp\n/classes/\n/dist/\n/exploded-archives/\n/test-build/\n/test-output/\n/test-report/\n/target/\ntemp-testng-customsuite.xml\n\n# based on http://stackoverflow.com/a/8865858/422476 I am removing inline comments\n\n#/classes/  \t\t              all class files\n#/dist/                       contains generated war files for deployment\n#/exploded-archives/\t\t      war content generation during deploy (or explode)\n#/test-build/                 test compilation (ant target for Seam)\n#/test-output/                test results\n#/test-report/                test report generation for, e.g., Hudson\n#/target/                     maven output folder\n#temp-testng-customsuite.xml\tgenerated when running test cases under Eclipse"}, {"id": "SeamGen.gitignore_1", "file": "SeamGen.gitignore", "content": "#temp-testng-customsuite.xml\tgenerated when running test cases under Eclipse\n\n# Thanks to @VonC and @kraftan for their helpful answers on a related question\n# on StackOverflow.com:\n# http://stackoverflow.com/questions/4176687\n# /what-is-the-recommended-source-control-ignore-pattern-for-seam-projects"}, {"id": "SketchUp.gitignore_0", "file": "SketchUp.gitignore", "content": "================================================\n*.skb"}, {"id": "Smalltalk.gitignore_0", "file": "Smalltalk.gitignore", "content": "================================================\n# changes file\n*.changes\n*.chg\n\n# system image\n*.image\n*.img7\n*.img\n\n# Pharo Smalltalk Debug log file\nPharoDebug.log\n\n# Squeak Smalltalk Debug log file\nSqueakDebug.log\n\n# Dolphin Smalltalk source file\n*.sml\n\n# Dolphin Smalltalk error file\n*.errors\n\n# Monticello package cache\n/package-cache\n\n# playground cache\n/play-cache\n/play-stash\n\n# Metacello-github cache\n/github-cache\ngithub-*.zip"}, {"id": "Solidity-Remix.gitignore_0", "file": "Solidity-Remix.gitignore", "content": "================================================\n# Remix compiler artifacts\n**/artifacts/\n**/artifacts/**\n\n# Remix plugin state folders\ndeps/\nstates/\n\n# Debug info\n*.dbg.json\n*.tsbuildinfo\n\n# Optional\n.env\n.env.local"}, {"id": "SSDT-sqlproj.gitignore_0", "file": "SSDT-sqlproj.gitignore", "content": "================================================\n## Ignore Visual Studio SSDT sqlproj specific temporary files, build results, etc\n##\n##\n## Get latest from https://github.com/github/gitignore/blob/master/SSDT-sqlproj.gitignore\n# Build output\nbin/\nobj/\n\n# DACPAC files\n*.dacpac\n\n# Publish profiles (optional, if environment-specific)\n*.publish.xml\n\n# SQL Server debug files\n*.dbmdl\n*.sqlcmdvars\n\n# Visual Studio settings\n.vs/\n\n# User-specific files\n*.user\n*.suo\n*.userosscache\n*.sln.docstates\n\n# Backup files\n*.bak\n*.log"}, {"id": "Stella.gitignore_0", "file": "Stella.gitignore", "content": "================================================\n# Atari 2600 (Stella) support for multiple assemblers\n# - DASM\n# - CC65\n\n# Assembled binaries and object directories\nobj/\na.out\n*.bin\n*.a26\n\n# Add in special Atari 7800-based binaries for good measure\n*.a78"}, {"id": "SugarCRM.gitignore_0", "file": "SugarCRM.gitignore", "content": "================================================"}, {"id": "SugarCRM.gitignore_1", "file": "SugarCRM.gitignore", "content": "## SugarCRM\n# Ignore custom .htaccess stuff.\n/.htaccess\n# Ignore the cache directory completely.\n# This will break the current behaviour. Which was often leading to\n# the misuse of the repository as backup replacement.\n# For development the cache directory can be safely ignored and\n# therefore it is ignored.\n/cache/*\n!/cache/index.html\n# Ignore some files and directories from the custom directory.\n/custom/history/\n/custom/modulebuilder/\n/custom/working/\n/custom/modules/*/Ext/\n/custom/application/Ext/\n# Custom configuration should also be ignored.\n/config.php\n/config_override.php\n# The silent upgrade scripts aren't needed.\n/silentUpgrade*.php\n# Logs files can safely be ignored.\n*.log\n# Ignore the new upload directories.\n/upload/*\n!/upload/index.html\n/upload_backup/"}, {"id": "Swift.gitignore_0", "file": "Swift.gitignore", "content": "================================================\n# Xcode\n#\n# gitignore contributors: remember to update Global/Xcode.gitignore, Objective-C.gitignore & Swift.gitignore\n\n## User settings\nxcuserdata/\n\n## Obj-C/Swift specific\n*.hmap\n\n## App packaging\n*.ipa\n*.dSYM.zip\n*.dSYM"}, {"id": "Swift.gitignore_1", "file": "Swift.gitignore", "content": "## Playgrounds\ntimeline.xctimeline\nplayground.xcworkspace\n\n# Swift Package Manager\n#\n# Add this line if you want to avoid checking in source code from Swift Package Manager dependencies.\n# Packages/\n# Package.pins\n# Package.resolved\n# *.xcodeproj\n#\n# Xcode automatically generates this directory with a .xcworkspacedata file and xcuserdata\n# hence it is not needed unless you have added a package configuration file to your project\n# .swiftpm\n\n.build/\n\n# CocoaPods\n#\n# We recommend against adding the Pods directory to your .gitignore. However\n# you should judge for yourself, the pros and cons are mentioned at:\n# https://guides.cocoapods.org/using/using-cocoapods.html#should-i-check-the-pods-directory-into-source-control\n#\n# Pods/\n#"}, {"id": "Swift.gitignore_2", "file": "Swift.gitignore", "content": "#\n# Pods/\n#\n# Add this line if you want to avoid checking in source code from the Xcode workspace\n# *.xcworkspace\n\n# Carthage\n#\n# Add this line if you want to avoid checking in source code from Carthage dependencies.\n# Carthage/Checkouts\n\nCarthage/Build/\n\n# fastlane\n#\n# It is recommended to not store the screenshots in the git repo.\n# Instead, use fastlane to re-generate the screenshots whenever they are needed.\n# For more information about the recommended setup visit:\n# https://docs.fastlane.tools/best-practices/source-control/#source-control\n\nfastlane/report.xml\nfastlane/Preview.html\nfastlane/screenshots/**/*.png\nfastlane/test_output"}, {"id": "Symfony.gitignore_0", "file": "Symfony.gitignore", "content": "================================================\n# Cache and logs (Symfony2)\n/app/cache/*\n/app/logs/*\n!app/cache/.gitkeep\n!app/logs/.gitkeep\n\n# Email spool folder\n/app/spool/*\n\n# Cache, session files and logs (Symfony3)\n/var/cache/*\n/var/logs/*\n/var/sessions/*\n!var/cache/.gitkeep\n!var/logs/.gitkeep\n!var/sessions/.gitkeep\n\n# Logs (Symfony4)\n/var/log/*\n!var/log/.gitkeep\n\n# Parameters\n/app/config/parameters.yml\n/app/config/parameters.ini\n\n# Managed by Composer\n/app/bootstrap.php.cache\n/var/bootstrap.php.cache\n/bin/*\n!bin/console\n!bin/symfony_requirements\n/vendor/\n\n# Assets and user uploads\n/web/bundles/\n/web/uploads/\n\n# PHPUnit\n/app/phpunit.xml\n/phpunit.xml\n\n# Build data\n/build/\n\n# Composer PHAR\n/composer.phar\n\n# Backup entities generated with doctrine:generate:entities command\n**/Entity/*~"}, {"id": "Symfony.gitignore_1", "file": "Symfony.gitignore", "content": "/composer.phar\n\n# Backup entities generated with doctrine:generate:entities command\n**/Entity/*~\n\n# Embedded web-server pid file\n/.web-server-pid"}, {"id": "SymphonyCMS.gitignore_0", "file": "SymphonyCMS.gitignore", "content": "================================================\nmanifest/cache/\nmanifest/logs/\nmanifest/tmp/\nsymphony/\nworkspace/uploads/\ninstall-log.txt"}, {"id": "Terraform.gitignore_0", "file": "Terraform.gitignore", "content": "================================================\n# Local .terraform directories\n.terraform/\n\n# .tfstate files\n*.tfstate\n*.tfstate.*\n\n# Crash log files\ncrash.log\ncrash.*.log\n\n# Exclude all .tfvars files, which are likely to contain sensitive data, such as\n# password, private keys, and other secrets. These should not be part of version\n# control as they are data points which are potentially sensitive and subject\n# to change depending on the environment.\n*.tfvars\n*.tfvars.json\n\n# Ignore override files as they are usually used to override resources locally and so\n# are not checked in\noverride.tf\noverride.tf.json\n*_override.tf\n*_override.tf.json\n\n# Ignore transient lock info files created by terraform apply\n.terraform.tfstate.lock.info"}, {"id": "Terraform.gitignore_1", "file": "Terraform.gitignore", "content": "# Ignore transient lock info files created by terraform apply\n.terraform.tfstate.lock.info\n\n# Include override files you do wish to add to version control using negated pattern\n# !example_override.tf\n\n# Include tfplan files to ignore the plan output of command: terraform plan -out=tfplan\n# example: *tfplan*\n\n# Ignore CLI configuration files\n.terraformrc\nterraform.rc\n\n# Optional: ignore graph output files generated by `terraform graph`\n# *.dot\n\n# Optional: ignore plan files saved before destroying Terraform configuration\n# Uncomment the line below if you want to ignore planout files.\n# planout"}, {"id": "TestComplete.gitignore_0", "file": "TestComplete.gitignore", "content": "================================================\n# Test Complete ignore files: https://support.smartbear.com/viewarticle/68002/\n\n# Tester-specific Settings\n*.tcCFGExtender\n*.tcLS\n\n# Type library declarations\n*.tlb\n\n# Log files\n*.tcLogs\n\n# Backup files\n*.bak"}, {"id": "TeX.gitignore_0", "file": "TeX.gitignore", "content": "================================================\n## Core latex/pdflatex auxiliary files:\n*.aux\n*.lof\n*.log\n*.lot\n*.fls\n*.out\n*.toc\n*.fmt\n*.fot\n*.cb\n*.cb2\n.*.lb\n\n## Intermediate documents:\n*.dvi\n*.xdv\n*-converted-to.*\n# these rules might exclude image files for figures etc.\n# *.ps\n# *.eps\n# *.pdf\n\n## Generated if empty string is given at \"Please type another file name for output:\"\n.pdf\n\n## Bibliography auxiliary files (bibtex/biblatex/biber):\n*.bbl\n*.bbl-SAVE-ERROR\n*.bcf\n*.bcf-SAVE-ERROR\n*.blg\n*-blx.aux\n*-blx.bib\n*.run.xml\n\n## Build tool auxiliary files:\n*.fdb_latexmk\n*.synctex\n*.synctex(busy)\n*.synctex.gz\n*.synctex.gz(busy)\n*.pdfsync\n*.rubbercache\nrubber.cache\n\n## Build tool directories for auxiliary files\n# latexrun\nlatex.out/"}, {"id": "TeX.gitignore_1", "file": "TeX.gitignore", "content": "## Auxiliary and intermediate files from other packages:\n# algorithms\n*.alg\n*.loa\n\n# achemso\nacs-*.bib\n\n# amsthm\n*.thm\n\n# attachfile2\n*.atfi\n\n# beamer\n*.nav\n*.pre\n*.snm\n*.vrb\n\n# changes\n*.soc\n*.loc\n\n# comment\n*.cut\n\n# cprotect\n*.cpt\n\n# elsarticle (documentclass of Elsevier journals)\n*.spl\n\n# endnotes\n*.ent\n\n# fixme\n*.lox\n\n# feynmf/feynmp\n*.mf\n*.mp\n*.t[1-9]\n*.t[1-9][0-9]\n*.tfm\n\n#(r)(e)ledmac/(r)(e)ledpar\n*.end\n*.?end\n*.[1-9]\n*.[1-9][0-9]\n*.[1-9][0-9][0-9]\n*.[1-9]R\n*.[1-9][0-9]R\n*.[1-9][0-9][0-9]R\n*.eledsec[1-9]\n*.eledsec[1-9]R\n*.eledsec[1-9][0-9]\n*.eledsec[1-9][0-9]R\n*.eledsec[1-9][0-9][0-9]\n*.eledsec[1-9][0-9][0-9]R\n\n# glossaries\n*.acn\n*.acr\n*.glg\n*.glg-abr\n*.glo\n*.glo-abr\n*.gls\n*.gls-abr\n*.glsdefs\n*.lzo\n*.lzs\n*.slg\n*.slo\n*.sls"}, {"id": "TeX.gitignore_2", "file": "TeX.gitignore", "content": "*.acr\n*.glg\n*.glg-abr\n*.glo\n*.glo-abr\n*.gls\n*.gls-abr\n*.glsdefs\n*.lzo\n*.lzs\n*.slg\n*.slo\n*.sls\n\n# uncomment this for glossaries-extra (will ignore makeindex's style files!)\n# *.ist\n\n# gnuplot\n*.gnuplot\n*.table\n\n# gnuplottex\n*-gnuplottex-*\n\n# gregoriotex\n*.gaux\n*.glog\n*.gtex\n\n# htlatex\n*.4ct\n*.4tc\n*.idv\n*.lg\n*.trc\n*.xref\n\n# hypdoc\n*.hd\n\n# hyperref\n*.brf\n\n# knitr\n*-concordance.tex\n# TODO Uncomment the next line if you use knitr and want to ignore its generated tikz files\n# *.tikz\n*-tikzDictionary\n\n# latexindent will create succesive backup files by default\n#*.bak*\n\n# listings\n*.lol\n\n# luatexja-ruby\n*.ltjruby\n\n# makeidx\n*.idx\n*.ilg\n*.ind\n\n# minitoc\n*.maf\n*.mlf\n*.mlt\n*.mtc[0-9]*\n*.slf[0-9]*\n*.slt[0-9]*\n*.stc[0-9]*\n\n# minted\n_minted*\n*.data.minted\n*.pyg\n\n# morewrites\n*.mw\n\n# newpax\n*.newpax"}, {"id": "TeX.gitignore_3", "file": "TeX.gitignore", "content": "*.stc[0-9]*\n\n# minted\n_minted*\n*.data.minted\n*.pyg\n\n# morewrites\n*.mw\n\n# newpax\n*.newpax\n\n# nomencl\n*.nlg\n*.nlo\n*.nls\n\n# pax\n*.pax\n\n# pdfpcnotes\n*.pdfpc\n\n# sagetex\n*.sagetex.sage\n*.sagetex.py\n*.sagetex.scmd\n\n# scrwfile\n*.wrt\n\n# spelling\n*.spell.bad\n*.spell.txt\n\n# svg\nsvg-inkscape/\n\n# sympy\n*.sout\n*.sympy\nsympy-plots-for-*.tex/\n\n# pdfcomment\n*.upa\n*.upb\n\n# pythontex\n*.pytxcode\npythontex-files-*/\n\n# tcolorbox\n*.listing\n\n# thmtools\n*.loe\n\n# TikZ & PGF\n*.dpth\n*.md5\n*.auxlock\n\n# titletoc\n*.ptc\n\n# todonotes\n*.tdo\n\n# vhistory\n*.hst\n*.ver\n\n# easy-todo\n*.lod\n\n# xcolor\n*.xcp\n\n# xmpincl\n*.xmpi\n\n# xindy\n*.xdy\n\n# xypic precompiled matrices and outlines\n*.xyc\n*.xyd\n\n# endfloat\n*.ttt\n*.fff\n\n# Latexian\nTSWLatexianTemp*"}, {"id": "TeX.gitignore_4", "file": "TeX.gitignore", "content": "## Editors:\n# WinEdt\n*.bak\n*.sav\n\n# latexindent.pl\n*.bak[0-9]*\n\n# Texpad\n.texpadtmp\n\n# LyX\n*.lyx~\n\n# Kile\n*.backup\n\n# gummi\n.*.swp\n\n# KBibTeX\n*~[0-9]*\n\n# TeXnicCenter\n*.tps\n\n# auto folder when using emacs and auctex\n./auto/*\n*.el\n\n# expex forward references with \\gathertags\n*-tags.tex\n\n# standalone packages\n*.sta\n\n# Makeindex log files\n*.lpz\n\n# xwatermark package\n*.xwm\n\n# REVTeX puts footnotes in the bibliography by default, unless the nofootinbib\n# option is specified. Footnotes are the stored in a file with suffix Notes.bib.\n# Uncomment the next line to have this generated file ignored.\n#*Notes.bib"}, {"id": "Textpattern.gitignore_0", "file": "Textpattern.gitignore", "content": "================================================\n.htaccess\ncss.php\nrpc/\nsites/site*/admin/\nsites/site*/private/\nsites/site*/public/admin/\nsites/site*/public/setup/\nsites/site*/public/theme/\ntextpattern/\nHISTORY.txt\nREADME.txt"}, {"id": "TurboGears2.gitignore_0", "file": "TurboGears2.gitignore", "content": "================================================\n*.py[co]\n\n# Default development database\ndevdata.db\n\n# Default data directory\ndata/*\n\n# Packages\n*.egg\n*.egg-info\ndist\nbuild\n\n# Installer logs\npip-log.txt\n\n# Unit test / coverage reports\n.coverage\n.tox"}, {"id": "TwinCAT3.gitignore_0", "file": "TwinCAT3.gitignore", "content": "================================================"}, {"id": "TwinCAT3.gitignore_1", "file": "TwinCAT3.gitignore", "content": "### TwinCAT3 ###\n# website: https://www.beckhoff.com/twincat3/\n\n# TwinCAT PLC\n*.plcproj.bak\n*.plcproj.orig\n*.tpy\n*.tclrs\n*.library\n*.compiled-library\n*.compileinfo\n*.asm\n*.core\nLineIDs.dbg\nLineIDs.dbg.bak\n\n# TwinCAT C++ and shared types\n# ignoring the TMC file is only useful for plain PLC programming\n# as soon as shared data types (via tmc), C++ or in general TcCom-Module are used, the TMC file has to be part of the repository\n*.tmc\n*.tmcRefac\n\n# TwinCAT project files\n*.tsproj.bak\n*.tsproj.b?k\n*.tsproj.orig\n*.tspproj.bak\n*.xti.bak\n*.xti.bk?\n*.xti.orig\n*.xtv\n*.xtv.bak\n*.xtv.bk?\n*.xt?.bk?\n*.xt?.orig\n\n# Multiuser specific\n**/.TcGit/\n\n# exclude not required folders\n**/_Boot/\n**/_CompileInfo/\n**/_Libraries/\n**/_ModuleInstall/\n**/_Deployment/\n**/_Repository/"}, {"id": "TwinCAT3.gitignore_2", "file": "TwinCAT3.gitignore", "content": "**/_Boot/\n**/_CompileInfo/\n**/_Libraries/\n**/_ModuleInstall/\n**/_Deployment/\n**/_Repository/\n\n\n# To include a specific library directory (i.e. third party/custom libs),\n# use pattern `!/**/_Libraries/<directory name>/` i.e. `!/**/_Libraries/www.tcunit.org/`\n#\n\n# VS Shell project specific files and folders\n**/.vs/\n*.~u\n*.project.~u\n*.suo"}, {"id": "Typo3.gitignore_0", "file": "Typo3.gitignore", "content": "================================================\n## TYPO3 v6.2\n# Ignore several upload and file directories.\n/fileadmin/user_upload/\n/fileadmin/_temp_/\n/fileadmin/_processed_/\n/uploads/\n# Ignore cache\n/typo3conf/temp_CACHED*\n/typo3conf/temp_fieldInfo.php\n/typo3conf/deprecation_*.log\n/typo3conf/ENABLE_INSTALL_TOOL\n/typo3conf/realurl_autoconf.php\n/FIRST_INSTALL\n# Ignore system folders, you should have them symlinked.\n# If not comment out the following entries.\n/typo3\n/typo3_src\n/typo3_src-*\n/Packages\n/.htaccess\n/index.php\n# Ignore temp directory.\n/typo3temp/"}, {"id": "Unity.gitignore_0", "file": "Unity.gitignore", "content": "================================================\n# This .gitignore file should be placed at the root of your Unity project directory\n#\n# Get latest from https://github.com/github/gitignore/blob/main/Unity.gitignore\n#\n.utmp/\n/[Ll]ibrary/\n/[Tt]emp/\n/[Oo]bj/\n/[Bb]uild/\n/[Bb]uilds/\n/[Ll]ogs/\n/[Uu]ser[Ss]ettings/\n*.log\n\n# By default unity supports Blender asset imports, *.blend1 blender files do not need to be commited to version control.\n*.blend1\n*.blend1.meta\n\n# MemoryCaptures can get excessive in size.\n# They also could contain extremely sensitive data\n/[Mm]emoryCaptures/\n\n# Recordings can get excessive in size\n/[Rr]ecordings/\n\n# Uncomment this line if you wish to ignore the asset store tools plugin\n# /[Aa]ssets/AssetStoreTools*\n\n# Autogenerated Jetbrains Rider plugin"}, {"id": "Unity.gitignore_1", "file": "Unity.gitignore", "content": "# /[Aa]ssets/AssetStoreTools*\n\n# Autogenerated Jetbrains Rider plugin\n/[Aa]ssets/Plugins/Editor/JetBrains*\n# Jetbrains Rider personal-layer settings\n*.DotSettings.user\n\n# Visual Studio cache directory\n.vs/\n\n# Gradle cache directory\n.gradle/\n\n# Autogenerated VS/MD/Consulo solution and project files\nExportedObj/\n.consulo/\n*.csproj\n*.unityproj\n*.sln\n*.suo\n*.tmp\n*.user\n*.userprefs\n*.pidb\n*.booproj\n*.svd\n*.pdb\n*.mdb\n*.opendb\n*.VC.db\n\n# Unity3D generated meta files\n*.pidb.meta\n*.pdb.meta\n*.mdb.meta\n\n# Unity3D generated file on crash reports\nsysinfo.txt\n\n# Mono auto generated files\nmono_crash.*\n\n# Builds\n*.apk\n*.aab\n*.unitypackage\n*.unitypackage.meta\n*.app\n\n# Crashlytics generated file\ncrashlytics-build.properties\n\n# TestRunner generated files\nInitTestScene*.unity*"}, {"id": "Unity.gitignore_2", "file": "Unity.gitignore", "content": "crashlytics-build.properties\n\n# TestRunner generated files\nInitTestScene*.unity*\n\n# Addressables default ignores, before user customizations\n/ServerData\n/[Aa]ssets/StreamingAssets/aa*\n/[Aa]ssets/AddressableAssetsData/link.xml*\n/[Aa]ssets/Addressables_Temp*\n# By default, Addressables content builds will generate addressables_content_state.bin\n# files in platform-specific subfolders, for example:\n# /Assets/AddressableAssetsData/OSX/addressables_content_state.bin\n/[Aa]ssets/AddressableAssetsData/*/*.bin*\n\n# Visual Scripting auto-generated files\n/[Aa]ssets/Unity.VisualScripting.Generated/VisualScripting.Flow/UnitOptions.db\n/[Aa]ssets/Unity.VisualScripting.Generated/VisualScripting.Flow/UnitOptions.db.meta\n/[Aa]ssets/Unity.VisualScripting.Generated/VisualScripting.Core/Property Providers"}, {"id": "Unity.gitignore_3", "file": "Unity.gitignore", "content": "/[Aa]ssets/Unity.VisualScripting.Generated/VisualScripting.Core/Property Providers\n/[Aa]ssets/Unity.VisualScripting.Generated/VisualScripting.Core/Property Providers.meta\n\n# Auto-generated scenes by play mode tests\n/[Aa]ssets/[Ii]nit[Tt]est[Ss]cene*.unity*"}, {"id": "UnrealEngine.gitignore_0", "file": "UnrealEngine.gitignore", "content": "================================================\n# Visual Studio 2015 user specific files\n.vs/\n\n# Compiled Object files\n*.slo\n*.lo\n*.o\n*.obj\n\n# Precompiled Headers\n*.gch\n*.pch\n\n# Compiled Dynamic libraries\n*.so\n*.dylib\n*.dll\n\n# Fortran module files\n*.mod\n\n# Compiled Static libraries\n*.lai\n*.la\n*.a\n*.lib\n\n# Executables\n*.exe\n*.out\n*.app\n*.ipa\n\n# These project files can be generated by the engine\n*.xcodeproj\n*.xcworkspace\n*.sln\n*.suo\n*.opensdf\n*.sdf\n*.VC.db\n*.VC.opendb\n.vsconfig\n\n# Precompiled Assets\nSourceArt/**/*.png\nSourceArt/**/*.tga\n\n# Binary Files\nBinaries/*\nPlugins/**/Binaries/*\n\n# Builds\nBuild/*\n\n# Whitelist PakBlacklist-<BuildConfiguration>.txt files\n!Build/*/\nBuild/*/**\n!Build/*/PakBlacklist*.txt\n\n# Don't ignore icon files in Build\n!Build/**/*.ico\n\n# Built data for maps"}, {"id": "UnrealEngine.gitignore_1", "file": "UnrealEngine.gitignore", "content": "# Don't ignore icon files in Build\n!Build/**/*.ico\n\n# Built data for maps\n*_BuiltData.uasset\n\n# Configuration files generated by the Editor\nSaved/*\n\n# Compiled source files for the engine to use\nIntermediate/*\nPlugins/**/Intermediate/*\n\n# Cache files for the editor to use\nDerivedDataCache/*"}, {"id": "VBA.gitignore_0", "file": "VBA.gitignore", "content": "================================================\n\n# Office temporary files\n~$*\n\n# Access database lock files (laccdb, ldb)\n*.[lL][aA][cC][cC][dD][bB]\n*.[lL][dD][bB]\n\n# The following sections constitute a list of Office file extensions that support VBA.\n# If you want to exclude Office files from your repo, uncomment the corresponding file extensions.\n\n# Excel (xls, xlsb, xlsm, xlt, xltm, xla, xlam)\n#*.[xX][lL][sS]\n#*.[xX][lL][sS][bB]\n#*.[xX][lL][sS][mM]\n#*.[xX][lL][tT]\n#*.[xX][lL][tT][mM]\n#*.[xX][lL][aA]\n#*.[xX][lL][aA][mM]\n\n# Word (doc, docm, dot, dotm)\n#*.[dD][oO][cC]\n#*.[dD][oO][cC][mM]\n#*.[dD][oO][tT]\n#*.[dD][oO][tT][mM]\n\n# Access (accda, accdb, accde, mdb, mde)\n#*.[aA][cC][cC][dD][aA]\n#*.[aA][cC][cC][dD][bB]\n#*.[aA][cC][cC][dD][eE]\n#*.[mM][dD][bB]\n#*.[mM][dD][eE]"}, {"id": "VBA.gitignore_1", "file": "VBA.gitignore", "content": "#*.[aA][cC][cC][dD][bB]\n#*.[aA][cC][cC][dD][eE]\n#*.[mM][dD][bB]\n#*.[mM][dD][eE]\n\n# PowerPoint (ppt, pptm, pot, potm, pps, ppsm)\n#*.[pP][pP][tT]\n#*.[pP][pP][tT][mM]\n#*.[pP][oO][tT]\n#*.[pP][oO][tT][mM]\n#*.[pP][pP][sS]\n#*.[pP][pP][sS][mM]"}, {"id": "VisualStudio.gitignore_0", "file": "VisualStudio.gitignore", "content": "================================================\n## Ignore Visual Studio temporary files, build results, and\n## files generated by popular Visual Studio add-ons.\n##"}, {"id": "VisualStudio.gitignore_1", "file": "VisualStudio.gitignore", "content": "## Get latest from https://github.com/github/gitignore/blob/main/VisualStudio.gitignore\n\n# User-specific files\n*.rsuser\n*.suo\n*.user\n*.userosscache\n*.sln.docstates\n*.env\n\n# User-specific files (MonoDevelop/Xamarin Studio)\n*.userprefs\n\n# Mono auto generated files\nmono_crash.*\n\n# Build results\n[Dd]ebug/\n[Dd]ebugPublic/\n[Rr]elease/\n[Rr]eleases/\n\n[Dd]ebug/x64/\n[Dd]ebugPublic/x64/\n[Rr]elease/x64/\n[Rr]eleases/x64/\nbin/x64/\nobj/x64/\n\n[Dd]ebug/x86/\n[Dd]ebugPublic/x86/\n[Rr]elease/x86/\n[Rr]eleases/x86/\nbin/x86/\nobj/x86/\n\n[Ww][Ii][Nn]32/\n[Aa][Rr][Mm]/\n[Aa][Rr][Mm]64/\n[Aa][Rr][Mm]64[Ee][Cc]/\nbld/\n[Oo]bj/\n[Oo]ut/\n[Ll]og/\n[Ll]ogs/\n\n# Build results on 'Bin' directories\n**/[Bb]in/*\n# Uncomment if you have tasks that rely on *.refresh files to move binaries"}, {"id": "VisualStudio.gitignore_2", "file": "VisualStudio.gitignore", "content": "**/[Bb]in/*\n# Uncomment if you have tasks that rely on *.refresh files to move binaries\n# (https://github.com/github/gitignore/pull/3736)\n#!**/[Bb]in/*.refresh\n\n# Visual Studio 2015/2017 cache/options directory\n.vs/\n# Uncomment if you have tasks that create the project's static files in wwwroot\n#wwwroot/\n\n# Visual Studio 2017 auto generated files\nGenerated\\ Files/\n\n# MSTest test Results\n[Tt]est[Rr]esult*/\n[Bb]uild[Ll]og.*\n*.trx\n\n# NUnit\n*.VisualState.xml\nTestResult.xml\nnunit-*.xml\n\n# Approval Tests result files\n*.received.*\n\n# Build Results of an ATL Project\n[Dd]ebugPS/\n[Rr]eleasePS/\ndlldata.c\n\n# Benchmark Results\nBenchmarkDotNet.Artifacts/\n\n# .NET Core\nproject.lock.json\nproject.fragment.lock.json\nartifacts/\n\n# ASP.NET Scaffolding\nScaffoldingReadMe.txt\n\n# StyleCop\nStyleCopReport.xml"}, {"id": "VisualStudio.gitignore_3", "file": "VisualStudio.gitignore", "content": "artifacts/\n\n# ASP.NET Scaffolding\nScaffoldingReadMe.txt\n\n# StyleCop\nStyleCopReport.xml\n\n# Files built by Visual Studio\n*_i.c\n*_p.c\n*_h.h\n*.ilk\n*.meta\n*.obj\n*.idb\n*.iobj\n*.pch\n*.pdb\n*.ipdb\n*.pgc\n*.pgd\n*.rsp\n# but not Directory.Build.rsp, as it configures directory-level build defaults\n!Directory.Build.rsp\n*.sbr\n*.tlb\n*.tli\n*.tlh\n*.tmp\n*.tmp_proj\n*_wpftmp.csproj\n*.log\n*.tlog\n*.vspscc\n*.vssscc\n.builds\n*.pidb\n*.svclog\n*.scc\n\n# Chutzpah Test files\n_Chutzpah*\n\n# Visual C++ cache files\nipch/\n*.aps\n*.ncb\n*.opendb\n*.opensdf\n*.sdf\n*.cachefile\n*.VC.db\n*.VC.VC.opendb\n\n# Visual Studio profiler\n*.psess\n*.vsp\n*.vspx\n*.sap\n\n# Visual Studio Trace Files\n*.e2e\n\n# TFS 2012 Local Workspace\n$tf/\n\n# Guidance Automation Toolkit\n*.gpState\n\n# ReSharper is a .NET coding add-in\n_ReSharper*/\n*.[Rr]e[Ss]harper"}, {"id": "VisualStudio.gitignore_4", "file": "VisualStudio.gitignore", "content": "*.gpState\n\n# ReSharper is a .NET coding add-in\n_ReSharper*/\n*.[Rr]e[Ss]harper\n*.DotSettings.user\n\n# TeamCity is a build add-in\n_TeamCity*\n\n# DotCover is a Code Coverage Tool\n*.dotCover\n\n# AxoCover is a Code Coverage Tool\n.axoCover/*\n!.axoCover/settings.json\n\n# Coverlet is a free, cross platform Code Coverage Tool\ncoverage*.json\ncoverage*.xml\ncoverage*.info\n\n# Visual Studio code coverage results\n*.coverage\n*.coveragexml\n\n# NCrunch\n_NCrunch_*\n.NCrunch_*\n.*crunch*.local.xml\nnCrunchTemp_*\n\n# MightyMoose\n*.mm.*\nAutoTest.Net/\n\n# Web workbench (sass)\n.sass-cache/\n\n# Installshield output folder\n[Ee]xpress/\n\n# DocProject is a documentation generator add-in\nDocProject/buildhelp/\nDocProject/Help/*.HxT\nDocProject/Help/*.HxC\nDocProject/Help/*.hhc\nDocProject/Help/*.hhk\nDocProject/Help/*.hhp"}, {"id": "VisualStudio.gitignore_5", "file": "VisualStudio.gitignore", "content": "DocProject/Help/*.HxC\nDocProject/Help/*.hhc\nDocProject/Help/*.hhk\nDocProject/Help/*.hhp\nDocProject/Help/Html2\nDocProject/Help/html\n\n# Click-Once directory\npublish/\n\n# Publish Web Output\n*.[Pp]ublish.xml\n*.azurePubxml\n# Note: Comment the next line if you want to checkin your web deploy settings,\n# but database connection strings (with potential passwords) will be unencrypted\n*.pubxml\n*.publishproj\n\n# Microsoft Azure Web App publish settings. Comment the next line if you want to\n# checkin your Azure Web App publish settings, but sensitive information contained\n# in these scripts will be unencrypted\nPublishScripts/\n\n# NuGet Packages\n*.nupkg\n# NuGet Symbol Packages\n*.snupkg\n# The packages folder can be ignored because of Package Restore\n**/[Pp]ackages/*"}, {"id": "VisualStudio.gitignore_6", "file": "VisualStudio.gitignore", "content": "*.snupkg\n# The packages folder can be ignored because of Package Restore\n**/[Pp]ackages/*\n# except build/, which is used as an MSBuild target.\n!**/[Pp]ackages/build/\n# Uncomment if necessary however generally it will be regenerated when needed\n#!**/[Pp]ackages/repositories.config\n# NuGet v3's project.json files produces more ignorable files\n*.nuget.props\n*.nuget.targets\n\n# Microsoft Azure Build Output\ncsx/\n*.build.csdef\n\n# Microsoft Azure Emulator\necf/\nrcf/\n\n# Windows Store app package directories and files\nAppPackages/\nBundleArtifacts/\nPackage.StoreAssociation.xml\n_pkginfo.txt\n*.appx\n*.appxbundle\n*.appxupload\n\n# Visual Studio cache files\n# files ending in .cache can be ignored\n*.[Cc]ache\n# but keep track of directories ending in .cache\n!?*.[Cc]ache/\n\n# Others\nClientBin/\n~$*\n*~\n*.dbmdl"}, {"id": "VisualStudio.gitignore_7", "file": "VisualStudio.gitignore", "content": "# but keep track of directories ending in .cache\n!?*.[Cc]ache/\n\n# Others\nClientBin/\n~$*\n*~\n*.dbmdl\n*.dbproj.schemaview\n*.jfm\n*.pfx\n*.publishsettings\norleans.codegen.cs\n\n# Including strong name files can present a security risk\n# (https://github.com/github/gitignore/pull/2483#issue-259490424)\n#*.snk\n\n# Since there are multiple workflows, uncomment next line to ignore bower_components\n# (https://github.com/github/gitignore/pull/1529#issuecomment-104372622)\n#bower_components/\n\n# RIA/Silverlight projects\nGenerated_Code/\n\n# Backup & report files from converting an old project file\n# to a newer Visual Studio version. Backup files are not needed,\n# because we have git ;-)\n_UpgradeReport_Files/\nBackup*/\nUpgradeLog*.XML\nUpgradeLog*.htm\nServiceFabricBackup/\n*.rptproj.bak\n\n# SQL Server files\n*.mdf"}, {"id": "VisualStudio.gitignore_8", "file": "VisualStudio.gitignore", "content": "UpgradeLog*.XML\nUpgradeLog*.htm\nServiceFabricBackup/\n*.rptproj.bak\n\n# SQL Server files\n*.mdf\n*.ldf\n*.ndf\n\n# Business Intelligence projects\n*.rdl.data\n*.bim.layout\n*.bim_*.settings\n*.rptproj.rsuser\n*- [Bb]ackup.rdl\n*- [Bb]ackup ([0-9]).rdl\n*- [Bb]ackup ([0-9][0-9]).rdl\n\n# Microsoft Fakes\nFakesAssemblies/\n\n# GhostDoc plugin setting file\n*.GhostDoc.xml\n\n# Node.js Tools for Visual Studio\n.ntvs_analysis.dat\nnode_modules/\n\n# Visual Studio 6 build log\n*.plg\n\n# Visual Studio 6 workspace options file\n*.opt\n\n# Visual Studio 6 auto-generated workspace file (contains which files were open etc.)\n*.vbw\n\n# Visual Studio 6 workspace and project file (working project files containing files to include in project)\n*.dsw\n*.dsp\n\n# Visual Studio 6 technical files\n*.ncb\n*.aps"}, {"id": "VisualStudio.gitignore_9", "file": "VisualStudio.gitignore", "content": "*.dsw\n*.dsp\n\n# Visual Studio 6 technical files\n*.ncb\n*.aps\n\n# Visual Studio LightSwitch build output\n**/*.HTMLClient/GeneratedArtifacts\n**/*.DesktopClient/GeneratedArtifacts\n**/*.DesktopClient/ModelManifest.xml\n**/*.Server/GeneratedArtifacts\n**/*.Server/ModelManifest.xml\n_Pvt_Extensions\n\n# Paket dependency manager\n**/.paket/paket.exe\npaket-files/\n\n# FAKE - F# Make\n**/.fake/\n\n# CodeRush personal settings\n**/.cr/personal\n\n# Python Tools for Visual Studio (PTVS)\n**/__pycache__/\n*.pyc\n\n# Cake - Uncomment if you are using it\n#tools/**\n#!tools/packages.config\n\n# Tabs Studio\n*.tss\n\n# Telerik's JustMock configuration file\n*.jmconfig\n\n# BizTalk build output\n*.btp.cs\n*.btm.cs\n*.odx.cs\n*.xsd.cs\n\n# OpenCover UI analysis results\nOpenCover/\n\n# Azure Stream Analytics local run output\nASALocalRun/"}, {"id": "VisualStudio.gitignore_10", "file": "VisualStudio.gitignore", "content": "# OpenCover UI analysis results\nOpenCover/\n\n# Azure Stream Analytics local run output\nASALocalRun/\n\n# MSBuild Binary and Structured Log\n*.binlog\nMSBuild_Logs/\n\n# AWS SAM Build and Temporary Artifacts folder\n.aws-sam\n\n# NVidia Nsight GPU debugger configuration file\n*.nvuser\n\n# MFractors (Xamarin productivity tool) working folder\n**/.mfractor/\n\n# Local History for Visual Studio\n**/.localhistory/\n\n# Visual Studio History (VSHistory) files\n.vshistory/\n\n# BeatPulse healthcheck temp database\nhealthchecksdb\n\n# Backup folder for Package Reference Convert tool in Visual Studio 2017\nMigrationBackup/\n\n# Ionide (cross platform F# VS Code tools) working folder\n**/.ionide/\n\n# Fody - auto-generated XML schema\nFodyWeavers.xsd\n\n# VS Code files for those working on multiple tools\n.vscode/*"}, {"id": "VisualStudio.gitignore_11", "file": "VisualStudio.gitignore", "content": "FodyWeavers.xsd\n\n# VS Code files for those working on multiple tools\n.vscode/*\n!.vscode/settings.json\n!.vscode/tasks.json\n!.vscode/launch.json\n!.vscode/extensions.json\n!.vscode/*.code-snippets\n\n# Local History for Visual Studio Code\n.history/\n\n# Built Visual Studio Code Extensions\n*.vsix\n\n# Windows Installer files from build outputs\n*.cab\n*.msi\n*.msix\n*.msm\n*.msp"}, {"id": "VVVV.gitignore_0", "file": "VVVV.gitignore", "content": "================================================\n\n# .v4p backup files\n*~.xml\n\n# Dynamic plugins .dll\nbin/"}, {"id": "Waf.gitignore_0", "file": "Waf.gitignore", "content": "================================================\n# For projects that use the Waf build system: https://waf.io/\n# Dot-hidden on Unix-like systems\n.waf-*-*/\n.waf3-*-*/\n# Hidden directory on Windows (no dot)\nwaf-*-*/\nwaf3-*-*/\n# Lockfile\n.lock-waf_*_build"}, {"id": "WordPress.gitignore_0", "file": "WordPress.gitignore", "content": "================================================\n# Wordpress - ignore core, configuration, examples, uploads and logs.\n# https://github.com/github/gitignore/blob/main/WordPress.gitignore\n\n# Core\n#\n# Note: if you want to stage/commit WP core files\n# you can delete this whole section/until Configuration.\n/wp-admin/\n/wp-content/index.php\n/wp-content/languages\n/wp-content/plugins/index.php\n/wp-content/themes/index.php\n/wp-includes/\n/index.php\n/license.txt\n/readme.html\n/wp-*.php\n/xmlrpc.php\n\n# Configuration\nwp-config.php\n\n# Example themes\n/wp-content/themes/twenty*/\n\n# Example plugin\n/wp-content/plugins/hello.php\n\n# Uploads\n/wp-content/uploads/\n\n# Log files\n*.log\n\n# htaccess\n/.htaccess\n\n# All plugins\n#\n# Note: If you wish to whitelist plugins,\n# uncomment the next line\n#/wp-content/plugins"}, {"id": "WordPress.gitignore_1", "file": "WordPress.gitignore", "content": "#\n# Note: If you wish to whitelist plugins,\n# uncomment the next line\n#/wp-content/plugins\n\n# All themes\n#\n# Note: If you wish to whitelist themes,\n# uncomment the next line\n#/wp-content/themes"}, {"id": "Xojo.gitignore_0", "file": "Xojo.gitignore", "content": "================================================\n# Xojo (formerly REALbasic and Real Studio)\n\nBuilds*\n*.debug\n*.debug.app\nDebug*.exe\nDebug*/Debug*.exe\nDebug*/Debug*\\ Libs\n*.rbuistate\n*.xojo_uistate\n*.obsolete*"}, {"id": "Yeoman.gitignore_0", "file": "Yeoman.gitignore", "content": "================================================\nnode_modules/\nbower_components/\n*.log\n\nbuild/\ndist/"}, {"id": "Yii.gitignore_0", "file": "Yii.gitignore", "content": "================================================\nassets/*\n!assets/.gitignore\nprotected/runtime/*\n!protected/runtime/.gitignore\nprotected/data/*.db\nthemes/classic/views/"}, {"id": "ZendFramework.gitignore_0", "file": "ZendFramework.gitignore", "content": "================================================\n# Composer files\ncomposer.phar\nvendor/\n\n# Local configs\nconfig/autoload/*.local.php\n\n# Binary gettext files\n*.mo\n\n# Data\ndata/logs/\ndata/cache/\ndata/sessions/\ndata/tmp/\ntemp/\n\n#Doctrine 2\ndata/DoctrineORMModule/Proxy/\ndata/DoctrineORMModule/cache/\n\n# Legacy ZF1\ndemos/\nextras/documentation"}, {"id": "Zephir.gitignore_0", "file": "Zephir.gitignore", "content": "================================================\n# Cache files, generates by Zephir\n.temp/\n.libs/\n\n# Object files, generates by linker\n*.lo\n*.la\n*.o\n*.loT\n\n# Files generated by configure and Zephir,\n# not required for extension compilation.\next/build/\next/modules/\next/Makefile*\next/config*\next/acinclude.m4\next/aclocal.m4\next/autom4te*\next/install-sh\next/ltmain.sh\next/missing\next/mkinstalldirs\next/run-tests.php\next/.deps\next/libtool"}, {"id": "Zig.gitignore_0", "file": "Zig.gitignore", "content": "================================================\n.zig-cache/\nzig-out/\n*.o"}, {"id": "community/Alteryx.gitignore_0", "file": "community/Alteryx.gitignore", "content": "================================================\n# gitignore template for Alteryx Designer\n# website: https://www.alteryx.com/\n# website: https://help.alteryx.com/current/designer/alteryx-file-types\n\n# Alteryx Data Files\n*.yxdb\n*.cydb\n*.cyidx\n*.rptx\n*.vvf\n*.aws\n\n# Alteryx Special Files\n*.yxwv\n*.yxft\n*.yxbe\n*.bak\n*.pcxml\n*.log\n*.bin\n*.yxlang\nCASS.ini\n\n# Alteryx License Files\n*.yxlc\n*.slc\n*.cylc\n*.alc\n*.gzlc\n\n## gitignore reference sites\n# https://git-scm.com/book/en/v2/Git-Basics-Recording-Changes-to-the-Repository#_ignoring\n# https://git-scm.com/docs/gitignore\n# https://help.github.com/articles/ignoring-files/"}, {"id": "community/Alteryx.gitignore_1", "file": "community/Alteryx.gitignore", "content": "## Useful knowledge from stackoverflow\n# Even if you haven't tracked the files so far, git seems to be able to \"know\" about them even after you add them to .gitignore.\n# WARNING: First commit your current changes, or you will lose them.\n# Then run the following commands from the top folder of your git repo:\n# git rm -r --cached .\n# git add .\n# git commit -m \"fixed untracked files\"\n\n# author: Kacper Ksieski"}, {"id": "community/AltiumDesigner.gitignore_0", "file": "community/AltiumDesigner.gitignore", "content": "================================================\n# For PCBs designed using Altium Designer\n# Website: https://www.altium.com/altium-designer/\n\n# Directories containing cache data\nHistory\n__Previews\n\n# Directories containing logs and generated outputs\nProject\\ Logs*\nProject\\ Outputs*\n\n# Misc files generated by altium\ndebug.log\nStatus\\ Report.txt\n*.PcbDoc.htm\n*.SchDocPreview\n*.PcbDocPreview\n\n# Lock files sometimes left behind\n.~lock.*"}, {"id": "community/AutoIt.gitignore_0", "file": "community/AutoIt.gitignore", "content": "================================================\n# Compiled Scripts\n*.a3x\n\n# Tidy Auto-Generated Backups\nBackup/*\n\n# Au3Stripper Auto-Generated Files\n*_stripped.au3"}, {"id": "community/AutomationStudio.gitignore_0", "file": "community/AutomationStudio.gitignore", "content": "================================================\n# gitignore template for B&R Automation Studio (AS) 4\n# website: https://www.br-automation.com/en-us/products/software/automation-software/automation-studio/\n\n# AS temporary directories\nBinaries/\nDiagnosis/\nTemp/\nTempObjects/\n\n# AS transfer files\n*artransfer.br\n*arTrsfmode.nv\n\n# 'ignored' directory\nignored/\n\n# ARNC0ext\n*arnc0ext.br\n\n# AS File types\n*.bak\n*.isopen\n*.orig\n*.log\n*.asar\n*.csvlog*\n*.set\n!**/Physical/**/*.set\n\n# RevInfo variables\n*RevInfo.var"}, {"id": "community/B4X.gitignore_0", "file": "community/B4X.gitignore", "content": "================================================\n**/Objects\n**/AutoBackups\n*.meta"}, {"id": "community/Bazel.gitignore_0", "file": "community/Bazel.gitignore", "content": "================================================\n# gitignore template for Bazel build system\n# website: https://bazel.build/\n\n# Ignore all bazel-* symlinks. There is no full list since this can change\n# based on the name of the directory bazel is cloned into.\n/bazel-*\n\n# Directories for the Bazel IntelliJ plugin containing the generated\n# IntelliJ project files and plugin configuration. Separate directories are\n# for the IntelliJ, Android Studio and CLion versions of the plugin.\n/.ijwb/\n/.aswb/\n/.clwb/"}, {"id": "community/Beef.gitignore_0", "file": "community/Beef.gitignore", "content": "================================================\nbuild/\nrecovery/\nBeefSpace_User.toml"}, {"id": "community/Dotter.gitignore_0", "file": "community/Dotter.gitignore", "content": "================================================\n# local files are for host-specific overrides\n.dotter/local.toml\n\n# ignore caches\n.dotter/cache.toml\n.dotter/cache"}, {"id": "community/Exercism.gitignore_0", "file": "community/Exercism.gitignore", "content": "================================================\n# gitignore template for Exercism project\n# website: https://exercism.io/\n\n# Ignore .exercism folder which contain sensitive data\n.exercism"}, {"id": "community/Gretl.gitignore_0", "file": "community/Gretl.gitignore", "content": "================================================\n# gitignore template for Gretl\n# website: http://gretl.sourceforge.net/\n\n# Auto-generated log file is overwritten whenever you start a new session\nsession.inp\n\n# Auto-generated temporary string code table\nstring_table.txt"}, {"id": "community/Hexo.gitignore_0", "file": "community/Hexo.gitignore", "content": "================================================\n# gitignore template for Hexo sites\n# website: https://hexo.io/\n# Recommended: Node.gitignore\n\n# Ignore generated directory\npublic/\n\n# Ignore temp files\ntmp/\n.tmp*\n\n# additional files\ndb.json\n.deploy*/"}, {"id": "community/LensStudio.gitignore_0", "file": "community/LensStudio.gitignore", "content": "================================================\n# gitignore template for LensStudio\n# website: https://lensstudio.snapchat.com/\n\n# macOS/IDE #\n.DS_Store\n.idea\n\n# js #\nnode_modules\nyarn.lock\n\n# Python #\n__pycache__/\n*.py[cod]\n*$py.class\n[Bb]ackup*"}, {"id": "community/libogc.gitignore_0", "file": "community/libogc.gitignore", "content": "================================================\n# Ignore build directories\nbuild/\n\n# Ignore Wii-specific metadata files\nmeta.xml\nicon.png\n\n\n# Ignore editor or IDE-specific files\n.vscode/\n.idea/\n*.sublime-project\n*.sublime-workspace\n\n# Ignore backup or temporary files\n*~\n*.bak\n*.swp\n*.tmp\n\n# Ignore log files\n*.log\n\n# Ignore libraries and dependencies\nlib/\ndeps/\nobj/\n\n# Ignore operating system-specific files\n$RECYCLE.BIN/\n.Trash-1000/\n.Spotlight-V100/\n.fseventsd/\n.DS_Store\n\n# Prerequisites\n*.d\n\n# Object files\n*.o\n*.ko\n*.obj\n*.elf\n*.o\n*.bin\n\n# Linker output\n*.ilk\n*.map\n*.exp\n\n# Precompiled Headers\n*.gch\n*.pch\n\n# Libraries\n*.lib\n*.a\n*.la\n*.lo\n\n# Shared objects (inc. Windows DLLs)\n*.dll\n*.so\n*.so.*\n*.dylib\n\n# Executables\n*.exe\n*.out\n*.app\n*.i*86\n*.x86_64\n*.hex\n*.dol\n*.elf\n\n# Debug files"}, {"id": "community/libogc.gitignore_1", "file": "community/libogc.gitignore", "content": "*.so.*\n*.dylib\n\n# Executables\n*.exe\n*.out\n*.app\n*.i*86\n*.x86_64\n*.hex\n*.dol\n*.elf\n\n# Debug files\n*.dSYM/\n*.su\n*.idb\n*.pdb\n\n# Kernel Module Compile Results\n*.mod*\n*.cmd\n.tmp_versions/\nmodules.order\nModule.symvers\nMkfile.old\ndkms.conf"}, {"id": "community/Logtalk.gitignore_0", "file": "community/Logtalk.gitignore", "content": "================================================\n# gitignore template for LogTalk, a programming language that builds upon Prolog\n# website: https://logtalk.org/\n\n# Logtalk temporary file directories\n.lgt_tmp/\nlgt_tmp/\n\n# Logtalk default unit testing and doclet results and logs directories\nlogtalk_tester_logs/\nlogtalk_doclet_logs/\n\n# backend Prolog compiler temporary files\n.pl-history\n*.out\n*.xwam\n*.qo\n*.ql\n*.itf\n*.po"}, {"id": "community/MetaTrader5.gitignore_0", "file": "community/MetaTrader5.gitignore", "content": "================================================\n# MetaTrader 5 and MQL5 gitignore template\n# Project homepage: https://www.metatrader5.com/en\n\n# Compiled MQL5 executables (binaries)\n# These are generated from .mq5 source files and should not be committed.\n*.ex5\n*.ex4 # For MQL4 compatibility if you also manage MT4 projects in a similar structure\n\n# Log files\n# Terminal logs, strategy tester logs, and custom logs from Print() functions.\n*.log\n*.slog # Strategy Tester logs\n\n# Strategy Tester specific files\n# History data, optimization results, and temporary files used by the tester.\n*.fxt  # FXT files (history data for testing)\n*.hst  # History data files (can be large)\n*.ini  # Initialization files (often generated by tester or EAs)\n*.dat  # Data files (various purposes, often temporary)"}, {"id": "community/MetaTrader5.gitignore_1", "file": "community/MetaTrader5.gitignore", "content": "*.dat  # Data files (various purposes, often temporary)\n*.csv  # CSV export files (e.g., from tester reports)\n*.jrn  # Journal files (tester journal)\n\n# Market Watch sets and profiles\n# User-specific lists of symbols in Market Watch, and terminal profiles.\n*.set  # Market Watch symbol sets\n*.tpl  # Chart templates\n*.chr  # Chart settings files (can be generated when saving templates or profiles)\n\n# External libraries (DLLs)\n# If you use custom DLLs, you might want to ignore them if they are built separately\n# and not part of your MQL5 source code repository.\n*.dll\n\n# User-specific configuration and credentials\n# Files containing sensitive information or local user settings.\n.env   # Environment variables (e.g., for Python integration credentials)"}, {"id": "community/MetaTrader5.gitignore_2", "file": "community/MetaTrader5.gitignore", "content": ".env   # Environment variables (e.g., for Python integration credentials)\n*.cfg  # Configuration files (if not meant to be shared)\n*.json # Be careful: if you have config JSONs you *do* want to commit, add specific exceptions.\n       # Example: !config.json (to include config.json but ignore other *.json)\n\n# Temporary files and backup files generated by MetaEditor\n*.~*   # Temporary files (e.g., ~MyScript.mq5)\n*.bak  # Backup files (e.g., MyScript.mq5.bak)\n*.mqh.bak\n*.mq5.bak\n\n# MetaEditor project files\n# Project files for MetaEditor workspaces.\n.mqproj\n\n# Python specific ignores (if you also keep Python scripts or Jupyter notebooks in this repository)\n# These are relevant if your Git repo root is higher up (e.g., the terminal folder itself)"}, {"id": "community/MetaTrader5.gitignore_3", "file": "community/MetaTrader5.gitignore", "content": "# These are relevant if your Git repo root is higher up (e.g., the terminal folder itself)\n# or if you mix Python code within your MQL5 structure.\n__pycache__/       # Python compiled bytecode cache\n.ipynb_checkpoints/ # Jupyter Notebook checkpoints\n*.pyc              # Python compiled files\n*.pyd              # Python dynamic modules"}, {"id": "community/Move.gitignore_0", "file": "community/Move.gitignore", "content": "================================================\n# Generated by Move\n# will have compiled files\nbuild/\n\n# Remove possibly saving credentials to the git repository\n.aptos/"}, {"id": "community/NasaSpecsIntact.gitignore_0", "file": "community/NasaSpecsIntact.gitignore", "content": "================================================\n# gitignore template for Nasa SpecsIntact (SI)\n# Website: https://specsintact.ksc.nasa.gov/\n#\n# Recommended:\n# MicrosoftOffice.gitignore\n#\n\n# SpecsIntact (SI) Locking file; this would lock everyone out.\n*.se$\n\n# SI Reports; auto-generated. They do not belong in the repository\n# as they will be re-created exactly when using a specific checkout point.\n*.RPT\nADDRVER.*\nBRKTVER.*\nDUPEREF.*\nREFVER.*\nSECTVER.*\nSUBMVER.*\nTTLDIFFS.*\n\n# SpecsIntact files that change a lot and don't actually affect SI\n# PULL.TBL is an auto-generated file to help speed SI loading.\nPULL.TBL\npulltbl.bck\n\n# Tailoring information.\n# Keep tailor.tag; it is a list of tailoring options in SI.\n\n# JOB.OTL informs SI where a spec section came from."}, {"id": "community/NasaSpecsIntact.gitignore_1", "file": "community/NasaSpecsIntact.gitignore", "content": "# JOB.OTL informs SI where a spec section came from.\n# Keeping the old one isn't useful in git.\nJOB.OTL.OLD\n\n# OneNote TOC Files; SI Work Directories may be installed in a location co-located with OneNote\n# notebooks, and if so, OneNote will litter the SI folder with these.\n*.onetoc*\n\n# Log files, typically tagfix or other auto generated logs that aren't useful\n# outside of the user that made them and clutter up the index.\n*.log"}, {"id": "community/OpenSSL.gitignore_0", "file": "community/OpenSSL.gitignore", "content": "================================================\n# OpenSSL-related files best not committed\n\n## Certificate Authority\n*.ca\n\n## Certificate\n*.crt\n\n## Certificate Sign Request\n*.csr\n\n## Certificate\n*.der\n\n## Key database file\n*.kdb\n\n## OSCP request data\n*.org\n\n## PKCS #12\n*.p12\n\n## PEM-encoded certificate data\n*.pem\n\n## Random number seed\n*.rnd\n\n## SSLeay data\n*.ssleay\n\n## S/MIME message\n*.smime"}, {"id": "community/OpenTofu.gitignore_0", "file": "community/OpenTofu.gitignore", "content": "================================================\n# Local .terraform directories\n**/.terraform/*\n\n# .tfstate files\n*.tfstate\n*.tfstate.*\n\n# Crash log files\ncrash.log\ncrash.*.log\n\n# Exclude all .tfvars files, which are likely to contain sensitive data, such as\n# password, private keys, and other secrets. These should not be part of version\n# control as they are data points which are potentially sensitive and subject\n# to change depending on the environment.\n*.tfvars\n*.tfvars.json\n\n# Ignore override files as they are usually used to override resources locally and so\n# are not checked in\noverride.tf\noverride.tofu\noverride.tf.json\noverride.tofu.json\n*_override.tf\n*_override.tofu\n*_override.tf.json\n*_override.tofu.json\n\n# Ignore transient lock info files created by tofu apply"}, {"id": "community/OpenTofu.gitignore_1", "file": "community/OpenTofu.gitignore", "content": "*_override.tf.json\n*_override.tofu.json\n\n# Ignore transient lock info files created by tofu apply\n.terraform.tfstate.lock.info\n\n# Include override files you do wish to add to version control using negated pattern\n# !example_override.tf\n# !example_override.tofu\n\n# Include tfplan files to ignore the plan output of command: tofu plan -out=tfplan\n# example: *tfplan*\n\n# Ignore CLI configuration files\n.terraformrc\nterraform.rc"}, {"id": "community/Puppet.gitignore_0", "file": "community/Puppet.gitignore", "content": "================================================\n# gitignore template for Puppet modules\n# website: https://forge.puppet.com/\n\n# Built packages\npkg/*\n\n# Should run on multiple platforms so don't check in\nGemfile.lock\n\n# Tests\nspec/fixtures/*\ncoverage/*\n\n# Third-party\nvendor/*\n.bundle/*"}, {"id": "community/Racket.gitignore_0", "file": "community/Racket.gitignore", "content": "================================================\n# gitignore template for the Racket language\n# website: http://www.racket-lang.org/\n\n# DrRacket autosave files\n*.rkt~\n*.rkt.bak\n\\#*.rkt#\n\\#*.rkt#*#\n\n# Compiled racket bytecode\ncompiled/\n*.zo\n\n# Dependency tracking files\n*.dep"}, {"id": "community/Red.gitignore_0", "file": "community/Red.gitignore", "content": "================================================\n# gitignore template for Red programming language\n# website: http://www.red-lang.org/\n\n# Red Compiled code\n*.red\n\n# Libraries\ncrush.dll\ncrush.dylib\ncrush.so\n\n# Files generated during test\nquick-test/quick-test.log\nquick-test/runnable/\nsystem/tests/source/units/auto-tests/\ntests/source/units/auto-tests/"}, {"id": "community/ROS2.gitignore_0", "file": "community/ROS2.gitignore", "content": "================================================\ninstall/\nlog/\nbuild/\n\n# Ignore generated docs\n*.dox\n*.wikidoc\n\n# eclipse stuff\n.project\n.cproject\n\n# qcreator stuff\nCMakeLists.txt.user\n\nsrv/_*.py\n*.pcd\n*.pyc\nqtcreator-*\n*.user\n\n*~\n\n# Emacs\n.#*\n\n# Colcon custom files\nCOLCON_IGNORE\nAMENT_IGNORE"}, {"id": "community/SPFx.gitignore_0", "file": "community/SPFx.gitignore", "content": "================================================\n#SharePoint Framework (SPFx)\n# Logs\nlogs\n*.log\nnpm-debug.log*\n\n# Dependency directories\nnode_modules\n\n# Build generated files\ndist\nlib\nsolution\ntemp\n*.sppkg\n\n# Coverage directory used by tools like istanbul\ncoverage\n\n# OSX\n.DS_Store\n\n# Visual Studio files\n.ntvs_analysis.dat\n.vs\nbin\nobj\n\n# Resx Generated Code\n*.resx.ts\n\n# Styles Generated Code\n*.scss.ts"}, {"id": "community/Splunk.gitignore_0", "file": "community/Splunk.gitignore", "content": "================================================\n# gitignore template for Splunk apps\n# documentation: http://docs.splunk.com/Documentation/Splunk/6.2.3/admin/Defaultmetaconf\n\n# Splunk local meta file\nlocal.meta\n\n# Splunk local folder\nlocal"}, {"id": "community/Strapi.gitignore_0", "file": "community/Strapi.gitignore", "content": "================================================\n############################\n# OS X\n############################\n\n.DS_Store\n.AppleDouble\n.LSOverride\nIcon\n.Spotlight-V100\n.Trashes\n._*\n\n\n############################\n# Linux\n############################\n\n*~\n\n\n############################\n# Windows\n############################\n\nThumbs.db\nehthumbs.db\nDesktop.ini\n$RECYCLE.BIN/\n*.cab\n*.msi\n*.msm\n*.msp\n\n\n############################\n# Packages\n############################\n\n*.7z\n*.csv\n*.dat\n*.dmg\n*.gz\n*.iso\n*.jar\n*.rar\n*.tar\n*.zip\n*.com\n*.class\n*.dll\n*.exe\n*.o\n*.seed\n*.so\n*.swo\n*.swp\n*.swn\n*.swm\n*.out\n*.pid\n\n\n############################\n# Logs and databases\n############################\n\n.tmp\n*.log\n*.sql\n*.sqlite\n\n\n############################\n# Misc.\n############################\n\n*#\n.idea"}, {"id": "community/Strapi.gitignore_1", "file": "community/Strapi.gitignore", "content": "*.log\n*.sql\n*.sqlite\n\n\n############################\n# Misc.\n############################\n\n*#\n.idea\nnbproject\n.vscode/\n\n\n############################\n# Node.js\n############################\n\nlib-cov\nlcov.info\npids\nlogs\nresults\nbuild\nnode_modules\n.node_history\npackage-lock.json\n**/package-lock.json\n!docs/package-lock.json\n*.heapsnapshot\n\n\n############################\n# Tests\n############################\n\ntestApp\ncoverage\ncypress/screenshots\ncypress/videos\n\n\n############################\n# Documentation\n############################\n\ndist\n\n############################\n# Builds\n############################\n\npackages/strapi-generate-new/files/public/\n\n############################\n# Example app\n############################\n\n.dev\n# *.cache\n\n############################\n# Visual Studio Code"}, {"id": "community/Strapi.gitignore_2", "file": "community/Strapi.gitignore", "content": "############################\n\n.dev\n# *.cache\n\n############################\n# Visual Studio Code\n############################\n\nfront-workspace.code-workspace"}, {"id": "community/Terragrunt.gitignore_0", "file": "community/Terragrunt.gitignore", "content": "================================================\n# Ignore the default terragrunt cache directory\n# https://terragrunt.gruntwork.io/docs/features/caching/\n.terragrunt-cache"}, {"id": "community/Toit.gitignore_0", "file": "community/Toit.gitignore", "content": "================================================\n.packages\n*_pb.toit"}, {"id": "community/UiPath.gitignore_0", "file": "community/UiPath.gitignore", "content": "================================================\n# gitignore template for RPA development using UiPath Studio\n# website: https://www.uipath.com/product/studio\n#\n# Recommended: n/a\n\n# Ignore folders that could cause issues if accidentally tracked\n**/.local/**\n**/.settings/**\n**/.objects/**\n**/.tmh/**\n**/*.log"}, {"id": "community/UTAU.gitignore_0", "file": "community/UTAU.gitignore", "content": "================================================\n# Adobe Audition\n*.pkf\n\n# UTAU Engines\n*.ctspec\n*.d4c\n*.dio\n*.frc\n*.frt\n*.frq\n*.harvest\n*.lessaudio\n*.llsm\n*.mrq\n*.pitchtier\n*.platinum\n*.pmk\n*.sc.npz\n*.star\n*.uspec\n*.vs4ufrq\n\n# UTAU related tools\n$read\n*.setParam-Scache\n*.lbp\n*.lbp.caches/*\n\n# OpenUtau\nerrors.txt\n\n# Deepvocal\n*.DVModel\n*-log.txt\nSKC\nSKI\nSKC_1\nSKC_2\n*.sksd\n\n# VocalSharp\n*.scep\n*.vssf\n*.vsdx\n*.vsdxindex\n\n# Binary Archive\n*.7z\n*.zip\n*.rar\n*.exe"}, {"id": "community/V.gitignore_0", "file": "community/V.gitignore", "content": "================================================\n*.exe\n*.o\n*.so\n*.tmp.c\n*.exp\n*.ilk\n*.pdb\n*.dll\n*.lib\n*.bak\n*.out"}, {"id": "community/Xilinx.gitignore_0", "file": "community/Xilinx.gitignore", "content": "================================================\n# gitignore template for Xilinx Vivado Design Suite\n# website: https://www.xilinx.com/support/download.html\n\n# [home]\n*.jou\n*.log\n*.debug\n*.str\n*.zip\n*.tmp\n*.rst\n*.os\n*.js\n*.pb\n*.dcp\n*.hwdef\n*.vds\n*.veo\n*.wdf\n*.vdi\n*.dmp\n*.rpx\n*.rpt\n*_stub.v\n*_stub.vhdl\n*_funcsim.v\n*_funcsim.vhdl\n.project\n\n# [dir]\n*.cache\n.metadata\n*.data\n*.ipdefs\n.Xil\n*.sdk\n*.hw\n*.ip_user_files\n\n### IP synth\n*_synth_*\n\n.jobs\n\n### project synth\n*/*.runs/synth*/*.xml\n*/*.runs/synth*/*.txt\n*/*.runs/synth*/*.sh\n*/*.runs/synth*/*.tcl\n*/*.runs/synth*/*.bat\n*/*.runs/synth*/*.xdc\n!*/*.runs/synth*/*utilization*.rpt\n\n*.runs/synth*/*.xml\n*.runs/synth*/*.txt\n*.runs/synth*/*.sh\n*.runs/synth*/*.tcl\n*.runs/synth*/*.bat\n*.runs/synth*/*.xdc\n!*.runs/synth*/*utilization*.rpt"}, {"id": "community/Xilinx.gitignore_1", "file": "community/Xilinx.gitignore", "content": "### project impl\n*/*.runs/impl*/*.xml\n*/*.runs/impl*/*.html\n*/*.runs/impl*/*.txt\n*/*.runs/impl*/*.sh\n*/*.runs/impl*/*.tcl\n*/*.runs/impl*/*.bat\n!*/*.runs/impl*/*utilization*.rpt\n\n*.runs/impl*/*.xml\n*.runs/impl*/*.html\n*.runs/impl*/*.txt\n*.runs/impl*/*.sh\n*.runs/impl*/*.tcl\n*.runs/impl*/*.bat\n!*.runs/impl*/*utilization*.rpt\n\n### block design\n*/*/bd/*/hdl\n*/*/*/bd/*/hdl\n\n*/*/bd/*/*.xdc\n*/*/*/bd/*/*.xdc\n\n*/*/bd/*/ip/*/*.xdc\n*/*/*/bd/*/ip/*/*.xdc\n\n*/*/bd/*/ip/*/*/\n*/*/*/bd/*/ip/*/*/\n\n*/*/bd/*/ip/*/*.vhd\n*/*/*/bd/*/ip/*/*.vhd\n\n*/*/bd/*/ip/*/*.xml\n*/*/*/bd/*/ip/*/*.xml\n\n*.c\n*.h\n*.vho\n*.html\n*/*/bd/*/ip/*/*.tcl\n*/*/*/bd/*/ip/*/*.tcl\nhw_handoff\nipshared"}, {"id": "community/AWS/CDK.gitignore_0", "file": "community/AWS/CDK.gitignore", "content": "================================================\n# CDK asset staging directory.\n# For more information about AWS-CDK, see  https://docs.aws.amazon.com/cdk/\n.cdk.staging/\ncdk.out/"}, {"id": "community/AWS/SAM.gitignore_0", "file": "community/AWS/SAM.gitignore", "content": "================================================\n# gitignore template for AWS Serverless Application Model project\n# website: https://docs.aws.amazon.com/serverless-application-model\n\n# Ignore build folder\n.aws-sam/"}, {"id": "community/BoxLang/ColdBox.gitignore_0", "file": "community/BoxLang/ColdBox.gitignore", "content": "================================================\n# Servelet Ignores\nWEB-INF\n\n# Engines + Database + CBFS + Secrets\n.tmp/**\n.env\n.engine/**\n.cbfs/**\n\n# Logs + Test Results\nlogs/**\ntests/results/**\n\n## Ignored Dependencies\n/boxlang_modules/*\neffective-pom.xml\n/coldbox/**\n/testbox/**\n/modules/**\n/lib/java/**\n\n# NPM JS Assets (If applicable)\n**/node_modules/*\nnpm-debug.log\nyarn-error.log"}, {"id": "community/CFML/ColdBox.gitignore_0", "file": "community/CFML/ColdBox.gitignore", "content": "================================================\n# Servelet Ignores\nWEB-INF\n\n# Engines + Database + CBFS + Secrets\n.tmp/**\n.env\n.engine/**\n.cbfs/**\n\n# Logs + Test Results\nlogs/**\ntests/results/**\n\n## Ignored Dependencies\neffective-pom.xml\n/coldbox/**\n/testbox/**\n/modules/**\n/lib/java/**\n\n# NPM JS Assets (If applicable)\n**/node_modules/*\nnpm-debug.log\nyarn-error.log"}, {"id": "community/DotNet/core.gitignore_0", "file": "community/DotNet/core.gitignore", "content": "================================================\n*.swp\n*.*~\nproject.lock.json\n.DS_Store\n*.pyc\nnupkg/\n\n# Visual Studio Code\n.vscode\n\n# Rider\n.idea\n\n# User-specific files\n*.suo\n*.user\n*.userosscache\n*.sln.docstates\n\n# Build results\n[Dd]ebug/\n[Dd]ebugPublic/\n[Rr]elease/\n[Rr]eleases/\nx64/\nx86/\nbuild/\nbld/\n[Bb]in/\n[Oo]bj/\n[Oo]ut/\nmsbuild.log\nmsbuild.err\nmsbuild.wrn\n\n# Visual Studio 2015\n.vs/"}, {"id": "community/DotNet/InforCMS.gitignore_0", "file": "community/DotNet/InforCMS.gitignore", "content": "================================================\n# gitignore template for InforCRM (formerly SalesLogix)\n# website: https://www.infor.com/product-summary/cx/infor-crm/\n#\n# Recommended: VisualStudio.gitignore\n\n# Ignore model files that are auto-generated\nModelIndex.xml\nExportedFiles.xml\n\n# Ignore deployment files\n[Mm]odel/[Dd]eployment\n\n# Force include portal SupportFiles\n!Model/Portal/*/SupportFiles/[Bb]in/\n!Model/Portal/PortalTemplates/*/SupportFiles/[Bb]in"}, {"id": "community/DotNet/Kentico.gitignore_0", "file": "community/DotNet/Kentico.gitignore", "content": "================================================\n# gitignore template for using Kentico CMS\n# website: http://www.kentico.com/\n#\n# Recommended template: VisualStudio.gitignore\n\n# Include some Kentico folders excluded by Visual Studio rules\n!CMS/CMSAdminControls/*/\n!CMS/CMSModules/System/*/\n!CMS/App_Data/CIRepository/**\n\n# Kentico temporary/environment files\nCMS/App_Data/AzureCache\nCMS/App_Data/AzureTemp\nCMS/App_Data/CMSModules/DeviceProfile/logFiftyOne.txt\nCMS/App_Data/CMSModules/DeviceProfiles/logFiftyOne.txt\nCMS/App_Data/CMSModules/WebFarm/webfarm.sync\nCMS/App_Data/CMSTemp\nCMS/App_Data/Persistent\nCMS/CMSSiteUtils/Export\nCMS/CMSSiteUtils/Import\n\n# Ignore all smart search indexes, but not the other system folder contents\nCMS/App_Data/CMSModules/SmartSearch/**"}, {"id": "community/DotNet/Kentico.gitignore_1", "file": "community/DotNet/Kentico.gitignore", "content": "CMS/App_Data/CMSModules/SmartSearch/**\n!CMS/App_Data/CMSModules/SmartSearch/*/\n!CMS/App_Data/CMSModules/SmartSearch/_StopWords/**\n!CMS/App_Data/CMSModules/SmartSearch/_Synonyms/**"}, {"id": "community/DotNet/Kentico.gitignore_2", "file": "community/DotNet/Kentico.gitignore", "content": "## Kentico Starter Sites\n# Starter site resource Files\nCMS/App_Data/DancingGoat\n\n# Starter site web templates\nCMS/App_Data/Templates/CommunitySite\nCMS/App_Data/Templates/CorporateSite\nCMS/App_Data/Templates/DancingGoat\nCMS/App_Data/Templates/EcommerceSite\nCMS/App_Data/Templates/IntranetPortal\nCMS/App_Data/Templates/PersonalSite\n\n# Starter site app themes\nCMS/App_Themes/CommunitySite\nCMS/App_Themes/CorporateSite\nCMS/App_Themes/EcommerceSite\nCMS/App_Themes/IntranetPortal*\nCMS/App_Themes/PersonalSite\n\n# Starter site ASPX templates\nCMS/CMSTemplates/CorporateSite\n\n# Starter site media libraries\nCMS/CommunitySite\nCMS/CorporateSite\nCMS/DancingGoat\nCMS/EcommerceSite\nCMS/IntranetPortal\nCMS/PersonalSite"}, {"id": "community/DotNet/Kentico.gitignore_3", "file": "community/DotNet/Kentico.gitignore", "content": "## Project specific ignores\n# Sensitive settings\nAppSettings.config\nConnectionStrings.config\n\n# Project media libraries (recommend shared file storage)\n# e.g. CMS/{SiteCodeName}"}, {"id": "community/DotNet/Umbraco.gitignore_0", "file": "community/DotNet/Umbraco.gitignore", "content": "================================================\n## Ignore Umbraco files/folders generated for each instance\n##\n## Get latest from https://github.com/github/gitignore/blob/main/Umbraco.gitignore\n\n# Note: VisualStudio gitignore rules may also be relevant\n\n# Umbraco\n# Ignore unimportant folders generated by Umbraco\n**/App_Data/Logs/\n**/App_Data/[Pp]review/\n**/App_Data/TEMP/\n**/App_Data/NuGetBackup/\n\n# Ignore Umbraco content cache file\n**/App_Data/umbraco.config\n\n## this [Uu]mbraco/ folder should be created by cmd like `Install-Package UmbracoCms -Version 8.5.3`\n## you can find your Umbraco version in your Web.config. (i.e. <add key=\"Umbraco.Core.ConfigurationStatus\" value=\"8.5.3\" />)\n## Uncomment this line if you think it fits the way you work on your project.\n## **/[Uu]mbraco/"}, {"id": "community/DotNet/Umbraco.gitignore_1", "file": "community/DotNet/Umbraco.gitignore", "content": "## Uncomment this line if you think it fits the way you work on your project.\n## **/[Uu]mbraco/\n\n## The [Mm]edia/ folder contains content. Content may vary by environment and should therefore not be added to source control.\n## Uncomment this line if you think it fits the way you work on your project."}, {"id": "community/DotNet/Umbraco.gitignore_2", "file": "community/DotNet/Umbraco.gitignore", "content": "## **/[Mm]edia/\n\n# Don't ignore Umbraco packages (VisualStudio.gitignore mistakes this for a NuGet packages folder)\n# Make sure to include details from VisualStudio.gitignore BEFORE this\n!**/App_Data/[Pp]ackages/*\n!**/[Uu]mbraco/[Dd]eveloper/[Pp]ackages/*\n!**/[Uu]mbraco/[Vv]iews/[Pp]ackages/*\n\n# ImageProcessor DiskCache\n**/App_Data/cache/\n\n# Ignore the Models Builder models out of date flag\n**/ood.flag\n\n# NEW for version 9 .Net 5 (Core)\n#ignore umbraco backoffice assest from wwwroot\n**/wwwroot/umbraco/\n\n# SQLite files\n*.sqlite.db*\n\n#ignore umbraco data/views/settings\n**/umbraco/*\n\n#include default location for modelsbuilder output\n!**/umbraco/models\n\n#include default location for packages\n!**/umbraco/Data/packages"}, {"id": "community/Elixir/Phoenix.gitignore_0", "file": "community/Elixir/Phoenix.gitignore", "content": "================================================\n# gitignore template for Phoenix projects\n# website: http://www.phoenixframework.org/\n#\n# Recommended template: Elixir.gitignore\n\n# Temporary files\n/tmp\n\n# Static artifacts\n/node_modules\n/assets/node_modules\n\n# Since we are building assets from web/static,\n# we ignore priv/static. You may want to comment\n# this depending on your deployment strategy.\n/priv/static/\n\n# Installer-related files\n/installer/_build\n/installer/tmp\n/installer/doc\n/installer/deps"}, {"id": "community/embedded/AtmelStudio.gitignore_0", "file": "community/embedded/AtmelStudio.gitignore", "content": "================================================\n## Ignore Atmel Studio temporary files and build results\n# https://www.microchip.com/mplab/avr-support/atmel-studio-7\n\n# Atmel Studio is powered by an older version of Visual Studio,\n# so most of the project and solution files are the same as VS files,\n# only prefixed by an `at`.\n\n#Build Directories\n[Dd]ebug/\n[Rr]elease/\n\n#Build Results\n*.o\n*.d\n*.eep\n*.elf\n*.hex\n*.map\n*.srec\n\n#User Specific Files\n*.atsuo"}, {"id": "community/embedded/esp-idf.gitignore_0", "file": "community/embedded/esp-idf.gitignore", "content": "================================================\n# gitignore template for esp-idf, the official development framework for ESP32\n# https://github.com/espressif/esp-idf\n\nbuild/\nsdkconfig\nsdkconfig.old"}, {"id": "community/embedded/IAR_EWARM.gitignore_0", "file": "community/embedded/IAR_EWARM.gitignore", "content": "================================================\n# gitignore template for the IAR EWARM\n# website: https://www.iar.com/knowledge/support/technical-notes/ide/which-files-should-be-version-controlled/\n\n# Some tools will put the EWARM files\n# under a subdirectory with the same name\n# as the configuration.\n# Example\n# EWARM/Config1/Obj /List /Exe\n# EWARM/Config2/Obj /List /Exe\nEWARM/**/Obj\nEWARM/**/List\nEWARM/**/Exe\n\n# Autogenerated project files\n*.dep\n*.ewt\n\n# Autogenerated folder for debugger\nEWARM/settings"}, {"id": "community/embedded/uVision.gitignore_0", "file": "community/embedded/uVision.gitignore", "content": "================================================\n# git ignore file for Keil \u00c3\u201a\u00c2\u00b5Vision Project\n\n# \u00c3\u201a\u00c2\u00b5Vision 5 and \u00c3\u201a\u00c2\u00b5Vision 4 Project screen layout file\n*.uvguix.*\n*.uvgui.*\n\n# Listing Files\n*.i\n*.lst\n*.m51\n*.m66\n*.map\n\n# Object Files\n*.axf\n*.b[0-2][0-9]\n*.b3[0-1]\n*.bak\n*.build_log.htm\n*.crf\n*.d\n*.dep\n*.elf\n*.htm\n*.iex\n*.lnp\n*.o\n*.obj\n*.sbr\n\n# Firmware Files\n*.bin\n*.h86\n*.hex\n\n# Build Files\n.bat\n\n# Debugger Files\n.ini\n\n# JLink Files\nJLinkLog.txt\n\n# Other Files"}, {"id": "community/GNOME/GNOMEShellExtension.gitignore_0", "file": "community/GNOME/GNOMEShellExtension.gitignore", "content": "================================================\n# Ignored files for GNOME extension git repository\n\n*.zip"}, {"id": "community/Golang/Go.AllowList.gitignore_0", "file": "community/Golang/Go.AllowList.gitignore", "content": "================================================\n# Allowlisting gitignore template for GO projects prevents us\n# from adding various unwanted local files, such as generated\n# files, developer configurations or IDE-specific files etc.\n#\n# Recommended: Go.AllowList.gitignore\n\n# Ignore everything\n*\n\n# But not these files...\n!/.gitignore\n\n!*.go\n!go.sum\n!go.mod\n\n!README.md\n!LICENSE\n\n# !Makefile\n\n# ...even if they are in subdirectories\n!*/"}, {"id": "community/Golang/Hugo.gitignore_0", "file": "community/Golang/Hugo.gitignore", "content": "================================================\n# Generated files by hugo\n/public/\n/resources/_gen/\n/assets/jsconfig.json\nhugo_stats.json\n\n# Executable may be added to repository\nhugo.exe\nhugo.darwin\nhugo.linux\n\n# Temporary lock file while building\n/.hugo_build.lock"}, {"id": "community/Java/JBoss4.gitignore_0", "file": "community/Java/JBoss4.gitignore", "content": "================================================\n# gitignore for JBoss v4 projects\n\n/server/all/data\n/server/all/log\n/server/all/tmp\n/server/all/work\n/server/default/data\n/server/default/log\n/server/default/tmp\n/server/default/work\n/server/minimal/data\n/server/minimal/log\n/server/minimal/tmp\n/server/minimal/work\n\n# Note:\n# there may be other directories that contain *.xml.failed or *.war.failed files\n/server/default/deploy/*.xml.failed\n/server/default/deploy/*.war.failed"}, {"id": "community/Java/JBoss6.gitignore_0", "file": "community/Java/JBoss6.gitignore", "content": "================================================\n# gitignore for JBoss v6 projects\n#\n# Note: to ensure empty directories remain part of the repository, like\n# `/server/minimal/lib`, you should add an empty `.gitignore` or `.gitkeep` file\n# to the directory - otherwise you may have issues when starting the service.\n\n/server/all/data\n/server/all/log\n/server/all/tmp\n/server/all/work\n/server/default/data\n/server/default/log\n/server/default/tmp\n/server/default/work\n/server/minimal/data\n/server/minimal/log\n/server/minimal/tmp\n/server/minimal/work\n/server/jbossweb-standalone/data\n/server/jbossweb-standalone/log\n/server/jbossweb-standalone/tmp\n/server/jbossweb-standalone/work\n/server/standard/data\n/server/standard/log\n/server/standard/tmp\n/server/standard/work\n/server/default/deploy/*.jar.failed"}, {"id": "community/Java/JBoss6.gitignore_1", "file": "community/Java/JBoss6.gitignore", "content": "/server/standard/log\n/server/standard/tmp\n/server/standard/work\n/server/default/deploy/*.jar.failed\n/server/default/deploy/*.jar.dodeploy\n/server/default/deploy/*.xml.failed\n/server/default/deploy/*.xml.dodeploy\n/server/default/deploy/*.war.failed\n/server/default/deploy/*.war.dodeploy"}, {"id": "community/JavaScript/Cordova.gitignore_0", "file": "community/JavaScript/Cordova.gitignore", "content": "================================================\n# gitignore template for the Cordova framework\n# website: https://cordova.apache.org/\n#\n# Recommended template: Node.gitignore\n\n# App platform binaries and built files\n/platforms\n\n# Optional to ignore plugin Git clones\n#/plugins"}, {"id": "community/JavaScript/Expo.gitignore_0", "file": "community/JavaScript/Expo.gitignore", "content": "================================================\n#\u00c3\u00a2\u00e2\u201a\u00ac\u00c6\u2019.gitignore template for Expo\n#\u00c3\u00a2\u00e2\u201a\u00ac\u00c6\u2019website: https://expo.dev/\n#\u00c3\u00a2\u00e2\u201a\u00ac\u00c6\u2019docs: https://docs.expo.dev/workflow/expo-cli/\n#\n#\u00c3\u00a2\u00e2\u201a\u00ac\u00c6\u2019Rationale:\n#\u00c3\u00a2\u00e2\u201a\u00ac\u00c6\u2019node_modules/ is always ignored\n#\u00c3\u00a2\u00e2\u201a\u00ac\u00c6\u2019.expo/, .expo-shared/ are Expo\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s local state and project-settings cache (see docs)\n#\u00c3\u00a2\u00e2\u201a\u00ac\u00c6\u2019 Metro caches/logs are *.expo, *.tunnel, *.cache, *.tmp, *.log\n\n# Node modules\nnode_modules/\n\n# Expo local state and caches\n.expo/             # runtime state (Metro bundler, dev-client data, tunnels)\n.expo-shared/      # shared project settings (app.json edits, etc.)\n\n# Metro bundler caches/logs\n*.expo             # generic Expo temp files\n*.tunnel           # Expo DevTools tunnels\n*.cache            # Metro cache folder"}, {"id": "community/JavaScript/Expo.gitignore_1", "file": "community/JavaScript/Expo.gitignore", "content": "*.tunnel           # Expo DevTools tunnels\n*.cache            # Metro cache folder\n*.tmp              # temp files created during bundling\n*.log              # build or Metro logs\n\n# Environment variables\n.env\n.env.local\n.env.*.local\n\n# Package manager logs\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*"}, {"id": "community/JavaScript/Meteor.gitignore_0", "file": "community/JavaScript/Meteor.gitignore", "content": "================================================\n# gitignore template for the Meteor framework\n# website: https://www.meteor.com/\n#\n# Recommended template: Node.gitignore\n\n# protect api keys in setting json\nsettings-production.json\nsettings.json\n\n# protect your mup.json settings\nmup.json\nmup.js"}, {"id": "community/JavaScript/NWjs.gitignore_0", "file": "community/JavaScript/NWjs.gitignore", "content": "================================================\n# gitignore template for NW.js projects\n# website: https://nwjs.io/\n\n# Seen in standard and sdk versions\ncredits.html\nlocales/\nlibEGL.dll\nlibGLEv2.dll\nnode.dll\nnw.dll\nnw.exe\nnatives_blob.bin\nnw_100_percent.pak\nnw_200_percent.pak\nnw_elf.dll\nsnapshot_blob.bin\nresources.pak\n\n# Seen only in standard\nd3dcompiler_47.dll\nffmpeg.dll\nicudtl.dat\n\n# Seen only in sdk\npnacl/\nchromedriver.exe\nnacl_irt_x86_64.nexe\nnwjc.exe\npayload.exe"}, {"id": "community/JavaScript/Vue.gitignore_0", "file": "community/JavaScript/Vue.gitignore", "content": "================================================\n# gitignore template for Vue.js projects\n#\n# Recommended template: Node.gitignore\n\n# TODO: where does this rule come from?\ndocs/_book\n\n# TODO: where does this rule come from?\ntest/"}, {"id": "community/Linux/Snap.gitignore_0", "file": "community/Linux/Snap.gitignore", "content": "================================================\n# gitginore template for creating Snap packages\n# website: https://snapcraft.io/\n\nparts/\nprime/\nstage/\n*.snap\n\n# Snapcraft global state tracking data(automatically generated)\n# https://forum.snapcraft.io/t/location-to-save-global-state/768\n/snap/.snapcraft/\n\n# Source archive packed by `snapcraft cleanbuild` before pushing to the LXD container\n/*_source.tar.bz2"}, {"id": "community/Obsidian/NotesAndCoreConfiguration.gitignore_0", "file": "community/Obsidian/NotesAndCoreConfiguration.gitignore", "content": "================================================\n# Excludes Obsidian workspace cache and plugins. All notes and core obsidian\n# configuration files are tracked by Git.\n\n# The current application UI state (DOM layout, recently-opened files, etc.) is\n# stored in these files (separate for desktop and mobile) so you can resume\n# your session seamlessly after a restart. If you want to track UI state, use\n# the Workspaces core plugin instead of relying on these files.\n.obsidian/workspace.json\n.obsidian/workspace-mobile.json\n\n# Obsidian plugins are stored under .obsidian/plugins/$plugin_name. They\n# contain metadata (manifest.json), application code (main.js), stylesheets\n# (styles.css), and user-configuration data (data.json)."}, {"id": "community/Obsidian/NotesAndCoreConfiguration.gitignore_1", "file": "community/Obsidian/NotesAndCoreConfiguration.gitignore", "content": "# (styles.css), and user-configuration data (data.json).\n# We want to exclude all plugin-related files, so we can exclude everything\n# under this directory.\n.obsidian/plugins/**/*"}, {"id": "community/Obsidian/NotesAndExtendedConfiguration.gitignore_0", "file": "community/Obsidian/NotesAndExtendedConfiguration.gitignore", "content": "================================================\n# Excludes Obsidian workspace cache and plugin code, but retains plugin\n# configuration. All notes and user-controlled configuration files are tracked\n# by Git.\n#\n# \t\t\t\t!!! WARNING !!!\n#\n# Community plugins may store sensitive secrets in their data.json files. By\n# including these files, those secrets may be tracked in your Git repository.\n#\n# To ignore configurations for specific plugins, add a line like this after the\n# contents of this file (order is important):\n#     .obsidian/plugins/{{plugin_name}}/data.json\n#\n# Alternatively, ensure that you are treating your entire Git repository as\n# sensitive data, since it may contain secrets, or may have contained them in\n# past commits.  Understand your threat profile, and make the decision"}, {"id": "community/Obsidian/NotesAndExtendedConfiguration.gitignore_1", "file": "community/Obsidian/NotesAndExtendedConfiguration.gitignore", "content": "# past commits.  Understand your threat profile, and make the decision\n# appropriate for yourself. If in doubt, err on the side of not including\n# plugin configuration. Use one of the alternative gitignore files instead:\n# * NotesOnly.gitignore\n# * NotesAndCoreConfiguration.gitignore\n\n# The current application UI state (DOM layout, recently-opened files, etc.) is\n# stored in these files (separate for desktop and mobile) so you can resume\n# your session seamlessly after a restart. If you want to track UI state, use\n# the Workspaces core plugin instead of relying on these files.\n.obsidian/workspace.json\n.obsidian/workspace-mobile.json\n\n# Obsidian plugins are stored under .obsidian/plugins/$plugin_name. They\n# contain metadata (manifest.json), application code (main.js), stylesheets"}, {"id": "community/Obsidian/NotesAndExtendedConfiguration.gitignore_2", "file": "community/Obsidian/NotesAndExtendedConfiguration.gitignore", "content": "# contain metadata (manifest.json), application code (main.js), stylesheets\n# (styles.css), and user-configuration data (data.json).\n# We only want to track data.json, so we:\n# 1. exclude everything that the plugin folders contain,\n# 2. unignore data.json in the plugin folders\n.obsidian/plugins/*/**\n!.obsidian/plugins/*/data.json"}, {"id": "community/Obsidian/NotesOnly.gitignore_0", "file": "community/Obsidian/NotesOnly.gitignore", "content": "================================================\n# Excludes all Obsidian-related configuration. All notes are tracked by Git.\n\n# All Obsidian configuration and runtime state is stored here\n.obsidian/**/*"}, {"id": "community/PHP/Bitrix.gitignore_0", "file": "community/PHP/Bitrix.gitignore", "content": "================================================\n# gitignore template for 1C-Bitrix, a PHP-based CMS\n# website: https://www.1c-bitrix.ru\n\n#Exclude all of core files\n/bitrix/*\n\n#But not the templates and non bitrix components\n!/bitrix/templates\n!/bitrix/components\n/bitrix/components/bitrix\n\n#Exclude bitrix gadgets\n!/bitrix/gadgets\n/bitrix/gadgets/bitrix\n\n#User can use that directory to store some stuff, but it's not really recommended, just use /local instead of this\n!/bitrix/php_interface/\n\n#Exclude database configs\n/bitrix/php_interface/dbconn.php\n\n#Exclude default file storage directory\n/upload/"}, {"id": "community/PHP/CodeSniffer.gitignore_0", "file": "community/PHP/CodeSniffer.gitignore", "content": "================================================\n# gitignore for the PHP Codesniffer framework\n# website: https://github.com/squizlabs/PHP_CodeSniffer\n#\n# Recommended template: PHP.gitignore\n\n/wpcs/*"}, {"id": "community/PHP/Drupal7.gitignore_0", "file": "community/PHP/Drupal7.gitignore", "content": "================================================\n# gitignore template for Drupal 7 projects\n#\n# It is recommended that you use `Drupal.gitignore` as this is the latest version\n\n# Ignore configuration files that may contain sensitive information.\nsites/*/*settings*.php\nsites/example.sites.php\n\n# Ignore paths that contain generated content.\nfiles/\nsites/*/files\nsites/*/private\nsites/*/translations\n\n# Ignore default text files\nrobots.txt\n/CHANGELOG.txt\n/COPYRIGHT.txt\n/INSTALL*.txt\n/LICENSE.txt\n/MAINTAINERS.txt\n/UPGRADE.txt\n/README.txt\nsites/README.txt\nsites/all/libraries/README.txt\nsites/all/modules/README.txt\nsites/all/themes/README.txt\n\n# Ignore everything but the \"sites\" folder ( for non core developer )\n.htaccess\nweb.config\nauthorize.php\ncron.php\nindex.php\ninstall.php\nupdate.php"}, {"id": "community/PHP/Drupal7.gitignore_1", "file": "community/PHP/Drupal7.gitignore", "content": ".htaccess\nweb.config\nauthorize.php\ncron.php\nindex.php\ninstall.php\nupdate.php\nxmlrpc.php\n/includes\n/misc\n/modules\n/profiles\n/scripts\n/themes"}, {"id": "community/PHP/Jigsaw.gitignore_0", "file": "community/PHP/Jigsaw.gitignore", "content": "================================================\n# gitignore template for Jigsaw Static Site Generator\n#\n# website - https://jigsaw.tighten.co\n\n# Ignore build folder\nbuild_*"}, {"id": "community/PHP/Magento1.gitignore_0", "file": "community/PHP/Magento1.gitignore", "content": "================================================\n# gitignore template for Magento v1 projects\n#\n# It is recommended that you use `Magento.gitignore` as this is the latest version\n\n/PATCH_*.sh\n\n/app/etc/local.xml\n\n/media/*\n!/media/.htaccess\n\n!/media/customer\n/media/customer/*\n!/media/customer/.htaccess\n\n!/media/dhl\n/media/dhl/*\n!/media/dhl/logo.jpg\n\n!/media/downloadable\n/media/downloadable/*\n!/media/downloadable/.htaccess\n\n!/media/xmlconnect\n/media/xmlconnect/*\n\n!/media/xmlconnect/custom\n/media/xmlconnect/custom/*\n!/media/xmlconnect/custom/ok.gif\n\n!/media/xmlconnect/original\n/media/xmlconnect/original/*\n!/media/xmlconnect/original/ok.gif\n\n!/media/xmlconnect/system\n/media/xmlconnect/system/*\n!/media/xmlconnect/system/ok.gif\n\n/var/*\n!/var/.htaccess\n\n!/var/package\n/var/package/*"}, {"id": "community/PHP/Magento1.gitignore_1", "file": "community/PHP/Magento1.gitignore", "content": "!/media/xmlconnect/system/ok.gif\n\n/var/*\n!/var/.htaccess\n\n!/var/package\n/var/package/*\n!/var/package/*.xml"}, {"id": "community/PHP/Magento2.gitignore_0", "file": "community/PHP/Magento2.gitignore", "content": "================================================\n/sitemap\n/sitemap.xml\n/pub/sitemap\n/pub/sitemap.xml\n/app/config_sandbox\n/app/etc/config.php\n/app/etc/env.php\n/app/code/Magento/TestModule*\n/lib/internal/flex/uploader/.actionScriptProperties\n/lib/internal/flex/uploader/.flexProperties\n/lib/internal/flex/uploader/.project\n/lib/internal/flex/uploader/.settings\n/lib/internal/flex/varien/.actionScriptProperties\n/lib/internal/flex/varien/.flexLibProperties\n/lib/internal/flex/varien/.project\n/lib/internal/flex/varien/.settings\n/.grunt\n/.php_cs.cache\n/grunt-config.json\n/dev/tools/grunt/configs/local-themes.js\n\n/pub/media/*.*\n!/pub/media/.htaccess\n/pub/media/attribute/*\n!/pub/media/attribute/.htaccess\n/pub/media/analytics/*\n/pub/media/catalog/*\n!/pub/media/catalog/.htaccess\n/pub/media/customer/*"}, {"id": "community/PHP/Magento2.gitignore_1", "file": "community/PHP/Magento2.gitignore", "content": "/pub/media/analytics/*\n/pub/media/catalog/*\n!/pub/media/catalog/.htaccess\n/pub/media/customer/*\n!/pub/media/customer/.htaccess\n/pub/media/downloadable/*\n!/pub/media/downloadable/.htaccess\n/pub/media/favicon/*\n/pub/media/import/*\n!/pub/media/import/.htaccess\n/pub/media/logo/*\n/pub/media/theme/*\n/pub/media/theme_customization/*\n!/pub/media/theme_customization/.htaccess\n/pub/media/wysiwyg/*\n!/pub/media/wysiwyg/.htaccess\n/pub/media/tmp/*\n!/pub/media/tmp/.htaccess\n/pub/media/captcha/*\n!/pub/media/captcha/.htaccess\n/pub/static/*\n!/pub/static/.htaccess\n\n/var/*\n!/var/.htaccess\n/vendor/*\n!/vendor/.htaccess\n/generated/*\n!/generated/.htaccess"}, {"id": "community/PHP/Pimcore.gitignore_0", "file": "community/PHP/Pimcore.gitignore", "content": "================================================\n# gitignore template for Pimcore CMS\n\n# pimcore source files\n/pimcore\n\n# asset files\n/website/var/assets/*\n\n# backups\n/website/var/backup/*\n\n# file cache\n/website/var/cache/*\n\n# generated PHP classes, keep definition files (.psf)\n/website/var/classes/Object*\n!/website/var/classes/objectbricks\n\n# various configuration files\n/website/var/config/system.xml\n/website/var/config/cache.xml\n/website/var/config/robots.txt\n/website/var/config/Geo*\n/website/var/config/object/*\n/website/var/config/portal/*\n/website/var/config/sqlreport/*\n\n# sent e-mail log files\n/website/var/email/*\n\n# log files\n/website/var/log/*.log\n\n# serialized recyclebin files\n/website/var/recyclebin/*\n\n# search plugin\n/website/var/search/*\n\n# various temp files"}, {"id": "community/PHP/Pimcore.gitignore_1", "file": "community/PHP/Pimcore.gitignore", "content": "/website/var/recyclebin/*\n\n# search plugin\n/website/var/search/*\n\n# various temp files\n/website/var/system/*\n/website/var/tmp/*\n\n# serialized version files\n/website/var/versions/asset/*\n/website/var/versions/document/*\n/website/var/versions/object/*\n\n# user profile images\n/website/var/user-image/*\n\n# keep .dummy files\n!.dummy"}, {"id": "community/PHP/ThinkPHP.gitignore_0", "file": "community/PHP/ThinkPHP.gitignore", "content": "================================================\n# gitignore template for ThinkPHP v3.2.3\n# website: http://www.thinkphp.cn/\n\n# Logs and Cache files\n/Application/Runtime/\n\n# Common configure file\n/Application/Common/Conf/config.php"}, {"id": "community/Python/JupyterNotebooks.gitignore_0", "file": "community/Python/JupyterNotebooks.gitignore", "content": "================================================\n# gitignore template for Jupyter Notebooks\n# website: http://jupyter.org/\n\n.ipynb_checkpoints\n*/.ipynb_checkpoints/*\n\n# IPython\nprofile_default/\nipython_config.py\n\n# Jupyter lab virtual documents\n# https://jupyterlab-lsp.readthedocs.io/en/2.x/Configuring.html#virtual_documents_dir\n.virtual_documents/\n\n# Remove previous ipynb_checkpoints\n#   git rm -r .ipynb_checkpoints/"}, {"id": "community/Python/Nikola.gitignore_0", "file": "community/Python/Nikola.gitignore", "content": "================================================\n# gitignore template for Nikola static site generator\n# website: https://getnikola.com/\n\n.doit.db\n*.py[cod]\ncache/\noutput/"}, {"id": "Global/README.md_0", "file": "Global/README.md", "content": "================================================\n## Globally Useful gitignores\n\nThis directory contains globally useful gitignores,\ne.g. OS-specific and editor specific.\n\nFor more on global gitignores:\n<https://help.github.com/en/github/using-git/ignoring-files#configuring-ignored-files-for-all-repositories-on-your-computer>\n\nAnd a good blog post about 'em:\n<http://augustl.com/blog/2009/global_gitignores>"}, {"id": "Global/AL.gitignore_0", "file": "Global/AL.gitignore", "content": "================================================\n.vscode/*\n!.vscode/settings.json\n!.vscode/tasks.json\n!.vscode/launch.json\n!.vscode/extensions.json\n*.code-workspace\n\n# Local History for Visual Studio Code\n.history/\n*.app\n.snapshots/*"}, {"id": "Global/Anjuta.gitignore_0", "file": "Global/Anjuta.gitignore", "content": "================================================\n# Local configuration folder and symbol database\n/.anjuta/\n/.anjuta_sym_db.db"}, {"id": "Global/Ansible.gitignore_0", "file": "Global/Ansible.gitignore", "content": "================================================\n*.retry\n.ansible/"}, {"id": "Global/Archives.gitignore_0", "file": "Global/Archives.gitignore", "content": "================================================\n# It's better to unpack these files and commit the raw source because\n# git has its own built in compression methods.\n*.7z\n*.jar\n*.rar\n*.zip\n*.gz\n*.gzip\n*.tgz\n*.bzip\n*.bzip2\n*.bz2\n*.xz\n*.lzma\n*.cab\n*.xar\n*.zst\n*.tzst\n\n# Packing-only formats\n*.iso\n*.tar\n\n# Package management formats\n*.dmg\n*.xpi\n*.gem\n*.egg\n*.deb\n*.rpm\n*.msi\n*.msm\n*.msp\n*.txz"}, {"id": "Global/Backup.gitignore_0", "file": "Global/Backup.gitignore", "content": "================================================\n*.bak\n*.gho\n*.ori\n*.orig\n*.tmp"}, {"id": "Global/Bazaar.gitignore_0", "file": "Global/Bazaar.gitignore", "content": "================================================\n.bzr/\n.bzrignore"}, {"id": "Global/BricxCC.gitignore_0", "file": "Global/BricxCC.gitignore", "content": "================================================\n# Bricx Command Center IDE\n# http://bricxcc.sourceforge.net\n*.bak\n*.sym"}, {"id": "Global/Calabash.gitignore_0", "file": "Global/Calabash.gitignore", "content": "================================================\n# Calabash / Cucumber\nrerun/\nreports/\nscreenshots/\nscreenshot*.png\ntest-servers/\n\n# bundler\n.bundle\nvendor"}, {"id": "Global/Cloud9.gitignore_0", "file": "Global/Cloud9.gitignore", "content": "================================================\n# Cloud9 IDE - http://c9.io\n.c9revisions\n.c9"}, {"id": "Global/CodeKit.gitignore_0", "file": "Global/CodeKit.gitignore", "content": "================================================\n# General CodeKit files to ignore\nconfig.codekit\nconfig.codekit3\n/min"}, {"id": "Global/Cursor.gitignore_0", "file": "Global/Cursor.gitignore", "content": "================================================\n.cursorignore\n.cursorindexingignore"}, {"id": "Global/CVS.gitignore_0", "file": "Global/CVS.gitignore", "content": "================================================\n/CVS/*\n**/CVS/*\n.cvsignore\n*/.cvsignore"}, {"id": "Global/DartEditor.gitignore_0", "file": "Global/DartEditor.gitignore", "content": "================================================\n.project\n.buildlog"}, {"id": "Global/Diff.gitignore_0", "file": "Global/Diff.gitignore", "content": "================================================\n*.patch\n*.diff"}, {"id": "Global/Dreamweaver.gitignore_0", "file": "Global/Dreamweaver.gitignore", "content": "================================================\n# DW Dreamweaver added files\n_notes\n_compareTemp\nconfigs/\ndwsync.xml\ndw_php_codehinting.config\n*.mno"}, {"id": "Global/Dropbox.gitignore_0", "file": "Global/Dropbox.gitignore", "content": "================================================\n# Dropbox settings and caches\n.dropbox\n.dropbox.attr\n.dropbox.cache"}, {"id": "Global/Eclipse.gitignore_0", "file": "Global/Eclipse.gitignore", "content": "================================================\n.metadata\nbin/\ntmp/\n*.tmp\n*.bak\n*.swp\n*~.nib\nlocal.properties\n.settings/\n.loadpath\n.recommenders\n\n# External tool builders\n.externalToolBuilders/\n\n# Locally stored \"Eclipse launch configurations\"\n*.launch\n\n# PyDev specific (Python IDE for Eclipse)\n*.pydevproject\n\n# CDT-specific (C/C++ Development Tooling)\n.cproject\n\n# CDT- autotools\n.autotools\n\n# Java annotation processor (APT)\n.factorypath\n\n# PDT-specific (PHP Development Tools)\n.buildpath\n\n# sbteclipse plugin\n.target\n\n# Tern plugin\n.tern-project\n\n# TeXlipse plugin\n.texlipse\n\n# STS (Spring Tool Suite)\n.springBeans\n\n# Code Recommenders\n.recommenders/\n\n# Annotation Processing\n.apt_generated/\n.apt_generated_tests/\n\n# Scala IDE specific (Scala & Java development for Eclipse)\n.cache-main"}, {"id": "Global/Eclipse.gitignore_1", "file": "Global/Eclipse.gitignore", "content": ".apt_generated_tests/\n\n# Scala IDE specific (Scala & Java development for Eclipse)\n.cache-main\n.scala_dependencies\n.worksheet\n\n# Uncomment this line if you wish to ignore the project description file.\n# Typically, this file would be tracked if it contains build/dependency configurations:\n#.project"}, {"id": "Global/EiffelStudio.gitignore_0", "file": "Global/EiffelStudio.gitignore", "content": "================================================\n# The compilation directory\nEIFGENs"}, {"id": "Global/Emacs.gitignore_0", "file": "Global/Emacs.gitignore", "content": "================================================\n# -*- mode: gitignore; -*-\n*~\n\\#*\\#\n/.emacs.desktop\n/.emacs.desktop.lock\n*.elc\nauto-save-list\ntramp\n.\\#*\n\n# Org-mode\n.org-id-locations\n*_archive\n\n# flymake-mode\n*_flymake.*\n\n# eshell files\n/eshell/history\n/eshell/lastdir\n\n# elpa packages\n/elpa/\n\n# reftex files\n*.rel\n\n# AUCTeX auto folder\n/auto/\n\n# cask packages\n.cask/\ndist/\n\n# Flycheck\nflycheck_*.el\n\n# server auth directory\n/server/\n\n# projectiles files\n.projectile\n\n# directory configuration\n.dir-locals.el\n\n# network security\n/network-security.data\n\n# undo-tree\n*.~undo-tree~"}, {"id": "Global/Ensime.gitignore_0", "file": "Global/Ensime.gitignore", "content": "================================================\n# Ensime specific\n.ensime\n.ensime_cache/\n.ensime_lucene/"}, {"id": "Global/Espresso.gitignore_0", "file": "Global/Espresso.gitignore", "content": "================================================\n*.esproj"}, {"id": "Global/FlexBuilder.gitignore_0", "file": "Global/FlexBuilder.gitignore", "content": "================================================\nbin/\nbin-debug/\nbin-release/"}, {"id": "Global/GPG.gitignore_0", "file": "Global/GPG.gitignore", "content": "================================================\nsecring.*"}, {"id": "Global/Images.gitignore_0", "file": "Global/Images.gitignore", "content": "================================================\n# JPEG\n*.jpg\n*.jpeg\n*.jpe\n*.jif\n*.jfif\n*.jfi\n\n# JPEG 2000\n*.jp2\n*.j2k\n*.jpf\n*.jpx\n*.jpm\n*.mj2\n\n# JPEG XR\n*.jxr\n*.hdp\n*.wdp\n\n# Graphics Interchange Format\n*.gif\n\n# RAW\n*.raw\n\n# Web P\n*.webp\n\n# Portable Network Graphics\n*.png\n\n# Animated Portable Network Graphics\n*.apng\n\n# Multiple-image Network Graphics\n*.mng\n\n# Tagged Image File Format\n*.tiff\n*.tif\n\n# Scalable Vector Graphics\n*.svg\n*.svgz\n\n# Portable Document Format\n*.pdf\n\n# X BitMap\n*.xbm\n\n# BMP\n*.bmp\n*.dib\n\n# ICO\n*.ico\n\n# 3D Images\n*.3dm\n*.max"}, {"id": "Global/JDeveloper.gitignore_0", "file": "Global/JDeveloper.gitignore", "content": "================================================\n# default application storage directory used by the IDE Performance Cache feature\n.data/\n\n# used for ADF styles caching\ntemp/\n\n# default output directories\nclasses/\ndeploy/\njavadoc/\n\n# lock file, a part of Oracle Credential Store Framework\ncwallet.sso.lck"}, {"id": "Global/JEnv.gitignore_0", "file": "Global/JEnv.gitignore", "content": "================================================\n# JEnv local Java version configuration file\n.java-version\n\n# Used by previous versions of JEnv\n.jenv-version"}, {"id": "Global/JetBrains.gitignore_0", "file": "Global/JetBrains.gitignore", "content": "================================================\n# Covers JetBrains IDEs: IntelliJ, GoLand, RubyMine, PhpStorm, AppCode, PyCharm, CLion, Android Studio, WebStorm and Rider\n# Reference: https://intellij-support.jetbrains.com/hc/en-us/articles/206544839\n\n# User-specific stuff\n.idea/**/workspace.xml\n.idea/**/tasks.xml\n.idea/**/usage.statistics.xml\n.idea/**/dictionaries\n.idea/**/shelf\n\n# AWS User-specific\n.idea/**/aws.xml\n\n# Generated files\n.idea/**/contentModel.xml\n\n# Sensitive or high-churn files\n.idea/**/dataSources/\n.idea/**/dataSources.ids\n.idea/**/dataSources.local.xml\n.idea/**/sqlDataSources.xml\n.idea/**/dynamic.xml\n.idea/**/uiDesigner.xml\n.idea/**/dbnavigator.xml\n\n# Gradle\n.idea/**/gradle.xml\n.idea/**/libraries\n\n# Gradle and Maven with auto-import"}, {"id": "Global/JetBrains.gitignore_1", "file": "Global/JetBrains.gitignore", "content": "# Gradle\n.idea/**/gradle.xml\n.idea/**/libraries\n\n# Gradle and Maven with auto-import\n# When using Gradle or Maven with auto-import, you should exclude module files,\n# since they will be recreated, and may cause churn.  Uncomment if using\n# auto-import.\n# .idea/artifacts\n# .idea/compiler.xml\n# .idea/jarRepositories.xml\n# .idea/modules.xml\n# .idea/*.iml\n# .idea/modules\n# *.iml\n# *.ipr\n\n# CMake\ncmake-build-*/\n\n# Mongo Explorer plugin\n.idea/**/mongoSettings.xml\n\n# File-based project format\n*.iws\n\n# IntelliJ\nout/\n\n# mpeltonen/sbt-idea plugin\n.idea_modules/\n\n# JIRA plugin\natlassian-ide-plugin.xml\n\n# Cursive Clojure plugin\n.idea/replstate.xml\n\n# SonarLint plugin\n.idea/sonarlint/"}, {"id": "Global/JetBrains.gitignore_2", "file": "Global/JetBrains.gitignore", "content": "# Cursive Clojure plugin\n.idea/replstate.xml\n\n# SonarLint plugin\n.idea/sonarlint/\n.idea/sonarlint.xml # see https://community.sonarsource.com/t/is-the-file-idea-idea-idea-sonarlint-xml-intended-to-be-under-source-control/121119\n\n# Crashlytics plugin (for Android Studio and IntelliJ)\ncom_crashlytics_export_strings.xml\ncrashlytics.properties\ncrashlytics-build.properties\nfabric.properties\n\n# Editor-based HTTP Client\n.idea/httpRequests\nhttp-client.private.env.json\n\n# Android studio 3.1+ serialized cache file\n.idea/caches/build_file_checksums.ser\n\n# Apifox Helper cache\n.idea/.cache/.Apifox_Helper\n.idea/ApifoxUploaderProjectSetting.xml"}, {"id": "Global/Kate.gitignore_0", "file": "Global/Kate.gitignore", "content": "================================================\n# Swap Files #\n.*.kate-swp\n.swp.*"}, {"id": "Global/KDevelop4.gitignore_0", "file": "Global/KDevelop4.gitignore", "content": "================================================\n*.kdev4\n.kdev4/"}, {"id": "Global/Lazarus.gitignore_0", "file": "Global/Lazarus.gitignore", "content": "================================================\n# Lazarus compiler-generated binaries (safe to delete)\n*.exe\n*.dll\n*.so\n*.dylib\n*.lrs\n*.res\n*.compiled\n*.dbg\n*.ppu\n*.o\n*.or\n*.a\n\n# Lazarus autogenerated files (duplicated info)\n*.rst\n*.rsj\n*.lrt\n\n# Lazarus local files (user-specific info)\n*.lps\n\n# Lazarus backups and unit output folders.\n# These can be changed by user in Lazarus/project options.\nbackup/\n*.bak\nlib/\n\n# Application bundle for Mac OS\n*.app/"}, {"id": "Global/Lefthook.gitignore_0", "file": "Global/Lefthook.gitignore", "content": "================================================\n# https://lefthook.dev/configuration/#config-file-name\n/.lefthook-local.json\n/.lefthook-local.toml\n/.lefthook-local.yaml\n/.lefthook-local.yml\n/lefthook-local.json\n/lefthook-local.toml\n/lefthook-local.yaml\n/lefthook-local.yml\n/.config/lefthook-local.json\n/.config/lefthook-local.toml\n/.config/lefthook-local.yaml\n/.config/lefthook-local.yml\n\n# https://lefthook.dev/configuration/source_dir_local.html\n/.lefthook-local/"}, {"id": "Global/LibreOffice.gitignore_0", "file": "Global/LibreOffice.gitignore", "content": "================================================\n# LibreOffice locks\n.~lock.*#"}, {"id": "Global/Linux.gitignore_0", "file": "Global/Linux.gitignore", "content": "================================================\n*~\n\n# temporary files which can be created if a process still has a handle open of a deleted file\n.fuse_hidden*\n\n# Metadata left by Dolphin file manager, which comes with KDE Plasma\n.directory\n\n# Linux trash folder which might appear on any partition or disk\n.Trash-*\n\n# .nfs files are created when an open file is removed but is still being accessed\n.nfs*\n\n# Log files created by default by the nohup command\nnohup.out"}, {"id": "Global/LyX.gitignore_0", "file": "Global/LyX.gitignore", "content": "================================================\n# Ignore LyX backup and autosave files\n# http://www.lyx.org/\n*.lyx~\n*.lyx#"}, {"id": "Global/macOS.gitignore_0", "file": "Global/macOS.gitignore", "content": "================================================\n# General\n.DS_Store\n__MACOSX/\n.AppleDouble\n.LSOverride\nIcon[\n]\n\n# Thumbnails\n._*\n\n# Files that might appear in the root of a volume\n.DocumentRevisions-V100\n.fseventsd\n.Spotlight-V100\n.TemporaryItems\n.Trashes\n.VolumeIcon.icns\n.com.apple.timemachine.donotpresent\n\n# Directories potentially created on remote AFP share\n.AppleDB\n.AppleDesktop\nNetwork Trash Folder\nTemporary Items\n.apdisk"}, {"id": "Global/MATLAB.gitignore_0", "file": "Global/MATLAB.gitignore", "content": "================================================\n# Autosave files\n*.asv\n*.m~\n*.autosave\n*.slx.r*\n*.mdl.r*\n\n# Derived content-obscured files\n*.p\n\n# Compiled MEX files\n*.mex*\n\n# Packaged app and toolbox files\n*.mlappinstall\n*.mltbx\n\n# Deployable archives\n*.ctf\n\n# Generated helpsearch folders\nhelpsearch*/\n\n# Code generation folders\nslprj/\nsccprj/\ncodegen/\n\n# Cache files\n*.slxc\n\n# Cloud based storage dotfile\n.MATLABDriveTag"}, {"id": "Global/Mercurial.gitignore_0", "file": "Global/Mercurial.gitignore", "content": "================================================\n.hg/\n.hgignore\n.hgsigs\n.hgsub\n.hgsubstate\n.hgtags"}, {"id": "Global/Metals.gitignore_0", "file": "Global/Metals.gitignore", "content": "================================================\n# Metals (Scala Language Server)\n# Reference: https://scalameta.org/metals/docs/editors/vscode#files-and-directories-to-include-in-your-gitignore\n.metals/\n.bloop/\n.ammonite/\nmetals.sbt"}, {"id": "Global/MicrosoftOffice.gitignore_0", "file": "Global/MicrosoftOffice.gitignore", "content": "================================================\n*.tmp\n\n# Word temporary\n~$*.doc*\n~$*.dot*\n\n# Word Auto Backup File\nBackup of *.doc*\n\n# Excel temporary\n~$*.xls*\n\n# Excel Backup File\n*.xlk\n\n# PowerPoint temporary\n~$*.ppt*\n\n# Visio autosave temporary files\n*.~vsd*"}, {"id": "Global/mise.gitignore_0", "file": "Global/mise.gitignore", "content": "================================================\n# https://mise.jdx.dev/configuration.html\n# https://mise.jdx.dev/configuration/environments.html\n.mise.*.local.toml\n.mise.local.toml\nmise.*.local.toml\nmise.local.toml\n.mise/*.local.toml\nmise/*.local.toml\n\n# https://mise.jdx.dev/configuration.html#tool-versions\n#.tool-versions"}, {"id": "Global/Momentics.gitignore_0", "file": "Global/Momentics.gitignore", "content": "================================================\n# Built files\nx86/\narm/\narm-p/\ntranslations/*.qm\n\n# IDE settings\n.settings/"}, {"id": "Global/MonoDevelop.gitignore_0", "file": "Global/MonoDevelop.gitignore", "content": "================================================\n#User Specific\n*.userprefs\n*.usertasks\n\n#Mono Project Files\n*.pidb\n*.resources\ntest-results/"}, {"id": "Global/NetBeans.gitignore_0", "file": "Global/NetBeans.gitignore", "content": "================================================\n**/nbproject/private/\n**/nbproject/Makefile-*.mk\n**/nbproject/Package-*.bash\nbuild/\nnbbuild/\ndist/\nnbdist/\n.nb-gradle/"}, {"id": "Global/Ninja.gitignore_0", "file": "Global/Ninja.gitignore", "content": "================================================\n.ninja_deps\n.ninja_log"}, {"id": "Global/NotepadPP.gitignore_0", "file": "Global/NotepadPP.gitignore", "content": "================================================\n# Notepad++ backups #\n*.bak"}, {"id": "Global/Octave.gitignore_0", "file": "Global/Octave.gitignore", "content": "================================================\nMATLAB.gitignore"}, {"id": "Global/Otto.gitignore_0", "file": "Global/Otto.gitignore", "content": "================================================\n.otto/"}, {"id": "Global/Patch.gitignore_0", "file": "Global/Patch.gitignore", "content": "================================================\n*.orig\n*.rej"}, {"id": "Global/PlatformIO.gitignore_0", "file": "Global/PlatformIO.gitignore", "content": "================================================\n.pio\n.pioenvs\n.piolibdeps\n.vscode/.browse.c_cpp.db*\n.vscode/c_cpp_properties.json\n.vscode/launch.json"}, {"id": "Global/PSoCCreator.gitignore_0", "file": "Global/PSoCCreator.gitignore", "content": "================================================\n# Project Settings\n*.cywrk.*\n*.cyprj.*\n\n# Generated Assets and Resources\nDebug/\nRelease/\nExport/\n*/codegentemp\n*/Generated_Source\n*_datasheet.pdf\n*_timing.html\n*.cycdx\n*.cyfit\n*.rpt\n*.svd\n*.log\n*.zip"}, {"id": "Global/PuTTY.gitignore_0", "file": "Global/PuTTY.gitignore", "content": "================================================\n# Private key\n*.ppk"}, {"id": "Global/Redcar.gitignore_0", "file": "Global/Redcar.gitignore", "content": "================================================\n.redcar"}, {"id": "Global/Redis.gitignore_0", "file": "Global/Redis.gitignore", "content": "================================================\n# Ignore redis binary dump (dump.rdb) files\n\n*.rdb"}, {"id": "Global/SBT.gitignore_0", "file": "Global/SBT.gitignore", "content": "================================================\n# Simple Build Tool\n# http://www.scala-sbt.org/release/docs/Getting-Started/Directories.html#configuring-version-control\n\ndist/*\ntarget/\nlib_managed/\nsrc_managed/\nproject/boot/\nproject/plugins/project/\n.history\n.cache\n.lib/\n.bsp/"}, {"id": "Global/SlickEdit.gitignore_0", "file": "Global/SlickEdit.gitignore", "content": "================================================\n# SlickEdit workspace and project files are ignored by default because\n# typically they are considered to be developer-specific and not part of a\n# project.\n*.vpw\n*.vpj\n\n# SlickEdit workspace history and tag files always contain user-specific\n# data so they should not be stored in a repository.\n*.vpwhistu\n*.vpwhist\n*.vtg"}, {"id": "Global/Stata.gitignore_0", "file": "Global/Stata.gitignore", "content": "================================================\n# .gitignore file for git projects containing Stata files\n# Commercial statistical software: http://www.stata.com\n\n# Stata dataset and output files\n*.dta\n*.gph\n*.log\n*.smcl\n*.stpr\n*.stsem\n~*.stswp\n\n# Graphic export files from Stata\n# Stata command graph export: http://www.stata.com/manuals14/g-2graphexport.pdf\n#\n# You may add graphic export files to your .gitignore. However you should be\n# aware that this will exclude all image files from this main directory\n# and subdirectories.\n# *.ps\n# *.eps\n# *.wmf\n# *.emf\n# *.pdf\n# *.png\n# *.tif"}, {"id": "Global/SublimeText.gitignore_0", "file": "Global/SublimeText.gitignore", "content": "================================================\n# Cache files for Sublime Text\n*.tmlanguage.cache\n*.tmPreferences.cache\n*.stTheme.cache\n\n# Workspace files are user-specific\n*.sublime-workspace\n\n# Project files should be checked into the repository, unless a significant\n# proportion of contributors will probably not be using Sublime Text\n# *.sublime-project\n\n# SFTP configuration file\nsftp-config.json\nsftp-config-alt*.json\n\n# Package control specific files\nPackage Control.last-run\nPackage Control.ca-list\nPackage Control.ca-bundle\nPackage Control.system-ca-bundle\nPackage Control.cache/\nPackage Control.ca-certs/\nPackage Control.merged-ca-bundle\nPackage Control.user-ca-bundle\noscrypto-ca-bundle.crt\nbh_unicode_properties.cache\n\n# Sublime-github package stores a github token in this file"}, {"id": "Global/SublimeText.gitignore_1", "file": "Global/SublimeText.gitignore", "content": "bh_unicode_properties.cache\n\n# Sublime-github package stores a github token in this file\n# https://packagecontrol.io/packages/sublime-github\nGitHub.sublime-settings"}, {"id": "Global/SVN.gitignore_0", "file": "Global/SVN.gitignore", "content": "================================================\n.svn/"}, {"id": "Global/Syncthing.gitignore_0", "file": "Global/Syncthing.gitignore", "content": "================================================\n# Syncthing caches\n.stversions"}, {"id": "Global/SynopsysVCS.gitignore_0", "file": "Global/SynopsysVCS.gitignore", "content": "================================================\n# Waveform formats\n*.vcd\n*.vpd\n*.evcd\n*.fsdb\n\n# Default name of the simulation executable.  A different name can be\n# specified with this switch (the associated daidir database name is\n# also taken from here):  -o <path>/<filename>\nsimv\n\n# Generated for Verilog and VHDL top configs\nsimv.daidir/\nsimv.db.dir/\n\n# Infrastructure necessary to co-simulate SystemC models with\n# Verilog/VHDL models.  An alternate directory may be specified with this\n# switch:  -Mdir=<directory_path>\ncsrc/\n\n# Log file - the following switch allows to specify the file that will be\n# used to write all messages from simulation:  -l <filename>\n*.log\n\n# Coverage results (generated with urg) and database location.  The"}, {"id": "Global/SynopsysVCS.gitignore_1", "file": "Global/SynopsysVCS.gitignore", "content": "*.log\n\n# Coverage results (generated with urg) and database location.  The\n# following switch can also be used:  urg -dir <coverage_directory>.vdb\nsimv.vdb/\nurgReport/\n\n# DVE and UCLI related files.\nDVEfiles/\nucli.key\n\n# When the design is elaborated for DirectC, the following file is created\n# with declarations for C/C++ functions.\nvc_hdrs.h"}, {"id": "Global/Tags.gitignore_0", "file": "Global/Tags.gitignore", "content": "================================================\n# Ignore tags created by etags, ctags, gtags (GNU global) and cscope\nTAGS\n.TAGS\n!TAGS/\ntags\n.tags\n!tags/\ngtags.files\nGTAGS\nGRTAGS\nGPATH\nGSYMS\ncscope.files\ncscope.out\ncscope.in.out\ncscope.po.out"}, {"id": "Global/TextMate.gitignore_0", "file": "Global/TextMate.gitignore", "content": "================================================\n*.tmproj\n*.tmproject\ntmtags"}, {"id": "Global/TortoiseGit.gitignore_0", "file": "Global/TortoiseGit.gitignore", "content": "================================================\n# Project-level settings\n/.tgitconfig"}, {"id": "Global/Vagrant.gitignore_0", "file": "Global/Vagrant.gitignore", "content": "================================================\n# General\n.vagrant/\n\n# Log files (if you are creating logs in debug mode, uncomment this)\n# *.log"}, {"id": "Global/Vim.gitignore_0", "file": "Global/Vim.gitignore", "content": "================================================\n# Swap\n[._]*.s[a-v][a-z]\n# comment out the next line if you don't need vector files\n!*.svg\n[._]*.sw[a-p]\n[._]s[a-rt-v][a-z]\n[._]ss[a-gi-z]\n[._]sw[a-p]\n\n# Session\nSession.vim\nSessionx.vim\n\n# Temporary\n.netrwhist\n*~\n# Auto-generated tag files\ntags\n# Persistent undo\n[._]*.un~"}, {"id": "Global/VirtualEnv.gitignore_0", "file": "Global/VirtualEnv.gitignore", "content": "================================================\n# Virtualenv\n# https://realpython.com/python-virtual-environments-a-primer/#the-virtualenv-project\n.Python\n[Bb]in\n[Ii]nclude\n[Ll]ib\n[Ll]ib64\n[Ll]ocal\n[Ss]cripts\npyvenv.cfg\n.venv\npip-selfcheck.json"}, {"id": "Global/Virtuoso.gitignore_0", "file": "Global/Virtuoso.gitignore", "content": "================================================\n# Gitignore for Cadence Virtuoso\n################################################################\n\n# Log files\n*.log\npanic*.log.*\n\n# OpenAccess database lock files\n*.cdslck*\n\n# Run directories for layout vs. schematic and design rule check\nlvsRunDir/*\ndrcRunDir/*\n\n# Abstract generation tool\nabstract.log*\nabstract.record*"}, {"id": "Global/VisualStudioCode.gitignore_0", "file": "Global/VisualStudioCode.gitignore", "content": "================================================\n.vscode/*\n!.vscode/settings.json\n!.vscode/tasks.json\n!.vscode/launch.json\n!.vscode/extensions.json\n!.vscode/*.code-snippets\n!*.code-workspace\n\n# Built Visual Studio Code Extensions\n*.vsix"}, {"id": "Global/WebMethods.gitignore_0", "file": "Global/WebMethods.gitignore", "content": "================================================\n**/IntegrationServer/datastore/\n**/IntegrationServer/db/\n**/IntegrationServer/DocumentStore/\n**/IntegrationServer/lib/\n**/IntegrationServer/logs/\n**/IntegrationServer/replicate/\n**/IntegrationServer/sdk/\n**/IntegrationServer/support/\n**/IntegrationServer/update/\n**/IntegrationServer/userFtpRoot/\n**/IntegrationServer/web/\n**/IntegrationServer/WmRepository4/\n**/IntegrationServer/XAStore/\n**/IntegrationServer/packages/Wm*/"}, {"id": "Global/Windows.gitignore_0", "file": "Global/Windows.gitignore", "content": "================================================\n# Windows thumbnail cache files\nThumbs.db\nThumbs.db:encryptable\nehthumbs.db\nehthumbs_vista.db\n\n# Dump file\n*.stackdump\n\n# Folder config file\n[Dd]esktop.ini\n\n# Recycle Bin used on file shares\n$RECYCLE.BIN/\n\n# Windows Installer files\n*.cab\n*.msi\n*.msix\n*.msm\n*.msp\n\n# Windows shortcuts\n*.lnk"}, {"id": "Global/Xcode.gitignore_0", "file": "Global/Xcode.gitignore", "content": "================================================\n## User settings\nxcuserdata/"}, {"id": "Global/XilinxISE.gitignore_0", "file": "Global/XilinxISE.gitignore", "content": "================================================\n# intermediate build files\n*.bgn\n*.bit\n*.bld\n*.cmd_log\n*.drc\n*.ll\n*.lso\n*.msd\n*.msk\n*.ncd\n*.ngc\n*.ngd\n*.ngr\n*.pad\n*.par\n*.pcf\n*.prj\n*.ptwx\n*.rbb\n*.rbd\n*.stx\n*.syr\n*.twr\n*.twx\n*.unroutes\n*.ut\n*.xpi\n*.xst\n*_bitgen.xwbt\n*_envsettings.html\n*_map.map\n*_map.mrp\n*_map.ngm\n*_map.xrpt\n*_ngdbuild.xrpt\n*_pad.csv\n*_pad.txt\n*_par.xrpt\n*_summary.html\n*_summary.xml\n*_usage.xml\n*_xst.xrpt\n\n# iMPACT generated files\n_impactbatch.log\nimpact.xsl\nimpact_impact.xwbt\nise_impact.cmd\nwebtalk_impact.xml\n\n# Core Generator generated files\nxaw2verilog.log\n\n# project-wide generated files\n*.gise\npar_usage_statistics.html\nusage_statistics_webtalk.html\nwebtalk.log\nwebtalk_pn.xml\n\n# generated folders\niseconfig/\nxlnx_auto_0_xdb/\nxst/\n_ngo/\n_xmsgs/"}, {"id": ".github/CODEOWNERS_0", "file": ".github/CODEOWNERS", "content": "================================================\n# Order is important. The LAST matching pattern has the MOST precedence.\n# gitignore style patterns are used, not globs.\n# https://docs.github.com/articles/about-codeowners\n# https://git-scm.com/docs/gitignore\n\n# Catch All - Defer to the gitignore maintainers\n* @github/gitignore-maintainers"}, {"id": ".github/PULL_REQUEST_TEMPLATE.md_0", "file": ".github/PULL_REQUEST_TEMPLATE.md", "content": "================================================\n### Reasons for making this change\n\n_TODO_\n<!---\nPlease provide some background for this change.\n--->\n\n### Links to documentation supporting these rule changes\n\n_TODO_\n\n<!---\nLink to the project docs, any existing .gitignore files that project may have in it's own repo, etc\n--->\n\n### If this is a new template\n\nLink to application or project\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s homepage: TODO\n\n### Merge and Approval Steps\n- [ ] Confirm that you've read the [contribution guidelines](https://github.com/github/gitignore/tree/main?tab=readme-ov-file#contributing-guidelines) and ensured your PR aligns\n- [ ] Ensure CI is passing\n- [ ] Get a review and Approval from one of the maintainers"}, {"id": ".github/workflows/stale.yml_0", "file": ".github/workflows/stale.yml", "content": "================================================\nname: Stale\n\n# **What it does**: Close pull requests after no updates for 180 days.\n# **Why we have it**: This repository gets a lot of PRs, and the maintainers team is small.\n#                     This helps reduce the open PRs to ones that are most desired by the community.\n# **Who does it impact**: Contributors and maintainers of github/gitignore.\n\non:\n  schedule:\n    - cron: '20 16 * * *' # Run every day at 16:20 UTC / 8:20 PST\n\npermissions:\n  actions: write\n  contents: write # only for delete-branch option\n  issues: write\n  pull-requests: write\n\njobs:\n  stale:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/stale@5bef64f19d7facfb25b37b414482c7164d639639 # v9.1.0\n        with:"}, {"id": ".github/workflows/stale.yml_1", "file": ".github/workflows/stale.yml", "content": "- uses: actions/stale@5bef64f19d7facfb25b37b414482c7164d639639 # v9.1.0\n        with:\n          stale-pr-message: 'This PR is stale because there have been no updates in 90 days. It will close after 180 days of inactivity. Leave a comment if you want to keep it open :smile:'\n          close-pr-message: 'This PR has been closed because it was inactive for 180 days. If you want to continue working on it, please open a new PR.'\n          days-before-stale: 90\n          days-before-close: 180\n          stale-pr-label: 'stale'\n          exempt-pr-labels: 'keep'\n          close-issue-reason: not_planned\n          ascending: true # Sort PRs by last updated date in ascending order\n          operations-per-run: 300"}, {"id": "gitingest_outputs/github_gitignore_20250905_194008.txt_0", "file": "gitingest_outputs/github_gitignore_20250905_194008.txt", "content": "================================================\nDirectory structure:\n\u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac github-gitignore/\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac README.md\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Actionscript.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Ada.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac AdventureGameStudio.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Agda.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac AL.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Android.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Angular.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac AppceleratorTitanium.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac AppEngine.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac ArchLinuxPackages.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Autotools.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Ballerina.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac C++.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac C.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CakePHP.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CFWheels.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac ChefCookbook.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Clojure.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CMake.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CodeIgniter.gitignore"}, {"id": "gitingest_outputs/github_gitignore_20250905_194008.txt_1", "file": "gitingest_outputs/github_gitignore_20250905_194008.txt", "content": "\u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Clojure.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CMake.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CodeIgniter.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CommonLisp.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Composer.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Concrete5.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CONTRIBUTING.md\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Coq.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CraftCMS.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CUDA.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac D.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Dart.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Delphi.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac DM.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Dotnet.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Drupal.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Eagle.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac ecu.test.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Elisp.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Elixir.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Elm.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac EPiServer.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Erlang.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac ExpressionEngine.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac ExtJs.gitignore"}, {"id": "gitingest_outputs/github_gitignore_20250905_194008.txt_2", "file": "gitingest_outputs/github_gitignore_20250905_194008.txt", "content": "\u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac ExpressionEngine.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac ExtJs.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Fancy.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Finale.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Firebase.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac FlaxEngine.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Flutter.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac ForceDotCom.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Fortran.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac FuelPHP.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Gcov.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac GitBook.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac GitHubPages.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Gleam.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Go.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Godot.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Gradle.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Grails.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac GWT.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Haskell.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Haxe.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac HIP.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac IAR.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Idris.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac IGORPro.gitignore"}, {"id": "gitingest_outputs/github_gitignore_20250905_194008.txt_3", "file": "gitingest_outputs/github_gitignore_20250905_194008.txt", "content": "\u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac IAR.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Idris.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac IGORPro.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Java.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac JBoss.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Jekyll.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac JENKINS_HOME.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Joomla.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Julia.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Katalon.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac KiCad.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Kohana.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Kotlin.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac LabVIEW.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac LangChain.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Laravel.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Leiningen.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac LemonStand.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac LICENSE\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Lilypond.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Lithium.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Lua.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Luau.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Magento.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Maven.gitignore"}, {"id": "gitingest_outputs/github_gitignore_20250905_194008.txt_4", "file": "gitingest_outputs/github_gitignore_20250905_194008.txt", "content": "\u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Luau.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Magento.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Maven.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Mercury.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac MetaProgrammingSystem.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Modelica.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac ModelSim.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Nanoc.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Nestjs.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Nextjs.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Nim.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Nix.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Node.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Objective-C.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac OCaml.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Opa.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac OpenCart.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac OracleForms.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Packer.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Perl.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Phalcon.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac PlayFramework.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Plone.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Prestashop.gitignore"}, {"id": "gitingest_outputs/github_gitignore_20250905_194008.txt_5", "file": "gitingest_outputs/github_gitignore_20250905_194008.txt", "content": "\u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Plone.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Prestashop.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Processing.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac PureScript.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Python.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Qooxdoo.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Qt.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac R.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Racket.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Rails.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Raku.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac ReScript.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac RhodesRhomobile.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac ROS.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Ruby.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Rust.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Salesforce.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Sass.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Scala.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Scheme.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac SCons.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Scrivener.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Sdcc.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac SeamGen.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac SketchUp.gitignore"}, {"id": "gitingest_outputs/github_gitignore_20250905_194008.txt_6", "file": "gitingest_outputs/github_gitignore_20250905_194008.txt", "content": "\u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Sdcc.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac SeamGen.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac SketchUp.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Smalltalk.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Solidity-Remix.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac SSDT-sqlproj.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Stella.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac SugarCRM.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Swift.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Symfony.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac SymphonyCMS.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Terraform.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac TestComplete.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac TeX.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Textpattern.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac TurboGears2.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac TwinCAT3.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Typo3.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Unity.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac UnrealEngine.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac VBA.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac VisualStudio.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac VVVV.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Waf.gitignore"}, {"id": "gitingest_outputs/github_gitignore_20250905_194008.txt_7", "file": "gitingest_outputs/github_gitignore_20250905_194008.txt", "content": "\u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac VisualStudio.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac VVVV.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Waf.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac WordPress.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Xojo.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Yeoman.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Yii.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac ZendFramework.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Zephir.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Zig.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac community/\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Alteryx.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac AltiumDesigner.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac AutoIt.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac AutomationStudio.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac B4X.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Bazel.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Beef.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Dotter.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Exercism.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Gretl.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Hexo.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac LensStudio.gitignore"}, {"id": "gitingest_outputs/github_gitignore_20250905_194008.txt_8", "file": "gitingest_outputs/github_gitignore_20250905_194008.txt", "content": "\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Hexo.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac LensStudio.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac libogc.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Logtalk.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac MetaTrader5.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Move.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac NasaSpecsIntact.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac OpenSSL.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac OpenTofu.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Puppet.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Racket.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Red.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac ROS2.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac SPFx.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Splunk.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Strapi.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Terragrunt.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Toit.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac UiPath.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac UTAU.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac V.gitignore"}, {"id": "gitingest_outputs/github_gitignore_20250905_194008.txt_9", "file": "gitingest_outputs/github_gitignore_20250905_194008.txt", "content": "\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac UTAU.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac V.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Xilinx.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac AWS/\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CDK.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac SAM.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac BoxLang/\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac ColdBox.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CFML/\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac ColdBox.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac DotNet/\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac core.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac InforCMS.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Kentico.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac Umbraco.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Elixir/\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac Phoenix.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac embedded/\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac AtmelStudio.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac esp-idf.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac IAR_EWARM.gitignore"}, {"id": "gitingest_outputs/github_gitignore_20250905_194008.txt_10", "file": "gitingest_outputs/github_gitignore_20250905_194008.txt", "content": "\u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac esp-idf.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac IAR_EWARM.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac uVision.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac GNOME/\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac GNOMEShellExtension.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Golang/\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Go.AllowList.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac Hugo.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Java/\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac JBoss4.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac JBoss6.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac JavaScript/\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Cordova.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Expo.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Meteor.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac NWjs.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac Vue.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Linux/\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac Snap.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Obsidian/"}, {"id": "gitingest_outputs/github_gitignore_20250905_194008.txt_11", "file": "gitingest_outputs/github_gitignore_20250905_194008.txt", "content": "\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Linux/\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac Snap.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Obsidian/\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac NotesAndCoreConfiguration.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac NotesAndExtendedConfiguration.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac NotesOnly.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac PHP/\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Bitrix.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CodeSniffer.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Drupal7.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Jigsaw.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Magento1.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Magento2.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Pimcore.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac ThinkPHP.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac Python/\n    \u00e2\u201d\u201a       \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac JupyterNotebooks.gitignore\n    \u00e2\u201d\u201a       \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac Nikola.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Global/"}, {"id": "gitingest_outputs/github_gitignore_20250905_194008.txt_12", "file": "gitingest_outputs/github_gitignore_20250905_194008.txt", "content": "\u00e2\u201d\u201a       \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac Nikola.gitignore\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Global/\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac README.md\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac AL.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Anjuta.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Ansible.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Archives.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Backup.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Bazaar.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac BricxCC.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Calabash.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Cloud9.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CodeKit.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Cursor.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CVS.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac DartEditor.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Diff.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Dreamweaver.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Dropbox.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Eclipse.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac EiffelStudio.gitignore"}, {"id": "gitingest_outputs/github_gitignore_20250905_194008.txt_13", "file": "gitingest_outputs/github_gitignore_20250905_194008.txt", "content": "\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Eclipse.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac EiffelStudio.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Emacs.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Ensime.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Espresso.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac FlexBuilder.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac GPG.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Images.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac JDeveloper.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac JEnv.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac JetBrains.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Kate.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac KDevelop4.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Lazarus.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Lefthook.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac LibreOffice.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Linux.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac LyX.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac macOS.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac MATLAB.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Mercurial.gitignore"}, {"id": "gitingest_outputs/github_gitignore_20250905_194008.txt_14", "file": "gitingest_outputs/github_gitignore_20250905_194008.txt", "content": "\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac MATLAB.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Mercurial.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Metals.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac MicrosoftOffice.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac mise.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Momentics.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac MonoDevelop.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac NetBeans.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Ninja.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac NotepadPP.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Octave.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Otto.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Patch.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac PlatformIO.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac PSoCCreator.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac PuTTY.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Redcar.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Redis.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac SBT.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac SlickEdit.gitignore"}, {"id": "gitingest_outputs/github_gitignore_20250905_194008.txt_15", "file": "gitingest_outputs/github_gitignore_20250905_194008.txt", "content": "\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac SBT.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac SlickEdit.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Stata.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac SublimeText.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac SVN.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Syncthing.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac SynopsysVCS.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Tags.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac TextMate.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac TortoiseGit.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Vagrant.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Vim.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac VirtualEnv.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Virtuoso.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac VisualStudioCode.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac WebMethods.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Windows.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Xcode.gitignore\n    \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac XilinxISE.gitignore\n    \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac .github/\n        \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CODEOWNERS"}, {"id": "gitingest_outputs/github_gitignore_20250905_194008.txt_16", "file": "gitingest_outputs/github_gitignore_20250905_194008.txt", "content": "\u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac XilinxISE.gitignore\n    \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac .github/\n        \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CODEOWNERS\n        \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac PULL_REQUEST_TEMPLATE.md\n        \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac workflows/\n            \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac stale.yml"}, {"id": "README.md_0", "file": "README.md", "content": "================================================\n# A collection of `.gitignore` templates\n\nThis is GitHub\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s collection of [`.gitignore`][man] file templates.\nWe use this list to populate the `.gitignore` template choosers available\nin the GitHub.com interface when creating new repositories and files.\n\nFor more information about how `.gitignore` files work, and how to use them,\nthe following resources are a great place to start:\n\n- The [Ignoring Files chapter][chapter] of the [Pro Git][progit] book.\n- The [Ignoring Files article][help] on the GitHub Help site.\n- The [gitignore(5)][man] manual page.\n\n[man]: https://git-scm.com/docs/gitignore\n[help]: https://help.github.com/articles/ignoring-files"}, {"id": "README.md_1", "file": "README.md", "content": "[man]: https://git-scm.com/docs/gitignore\n[help]: https://help.github.com/articles/ignoring-files\n[chapter]: https://git-scm.com/book/en/v2/Git-Basics-Recording-Changes-to-the-Repository#_ignoring\n[progit]: https://git-scm.com/book"}, {"id": "README.md_2", "file": "README.md", "content": "## Folder structure\n\nWe support a collection of templates, organized in this way:\n\n- The root folder contains templates in common use, to help people get started\n  with popular programming languages and technologies. These define a meaningful\n  set of rules to help get started, and ensure you are not committing\n  unimportant files into your repository.\n- [`Global`](./Global) contains templates for various editors, tools and\n  operating systems that can be used in different situations. It is recommended\n  that you either [add these to your global template](https://docs.github.com/en/get-started/getting-started-with-git/ignoring-files#configuring-ignored-files-for-all-repositories-on-your-computer)\n  or merge these rules into your project-specific templates if you want to use"}, {"id": "README.md_3", "file": "README.md", "content": "or merge these rules into your project-specific templates if you want to use\n  them permanently.\n- [`community`](./community) contains specialized templates for other popular\n  languages, tools and project, which don't currently belong in the mainstream\n  templates. These should be added to your project-specific templates when you\n  decide to adopt the framework or tool."}, {"id": "README.md_4", "file": "README.md", "content": "## What makes a good template?\n\nA template should contain a set of rules to help Git repositories work with a\nspecific programming language, framework, tool or environment.\n\nIf it's not possible to curate a small set of useful rules for this situation,\nthen the template is not a good fit for this collection.\n\nIf a template is mostly a list of files installed by a particular version of\nsome software (e.g. a PHP framework), it could live under the `community`\ndirectory. See [versioned templates](#versioned-templates) for more details.\n\nIf you have a small set of rules, or want to support a technology that is not\nwidely in use, and still believe this will be helpful to others, please read the\nsection about [specialized templates](#specialized-templates) for more details."}, {"id": "README.md_5", "file": "README.md", "content": "section about [specialized templates](#specialized-templates) for more details.\n\nInclude details when opening pull request if the template is important and visible. We\nmay not accept it immediately, but we can promote it to the root at a later date\nbased on interest.\n\nPlease also understand that we can\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2t list every tool that ever existed.\nOur aim is to curate a collection of the _most common and helpful_ templates,\nnot to make sure we cover every project possible. If we choose not to\ninclude your language, tool, or project, it\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s not because it\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s not awesome."}, {"id": "README.md_6", "file": "README.md", "content": "## Contributing guidelines\n\nWe\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2d love for you to help us improve this project. To help us keep this collection\nhigh quality, we request that contributions adhere to the following guidelines.\n\n- **Provide a link to the application or project\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s homepage**. Unless it\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s\n  extremely popular, there\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s a chance the maintainers don\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2t know about or use\n  the language, framework, editor, app, or project your change applies to.\n\n- **Provide links to documentation** supporting the change you\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2re making.\n  Current, canonical documentation mentioning the files being ignored is best.\n  If documentation isn\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2t available to support your change, do the best you can\n  to explain what the files being ignored are for."}, {"id": "README.md_7", "file": "README.md", "content": "to explain what the files being ignored are for.\n\n- **Explain why you\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2re making a change**. Even if it seems self-evident, please\n  take a sentence or two to tell us why your change or addition should happen.\n  It\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s especially helpful to articulate why this change applies to _everyone_\n  who works with the applicable technology, rather than just you or your team.\n\n- **Please consider the scope of your change**. If your change is specific to a\n  certain language or framework, then make sure the change is made to the\n  template for that language or framework, rather than to the template for an\n  editor, tool, or operating system.\n\n- **Please only modify _one template_ per pull request**. This helps keep pull"}, {"id": "README.md_8", "file": "README.md", "content": "- **Please only modify _one template_ per pull request**. This helps keep pull\n  requests and feedback focused on a specific project or technology.\n\nIn general, the more you can do to help us understand the change you\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2re making,\nthe more likely we\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2ll be to accept your contribution quickly."}, {"id": "README.md_9", "file": "README.md", "content": "## Versioned templates\n\nSome templates can change greatly between versions, and if you wish to contribute\nto this repository we need to follow this specific flow:\n\n- the template at the root should be the current supported version\n- the template at the root should not have a version in the filename (i.e.\n  \"evergreen\")\n- previous versions of templates should live under `community/`\n- previous versions of the template should embed the version in the filename,\n  for readability\n\nThis helps ensure users get the latest version (because they'll use whatever is\nat the root) but helps maintainers support older versions still in the wild."}, {"id": "README.md_10", "file": "README.md", "content": "## Specialized templates\n\nIf you have a template that you would like to contribute, but it isn't quite\nmainstream, please consider adding this to the `community` directory under a\nfolder that best suits where it belongs.\n\nThe rules in your specialized template should be specific to the framework or\ntool, and any additional templates should be mentioned in a comment in the\nheader of the template.\n\nFor example, this template might live at `community/DotNet/InforCRM.gitignore`:\n\n```gitignore\n# gitignore template for InforCRM (formerly SalesLogix)\n# website: https://www.infor.com/product-summary/cx/infor-crm/\n#\n# Recommended: VisualStudio.gitignore\n\n# Ignore model files that are auto-generated\nModelIndex.xml\nExportedFiles.xml\n\n# Ignore deployment files\n[Mm]odel/[Dd]eployment"}, {"id": "README.md_11", "file": "README.md", "content": "ModelIndex.xml\nExportedFiles.xml\n\n# Ignore deployment files\n[Mm]odel/[Dd]eployment\n\n# Force include portal SupportFiles\n!Model/Portal/*/SupportFiles/[Bb]in/\n!Model/Portal/PortalTemplates/*/SupportFiles/[Bb]in\n```"}, {"id": "README.md_12", "file": "README.md", "content": "## Contributing workflow\n\nHere\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s how we suggest you go about proposing a change to this project:\n\n1. [Fork this project][fork] to your account.\n2. [Create a branch][branch] for the change you intend to make.\n3. Make your changes to your fork.\n4. [Send a pull request][pr] from your fork\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s branch to our `main` branch.\n\nUsing the web-based interface to make changes is fine too, and will help you\nby automatically forking the project and prompting to send a pull request too.\n\n[fork]: https://help.github.com/articles/fork-a-repo/\n[branch]: https://help.github.com/articles/creating-and-deleting-branches-within-your-repository\n[pr]: https://help.github.com/articles/using-pull-requests/\n\n## License\n\n[CC0-1.0](./LICENSE)."}, {"id": "Actionscript.gitignore_0", "file": "Actionscript.gitignore", "content": "================================================\n# Build and Release Folders\nbin-debug/\nbin-release/\n[Oo]bj/\n[Bb]in/\n\n# Other files and folders\n.settings/\n\n# Executables\n*.swf\n*.air\n*.ipa\n*.apk\n\n# Project files, i.e. `.project`, `.actionScriptProperties` and `.flexProperties`\n# should NOT be excluded as they contain compiler settings and other important\n# information for Eclipse / Flash Builder."}, {"id": "Ada.gitignore_0", "file": "Ada.gitignore", "content": "================================================\n# Object file\n*.o\n\n# Ada Library Information\n*.ali"}, {"id": "AdventureGameStudio.gitignore_0", "file": "AdventureGameStudio.gitignore", "content": "================================================\n# Built things\n_Debug/\nCompiled/\n\n# AudioCache can be rebuilt from sources\nAudioCache/\n\n# Lockfile\n_OpenInEditor.lock\n\n# User settings\nGame.agf.user\n*.crm.user\n\n# Backups\nGame.agf.bak\nbackup_acsprset.spr\n\n# Memory dumps\n*.dmp\n\n# Temporary files\n# temporarily created during sprite or room background compression\n~aclzw.tmp\n# temporary, main game data, before getting packed into exe\ngame28.dta\n# temporary build of the game before being moved to Compiled/ folder\n*.exe\n\n# Log files\nwarnings.log"}, {"id": "Agda.gitignore_0", "file": "Agda.gitignore", "content": "================================================\n*.agdai\nMAlonzo/**"}, {"id": "AL.gitignore_0", "file": "AL.gitignore", "content": "================================================\n### AL ###\n#Template for AL projects for Dynamics 365 Business Central\n#launch.json folder\n.vscode/\n#Cache folder\n.alcache/\n#Symbols folder\n.alpackages/\n#Snapshots folder\n.snapshots/\n#Testing Output folder\n.output/\n#Extension App-file\n*.app\n#Rapid Application Development File\nrad.json\n#Translation Base-file\n*.g.xlf\n#License-file\n*.flf\n#Test results file\nTestResults.xml"}, {"id": "Android.gitignore_0", "file": "Android.gitignore", "content": "================================================\n# Gradle files\n.gradle/\nbuild/\n\n# Local configuration file (sdk path, etc)\nlocal.properties\n\n# Log/OS Files\n*.log\n\n# Android Studio generated files and folders\ncaptures/\n.externalNativeBuild/\n.cxx/\n*.aab\n*.apk\noutput-metadata.json\n\n# IntelliJ\n*.iml\n.idea/\nmisc.xml\ndeploymentTargetDropDown.xml\nrender.experimental.xml\n\n# Keystore files\n*.jks\n*.keystore\n\n# Google Services (e.g. APIs or Firebase)\ngoogle-services.json\n\n# Android Profiling\n*.hprof"}, {"id": "Angular.gitignore_0", "file": "Angular.gitignore", "content": "================================================\n# Angular specific\n/dist/\n/out-tsc/\n/tmp/\n/coverage/\n/e2e/test-output/\n/.angular/\n.angular/\n\n# Node modules and dependency files\n/node_modules/\n/package-lock.json\n/yarn.lock\n\n# Environment files\n/.env\n\n# Angular CLI and build artefacts\n/.angular-cli.json\n/.ng/\n\n# TypeScript cache\n*.tsbuildinfo\n\n# Logs\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*"}, {"id": "AppceleratorTitanium.gitignore_0", "file": "AppceleratorTitanium.gitignore", "content": "================================================\n# Build folder and log file\nbuild/\nbuild.log"}, {"id": "AppEngine.gitignore_0", "file": "AppEngine.gitignore", "content": "================================================\n# Google App Engine generated folder\nappengine-generated/"}, {"id": "ArchLinuxPackages.gitignore_0", "file": "ArchLinuxPackages.gitignore", "content": "================================================\n*.tar\n*.tar.*\n*.jar\n*.exe\n*.msi\n*.deb\n*.zip\n*.tgz\n*.log\n*.log.*\n*.sig\n\npkg/\nsrc/"}, {"id": "Autotools.gitignore_0", "file": "Autotools.gitignore", "content": "================================================\n# http://www.gnu.org/software/automake\n\nMakefile.in\n/ar-lib\n/mdate-sh\n/py-compile\n/test-driver\n/ylwrap\n.deps/\n.dirstamp\n\n# http://www.gnu.org/software/autoconf\n\nautom4te.cache\n/autoscan.log\n/autoscan-*.log\n/aclocal.m4\n/compile\n/config.cache\n/config.guess\n/config.h.in\n/config.log\n/config.status\n/config.sub\n/configure\n/configure.scan\n/depcomp\n/install-sh\n/missing\n/stamp-h1\n\n# https://www.gnu.org/software/libtool/\n\n/libtool\n/ltmain.sh\n.libs/\n\n# http://www.gnu.org/software/texinfo\n\n/texinfo.tex\n\n# http://www.gnu.org/software/m4/\n\nm4/libtool.m4\nm4/ltoptions.m4\nm4/ltsugar.m4\nm4/ltversion.m4\nm4/lt~obsolete.m4\n\n# Generated Makefile\n# (meta build system like autotools,\n# can automatically generate from config.status script"}, {"id": "Autotools.gitignore_1", "file": "Autotools.gitignore", "content": "# (meta build system like autotools,\n# can automatically generate from config.status script\n# (which is called by configure script))\nMakefile"}, {"id": "Ballerina.gitignore_0", "file": "Ballerina.gitignore", "content": "================================================\n# generated files\ntarget/\ngenerated/\n\n# dependencies\nDependencies.toml\n\n# config files\nConfig.toml\n# the config files used for testing, Uncomment the following line if you want to commit the test config files\n#!**/tests/Config.toml"}, {"id": "C++.gitignore_0", "file": "C++.gitignore", "content": "================================================\n# Prerequisites\n*.d\n\n# Compiled Object files\n*.slo\n*.lo\n*.o\n*.obj\n\n# Precompiled Headers\n*.gch\n*.pch\n\n# Linker files\n*.ilk\n\n# Debugger Files\n*.pdb\n\n# Compiled Dynamic libraries\n*.so\n*.dylib\n*.dll\n\n# Fortran module files\n*.mod\n*.smod\n\n# Compiled Static libraries\n*.lai\n*.la\n*.a\n*.lib\n\n# Executables\n*.exe\n*.out\n*.app\n\n# debug information files\n*.dwo"}, {"id": "C.gitignore_0", "file": "C.gitignore", "content": "================================================\n# Prerequisites\n*.d\n\n# Object files\n*.o\n*.ko\n*.obj\n*.elf\n\n# Linker output\n*.ilk\n*.map\n*.exp\n\n# Precompiled Headers\n*.gch\n*.pch\n\n# Libraries\n*.lib\n*.a\n*.la\n*.lo\n\n# Shared objects (inc. Windows DLLs)\n*.dll\n*.so\n*.so.*\n*.dylib\n\n# Executables\n*.exe\n*.out\n*.app\n*.i*86\n*.x86_64\n*.hex\n\n# Debug files\n*.dSYM/\n*.su\n*.idb\n*.pdb\n\n# Kernel Module Compile Results\n*.mod*\n*.cmd\n.tmp_versions/\nmodules.order\nModule.symvers\nMkfile.old\ndkms.conf\n\n# debug information files\n*.dwo"}, {"id": "CakePHP.gitignore_0", "file": "CakePHP.gitignore", "content": "================================================\n# CakePHP 3\n\n/vendor/*\n/config/app.php\n\n/tmp/cache/models/*\n!/tmp/cache/models/empty\n/tmp/cache/persistent/*\n!/tmp/cache/persistent/empty\n/tmp/cache/views/*\n!/tmp/cache/views/empty\n/tmp/sessions/*\n!/tmp/sessions/empty\n/tmp/tests/*\n!/tmp/tests/empty\n\n/logs/*\n!/logs/empty\n\n# CakePHP 2\n\n/app/tmp/*\n/app/Config/core.php\n/app/Config/database.php\n/vendors/*"}, {"id": "CFWheels.gitignore_0", "file": "CFWheels.gitignore", "content": "================================================\n# unpacked plugin folders\nplugins/**/*\n\n# files directory where uploads go\nfiles\n\n# DBMigrate plugin: generated SQL\ndb/sql\n\n# AssetBundler plugin: generated bundles\njavascripts/bundles\nstylesheets/bundles"}, {"id": "ChefCookbook.gitignore_0", "file": "ChefCookbook.gitignore", "content": "================================================\n.vagrant\n/cookbooks\n\n# Bundler\nbin/*\n.bundle/*\n\n.kitchen/\n.kitchen.local.yml"}, {"id": "Clojure.gitignore_0", "file": "Clojure.gitignore", "content": "================================================\nLeiningen.gitignore"}, {"id": "CMake.gitignore_0", "file": "CMake.gitignore", "content": "================================================\nCMakeLists.txt.user\nCMakeCache.txt\nCMakeFiles\nCMakeScripts\nTesting\nMakefile\ncmake_install.cmake\ninstall_manifest.txt\ncompile_commands.json\nCTestTestfile.cmake\n_deps\nCMakeUserPresets.json\n\n# CLion\n#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can\n#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore\n#  and can be added to the global gitignore or merged into this file.  For a more nuclear\n#  option (not recommended) you can uncomment the following to ignore the entire idea folder.\n#cmake-build-*"}, {"id": "CodeIgniter.gitignore_0", "file": "CodeIgniter.gitignore", "content": "================================================\n*/config/development\n*/logs/log-*.php\n!*/logs/index.html\n*/cache/*\n!system/cache/*\n!*/cache/index.html\n!*/cache/.htaccess\n\nuser_guide_src/build/*\nuser_guide_src/cilexer/build/*\nuser_guide_src/cilexer/dist/*\nuser_guide_src/cilexer/pycilexer.egg-info/*\n\n#codeigniter 3\napplication/logs/*\n!application/logs/index.html\n!application/logs/.htaccess\n/vendor/"}, {"id": "CommonLisp.gitignore_0", "file": "CommonLisp.gitignore", "content": "================================================\n*.FASL\n*.fasl\n*.lisp-temp\n*.dfsl\n*.pfsl\n*.d64fsl\n*.p64fsl\n*.lx64fsl\n*.lx32fsl\n*.dx64fsl\n*.dx32fsl\n*.fx64fsl\n*.fx32fsl\n*.sx64fsl\n*.sx32fsl\n*.wx64fsl\n*.wx32fsl"}, {"id": "Composer.gitignore_0", "file": "Composer.gitignore", "content": "================================================\ncomposer.phar\n/vendor/\n\n# Commit your application's lock file https://getcomposer.org/doc/01-basic-usage.md#commit-your-composer-lock-file-to-version-control\n# You may choose to ignore a library lock file http://getcomposer.org/doc/02-libraries.md#lock-file\n# composer.lock"}, {"id": "Concrete5.gitignore_0", "file": "Concrete5.gitignore", "content": "================================================\n# ignore the error log and .htaccess and others\nerror_log\n.htaccess\n\n# concrete5 5.6 specific\n\nconfig/site.php\nfiles/cache/*\nfiles/tmp/*\n\n# concrete5 5.7 specific\n\n# ignore everything but the index.html\n/application/files/*\n!/application/files/index.html\n\n# ignore updates folder\n/updates/*\n\n# ignore sitemap.xml\n/sitemap.xml"}, {"id": "CONTRIBUTING.md_0", "file": "CONTRIBUTING.md", "content": "================================================\n# Contributing guidelines\n\nWe\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2d love you to help us improve this project. To help us keep this collection\nhigh quality, we request that contributions adhere to the following guidelines.\n\n- **Provide a link to the application or project\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s homepage**. Unless it\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s\n  extremely popular, there\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s a chance the maintainers don\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2t know about or use\n  the language, framework, editor, app, or project your change applies to.\n\n- **Provide links to documentation** supporting the change you\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2re making.\n  Current, canonical documentation mentioning the files being ignored is best.\n  If documentation isn\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2t available to support your change, do the best you can\n  to explain what the files being ignored are for."}, {"id": "CONTRIBUTING.md_1", "file": "CONTRIBUTING.md", "content": "to explain what the files being ignored are for.\n\n- **Explain why you\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2re making a change**. Even if it seems self-evident, please\n  take a sentence or two to tell us why your change or addition should happen.\n  It\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s especially helpful to articulate why this change applies to *everyone*\n  who works with the applicable technology, rather than just you or your team.\n\n- **Please consider the scope of your change**. If your change specific to a\n  certain language or framework, then make sure the change is made to the\n  template for that language or framework, rather than to the template for an\n  editor, tool, or operating system.\n\n- **Please only modify *one template* per pull request**. This helps keep pull\n  requests and feedback focused on a specific project or technology."}, {"id": "CONTRIBUTING.md_2", "file": "CONTRIBUTING.md", "content": "requests and feedback focused on a specific project or technology.\n\nIn general, the more you can do to help us understand the change you\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2re making,\nthe more likely we\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2ll be to accept your contribution quickly.\n\nIf a template is mostly a list of files installed by a particular version of\nsome software (e.g. a PHP framework) then it's brittle and probably no more\nhelpful than a simple `ls`. If it's not possible to curate a small set of\nuseful rules, then the template might not be a good fit for this collection.\n\nPlease also understand that we can\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2t list every tool that ever existed.\nOur aim is to curate a collection of the *most common and helpful* templates,\nnot to make sure we cover every project possible. If we choose not to"}, {"id": "CONTRIBUTING.md_3", "file": "CONTRIBUTING.md", "content": "not to make sure we cover every project possible. If we choose not to\ninclude your language, tool, or project, it\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s not because it\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s not awesome."}, {"id": "Coq.gitignore_0", "file": "Coq.gitignore", "content": "================================================\n.*.aux\n.*.d\n*.a\n*.cma\n*.cmi\n*.cmo\n*.cmx\n*.cmxa\n*.cmxs\n*.glob\n*.ml.d\n*.ml4.d\n*.mlg.d\n*.mli.d\n*.mllib.d\n*.mlpack.d\n*.native\n*.o\n*.v.d\n*.vio\n*.vo\n*.vok\n*.vos\n.coq-native\n.csdp.cache\n.lia.cache\n.nia.cache\n.nlia.cache\n.nra.cache\ncsdp.cache\nlia.cache\nnia.cache\nnlia.cache\nnra.cache\nnative_compute_profile_*.data\n\n# generated timing files\n*.timing.diff\n*.v.after-timing\n*.v.before-timing\n*.v.timing\ntime-of-build-after.log\ntime-of-build-before.log\ntime-of-build-both.log\ntime-of-build-pretty.log"}, {"id": "CraftCMS.gitignore_0", "file": "CraftCMS.gitignore", "content": "================================================\n# Craft 2 Storage (https://craftcms.com/support/craft-storage-gitignore)\n# not necessary for Craft 3 (https://github.com/craftcms/craft/issues/26)\n/craft/storage/*\n!/craft/storage/rebrand"}, {"id": "CUDA.gitignore_0", "file": "CUDA.gitignore", "content": "================================================\n*.i\n*.ii\n*.gpu\n*.ptx\n*.cubin\n*.fatbin"}, {"id": "D.gitignore_0", "file": "D.gitignore", "content": "================================================\n# Compiled Object files\n*.o\n*.obj\n\n# Compiled Dynamic libraries\n*.so\n*.dylib\n*.dll\n\n# Compiled Static libraries\n*.a\n*.lib\n\n# Executables\n*.exe\n\n# DUB\n.dub\ndocs.json\n__dummy.html\ndocs/\n\n# Code coverage\n*.lst"}, {"id": "Dart.gitignore_0", "file": "Dart.gitignore", "content": "================================================\n# See https://www.dartlang.org/guides/libraries/private-files\n\n# Files and directories created by pub\n.dart_tool/\n.packages\nbuild/\n# If you're building an application, you may want to check-in your pubspec.lock\npubspec.lock\n\n# Directory created by dartdoc\n# If you don't generate documentation locally you can remove this line.\ndoc/api/\n\n# dotenv environment variables file\n.env*\n\n# Avoid committing generated Javascript files:\n*.dart.js\n# Produced by the --dump-info flag.\n*.info.json\n# When generated by dart2js. Don't specify *.js if your\n# project includes source files written in JavaScript.\n*.js\n*.js_\n*.js.deps\n*.js.map\n\n.flutter-plugins\n.flutter-plugins-dependencies"}, {"id": "Delphi.gitignore_0", "file": "Delphi.gitignore", "content": "================================================\n# Uncomment these types if you want even more clean repository. But be careful.\n# It can make harm to an existing project source. Read explanations below.\n#\n# Resource files are binaries containing manifest, project icon and version info.\n# They can not be viewed as text or compared by diff-tools. Consider replacing them with .rc files.\n#*.res\n#\n# Type library file (binary). In old Delphi versions it should be stored.\n# Since Delphi 2009 it is produced from .ridl file and can safely be ignored.\n#*.tlb\n#\n# Diagram Portfolio file. Used by the diagram editor up to Delphi 7.\n# Uncomment this if you are not using diagrams or use newer Delphi version.\n#*.ddp\n#\n# Visual LiveBindings file. Added in Delphi XE2."}, {"id": "Delphi.gitignore_1", "file": "Delphi.gitignore", "content": "#*.ddp\n#\n# Visual LiveBindings file. Added in Delphi XE2.\n# Uncomment this if you are not using LiveBindings Designer.\n#*.vlb\n#\n# Deployment Manager configuration file for your project. Added in Delphi XE2.\n# Uncomment this if it is not mobile development and you do not use remote debug feature.\n#*.deployproj\n#\n# C++ object files produced when C/C++ Output file generation is configured.\n# Uncomment this if you are not using external objects (zlib library for example).\n#*.obj\n#\n\n# Default Delphi compiler directories\n# Content of this directories are generated with each Compile/Construct of a project.\n# Most of the time, files here have not there place in a code repository.\n#Win32/\n#Win64/\n#OSX64/\n#OSXARM64/\n#Android/\n#Android64/\n#iOSDevice64/\n#Linux64/"}, {"id": "Delphi.gitignore_2", "file": "Delphi.gitignore", "content": "#Win32/\n#Win64/\n#OSX64/\n#OSXARM64/\n#Android/\n#Android64/\n#iOSDevice64/\n#Linux64/\n\n# Delphi compiler-generated binaries (safe to delete)\n*.exe\n*.dll\n*.bpl\n*.bpi\n*.dcp\n*.so\n*.apk\n*.drc\n*.map\n*.dres\n*.rsm\n*.tds\n*.dcu\n*.lib\n*.a\n*.o\n*.ocx\n\n# Delphi autogenerated files (duplicated info)\n*.cfg\n*.hpp\n*Resource.rc\n\n# Delphi local files (user-specific info)\n*.local\n*.identcache\n*.projdata\n*.tvsconfig\n*.dsk\n*.dsv\n\n# Delphi history and backups\n__history/\n__recovery/\n*.~*\n\n# Castalia statistics file (since XE7 Castalia is distributed with Delphi)\n*.stat\n\n# Boss dependency manager vendor folder https://github.com/HashLoad/boss\nmodules/"}, {"id": "DM.gitignore_0", "file": "DM.gitignore", "content": "================================================\n*.dmb\n*.rsc\n*.int\n*.lk\n*.zip"}, {"id": "Dotnet.gitignore_0", "file": "Dotnet.gitignore", "content": "================================================\n## A streamlined .gitignore for modern .NET projects\n## including temporary files, build results, and\n## files generated by popular .NET tools. If you are\n## developing with Visual Studio, the VS .gitignore\n## https://github.com/github/gitignore/blob/main/VisualStudio.gitignore\n## has more thorough IDE-specific entries.\n##"}, {"id": "Dotnet.gitignore_1", "file": "Dotnet.gitignore", "content": "## has more thorough IDE-specific entries.\n##\n## Get latest from https://github.com/github/gitignore/blob/main/Dotnet.gitignore\n\n# Build results\n[Dd]ebug/\n[Dd]ebugPublic/\n[Rr]elease/\n[Rr]eleases/\nx64/\nx86/\n[Ww][Ii][Nn]32/\n[Aa][Rr][Mm]/\n[Aa][Rr][Mm]64/\nbld/\n[Bb]in/\n[Oo]bj/\n[Ll]og/\n[Ll]ogs/\n\n# .NET Core\nproject.lock.json\nproject.fragment.lock.json\nartifacts/\n\n# ASP.NET Scaffolding\nScaffoldingReadMe.txt\n\n# NuGet Packages\n*.nupkg\n# NuGet Symbol Packages\n*.snupkg\n\n# Others\n~$*\n*~\nCodeCoverage/\n\n# MSBuild Binary and Structured Log\n*.binlog\n\n# MSTest test Results\n[Tt]est[Rr]esult*/\n[Bb]uild[Ll]og.*\n\n# NUnit\n*.VisualState.xml\nTestResult.xml\nnunit-*.xml"}, {"id": "Drupal.gitignore_0", "file": "Drupal.gitignore", "content": "================================================\n# gitignore template for Drupal 8 projects\n#\n# earlier versions of Drupal are tracked in `community/PHP/`\n#\n# follows official upstream conventions:\n# https://www.drupal.org/docs/develop/using-composer\n\n# Ignore configuration files that may contain sensitive information\n/web/sites/*/*settings*.php\n/web/sites/*/*services*.yml\n\n# Ignore paths that may contain user-generated content\n/web/sites/*/files\n/web/sites/*/public\n/web/sites/*/private\n/web/sites/*/files-public\n/web/sites/*/files-private\n\n# Ignore paths that may contain temporary files\n/web/sites/*/translations\n/web/sites/*/tmp\n/web/sites/*/cache\n\n# Ignore drupal core (if not versioning drupal sources)\n/web/vendor\n/web/core\n/web/modules/README.txt\n/web/modules/contrib"}, {"id": "Drupal.gitignore_1", "file": "Drupal.gitignore", "content": "/web/vendor\n/web/core\n/web/modules/README.txt\n/web/modules/contrib\n/web/profiles/README.txt\n/web/profiles/contrib\n/web/sites/development.services.yml\n/web/sites/example.settings.local.php\n/web/sites/example.sites.php\n/web/sites/README.txt\n/web/themes/README.txt\n/web/themes/contrib\n/web/.csslintrc\n/web/.editorconfig\n/web/.eslintignore\n/web/.eslintrc.json\n/web/.gitattributes\n/web/.htaccess\n/web/.ht.router.php\n/web/autoload.php\n/web/composer.json\n/web/composer.lock\n/web/example.gitignore\n/web/index.php\n/web/INSTALL.txt\n/web/LICENSE.txt\n/web/README.txt\n/web/robots.txt\n/web/update.php\n/web/web.config\n\n# Ignore vendor dependencies and scripts\n/vendor\n/composer.phar\n/composer\n/robo.phar\n/robo\n/drush.phar\n/drush\n/drupal.phar\n/drupal"}, {"id": "Eagle.gitignore_0", "file": "Eagle.gitignore", "content": "================================================\n# Ignore list for Eagle, a PCB layout tool\n\n# Backup files\n*.s#?\n*.b#?\n*.l#?\n*.b$?\n*.s$?\n*.l$?\n\n# Eagle project file\n# It contains a serial number and references to the file structure\n# on your computer.\n# comment the following line if you want to have your project file included.\neagle.epf\n\n# Autorouter files\n*.pro\n*.job\n\n# CAM files\n*.$$$\n*.cmp\n*.ly2\n*.l15\n*.sol\n*.plc\n*.stc\n*.sts\n*.crc\n*.crs\n\n*.dri\n*.drl\n*.gpi\n*.pls\n*.ger\n*.xln\n\n*.drd\n*.drd.*\n\n*.s#*\n*.b#*\n\n*.info\n\n*.eps\n\n# file locks introduced since 7.x\n*.lck"}, {"id": "ecu.test.gitignore_0", "file": "ecu.test.gitignore", "content": "================================================\n# gitignore template for ecu.test workspaces - by tracetronic https://tracetronic.com\n# website: https://www.ecu-test.com\n#   * all directories are related to the default directories, please adapt the .gitignore if you use customized directories\n\n# Dynamic workspace settings\n#   * We don't recommend to ignore the .workspace directory, because of important\n#     * project specific settings\n#     * local user settings\n.workspace/ETdrive.xml\n.workspace/favorites.xml\n.workspace/filters.xml\n.workspace/generators.xml\n.workspace/history.xml\n.workspace/parallelExecution.xml\n.workspace/signalviewer.xml\n.workspace/signalViewerHistory.json\n.workspace/signalviewer2layout.xml\n.workspace/testeditor.xml\n.workspace/tooladapter.xml\n.workspace/view.xml"}, {"id": "ecu.test.gitignore_1", "file": "ecu.test.gitignore", "content": ".workspace/testeditor.xml\n.workspace/tooladapter.xml\n.workspace/view.xml\n# optional, if your process depends on this file remove exclusion\n.workspace/attributeLists.xml\n.workspace/interactiveexecution.xml\n.workspace/protocol.xml\n.workspace/pythonlibrary.xml\n# deprecated, support for older versions\n.workspace/traceexplorer.xml\n\n# Custom file formats and test dependencies\n#  * you can manage your artifacts also with test.guide (https://www.test-guide.info) and reference them via Playbooks\n*.arxml\n*.a2l\n*.dbc\n*.hex\n*.s19\n[tT]estdata\n[tT]estdaten\n\n# Test results and test execution related content\n#   * Git is not intended to store and provide test results for all iterations\n#   * We recommend to use test.guide (https://www.test-guide.info) for the test report management\nTestReports"}, {"id": "ecu.test.gitignore_2", "file": "ecu.test.gitignore", "content": "TestReports\n\n# Report generators and templates\n#   * if you want to provide (f.e.) your own report generators exclude the directory here and ignore only the unnecessary subdirectories\nTemplates\n\n# optional, default for external Python libraries\nPyLibs\n\n# Exclude large binary artifacts\n#  * you can manage your artifacts also with test.guide (https://www.test-guide.info) and reference them via Playbooks\nOffline-FIUs\nOffline-Models\nOffline-SGBDs\n*.exe\n*.msi\n*.zip\n*.7z\n\n# Exclude default and custom temporary directories\nBackup_*\n\n# Python bytecode and cache files\n__pycache__/\n*.py[cod]"}, {"id": "Elisp.gitignore_0", "file": "Elisp.gitignore", "content": "================================================\n# Compiled\n*.elc\n\n# Packaging\n.cask/\n.eask/\n.eldev/\n.keg/\n\n# Built distribution\ndist/\n\n# Backup files\n*~\n\n# Undo-tree save-files\n*.~undo-tree"}, {"id": "Elixir.gitignore_0", "file": "Elixir.gitignore", "content": "================================================\n/_build\n/cover\n/deps\n/doc\n/.fetch\nerl_crash.dump\n*.ez\n*.beam\n/config/*.secret.exs\n.elixir_ls/"}, {"id": "Elm.gitignore_0", "file": "Elm.gitignore", "content": "================================================\n# elm-package generated files\nelm-stuff\n# elm-repl generated files\nrepl-temp-*"}, {"id": "EPiServer.gitignore_0", "file": "EPiServer.gitignore", "content": "================================================\n######################\n## EPiServer Files\n######################\n*License.config"}, {"id": "Erlang.gitignore_0", "file": "Erlang.gitignore", "content": "================================================\n.eunit\n*.o\n*.beam\n*.plt\nerl_crash.dump\n.concrete/DEV_MODE\n\n# rebar 2.x\n.rebar\nrel/example_project\nebin/*.beam\ndeps\n\n# rebar 3\n.rebar3\n_build/\n_checkouts/"}, {"id": "ExpressionEngine.gitignore_0", "file": "ExpressionEngine.gitignore", "content": "================================================\n.DS_Store\n\n# Images\nimages/avatars/\nimages/captchas/\nimages/smileys/\nimages/member_photos/\nimages/signature_attachments/\nimages/pm_attachments/\n\n# For security do not publish the following files\nsystem/expressionengine/config/database.php\nsystem/expressionengine/config/config.php\n\n# Caches\nsized/\nthumbs/\n_thumbs/\n*/expressionengine/cache/*"}, {"id": "ExtJs.gitignore_0", "file": "ExtJs.gitignore", "content": "================================================\n.architect\nbootstrap.css\nbootstrap.js\nbootstrap.json\nbootstrap.jsonp\nbuild/\nclassic.json\nclassic.jsonp\next/\nmodern.json\nmodern.jsonp\nresources/sass/.sass-cache/\nresources/.arch-internal-preview.css\n.arch-internal-preview.css"}, {"id": "Fancy.gitignore_0", "file": "Fancy.gitignore", "content": "================================================\n*.rbc\n*.fyc"}, {"id": "Finale.gitignore_0", "file": "Finale.gitignore", "content": "================================================\n*.bak\n*.db\n*.avi\n*.pdf\n*.ps\n*.mid\n*.midi\n*.mp3\n*.aif\n*.wav\n# Some versions of Finale have a bug and randomly save extra copies of\n# the music source as \"<Filename> copy.mus\"\n*copy.mus"}, {"id": "Firebase.gitignore_0", "file": "Firebase.gitignore", "content": "================================================\n# Firebase build and deployment files\n/firebase-debug.log\n/firebase-debug.*.log\n.firebaserc\n\n# Firebase Hosting\n/firebase.json\n*.cache\nhosting/.cache\n\n# Firebase Functions\n/functions/node_modules/\n/functions/.env\n/functions/package-lock.json\n\n# Firebase Emulators\n/firebase-*.zip\n/.firebase/\n/emulator-ui/\n\n# Logs\n*.log\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\n\n# Environment files (local configs)\n/.env.*"}, {"id": "FlaxEngine.gitignore_0", "file": "FlaxEngine.gitignore", "content": "================================================\n# Ignore Flax project files\nBinaries/\nCache/\nLogs/\nOutput/\nScreenshots/\n*.HotReload.*\n\n# Ignore Visual Studio project files (generated locally)\n*.csproj\n*.sln\n\n# Ignore thumbnails created by Windows\nThumbs.db\n\n# Ignore files built by Visual Studio\n*.obj\n*.exe\n*.pdb\n*.user\n*.aps\n*.pch\n*.vspscc\n*_i.c\n*_p.c\n*.ncb\n*.suo\n*.tlb\n*.tlh\n*.bak\n*.cache\n*.ilk\n*.log\n[Bb]in\n[Dd]ebug*/\n*.lib\n*.sbr\nobj/\n[Rr]elease*/\n_ReSharper*/\n[Tt]est[Rr]esult*\n.vs/\n\n# Ignore Nuget packages folder\npackages/"}, {"id": "Flutter.gitignore_0", "file": "Flutter.gitignore", "content": "================================================\n# Miscellaneous\n*.class\n*.lock\n*.log\n*.pyc\n*.swp\n.buildlog/\n.history\n\n\n\n# Flutter repo-specific\n/bin/cache/\n/bin/internal/bootstrap.bat\n/bin/internal/bootstrap.sh\n/bin/mingit/\n/dev/benchmarks/mega_gallery/\n/dev/bots/.recipe_deps\n/dev/bots/android_tools/\n/dev/devicelab/ABresults*.json\n/dev/docs/doc/\n/dev/docs/flutter.docs.zip\n/dev/docs/lib/\n/dev/docs/pubspec.yaml\n/dev/integration_tests/**/xcuserdata\n/dev/integration_tests/**/Pods\n/packages/flutter/coverage/\nversion\nanalysis_benchmark.json\n\n# packages file containing multi-root paths\n.packages.generated\n\n# Flutter/Dart/Pub related\n**/doc/api/\n.dart_tool/\n.flutter-plugins\n.flutter-plugins-dependencies\n**/generated_plugin_registrant.dart\n.packages\n.pub-preload-cache/\n.pub/\nbuild/\nflutter_*.png"}, {"id": "Flutter.gitignore_1", "file": "Flutter.gitignore", "content": "**/generated_plugin_registrant.dart\n.packages\n.pub-preload-cache/\n.pub/\nbuild/\nflutter_*.png\nlinked_*.ds\nunlinked.ds\nunlinked_spec.ds\n\n# Android related\n**/android/**/gradle-wrapper.jar\n.gradle/\n**/android/captures/\n**/android/gradlew\n**/android/gradlew.bat\n**/android/local.properties\n**/android/**/GeneratedPluginRegistrant.java\n**/android/key.properties\n*.jks\n\n# iOS/XCode related\n**/ios/**/*.mode1v3\n**/ios/**/*.mode2v3\n**/ios/**/*.moved-aside\n**/ios/**/*.pbxuser\n**/ios/**/*.perspectivev3\n**/ios/**/*sync/\n**/ios/**/.sconsign.dblite\n**/ios/**/.tags*\n**/ios/**/.vagrant/\n**/ios/**/DerivedData/\n**/ios/**/Icon?\n**/ios/**/Pods/\n**/ios/**/.symlinks/\n**/ios/**/profile\n**/ios/**/xcuserdata\n**/ios/.generated/\n**/ios/Flutter/.last_build_id\n**/ios/Flutter/App.framework"}, {"id": "Flutter.gitignore_2", "file": "Flutter.gitignore", "content": "**/ios/**/xcuserdata\n**/ios/.generated/\n**/ios/Flutter/.last_build_id\n**/ios/Flutter/App.framework\n**/ios/Flutter/Flutter.framework\n**/ios/Flutter/Flutter.podspec\n**/ios/Flutter/Generated.xcconfig\n**/ios/Flutter/ephemeral\n**/ios/Flutter/app.flx\n**/ios/Flutter/app.zip\n**/ios/Flutter/flutter_assets/\n**/ios/Flutter/flutter_export_environment.sh\n**/ios/ServiceDefinitions.json\n**/ios/Runner/GeneratedPluginRegistrant.*\n\n# macOS\n**/Flutter/ephemeral/\n**/Pods/\n**/macos/Flutter/GeneratedPluginRegistrant.swift\n**/macos/Flutter/ephemeral\n**/xcuserdata/\n\n# Windows\n**/windows/flutter/generated_plugin_registrant.cc\n**/windows/flutter/generated_plugin_registrant.h\n**/windows/flutter/generated_plugins.cmake\n\n# Linux\n**/linux/flutter/generated_plugin_registrant.cc"}, {"id": "Flutter.gitignore_3", "file": "Flutter.gitignore", "content": "**/windows/flutter/generated_plugins.cmake\n\n# Linux\n**/linux/flutter/generated_plugin_registrant.cc\n**/linux/flutter/generated_plugin_registrant.h\n**/linux/flutter/generated_plugins.cmake\n\n# Coverage\ncoverage/\n\n# Symbols\napp.*.symbols\n\n# Exceptions to above rules.\n!**/ios/**/default.mode1v3\n!**/ios/**/default.mode2v3\n!**/ios/**/default.pbxuser\n!**/ios/**/default.perspectivev3\n!/packages/flutter_tools/test/data/dart_dependencies_test/**/.packages\n!/dev/ci/**/Gemfile.lock"}, {"id": "ForceDotCom.gitignore_0", "file": "ForceDotCom.gitignore", "content": "================================================\n.project\n.settings\nsalesforce.schema\nReferenced Packages"}, {"id": "Fortran.gitignore_0", "file": "Fortran.gitignore", "content": "================================================\nC++.gitignore"}, {"id": "FuelPHP.gitignore_0", "file": "FuelPHP.gitignore", "content": "================================================\n# the composer package lock file and install directory\n# Commit your application's lock file http://getcomposer.org/doc/01-basic-usage.md#composer-lock-the-lock-file\n# You may choose to ignore a library lock file http://getcomposer.org/doc/02-libraries.md#lock-file\n# /composer.lock\n/fuel/vendor\n\n# the fuelphp document\n/docs/\n\n# you may install these packages with `oil package`.\n# http://fuelphp.com/docs/packages/oil/package.html\n# /fuel/packages/auth/\n# /fuel/packages/email/\n# /fuel/packages/oil/\n# /fuel/packages/orm/\n# /fuel/packages/parser/\n\n# dynamically generated files\n/fuel/app/logs/*/*/*\n/fuel/app/cache/*/*\n/fuel/app/config/crypt.php"}, {"id": "Gcov.gitignore_0", "file": "Gcov.gitignore", "content": "================================================\n# gcc coverage testing tool files\n\n*.gcno\n*.gcda\n*.gcov"}, {"id": "GitBook.gitignore_0", "file": "GitBook.gitignore", "content": "================================================\n# Node rules:\n## Grunt intermediate storage (http://gruntjs.com/creating-plugins#storing-task-files)\n.grunt\n\n## Dependency directory\n## Commenting this out is preferred by some people, see\n## https://docs.npmjs.com/misc/faq#should-i-check-my-node_modules-folder-into-git\nnode_modules\n\n# Book build output\n_book\n\n# eBook build output\n*.epub\n*.mobi\n*.pdf"}, {"id": "GitHubPages.gitignore_0", "file": "GitHubPages.gitignore", "content": "================================================\n# This .gitignore is appropriate for repositories deployed to GitHub Pages and using\n# a Gemfile as specified at https://github.com/github/pages-gem#conventional\n\n# Basic Jekyll gitignores (synchronize to Jekyll.gitignore)\n_site/\n.sass-cache/\n.jekyll-cache/\n.jekyll-metadata\n\n# Additional Ruby/bundler ignore for when you run: bundle install\n/vendor\n\n# Specific ignore for GitHub Pages\n# GitHub Pages will always use its own deployed version of pages-gem\n# This means GitHub Pages will NOT use your Gemfile.lock and therefore it is\n# counterproductive to check this file into the repository.\n# Details at https://github.com/github/pages-gem/issues/768\nGemfile.lock"}, {"id": "Gleam.gitignore_0", "file": "Gleam.gitignore", "content": "================================================\n*.beam\n*.ez\n/build\nerl_crash.dump"}, {"id": "Go.gitignore_0", "file": "Go.gitignore", "content": "================================================\n# If you prefer the allow list template instead of the deny list, see community template:\n# https://github.com/github/gitignore/blob/main/community/Golang/Go.AllowList.gitignore\n#\n# Binaries for programs and plugins\n*.exe\n*.exe~\n*.dll\n*.so\n*.dylib\n\n# Test binary, built with `go test -c`\n*.test\n\n# Code coverage profiles and other test artifacts\n*.out\ncoverage.*\n*.coverprofile\nprofile.cov\n\n# Dependency directories (remove the comment below to include it)\n# vendor/\n\n# Go workspace file\ngo.work\ngo.work.sum\n\n# env file\n.env\n\n# Editor/IDE\n# .idea/\n# .vscode/"}, {"id": "Godot.gitignore_0", "file": "Godot.gitignore", "content": "================================================\n# Godot 4+ specific ignores\n.godot/\n.nomedia\n\n# Godot-specific ignores\n.import/\nexport.cfg\nexport_credentials.cfg\n*.tmp\n\n# Imported translations (automatically generated from CSV files)\n*.translation\n\n# Mono-specific ignores\n.mono/\ndata_*/\nmono_crash.*.json"}, {"id": "Gradle.gitignore_0", "file": "Gradle.gitignore", "content": "================================================\n.gradle\n**/build/\n!**/src/**/build/\n\n# Ignore Gradle GUI config\ngradle-app.setting\n\n# Avoid ignoring Gradle wrapper jar file (.jar files are usually ignored)\n!gradle-wrapper.jar\n\n# Avoid ignore Gradle wrappper properties\n!gradle-wrapper.properties\n\n# Cache of project\n.gradletasknamecache\n\n# Eclipse Gradle plugin generated files\n# Eclipse Core\n.project\n# JDT-specific (Eclipse Java Development Tools)\n.classpath"}, {"id": "Grails.gitignore_0", "file": "Grails.gitignore", "content": "================================================\n# .gitignore for Grails 1.2 and 1.3\n# Although this should work for most versions of grails, it is\n# suggested that you use the \"grails integrate-with --git\" command\n# to generate your .gitignore file.\n\n# web application files\n/web-app/WEB-INF/classes\n\n# default HSQL database files for production mode\n/prodDb.*\n\n# general HSQL database files\n*Db.properties\n*Db.script\n\n# logs\n/stacktrace.log\n/test/reports\n/logs\n\n# project release file\n/*.war\n\n# plugin release files\n/*.zip\n/plugin.xml\n\n# older plugin install locations\n/plugins\n/web-app/plugins\n\n# \"temporary\" build files\n/target"}, {"id": "GWT.gitignore_0", "file": "GWT.gitignore", "content": "================================================\n*.class\n\n# Package Files #\n*.jar\n*.war\n\n# gwt caches and compiled units #\nwar/gwt_bree/\ngwt-unitCache/\n\n# boilerplate generated classes #\n.apt_generated/\n\n# more caches and things from deploy #\nwar/WEB-INF/deploy/\nwar/WEB-INF/classes/\n\n#compilation logs\n.gwt/\n\n#gwt junit compilation files\nwww-test/\n\n#old GWT (1.5) created this dir\n.gwt-tmp/"}, {"id": "Haskell.gitignore_0", "file": "Haskell.gitignore", "content": "================================================\ndist\ndist-*\ncabal-dev\n*.o\n*.hi\n*.hie\n*.chi\n*.chs.h\n*.dyn_o\n*.dyn_hi\n.hpc\n.hsenv\n.cabal-sandbox/\ncabal.sandbox.config\n*.prof\n*.aux\n*.hp\n*.eventlog\n.stack-work/\ncabal.project.local\ncabal.project.local~\n.HTF/\n.ghc.environment.*"}, {"id": "Haxe.gitignore_0", "file": "Haxe.gitignore", "content": "================================================\n.haxelib/\n.haxelsp/recording/\ndump/"}, {"id": "HIP.gitignore_0", "file": "HIP.gitignore", "content": "================================================\n# HIP.gitignore\n# GitHub gitignore template for AMD HIP (ROCm) projects\n#\n# Reference:\n#   Official AMD ROCm HIP .gitignore: https://github.com/ROCm/hip/blob/amd-staging/.gitignore\n\n# 1. Build directories and files\n/build/                          # common build directory\n/CMakeFiles/                     # CMake internal files\n/CMakeCache.txt                  # CMake cache file\n/Makefile                        # autogenerated Makefile\n/cmake_install.cmake             # install script\n/install_manifest.txt            # install manifest list\n*.ninja-dep                      # Ninja dependency files\n*.ninja_log                      # Ninja log files\nmeson-logs/                      # Meson log directory"}, {"id": "HIP.gitignore_1", "file": "HIP.gitignore", "content": "meson-logs/                      # Meson log directory\n\n# 2. Compilation outputs and intermediates\n*.o                              # object files\n*.obj                            # Windows object files\n*.so                             # shared libraries\n*.a                              # static librarie\n*.d                              # dependency files\n*.gch                            # precompiled headers\n*.ii                             # preprocessed output\n*.ii.cpp                         # C++ preprocessed output\n*.out                            # generic executable outputs\n*.exe                            # Windows executables\n\n# 3. HIP/ROCm specific binaries and intermediates\n*.hsaco                          # ROCm compiled binary"}, {"id": "HIP.gitignore_2", "file": "HIP.gitignore", "content": "*.hsaco                          # ROCm compiled binary\n*.s                              # assembly output\n*.kernels.cpp                    # autogenerated kernel sources\n*.hip.cpp.*                      # hipcc intermediate outputs\n\n# 4. Official sample binaries and tutorial outputs\nbin/hipInfo                      # sample binary\nbin/hipBusBandwidth              # sample binary\nbin/hipDispatchLatency           # sample binary\nbin/hipify-clang                 # sample tool\nsamples/**/*.out                 # tutorial outputs\nsamples/**/*.code                # ISA/code dumps\nsamples/**/*.hsaco               # compiled binaries\nsamples/**/*.co                  # kernel code outputs\n\n# 5. Tags, logs and test outputs\ntags                             # ctags index"}, {"id": "HIP.gitignore_3", "file": "HIP.gitignore", "content": "# 5. Tags, logs and test outputs\ntags                             # ctags index\n*.log                            # log files\n/tests_output/                   # custom test output directory\n/samples_output/                 # custom sample output directory"}, {"id": "IAR.gitignore_0", "file": "IAR.gitignore", "content": "================================================\n# Compiled binaries\n*.o\n*.bin\n*.elf\n*.hex\n*.map\n*.out\n*.obj\n\n# Trash\n*.bak\nthumbs.db\n*.~*\n\n# IAR Settings\n**/settings/*.crun\n**/settings/*.dbgdt\n**/settings/*.cspy\n**/settings/*.cspy.*\n**/settings/*.xcl\n**/settings/*.dni\n**/settings/*.wsdt\n**/settings/*.wspos\n\n# IAR Debug Exe\n**/Exe/*.sim\n\n# IAR Debug Obj\n**/Obj/*.pbd\n**/Obj/*.pbd.*\n**/Obj/*.pbi\n**/Obj/*.pbi.*\n\n# IAR project \"Debug\" directory\nDebug/\n\n# IAR project \"Release\" directory\nRelease/\n\n# IAR project settings directory\nsettings/\n\n# IAR backup files\nBackup*\n\n# IAR .dep files\n*.dep"}, {"id": "Idris.gitignore_0", "file": "Idris.gitignore", "content": "================================================\n# Idris 2\n*.ttc\n*.ttm\n\n# Idris 1\n*.ibc\n*.o"}, {"id": "IGORPro.gitignore_0", "file": "IGORPro.gitignore", "content": "================================================\n# Avoid including Experiment files: they can be created and edited locally to test the ipf files\n*.pxp\n*.pxt\n*.uxp\n*.uxt"}, {"id": "Java.gitignore_0", "file": "Java.gitignore", "content": "================================================\n# Compiled class file\n*.class\n\n# Log file\n*.log\n\n# BlueJ files\n*.ctxt\n\n# Mobile Tools for Java (J2ME)\n.mtj.tmp/\n\n# Package Files #\n*.jar\n*.war\n*.nar\n*.ear\n*.zip\n*.tar.gz\n*.rar\n\n# virtual machine crash logs, see http://www.java.com/en/download/help/error_hotspot.xml\nhs_err_pid*\nreplay_pid*"}, {"id": "JBoss.gitignore_0", "file": "JBoss.gitignore", "content": "================================================\njboss/server/all/deploy/project.ext\njboss/server/default/deploy/project.ext\njboss/server/minimal/deploy/project.ext\njboss/server/all/log/*.log\njboss/server/all/tmp/**/*\njboss/server/all/data/**/*\njboss/server/all/work/**/*\njboss/server/default/log/*.log\njboss/server/default/tmp/**/*\njboss/server/default/data/**/*\njboss/server/default/work/**/*\njboss/server/minimal/log/*.log\njboss/server/minimal/tmp/**/*\njboss/server/minimal/data/**/*\njboss/server/minimal/work/**/*\n\n# deployed package files #\n\n*.DEPLOYED"}, {"id": "Jekyll.gitignore_0", "file": "Jekyll.gitignore", "content": "================================================\n_site/\n.sass-cache/\n.jekyll-cache/\n.jekyll-metadata\n# Ignore folders generated by Bundler\n.bundle/\nvendor/"}, {"id": "JENKINS_HOME.gitignore_0", "file": "JENKINS_HOME.gitignore", "content": "================================================\n# Learn more about Jenkins and JENKINS_HOME directory for which this file is\n# intended.\n#\n#  http://jenkins-ci.org/\n#  https://wiki.jenkins-ci.org/display/JENKINS/Administering+Jenkins\n#\n# Note: secret.key is purposefully not tracked by git. This should be backed up\n# separately because configs may contain secrets which were encrypted using the\n# secret.key.  To back up secrets use 'tar -czf /tmp/secrets.tgz secret*' and\n# save the file separate from your repository.  If you want secrets backed up\n# with configuration, then see the bottom of this file for an example.\n\n# Ignore all JENKINS_HOME except jobs directory, root xml config, and\n# .gitignore file.\n/*\n!/jobs\n!/.gitignore\n!/*.xml"}, {"id": "JENKINS_HOME.gitignore_1", "file": "JENKINS_HOME.gitignore", "content": "# .gitignore file.\n/*\n!/jobs\n!/.gitignore\n!/*.xml\n\n# Ignore all files in jobs subdirectories except for folders.\n# Note: git doesn't track folders, only file content.\njobs/**\n!jobs/**/\n\n# Uncomment the following line to save next build numbers with config.\n\n#!jobs/**/nextBuildNumber\n\n# For performance reasons, we want to ignore builds in Jenkins jobs because it\n# contains many tiny files on large installations.  This can impact git\n# performance when running even basic commands like 'git status'.\nbuilds\nindexing\n\n# Exclude only config.xml files in repository subdirectories.\n!config.xml\n\n# Don't track workspaces (when users build on the master).\njobs/**/*workspace\n\n# Security warning: If secrets are included with your configuration, then an"}, {"id": "JENKINS_HOME.gitignore_2", "file": "JENKINS_HOME.gitignore", "content": "jobs/**/*workspace\n\n# Security warning: If secrets are included with your configuration, then an\n# adversary will be able to decrypt all encrypted secrets within Jenkins\n# config.  Including secrets is a bad practice, but the example is included in\n# case someone still wants it for convenience.  Uncomment the following line to\n# include secrets for decryption with repository configuration in Git.\n\n#!/secret*\n\n# As a result, only Jenkins settings and job config.xml files in JENKINS_HOME\n# will be tracked by git."}, {"id": "Joomla.gitignore_0", "file": "Joomla.gitignore", "content": "================================================\n/.htaccess\n/administrator/cache/*\n/administrator/components/com_actionlogs/*\n/administrator/components/com_admin/*\n/administrator/components/com_ajax/*\n/administrator/components/com_associations/*\n/administrator/components/com_banners/*\n/administrator/components/com_cache/*\n/administrator/components/com_categories/*\n/administrator/components/com_checkin/*\n/administrator/components/com_config/*\n/administrator/components/com_contact/*\n/administrator/components/com_content/*\n/administrator/components/com_contenthistory/*\n/administrator/components/com_cpanel/*\n/administrator/components/com_fields/*\n/administrator/components/com_finder/*\n/administrator/components/com_installer/*\n/administrator/components/com_joomlaupdate/*"}, {"id": "Joomla.gitignore_1", "file": "Joomla.gitignore", "content": "/administrator/components/com_installer/*\n/administrator/components/com_joomlaupdate/*\n/administrator/components/com_languages/*\n/administrator/components/com_login/*\n/administrator/components/com_media/*\n/administrator/components/com_menus/*\n/administrator/components/com_messages/*\n/administrator/components/com_modules/*\n/administrator/components/com_newsfeeds/*\n/administrator/components/com_plugins/*\n/administrator/components/com_postinstall/*\n/administrator/components/com_privacy/*\n/administrator/components/com_redirect/*\n/administrator/components/com_search/*\n/administrator/components/com_tags/*\n/administrator/components/com_templates/*\n/administrator/components/com_users/*\n/administrator/help/*\n/administrator/includes/*\n/administrator/index.php"}, {"id": "Joomla.gitignore_2", "file": "Joomla.gitignore", "content": "/administrator/help/*\n/administrator/includes/*\n/administrator/index.php\n/administrator/language/en-GB/en-GB.com_actionlogs.ini\n/administrator/language/en-GB/en-GB.com_actionlogs.sys.ini\n/administrator/language/en-GB/en-GB.com_admin.ini\n/administrator/language/en-GB/en-GB.com_admin.sys.ini\n/administrator/language/en-GB/en-GB.com_ajax.ini\n/administrator/language/en-GB/en-GB.com_ajax.sys.ini\n/administrator/language/en-GB/en-GB.com_associations.ini\n/administrator/language/en-GB/en-GB.com_associations.sys.ini\n/administrator/language/en-GB/en-GB.com_banners.ini\n/administrator/language/en-GB/en-GB.com_banners.sys.ini\n/administrator/language/en-GB/en-GB.com_cache.ini\n/administrator/language/en-GB/en-GB.com_cache.sys.ini\n/administrator/language/en-GB/en-GB.com_categories.ini"}, {"id": "Joomla.gitignore_3", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.com_categories.ini\n/administrator/language/en-GB/en-GB.com_categories.sys.ini\n/administrator/language/en-GB/en-GB.com_checkin.ini\n/administrator/language/en-GB/en-GB.com_checkin.sys.ini\n/administrator/language/en-GB/en-GB.com_config.ini\n/administrator/language/en-GB/en-GB.com_config.sys.ini\n/administrator/language/en-GB/en-GB.com_contact.ini\n/administrator/language/en-GB/en-GB.com_contact.sys.ini\n/administrator/language/en-GB/en-GB.com_content.ini\n/administrator/language/en-GB/en-GB.com_content.sys.ini\n/administrator/language/en-GB/en-GB.com_contenthistory.ini\n/administrator/language/en-GB/en-GB.com_contenthistory.sys.ini\n/administrator/language/en-GB/en-GB.com_cpanel.ini\n/administrator/language/en-GB/en-GB.com_cpanel.sys.ini"}, {"id": "Joomla.gitignore_4", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.com_cpanel.sys.ini\n/administrator/language/en-GB/en-GB.com_fields.ini\n/administrator/language/en-GB/en-GB.com_fields.sys.ini\n/administrator/language/en-GB/en-GB.com_finder.ini\n/administrator/language/en-GB/en-GB.com_finder.sys.ini\n/administrator/language/en-GB/en-GB.com_installer.ini\n/administrator/language/en-GB/en-GB.com_installer.sys.ini\n/administrator/language/en-GB/en-GB.com_joomlaupdate.ini\n/administrator/language/en-GB/en-GB.com_joomlaupdate.sys.ini\n/administrator/language/en-GB/en-GB.com_languages.ini\n/administrator/language/en-GB/en-GB.com_languages.sys.ini\n/administrator/language/en-GB/en-GB.com_login.ini\n/administrator/language/en-GB/en-GB.com_login.sys.ini\n/administrator/language/en-GB/en-GB.com_mailto.sys.ini"}, {"id": "Joomla.gitignore_5", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.com_mailto.sys.ini\n/administrator/language/en-GB/en-GB.com_media.ini\n/administrator/language/en-GB/en-GB.com_media.sys.ini\n/administrator/language/en-GB/en-GB.com_menus.ini\n/administrator/language/en-GB/en-GB.com_menus.sys.ini\n/administrator/language/en-GB/en-GB.com_messages.ini\n/administrator/language/en-GB/en-GB.com_messages.sys.ini\n/administrator/language/en-GB/en-GB.com_modules.ini\n/administrator/language/en-GB/en-GB.com_modules.sys.ini\n/administrator/language/en-GB/en-GB.com_newsfeeds.ini\n/administrator/language/en-GB/en-GB.com_newsfeeds.sys.ini\n/administrator/language/en-GB/en-GB.com_plugins.ini\n/administrator/language/en-GB/en-GB.com_plugins.sys.ini\n/administrator/language/en-GB/en-GB.com_postinstall.ini"}, {"id": "Joomla.gitignore_6", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.com_postinstall.ini\n/administrator/language/en-GB/en-GB.com_postinstall.sys.ini\n/administrator/language/en-GB/en-GB.com_privacy.ini\n/administrator/language/en-GB/en-GB.com_privacy.sys.ini\n/administrator/language/en-GB/en-GB.com_redirect.ini\n/administrator/language/en-GB/en-GB.com_redirect.sys.ini\n/administrator/language/en-GB/en-GB.com_search.ini\n/administrator/language/en-GB/en-GB.com_search.sys.ini\n/administrator/language/en-GB/en-GB.com_tags.ini\n/administrator/language/en-GB/en-GB.com_tags.sys.ini\n/administrator/language/en-GB/en-GB.com_templates.ini\n/administrator/language/en-GB/en-GB.com_templates.sys.ini\n/administrator/language/en-GB/en-GB.com_users.ini\n/administrator/language/en-GB/en-GB.com_users.sys.ini"}, {"id": "Joomla.gitignore_7", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.com_users.sys.ini\n/administrator/language/en-GB/en-GB.com_weblinks.ini\n/administrator/language/en-GB/en-GB.com_weblinks.sys.ini\n/administrator/language/en-GB/en-GB.com_wrapper.ini\n/administrator/language/en-GB/en-GB.com_wrapper.sys.ini\n/administrator/language/en-GB/en-GB.ini\n/administrator/language/en-GB/en-GB.lib_joomla.ini\n/administrator/language/en-GB/en-GB.localise.php\n/administrator/language/en-GB/en-GB.mod_custom.ini\n/administrator/language/en-GB/en-GB.mod_custom.sys.ini\n/administrator/language/en-GB/en-GB.mod_feed.ini\n/administrator/language/en-GB/en-GB.mod_feed.sys.ini\n/administrator/language/en-GB/en-GB.mod_latest.ini\n/administrator/language/en-GB/en-GB.mod_latest.sys.ini\n/administrator/language/en-GB/en-GB.mod_latestactions.ini"}, {"id": "Joomla.gitignore_8", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.mod_latestactions.ini\n/administrator/language/en-GB/en-GB.mod_latestactions.sys.ini\n/administrator/language/en-GB/en-GB.mod_logged.ini\n/administrator/language/en-GB/en-GB.mod_logged.sys.ini\n/administrator/language/en-GB/en-GB.mod_login.ini\n/administrator/language/en-GB/en-GB.mod_login.sys.ini\n/administrator/language/en-GB/en-GB.mod_menu.ini\n/administrator/language/en-GB/en-GB.mod_menu.sys.ini\n/administrator/language/en-GB/en-GB.mod_multilangstatus.ini\n/administrator/language/en-GB/en-GB.mod_multilangstatus.sys.ini\n/administrator/language/en-GB/en-GB.mod_online.ini\n/administrator/language/en-GB/en-GB.mod_online.sys.ini\n/administrator/language/en-GB/en-GB.mod_popular.ini\n/administrator/language/en-GB/en-GB.mod_popular.sys.ini"}, {"id": "Joomla.gitignore_9", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.mod_popular.sys.ini\n/administrator/language/en-GB/en-GB.mod_privacy_dashboard.ini\n/administrator/language/en-GB/en-GB.mod_privacy_dashboard.sys.ini\n/administrator/language/en-GB/en-GB.mod_quickicon.ini\n/administrator/language/en-GB/en-GB.mod_quickicon.sys.ini\n/administrator/language/en-GB/en-GB.mod_sampledata.ini\n/administrator/language/en-GB/en-GB.mod_sampledata.sys.ini\n/administrator/language/en-GB/en-GB.mod_stats_admin.ini\n/administrator/language/en-GB/en-GB.mod_stats_admin.sys.ini\n/administrator/language/en-GB/en-GB.mod_status.ini\n/administrator/language/en-GB/en-GB.mod_status.sys.ini\n/administrator/language/en-GB/en-GB.mod_submenu.ini\n/administrator/language/en-GB/en-GB.mod_submenu.sys.ini\n/administrator/language/en-GB/en-GB.mod_title.ini"}, {"id": "Joomla.gitignore_10", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.mod_title.ini\n/administrator/language/en-GB/en-GB.mod_title.sys.ini\n/administrator/language/en-GB/en-GB.mod_toolbar.ini\n/administrator/language/en-GB/en-GB.mod_toolbar.sys.ini\n/administrator/language/en-GB/en-GB.mod_unread.ini\n/administrator/language/en-GB/en-GB.mod_unread.sys.ini\n/administrator/language/en-GB/en-GB.mod_version.ini\n/administrator/language/en-GB/en-GB.mod_version.sys.ini\n/administrator/language/en-GB/en-GB.plg_actionlog_joomla.ini\n/administrator/language/en-GB/en-GB.plg_actionlog_joomla.sys.ini\n/administrator/language/en-GB/en-GB.plg_authentication_cookie.ini\n/administrator/language/en-GB/en-GB.plg_authentication_cookie.sys.ini\n/administrator/language/en-GB/en-GB.plg_authentication_example.ini"}, {"id": "Joomla.gitignore_11", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_authentication_example.ini\n/administrator/language/en-GB/en-GB.plg_authentication_example.sys.ini\n/administrator/language/en-GB/en-GB.plg_authentication_gmail.ini\n/administrator/language/en-GB/en-GB.plg_authentication_gmail.sys.ini\n/administrator/language/en-GB/en-GB.plg_authentication_joomla.ini\n/administrator/language/en-GB/en-GB.plg_authentication_joomla.sys.ini\n/administrator/language/en-GB/en-GB.plg_authentication_ldap.ini\n/administrator/language/en-GB/en-GB.plg_authentication_ldap.sys.ini\n/administrator/language/en-GB/en-GB.plg_captcha_recaptcha.ini\n/administrator/language/en-GB/en-GB.plg_captcha_recaptcha.sys.ini\n/administrator/language/en-GB/en-GB.plg_captcha_recaptcha_invisible.ini"}, {"id": "Joomla.gitignore_12", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_captcha_recaptcha_invisible.ini\n/administrator/language/en-GB/en-GB.plg_captcha_recaptcha_invisible.sys.ini\n/administrator/language/en-GB/en-GB.plg_content_confirmconsent.ini\n/administrator/language/en-GB/en-GB.plg_content_confirmconsent.sys.ini\n/administrator/language/en-GB/en-GB.plg_content_contact.ini\n/administrator/language/en-GB/en-GB.plg_content_contact.sys.ini\n/administrator/language/en-GB/en-GB.plg_content_emailcloak.ini\n/administrator/language/en-GB/en-GB.plg_content_emailcloak.sys.ini\n/administrator/language/en-GB/en-GB.plg_content_fields.ini\n/administrator/language/en-GB/en-GB.plg_content_fields.sys.ini\n/administrator/language/en-GB/en-GB.plg_content_finder.ini\n/administrator/language/en-GB/en-GB.plg_content_finder.sys.ini"}, {"id": "Joomla.gitignore_13", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_content_finder.sys.ini\n/administrator/language/en-GB/en-GB.plg_content_geshi.ini\n/administrator/language/en-GB/en-GB.plg_content_geshi.sys.ini\n/administrator/language/en-GB/en-GB.plg_content_joomla.ini\n/administrator/language/en-GB/en-GB.plg_content_joomla.sys.ini\n/administrator/language/en-GB/en-GB.plg_content_loadmodule.ini\n/administrator/language/en-GB/en-GB.plg_content_loadmodule.sys.ini\n/administrator/language/en-GB/en-GB.plg_content_pagebreak.ini\n/administrator/language/en-GB/en-GB.plg_content_pagebreak.sys.ini\n/administrator/language/en-GB/en-GB.plg_content_pagenavigation.ini\n/administrator/language/en-GB/en-GB.plg_content_pagenavigation.sys.ini\n/administrator/language/en-GB/en-GB.plg_content_vote.ini"}, {"id": "Joomla.gitignore_14", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_content_vote.ini\n/administrator/language/en-GB/en-GB.plg_content_vote.sys.ini\n/administrator/language/en-GB/en-GB.plg_editors-xtd_article.ini\n/administrator/language/en-GB/en-GB.plg_editors-xtd_article.sys.ini\n/administrator/language/en-GB/en-GB.plg_editors-xtd_contact.ini\n/administrator/language/en-GB/en-GB.plg_editors-xtd_contact.sys.ini\n/administrator/language/en-GB/en-GB.plg_editors-xtd_fields.ini\n/administrator/language/en-GB/en-GB.plg_editors-xtd_fields.sys.ini\n/administrator/language/en-GB/en-GB.plg_editors-xtd_image.ini\n/administrator/language/en-GB/en-GB.plg_editors-xtd_image.sys.ini\n/administrator/language/en-GB/en-GB.plg_editors-xtd_menu.ini\n/administrator/language/en-GB/en-GB.plg_editors-xtd_menu.sys.ini"}, {"id": "Joomla.gitignore_15", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_editors-xtd_menu.sys.ini\n/administrator/language/en-GB/en-GB.plg_editors-xtd_module.ini\n/administrator/language/en-GB/en-GB.plg_editors-xtd_module.sys.ini\n/administrator/language/en-GB/en-GB.plg_editors-xtd_pagebreak.ini\n/administrator/language/en-GB/en-GB.plg_editors-xtd_pagebreak.sys.ini\n/administrator/language/en-GB/en-GB.plg_editors-xtd_readmore.ini\n/administrator/language/en-GB/en-GB.plg_editors-xtd_readmore.sys.ini\n/administrator/language/en-GB/en-GB.plg_editors_codemirror.ini\n/administrator/language/en-GB/en-GB.plg_editors_codemirror.sys.ini\n/administrator/language/en-GB/en-GB.plg_editors_none.ini\n/administrator/language/en-GB/en-GB.plg_editors_none.sys.ini\n/administrator/language/en-GB/en-GB.plg_editors_tinymce.ini"}, {"id": "Joomla.gitignore_16", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_editors_tinymce.ini\n/administrator/language/en-GB/en-GB.plg_editors_tinymce.sys.ini\n/administrator/language/en-GB/en-GB.plg_extension_joomla.ini\n/administrator/language/en-GB/en-GB.plg_extension_joomla.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_calendar.ini\n/administrator/language/en-GB/en-GB.plg_fields_calendar.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_checkboxes.ini\n/administrator/language/en-GB/en-GB.plg_fields_checkboxes.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_color.ini\n/administrator/language/en-GB/en-GB.plg_fields_color.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_editor.ini\n/administrator/language/en-GB/en-GB.plg_fields_editor.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_image.ini"}, {"id": "Joomla.gitignore_17", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_fields_image.ini\n/administrator/language/en-GB/en-GB.plg_fields_image.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_imagelist.ini\n/administrator/language/en-GB/en-GB.plg_fields_imagelist.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_integer.ini\n/administrator/language/en-GB/en-GB.plg_fields_integer.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_list.ini\n/administrator/language/en-GB/en-GB.plg_fields_list.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_media.ini\n/administrator/language/en-GB/en-GB.plg_fields_media.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_radio.ini\n/administrator/language/en-GB/en-GB.plg_fields_radio.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_repeatable.ini"}, {"id": "Joomla.gitignore_18", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_fields_repeatable.ini\n/administrator/language/en-GB/en-GB.plg_fields_repeatable.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_sql.ini\n/administrator/language/en-GB/en-GB.plg_fields_sql.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_text.ini\n/administrator/language/en-GB/en-GB.plg_fields_text.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_textarea.ini\n/administrator/language/en-GB/en-GB.plg_fields_textarea.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_url.ini\n/administrator/language/en-GB/en-GB.plg_fields_url.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_user.ini\n/administrator/language/en-GB/en-GB.plg_fields_user.sys.ini\n/administrator/language/en-GB/en-GB.plg_fields_usergrouplist.ini"}, {"id": "Joomla.gitignore_19", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_fields_usergrouplist.ini\n/administrator/language/en-GB/en-GB.plg_fields_usergrouplist.sys.ini\n/administrator/language/en-GB/en-GB.plg_finder_categories.ini\n/administrator/language/en-GB/en-GB.plg_finder_categories.sys.ini\n/administrator/language/en-GB/en-GB.plg_finder_contacts.ini\n/administrator/language/en-GB/en-GB.plg_finder_contacts.sys.ini\n/administrator/language/en-GB/en-GB.plg_finder_content.ini\n/administrator/language/en-GB/en-GB.plg_finder_content.sys.ini\n/administrator/language/en-GB/en-GB.plg_finder_newsfeeds.ini\n/administrator/language/en-GB/en-GB.plg_finder_newsfeeds.sys.ini\n/administrator/language/en-GB/en-GB.plg_finder_tags.ini\n/administrator/language/en-GB/en-GB.plg_finder_tags.sys.ini"}, {"id": "Joomla.gitignore_20", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_finder_tags.sys.ini\n/administrator/language/en-GB/en-GB.plg_finder_weblinks.ini\n/administrator/language/en-GB/en-GB.plg_finder_weblinks.sys.ini\n/administrator/language/en-GB/en-GB.plg_installer_folderinstaller.ini\n/administrator/language/en-GB/en-GB.plg_installer_folderinstaller.sys.ini\n/administrator/language/en-GB/en-GB.plg_installer_packageinstaller.ini\n/administrator/language/en-GB/en-GB.plg_installer_packageinstaller.sys.ini\n/administrator/language/en-GB/en-GB.plg_installer_urlinstaller.ini\n/administrator/language/en-GB/en-GB.plg_installer_urlinstaller.sys.ini\n/administrator/language/en-GB/en-GB.plg_installer_webinstaller.ini\n/administrator/language/en-GB/en-GB.plg_installer_webinstaller.sys.ini"}, {"id": "Joomla.gitignore_21", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_installer_webinstaller.sys.ini\n/administrator/language/en-GB/en-GB.plg_privacy_actionlogs.ini\n/administrator/language/en-GB/en-GB.plg_privacy_actionlogs.sys.ini\n/administrator/language/en-GB/en-GB.plg_privacy_consents.ini\n/administrator/language/en-GB/en-GB.plg_privacy_consents.sys.ini\n/administrator/language/en-GB/en-GB.plg_privacy_contact.ini\n/administrator/language/en-GB/en-GB.plg_privacy_contact.sys.ini\n/administrator/language/en-GB/en-GB.plg_privacy_content.ini\n/administrator/language/en-GB/en-GB.plg_privacy_content.sys.ini\n/administrator/language/en-GB/en-GB.plg_privacy_message.ini\n/administrator/language/en-GB/en-GB.plg_privacy_message.sys.ini\n/administrator/language/en-GB/en-GB.plg_privacy_user.ini"}, {"id": "Joomla.gitignore_22", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_privacy_user.ini\n/administrator/language/en-GB/en-GB.plg_privacy_user.sys.ini\n/administrator/language/en-GB/en-GB.plg_quickicon_extensionupdate.ini\n/administrator/language/en-GB/en-GB.plg_quickicon_extensionupdate.sys.ini\n/administrator/language/en-GB/en-GB.plg_quickicon_joomlaupdate.ini\n/administrator/language/en-GB/en-GB.plg_quickicon_joomlaupdate.sys.ini\n/administrator/language/en-GB/en-GB.plg_quickicon_phpversioncheck.ini\n/administrator/language/en-GB/en-GB.plg_quickicon_phpversioncheck.sys.ini\n/administrator/language/en-GB/en-GB.plg_quickicon_privacycheck.ini\n/administrator/language/en-GB/en-GB.plg_quickicon_privacycheck.sys.ini\n/administrator/language/en-GB/en-GB.plg_sampledata_blog.ini"}, {"id": "Joomla.gitignore_23", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_sampledata_blog.ini\n/administrator/language/en-GB/en-GB.plg_sampledata_blog.sys.ini\n/administrator/language/en-GB/en-GB.plg_search_categories.ini\n/administrator/language/en-GB/en-GB.plg_search_categories.sys.ini\n/administrator/language/en-GB/en-GB.plg_search_contacts.ini\n/administrator/language/en-GB/en-GB.plg_search_contacts.sys.ini\n/administrator/language/en-GB/en-GB.plg_search_content.ini\n/administrator/language/en-GB/en-GB.plg_search_content.sys.ini\n/administrator/language/en-GB/en-GB.plg_search_newsfeeds.ini\n/administrator/language/en-GB/en-GB.plg_search_newsfeeds.sys.ini\n/administrator/language/en-GB/en-GB.plg_search_tags.ini\n/administrator/language/en-GB/en-GB.plg_search_tags.sys.ini\n/administrator/language/en-GB/en-GB.plg_search_weblinks.ini"}, {"id": "Joomla.gitignore_24", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_search_weblinks.ini\n/administrator/language/en-GB/en-GB.plg_search_weblinks.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_actionlogs.ini\n/administrator/language/en-GB/en-GB.plg_system_actionlogs.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_cache.ini\n/administrator/language/en-GB/en-GB.plg_system_cache.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_debug.ini\n/administrator/language/en-GB/en-GB.plg_system_debug.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_fields.ini\n/administrator/language/en-GB/en-GB.plg_system_fields.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_highlight.ini\n/administrator/language/en-GB/en-GB.plg_system_highlight.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_languagecode.ini"}, {"id": "Joomla.gitignore_25", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_system_languagecode.ini\n/administrator/language/en-GB/en-GB.plg_system_languagecode.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_languagefilter.ini\n/administrator/language/en-GB/en-GB.plg_system_languagefilter.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_log.ini\n/administrator/language/en-GB/en-GB.plg_system_log.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_logout.ini\n/administrator/language/en-GB/en-GB.plg_system_logout.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_logrotation.ini\n/administrator/language/en-GB/en-GB.plg_system_logrotation.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_p3p.ini\n/administrator/language/en-GB/en-GB.plg_system_p3p.sys.ini"}, {"id": "Joomla.gitignore_26", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_system_p3p.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_privacyconsent.ini\n/administrator/language/en-GB/en-GB.plg_system_privacyconsent.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_redirect.ini\n/administrator/language/en-GB/en-GB.plg_system_redirect.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_remember.ini\n/administrator/language/en-GB/en-GB.plg_system_remember.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_sef.ini\n/administrator/language/en-GB/en-GB.plg_system_sef.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_sessiongc.ini\n/administrator/language/en-GB/en-GB.plg_system_sessiongc.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_stats.ini"}, {"id": "Joomla.gitignore_27", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_system_stats.ini\n/administrator/language/en-GB/en-GB.plg_system_stats.sys.ini\n/administrator/language/en-GB/en-GB.plg_system_updatenotification.ini\n/administrator/language/en-GB/en-GB.plg_system_updatenotification.sys.ini\n/administrator/language/en-GB/en-GB.plg_twofactorauth_totp.ini\n/administrator/language/en-GB/en-GB.plg_twofactorauth_totp.sys.ini\n/administrator/language/en-GB/en-GB.plg_twofactorauth_yubikey.ini\n/administrator/language/en-GB/en-GB.plg_twofactorauth_yubikey.sys.ini\n/administrator/language/en-GB/en-GB.plg_user_contactcreator.ini\n/administrator/language/en-GB/en-GB.plg_user_contactcreator.sys.ini\n/administrator/language/en-GB/en-GB.plg_user_joomla.ini\n/administrator/language/en-GB/en-GB.plg_user_joomla.sys.ini"}, {"id": "Joomla.gitignore_28", "file": "Joomla.gitignore", "content": "/administrator/language/en-GB/en-GB.plg_user_joomla.sys.ini\n/administrator/language/en-GB/en-GB.plg_user_profile.ini\n/administrator/language/en-GB/en-GB.plg_user_profile.sys.ini\n/administrator/language/en-GB/en-GB.plg_user_terms.ini\n/administrator/language/en-GB/en-GB.plg_user_terms.sys.ini\n/administrator/language/en-GB/en-GB.tpl_hathor.ini\n/administrator/language/en-GB/en-GB.tpl_hathor.sys.ini\n/administrator/language/en-GB/en-GB.tpl_isis.ini\n/administrator/language/en-GB/en-GB.tpl_isis.sys.ini\n/administrator/language/en-GB/en-GB.xml\n/administrator/language/en-GB/install.xml\n/administrator/language/overrides/*\n/administrator/language/index.html\n/administrator/logs/*\n/administrator/manifests/files/joomla.xml\n/administrator/manifests/libraries/fof.xml"}, {"id": "Joomla.gitignore_29", "file": "Joomla.gitignore", "content": "/administrator/manifests/files/joomla.xml\n/administrator/manifests/libraries/fof.xml\n/administrator/manifests/libraries/idna_convert.xml\n/administrator/manifests/libraries/joomla.xml\n/administrator/manifests/libraries/phpass.xml\n/administrator/manifests/libraries/phputf8.xml\n/administrator/manifests/packages/pkg_en-GB.xml\n/administrator/manifests/packages/index.html\n/administrator/modules/mod_custom/*\n/administrator/modules/mod_feed/*\n/administrator/modules/mod_latest/*\n/administrator/modules/mod_latestactions/*\n/administrator/modules/mod_logged/*\n/administrator/modules/mod_login/*\n/administrator/modules/mod_menu/*\n/administrator/modules/mod_multilangstatus/*\n/administrator/modules/mod_online/*\n/administrator/modules/mod_popular/*\n/administrator/modules/mod_privacy_dashboard/*"}, {"id": "Joomla.gitignore_30", "file": "Joomla.gitignore", "content": "/administrator/modules/mod_popular/*\n/administrator/modules/mod_privacy_dashboard/*\n/administrator/modules/mod_quickicon/*\n/administrator/modules/mod_sampledata/*\n/administrator/modules/mod_stats_admin/*\n/administrator/modules/mod_status/*\n/administrator/modules/mod_submenu/*\n/administrator/modules/mod_title/*\n/administrator/modules/mod_toolbar/*\n/administrator/modules/mod_unread/*\n/administrator/modules/mod_version/*\n/administrator/templates/hathor/*\n/administrator/templates/isis/*\n/administrator/templates/system/*\n/bin/*\n/cache/*\n/cli/*\n/components/com_ajax/*\n/components/com_banners/*\n/components/com_config/*\n/components/com_contact/*\n/components/com_content/*\n/components/com_contenthistory/*\n/components/com_fields/*\n/components/com_finder/*\n/components/com_mailto/*"}, {"id": "Joomla.gitignore_31", "file": "Joomla.gitignore", "content": "/components/com_fields/*\n/components/com_finder/*\n/components/com_mailto/*\n/components/com_media/*\n/components/com_menus/*\n/components/com_modules/*\n/components/com_newsfeeds/*\n/components/com_privacy/*\n/components/com_search/*\n/components/com_tags/*\n/components/com_users/*\n/components/com_wrapper/*\n/components/index.html\n/images/banners/*\n/images/headers/*\n/images/sampledata/*\n/images/index.html\n/images/joomla*\n/images/powered_by.png\n/includes/*\n/installation/*\n/language/en-GB/en-GB.com_ajax.ini\n/language/en-GB/en-GB.com_config.ini\n/language/en-GB/en-GB.com_contact.ini\n/language/en-GB/en-GB.com_content.ini\n/language/en-GB/en-GB.com_finder.ini\n/language/en-GB/en-GB.com_mailto.ini\n/language/en-GB/en-GB.com_media.ini\n/language/en-GB/en-GB.com_messages.ini"}, {"id": "Joomla.gitignore_32", "file": "Joomla.gitignore", "content": "/language/en-GB/en-GB.com_media.ini\n/language/en-GB/en-GB.com_messages.ini\n/language/en-GB/en-GB.com_newsfeeds.ini\n/language/en-GB/en-GB.com_privacy.ini\n/language/en-GB/en-GB.com_search.ini\n/language/en-GB/en-GB.com_tags.ini\n/language/en-GB/en-GB.com_users.ini\n/language/en-GB/en-GB.com_weblinks.ini\n/language/en-GB/en-GB.com_wrapper.ini\n/language/en-GB/en-GB.files_joomla.sys.ini\n/language/en-GB/en-GB.finder_cli.ini\n/language/en-GB/en-GB.ini\n/language/en-GB/en-GB.lib_fof.ini\n/language/en-GB/en-GB.lib_fof.sys.ini\n/language/en-GB/en-GB.lib_idna_convert.sys.ini\n/language/en-GB/en-GB.lib_joomla.ini\n/language/en-GB/en-GB.lib_joomla.sys.ini\n/language/en-GB/en-GB.lib_phpass.sys.ini\n/language/en-GB/en-GB.lib_phpmailer.sys.ini\n/language/en-GB/en-GB.lib_phputf8.sys.ini"}, {"id": "Joomla.gitignore_33", "file": "Joomla.gitignore", "content": "/language/en-GB/en-GB.lib_phpmailer.sys.ini\n/language/en-GB/en-GB.lib_phputf8.sys.ini\n/language/en-GB/en-GB.lib_simplepie.sys.ini\n/language/en-GB/en-GB.localise.php\n/language/en-GB/en-GB.mod_articles_archive.ini\n/language/en-GB/en-GB.mod_articles_archive.sys.ini\n/language/en-GB/en-GB.mod_articles_categories.ini\n/language/en-GB/en-GB.mod_articles_categories.sys.ini\n/language/en-GB/en-GB.mod_articles_category.ini\n/language/en-GB/en-GB.mod_articles_category.sys.ini\n/language/en-GB/en-GB.mod_articles_latest.ini\n/language/en-GB/en-GB.mod_articles_latest.sys.ini\n/language/en-GB/en-GB.mod_articles_news.ini\n/language/en-GB/en-GB.mod_articles_news.sys.ini\n/language/en-GB/en-GB.mod_articles_popular.ini\n/language/en-GB/en-GB.mod_articles_popular.sys.ini\n/language/en-GB/en-GB.mod_banners.ini"}, {"id": "Joomla.gitignore_34", "file": "Joomla.gitignore", "content": "/language/en-GB/en-GB.mod_articles_popular.sys.ini\n/language/en-GB/en-GB.mod_banners.ini\n/language/en-GB/en-GB.mod_banners.sys.ini\n/language/en-GB/en-GB.mod_breadcrumbs.ini\n/language/en-GB/en-GB.mod_breadcrumbs.sys.ini\n/language/en-GB/en-GB.mod_custom.ini\n/language/en-GB/en-GB.mod_custom.sys.ini\n/language/en-GB/en-GB.mod_feed.ini\n/language/en-GB/en-GB.mod_feed.sys.ini\n/language/en-GB/en-GB.mod_finder.ini\n/language/en-GB/en-GB.mod_finder.sys.ini\n/language/en-GB/en-GB.mod_footer.ini\n/language/en-GB/en-GB.mod_footer.sys.ini\n/language/en-GB/en-GB.mod_languages.ini\n/language/en-GB/en-GB.mod_languages.sys.ini\n/language/en-GB/en-GB.mod_login.ini\n/language/en-GB/en-GB.mod_login.sys.ini\n/language/en-GB/en-GB.mod_menu.ini\n/language/en-GB/en-GB.mod_menu.sys.ini"}, {"id": "Joomla.gitignore_35", "file": "Joomla.gitignore", "content": "/language/en-GB/en-GB.mod_menu.ini\n/language/en-GB/en-GB.mod_menu.sys.ini\n/language/en-GB/en-GB.mod_random_image.ini\n/language/en-GB/en-GB.mod_random_image.sys.ini\n/language/en-GB/en-GB.mod_related_items.ini\n/language/en-GB/en-GB.mod_related_items.sys.ini\n/language/en-GB/en-GB.mod_search.ini\n/language/en-GB/en-GB.mod_search.sys.ini\n/language/en-GB/en-GB.mod_stats.ini\n/language/en-GB/en-GB.mod_stats.sys.ini\n/language/en-GB/en-GB.mod_syndicate.ini\n/language/en-GB/en-GB.mod_syndicate.sys.ini\n/language/en-GB/en-GB.mod_tags_popular.ini\n/language/en-GB/en-GB.mod_tags_popular.sys.ini\n/language/en-GB/en-GB.mod_tags_similar.ini\n/language/en-GB/en-GB.mod_tags_similar.sys.ini\n/language/en-GB/en-GB.mod_users_latest.ini\n/language/en-GB/en-GB.mod_users_latest.sys.ini"}, {"id": "Joomla.gitignore_36", "file": "Joomla.gitignore", "content": "/language/en-GB/en-GB.mod_users_latest.ini\n/language/en-GB/en-GB.mod_users_latest.sys.ini\n/language/en-GB/en-GB.mod_weblinks.ini\n/language/en-GB/en-GB.mod_weblinks.sys.ini\n/language/en-GB/en-GB.mod_whosonline.ini\n/language/en-GB/en-GB.mod_whosonline.sys.ini\n/language/en-GB/en-GB.mod_wrapper.ini\n/language/en-GB/en-GB.mod_wrapper.sys.ini\n/language/en-GB/en-GB.tpl_atomic.ini\n/language/en-GB/en-GB.tpl_atomic.sys.ini\n/language/en-GB/en-GB.tpl_beez3.ini\n/language/en-GB/en-GB.tpl_beez3.sys.ini\n/language/en-GB/en-GB.tpl_beez5.ini\n/language/en-GB/en-GB.tpl_beez5.sys.ini\n/language/en-GB/en-GB.tpl_beez_20.ini\n/language/en-GB/en-GB.tpl_beez_20.sys.ini\n/language/en-GB/en-GB.tpl_protostar.ini\n/language/en-GB/en-GB.tpl_protostar.sys.ini\n/language/en-GB/en-GB.xml\n/language/en-GB/install.xml"}, {"id": "Joomla.gitignore_37", "file": "Joomla.gitignore", "content": "/language/en-GB/en-GB.tpl_protostar.sys.ini\n/language/en-GB/en-GB.xml\n/language/en-GB/install.xml\n/language/overrides/*\n/language/index.html\n/layouts/joomla/*\n/layouts/libraries/*\n/layouts/plugins/*\n/layouts/index.html\n/libraries/cms/*\n/libraries/fof/*\n/libraries/idna_convert/*\n/libraries/joomla/*\n/libraries/legacy/*\n/libraries/php-encryption/*\n/libraries/phpass/*\n/libraries/phpmailer/*\n/libraries/phputf8/*\n/libraries/simplepie/*\n/libraries/src/*\n/libraries/vendor/*\n/libraries/classmap.php\n/libraries/cms.php\n/libraries/import.legacy.php\n/libraries/import.php\n/libraries/index.html\n/libraries/loader.php\n/media/cms/*\n/media/com_associations/*\n/media/com_contact/*\n/media/com_content/*\n/media/com_contenthistory/*\n/media/com_fields/*\n/media/com_finder/*\n/media/com_joomlaupdate/*"}, {"id": "Joomla.gitignore_38", "file": "Joomla.gitignore", "content": "/media/com_contenthistory/*\n/media/com_fields/*\n/media/com_finder/*\n/media/com_joomlaupdate/*\n/media/com_menus/*\n/media/com_modules/*\n/media/com_wrapper/*\n/media/contacts/*\n/media/editors/*\n/media/jui/*\n/media/mailto/*\n/media/media/*\n/media/mod_languages/*\n/media/mod_sampledata/*\n/media/overrider/*\n/media/plg_captcha_recaptcha/*\n/media/plg_captcha_recaptcha_invisible/*\n/media/plg_quickicon_extensionupdate/*\n/media/plg_quickicon_joomlaupdate/*\n/media/plg_quickicon_privacycheck/*\n/media/plg_system_highlight/*\n/media/plg_system_stats/*\n/media/plg_twofactorauth_totp/*\n/media/system/*\n/media/index.html\n/modules/mod_articles_archive/*\n/modules/mod_articles_categories/*\n/modules/mod_articles_category/*\n/modules/mod_articles_latest/*\n/modules/mod_articles_news/*\n/modules/mod_articles_popular/*"}, {"id": "Joomla.gitignore_39", "file": "Joomla.gitignore", "content": "/modules/mod_articles_latest/*\n/modules/mod_articles_news/*\n/modules/mod_articles_popular/*\n/modules/mod_banners/*\n/modules/mod_breadcrumbs/*\n/modules/mod_custom/*\n/modules/mod_feed/*\n/modules/mod_finder/*\n/modules/mod_footer/*\n/modules/mod_languages/*\n/modules/mod_login/*\n/modules/mod_menu/*\n/modules/mod_random_image/*\n/modules/mod_related_items/*\n/modules/mod_search/*\n/modules/mod_stats/*\n/modules/mod_syndicate/*\n/modules/mod_tags_popular/*\n/modules/mod_tags_similar/*\n/modules/mod_users_latest/*\n/modules/mod_whosonline/*\n/modules/mod_wrapper/*\n/modules/index.html\n/plugins/actionlog/joomla/*\n/plugins/authentication/cookie/*\n/plugins/authentication/example/*\n/plugins/authentication/gmail/*\n/plugins/authentication/joomla/*\n/plugins/authentication/ldap/*\n/plugins/captcha/recaptcha/*"}, {"id": "Joomla.gitignore_40", "file": "Joomla.gitignore", "content": "/plugins/authentication/joomla/*\n/plugins/authentication/ldap/*\n/plugins/captcha/recaptcha/*\n/plugins/captcha/recaptcha_invisible/*\n/plugins/content/confirmconsent/*\n/plugins/content/contact/*\n/plugins/content/emailcloak/*\n/plugins/content/example/*\n/plugins/content/fields/*\n/plugins/content/finder/*\n/plugins/content/geshi/*\n/plugins/content/joomla/*\n/plugins/content/loadmodule/*\n/plugins/content/pagebreak/*\n/plugins/content/pagenavigation/*\n/plugins/content/vote/*\n/plugins/editors/codemirror/*\n/plugins/editors/none/*\n/plugins/editors/tinymce/*\n/plugins/editors-xtd/article/*\n/plugins/editors-xtd/contact/*\n/plugins/editors-xtd/fields/*\n/plugins/editors-xtd/image/*\n/plugins/editors-xtd/menu/*\n/plugins/editors-xtd/module/*\n/plugins/editors-xtd/pagebreak/*\n/plugins/editors-xtd/readmore/*"}, {"id": "Joomla.gitignore_41", "file": "Joomla.gitignore", "content": "/plugins/editors-xtd/module/*\n/plugins/editors-xtd/pagebreak/*\n/plugins/editors-xtd/readmore/*\n/plugins/extension/example/*\n/plugins/extension/joomla/*\n/plugins/fields/calendar/*\n/plugins/fields/checkboxes/*\n/plugins/fields/color/*\n/plugins/fields/editor/*\n/plugins/fields/imagelist/*\n/plugins/fields/integer/*\n/plugins/fields/list/*\n/plugins/fields/media/*\n/plugins/fields/radio/*\n/plugins/fields/repeatable/*\n/plugins/fields/sql/*\n/plugins/fields/text/*\n/plugins/fields/textarea/*\n/plugins/fields/url/*\n/plugins/fields/user/*\n/plugins/fields/usergrouplist/*\n/plugins/finder/categories/*\n/plugins/finder/contacts/*\n/plugins/finder/content/*\n/plugins/finder/newsfeeds/*\n/plugins/finder/tags/*\n/plugins/installer/folderinstaller/*\n/plugins/installer/packageinstaller/*"}, {"id": "Joomla.gitignore_42", "file": "Joomla.gitignore", "content": "/plugins/finder/tags/*\n/plugins/installer/folderinstaller/*\n/plugins/installer/packageinstaller/*\n/plugins/installer/urlinstaller/*\n/plugins/privacy/actionlogs/*\n/plugins/privacy/consents/*\n/plugins/privacy/contact/*\n/plugins/privacy/content/*\n/plugins/privacy/message/*\n/plugins/privacy/user/*\n/plugins/quickicon/extensionupdate/*\n/plugins/quickicon/joomlaupdate/*\n/plugins/quickicon/phpversioncheck/*\n/plugins/quickicon/privacycheck/*\n/plugins/quickicon/index.html\n/plugins/sampledata/blog/*\n/plugins/search/categories/*\n/plugins/search/contacts/*\n/plugins/search/content/*\n/plugins/search/newsfeeds/*\n/plugins/search/tags/*\n/plugins/search/weblinks/*\n/plugins/search/index.html\n/plugins/system/actionlogs/*\n/plugins/system/cache/*\n/plugins/system/debug/*\n/plugins/system/fields/*"}, {"id": "Joomla.gitignore_43", "file": "Joomla.gitignore", "content": "/plugins/system/cache/*\n/plugins/system/debug/*\n/plugins/system/fields/*\n/plugins/system/highlight/*\n/plugins/system/languagecode/*\n/plugins/system/languagefilter/*\n/plugins/system/log/*\n/plugins/system/logout/*\n/plugins/system/logrotation/*\n/plugins/system/p3p/*\n/plugins/system/privacyconsent/*\n/plugins/system/redirect/*\n/plugins/system/remember/*\n/plugins/system/sef/*\n/plugins/system/sessiongc/*\n/plugins/system/stats/*\n/plugins/system/updatenotification/*\n/plugins/system/index.html\n/plugins/twofactorauth/totp/*\n/plugins/twofactorauth/yubikey/*\n/plugins/user/contactcreator/*\n/plugins/user/example/*\n/plugins/user/joomla/*\n/plugins/user/profile/*\n/plugins/user/terms/*\n/plugins/user/index.html\n/plugins/index.html\n/templates/beez3/*\n/templates/protostar/*\n/templates/system/*"}, {"id": "Joomla.gitignore_44", "file": "Joomla.gitignore", "content": "/plugins/index.html\n/templates/beez3/*\n/templates/protostar/*\n/templates/system/*\n/templates/index.html\n/tmp/*\n/configuration.php\n/htaccess.txt\n/index.php\n/joomla.xml\n/LICENSE.txt\n/README.txt\n/robots.txt.dist\n/web.config.txt"}, {"id": "Julia.gitignore_0", "file": "Julia.gitignore", "content": "================================================\n# Files generated by invoking Julia with --code-coverage\n*.jl.cov\n*.jl.*.cov\n\n# Files generated by invoking Julia with --track-allocation\n*.jl.mem\n\n# System-specific files and directories generated by the BinaryProvider and BinDeps packages\n# They contain absolute paths specific to the host computer, and so should not be committed\ndeps/deps.jl\ndeps/build.log\ndeps/downloads/\ndeps/usr/\ndeps/src/\n\n# Build artifacts for creating documentation generated by the Documenter package\ndocs/build/\ndocs/site/\n\n# File generated by Pkg, the package manager, based on a corresponding Project.toml\n# It records a fixed state of all packages used by the project. As such, it should not be"}, {"id": "Julia.gitignore_1", "file": "Julia.gitignore", "content": "# It records a fixed state of all packages used by the project. As such, it should not be\n# committed for packages, but should be committed for applications that require a static\n# environment.\nManifest*.toml\n\n# File generated by the Preferences package to store local preferences\nLocalPreferences.toml\nJuliaLocalPreferences.toml"}, {"id": "Katalon.gitignore_0", "file": "Katalon.gitignore", "content": "================================================\n# Katalon Test Suite\n# Compiled class file\n*.class\n*.swp\noutput\n!output/.gitkeep\nbuild\n\nLibs/TempTestCase*\nLibs/TempTestSuite*\nbin/lib/TempTestCase*\nReports/\n\\.classpath\n\\.project\n\\.settings/\nbin/lib/\nLibs/\n.svn/\n.gradle\n\n\n# Log file\n*.log\n\n# BlueJ files\n*.ctxt\n\n# Mobile Tools for Java (J2ME)\n.mtj.tmp/\n\n# Package Files #\n*.jar\n*.war\n*.ear\n*.zip\n*.tar.gz\n*.rar\n\n# virtual machine crash logs, see http://www.java.com/en/download/help/error_hotspot.xml\nhs_err_pid*"}, {"id": "KiCad.gitignore_0", "file": "KiCad.gitignore", "content": "================================================\n# For PCBs designed using KiCad: https://www.kicad.org/\n# Format documentation: https://kicad.org/help/file-formats/\n\n# Temporary files\n*.000\n*.bak\n*.bck\n*.kicad_pcb-bak\n*.kicad_sch-bak\n*-backups\n*-cache*\n*-bak\n*-bak*\n*~\n~*\n_autosave-*\n\\#auto_saved_files\\#\n*.tmp\n*-save.pro\n*-save.kicad_pcb\nfp-info-cache\n~*.lck\n\\#auto_saved_files#\n\n# Netlist files (exported from Eeschema)\n*.net\n\n# Autorouter files (exported from Pcbnew)\n*.dsn\n*.ses\n\n# Exported BOM files\n*.xml\n*.csv\n\n# Archived Backups (KiCad 6.0)\n**/*-backups/*.zip\n\n# Local project settings\n*.kicad_prl"}, {"id": "Kohana.gitignore_0", "file": "Kohana.gitignore", "content": "================================================\napplication/cache/*\napplication/logs/*"}, {"id": "Kotlin.gitignore_0", "file": "Kotlin.gitignore", "content": "================================================\n# Compiled class file\n*.class\n\n# Log file\n*.log\n\n# BlueJ files\n*.ctxt\n\n# Mobile Tools for Java (J2ME)\n.mtj.tmp/\n\n# Package Files #\n*.jar\n*.war\n*.nar\n*.ear\n*.zip\n*.tar.gz\n*.rar\n\n# virtual machine crash logs, see http://www.java.com/en/download/help/error_hotspot.xml\nhs_err_pid*\nreplay_pid*\n\n# Kotlin Gradle plugin data, see https://kotlinlang.org/docs/whatsnew20.html#new-directory-for-kotlin-data-in-gradle-projects\n.kotlin/"}, {"id": "LabVIEW.gitignore_0", "file": "LabVIEW.gitignore", "content": "================================================\n# Libraries\n*.lvlibp\n*.llb\n\n# Shared objects (inc. Windows DLLs)\n*.dll\n*.so\n*.so.*\n*.dylib\n\n# Executables\n*.exe\n\n# Metadata\n*.aliases\n*.lvlps\n.cache/"}, {"id": "LangChain.gitignore_0", "file": "LangChain.gitignore", "content": "================================================\n# gitignore template for LangChain products, e.g., LangGraph, LangSmith\n# website: https://www.langchain.com/\n# website: https://www.langchain.com/langgraph\n\n# LangGraph\n.langgraph_api/"}, {"id": "Laravel.gitignore_0", "file": "Laravel.gitignore", "content": "================================================\n/vendor/\nnode_modules/\nnpm-debug.log\nyarn-error.log\n\n# Laravel 4 specific\nbootstrap/compiled.php\napp/storage/\n\n# Laravel 5 & Lumen specific\npublic/storage\npublic/hot\n\n# Laravel 5 & Lumen specific with changed public path\npublic_html/storage\npublic_html/hot\n\nstorage/*.key\n.env\nHomestead.yaml\nHomestead.json\n/.vagrant\n.phpunit.result.cache\n\n/public/build\n/storage/pail\n.env.backup\n.env.production\n.phpactor.json\nauth.json"}, {"id": "Leiningen.gitignore_0", "file": "Leiningen.gitignore", "content": "================================================\npom.xml\npom.xml.asc\n*.jar\n*.class\n/lib/\n/classes/\n/target/\n/checkouts/\n.lein-deps-sum\n.lein-repl-history\n.lein-plugins/\n.lein-failures\n.nrepl-port\n.cpcache/"}, {"id": "LemonStand.gitignore_0", "file": "LemonStand.gitignore", "content": "================================================\nboot.php\nindex.php\ninstall.php\n/config/*\n!/config/config.php\n/controllers/*\n/init/*\n/logs/*\n/phproad/*\n/temp/*\n/uploaded/*\n/installer_files/*\n/modules/backend/*\n/modules/blog/*\n/modules/cms/*\n/modules/core/*\n/modules/session/*\n/modules/shop/*\n/modules/system/*\n/modules/users/*\n# add content_*.php if you don't want erase client changes to content"}, {"id": "LICENSE_0", "file": "LICENSE", "content": "================================================\nCC0 1.0 Universal\n\nStatement of Purpose\n\nThe laws of most jurisdictions throughout the world automatically confer\nexclusive Copyright and Related Rights (defined below) upon the creator and\nsubsequent owner(s) (each and all, an \"owner\") of an original work of\nauthorship and/or a database (each, a \"Work\").\n\nCertain owners wish to permanently relinquish those rights to a Work for the\npurpose of contributing to a commons of creative, cultural and scientific\nworks (\"Commons\") that the public can reliably and without fear of later\nclaims of infringement build upon, modify, incorporate in other works, reuse\nand redistribute as freely as possible in any form whatsoever and for any"}, {"id": "LICENSE_1", "file": "LICENSE", "content": "and redistribute as freely as possible in any form whatsoever and for any\npurposes, including without limitation commercial purposes. These owners may\ncontribute to the Commons to promote the ideal of a free culture and the\nfurther production of creative, cultural and scientific works, or to gain\nreputation or greater distribution for their Work in part through the use and\nefforts of others.\n\nFor these and/or other purposes and motivations, and without any expectation\nof additional consideration or compensation, the person associating CC0 with a\nWork (the \"Affirmer\"), to the extent that he or she is an owner of Copyright\nand Related Rights in the Work, voluntarily elects to apply CC0 to the Work\nand publicly distribute the Work under its terms, with knowledge of his or her"}, {"id": "LICENSE_2", "file": "LICENSE", "content": "and publicly distribute the Work under its terms, with knowledge of his or her\nCopyright and Related Rights in the Work and the meaning and intended legal\neffect of CC0 on those rights.\n\n1. Copyright and Related Rights. A Work made available under CC0 may be\nprotected by copyright and related or neighboring rights (\"Copyright and\nRelated Rights\"). Copyright and Related Rights include, but are not limited\nto, the following:\n\n  i. the right to reproduce, adapt, distribute, perform, display, communicate,\n  and translate a Work;\n\n  ii. moral rights retained by the original author(s) and/or performer(s);\n\n  iii. publicity and privacy rights pertaining to a person's image or likeness\n  depicted in a Work;\n\n  iv. rights protecting against unfair competition in regards to a Work,"}, {"id": "LICENSE_3", "file": "LICENSE", "content": "depicted in a Work;\n\n  iv. rights protecting against unfair competition in regards to a Work,\n  subject to the limitations in paragraph 4(a), below;\n\n  v. rights protecting the extraction, dissemination, use and reuse of data in\n  a Work;\n\n  vi. database rights (such as those arising under Directive 96/9/EC of the\n  European Parliament and of the Council of 11 March 1996 on the legal\n  protection of databases, and under any national implementation thereof,\n  including any amended or successor version of such directive); and\n\n  vii. other similar, equivalent or corresponding rights throughout the world\n  based on applicable law or treaty, and any national implementations thereof.\n\n2. Waiver. To the greatest extent permitted by, but not in contravention of,"}, {"id": "LICENSE_4", "file": "LICENSE", "content": "2. Waiver. To the greatest extent permitted by, but not in contravention of,\napplicable law, Affirmer hereby overtly, fully, permanently, irrevocably and\nunconditionally waives, abandons, and surrenders all of Affirmer's Copyright\nand Related Rights and associated claims and causes of action, whether now\nknown or unknown (including existing as well as future claims and causes of\naction), in the Work (i) in all territories worldwide, (ii) for the maximum\nduration provided by applicable law or treaty (including future time\nextensions), (iii) in any current or future medium and for any number of\ncopies, and (iv) for any purpose whatsoever, including without limitation\ncommercial, advertising or promotional purposes (the \"Waiver\"). Affirmer makes"}, {"id": "LICENSE_5", "file": "LICENSE", "content": "commercial, advertising or promotional purposes (the \"Waiver\"). Affirmer makes\nthe Waiver for the benefit of each member of the public at large and to the\ndetriment of Affirmer's heirs and successors, fully intending that such Waiver\nshall not be subject to revocation, rescission, cancellation, termination, or\nany other legal or equitable action to disrupt the quiet enjoyment of the Work\nby the public as contemplated by Affirmer's express Statement of Purpose.\n\n3. Public License Fallback. Should any part of the Waiver for any reason be\njudged legally invalid or ineffective under applicable law, then the Waiver\nshall be preserved to the maximum extent permitted taking into account\nAffirmer's express Statement of Purpose. In addition, to the extent the Waiver"}, {"id": "LICENSE_6", "file": "LICENSE", "content": "Affirmer's express Statement of Purpose. In addition, to the extent the Waiver\nis so judged Affirmer hereby grants to each affected person a royalty-free,\nnon transferable, non sublicensable, non exclusive, irrevocable and\nunconditional license to exercise Affirmer's Copyright and Related Rights in\nthe Work (i) in all territories worldwide, (ii) for the maximum duration\nprovided by applicable law or treaty (including future time extensions), (iii)\nin any current or future medium and for any number of copies, and (iv) for any\npurpose whatsoever, including without limitation commercial, advertising or\npromotional purposes (the \"License\"). The License shall be deemed effective as\nof the date CC0 was applied by Affirmer to the Work. Should any part of the"}, {"id": "LICENSE_7", "file": "LICENSE", "content": "of the date CC0 was applied by Affirmer to the Work. Should any part of the\nLicense for any reason be judged legally invalid or ineffective under\napplicable law, such partial invalidity or ineffectiveness shall not\ninvalidate the remainder of the License, and in such case Affirmer hereby\naffirms that he or she will not (i) exercise any of his or her remaining\nCopyright and Related Rights in the Work or (ii) assert any associated claims\nand causes of action with respect to the Work, in either case contrary to\nAffirmer's express Statement of Purpose.\n\n4. Limitations and Disclaimers.\n\n  a. No trademark or patent rights held by Affirmer are waived, abandoned,\n  surrendered, licensed or otherwise affected by this document."}, {"id": "LICENSE_8", "file": "LICENSE", "content": "surrendered, licensed or otherwise affected by this document.\n\n  b. Affirmer offers the Work as-is and makes no representations or warranties\n  of any kind concerning the Work, express, implied, statutory or otherwise,\n  including without limitation warranties of title, merchantability, fitness\n  for a particular purpose, non infringement, or the absence of latent or\n  other defects, accuracy, or the present or absence of errors, whether or not\n  discoverable, all to the greatest extent permissible under applicable law.\n\n  c. Affirmer disclaims responsibility for clearing rights of other persons\n  that may apply to the Work or any use thereof, including without limitation\n  any person's Copyright and Related Rights in the Work. Further, Affirmer"}, {"id": "LICENSE_9", "file": "LICENSE", "content": "any person's Copyright and Related Rights in the Work. Further, Affirmer\n  disclaims responsibility for obtaining any necessary consents, permissions\n  or other rights required for any use of the Work.\n\n  d. Affirmer understands and acknowledges that Creative Commons is not a\n  party to this document and has no duty or obligation with respect to this\n  CC0 or use of the Work.\n\nFor more information, please see\n<http://creativecommons.org/publicdomain/zero/1.0/>"}, {"id": "Lilypond.gitignore_0", "file": "Lilypond.gitignore", "content": "================================================\n*.pdf\n*.ps\n*.midi\n*.mid\n*.log\n*~"}, {"id": "Lithium.gitignore_0", "file": "Lithium.gitignore", "content": "================================================\nlibraries/*\nresources/tmp/*"}, {"id": "Lua.gitignore_0", "file": "Lua.gitignore", "content": "================================================\n# Compiled Lua sources\nluac.out\n\n# luarocks build files\n*.src.rock\n*.zip\n*.tar.gz\n\n# Object files\n*.o\n*.os\n*.ko\n*.obj\n*.elf\n\n# Precompiled Headers\n*.gch\n*.pch\n\n# Libraries\n*.lib\n*.a\n*.la\n*.lo\n*.def\n*.exp\n\n# Shared objects (inc. Windows DLLs)\n*.dll\n*.so\n*.so.*\n*.dylib\n\n# Executables\n*.exe\n*.out\n*.app\n*.i*86\n*.x86_64\n*.hex"}, {"id": "Luau.gitignore_0", "file": "Luau.gitignore", "content": "================================================\n# A fast, small, safe, gradually typed embeddable scripting language derived from Lua\n#\n# https://github.com/luau-lang/luau\n# https://luau.org/\n\n# Code coverage\ncoverage.out\n\n# Profiling\nprofile.out\nprofile.svg\n\n# Time trace\ntrace.json"}, {"id": "Magento.gitignore_0", "file": "Magento.gitignore", "content": "================================================\n#--------------------------#\n# Magento Default Files    #\n#--------------------------#\n\n/PATCH_*.sh\n\n/app/etc/local.xml\n\n/media/*\n!/media/.htaccess\n\n!/media/customer\n/media/customer/*\n!/media/customer/.htaccess\n\n!/media/dhl\n/media/dhl/*\n!/media/dhl/logo.jpg\n\n!/media/downloadable\n/media/downloadable/*\n!/media/downloadable/.htaccess\n\n!/media/xmlconnect\n/media/xmlconnect/*\n\n!/media/xmlconnect/custom\n/media/xmlconnect/custom/*\n!/media/xmlconnect/custom/ok.gif\n\n!/media/xmlconnect/original\n/media/xmlconnect/original/*\n!/media/xmlconnect/original/ok.gif\n\n!/media/xmlconnect/system\n/media/xmlconnect/system/*\n!/media/xmlconnect/system/ok.gif\n\n/var/*\n!/var/.htaccess\n\n!/var/package\n/var/package/*\n!/var/package/*.xml"}, {"id": "Maven.gitignore_0", "file": "Maven.gitignore", "content": "================================================\ntarget/\npom.xml.tag\npom.xml.releaseBackup\npom.xml.versionsBackup\npom.xml.next\nrelease.properties\ndependency-reduced-pom.xml\nbuildNumber.properties\n.mvn/timing.properties\n# https://maven.apache.org/wrapper/#usage-without-binary-jar\n.mvn/wrapper/maven-wrapper.jar\n\n# Eclipse m2e generated files\n# Eclipse Core\n.project\n# JDT-specific (Eclipse Java Development Tools)\n.classpath"}, {"id": "Mercury.gitignore_0", "file": "Mercury.gitignore", "content": "================================================\nMercury/\nMercury.modules\n*.mh\n*.err\n*.init\n*.dll\n*.exe\n*.a\n*.so\n*.dylib\n*.beams\n*.d\n*.c_date"}, {"id": "MetaProgrammingSystem.gitignore_0", "file": "MetaProgrammingSystem.gitignore", "content": "================================================\nworkspace.xml\njunitvmwatcher*.properties\nbuild.properties\n\n# generated java classes and java source files\n#   manually add any custom artifacts that can't be generated from the models\n#   http://confluence.jetbrains.com/display/MPSD25/HowTo+--+MPS+and+Git\nclasses_gen\nsource_gen\nsource_gen.caches\n\n# generated test code and test results\ntest_gen\ntest_gen.caches\nTEST-*.xml\njunit*.properties"}, {"id": "Modelica.gitignore_0", "file": "Modelica.gitignore", "content": "================================================\n# Modelica - an object-oriented language for modeling of cyber-physical systems\n# https://modelica.org/\n# Ignore temporary files, build results, simulation files\n\n## Modelica-specific files\n*~\n*.bak\n*.bak-mo\n*.mof\n\\#*\\#\n*.moe\n*.mol\n\n## Build artefacts\n*.exe\n*.exp\n*.o\n*.pyc\n\n## Simulation files\n*.mat\n\n## Package files\n*.gz\n*.rar\n*.tar\n*.zip\n\n## Dymola-specific files\nbuildlog.txt\ndsfinal.txt\ndsin.txt\ndslog.txt\ndsmodel*\ndsres.txt\ndymosim*\nrequest\nstat\nstatus\nstop\nsuccess\n*."}, {"id": "ModelSim.gitignore_0", "file": "ModelSim.gitignore", "content": "================================================\n# ignore ModelSim generated files and directories (temp files and so on)\n[_@]*\n\n# ignore compilation output of ModelSim\n*.mti\n*.dat\n*.dbs\n*.psm\n*.bak\n*.cmp\n*.jpg\n*.html\n*.bsf\n\n# ignore simulation output of ModelSim\nwlf*\n*.wlf\n*.vstf\n*.ucdb\ncov*/\ntranscript*\nsc_dpiheader.h\nvsim.dbg"}, {"id": "Nanoc.gitignore_0", "file": "Nanoc.gitignore", "content": "================================================\n# For projects using Nanoc (http://nanoc.ws/)\n\n# Default location for output (needs to match output_dir's value found in nanoc.yaml)\noutput/\n\n# Temporary file directory\ntmp/nanoc/\n\n# Crash Log\ncrash.log"}, {"id": "Nestjs.gitignore_0", "file": "Nestjs.gitignore", "content": "================================================\n# Nestjs specific\n/dist\n/node_modules\n/build\n/tmp\n\n# Logs\nlogs\n*.log\nnpm-debug.log*\npnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\nlerna-debug.log*\n\n# dotenv environment variable files\n.env\n.env.development\n.env.test\n.env.production\n\n# temp directory\n.temp\n.tmp"}, {"id": "Nextjs.gitignore_0", "file": "Nextjs.gitignore", "content": "================================================\n# See https://help.github.com/articles/ignoring-files/ for more about ignoring files.\n\n# dependencies\n/node_modules\n/.pnp\n.pnp.js\n\n# testing\n/coverage\n\n# next.js\n/.next/\n/out/\n\n# production\n/build\n\n# misc\n.DS_Store\n*.pem\n\n# debug\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\n\n# local env files\n.env*.local\n.env\n\n# vercel\n.vercel\n\n# typescript\n*.tsbuildinfo\nnext-env.d.ts"}, {"id": "Nim.gitignore_0", "file": "Nim.gitignore", "content": "================================================\nnimcache/\nnimblecache/\nhtmldocs/"}, {"id": "Nix.gitignore_0", "file": "Nix.gitignore", "content": "================================================\n# Ignore build outputs from performing a nix-build or `nix build` command\nresult\nresult-*\n\n# Ignore automatically generated direnv output\n.direnv"}, {"id": "Node.gitignore_0", "file": "Node.gitignore", "content": "================================================\n# Logs\nlogs\n*.log\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\nlerna-debug.log*\n\n# Diagnostic reports (https://nodejs.org/api/report.html)\nreport.[0-9]*.[0-9]*.[0-9]*.[0-9]*.json\n\n# Runtime data\npids\n*.pid\n*.seed\n*.pid.lock\n\n# Directory for instrumented libs generated by jscoverage/JSCover\nlib-cov\n\n# Coverage directory used by tools like istanbul\ncoverage\n*.lcov\n\n# nyc test coverage\n.nyc_output\n\n# Grunt intermediate storage (https://gruntjs.com/creating-plugins#storing-task-files)\n.grunt\n\n# Bower dependency directory (https://bower.io/)\nbower_components\n\n# node-waf configuration\n.lock-wscript\n\n# Compiled binary addons (https://nodejs.org/api/addons.html)\nbuild/Release\n\n# Dependency directories\nnode_modules/\njspm_packages/"}, {"id": "Node.gitignore_1", "file": "Node.gitignore", "content": "build/Release\n\n# Dependency directories\nnode_modules/\njspm_packages/\n\n# Snowpack dependency directory (https://snowpack.dev/)\nweb_modules/\n\n# TypeScript cache\n*.tsbuildinfo\n\n# Optional npm cache directory\n.npm\n\n# Optional eslint cache\n.eslintcache\n\n# Optional stylelint cache\n.stylelintcache\n\n# Optional REPL history\n.node_repl_history\n\n# Output of 'npm pack'\n*.tgz\n\n# Yarn Integrity file\n.yarn-integrity\n\n# dotenv environment variable files\n.env\n.env.*\n!.env.example\n\n# parcel-bundler cache (https://parceljs.org/)\n.cache\n.parcel-cache\n\n# Next.js build output\n.next\nout\n\n# Nuxt.js build / generate output\n.nuxt\ndist\n.output\n\n# Gatsby files\n.cache/\n# Comment in the public line in if your project uses Gatsby and not Next.js\n# https://nextjs.org/blog/next-9-1#public-directory-support\n# public"}, {"id": "Node.gitignore_2", "file": "Node.gitignore", "content": "# https://nextjs.org/blog/next-9-1#public-directory-support\n# public\n\n# vuepress build output\n.vuepress/dist\n\n# vuepress v2.x temp and cache directory\n.temp\n.cache\n\n# Sveltekit cache directory\n.svelte-kit/\n\n# vitepress build output\n**/.vitepress/dist\n\n# vitepress cache directory\n**/.vitepress/cache\n\n# Docusaurus cache and generated files\n.docusaurus\n\n# Serverless directories\n.serverless/\n\n# FuseBox cache\n.fusebox/\n\n# DynamoDB Local files\n.dynamodb/\n\n# Firebase cache directory\n.firebase/\n\n# TernJS port file\n.tern-port\n\n# Stores VSCode versions used for testing VSCode extensions\n.vscode-test\n\n# yarn v3\n.pnp.*\n.yarn/*\n!.yarn/patches\n!.yarn/plugins\n!.yarn/releases\n!.yarn/sdks\n!.yarn/versions\n\n# Vite files\nvite.config.js.timestamp-*\nvite.config.ts.timestamp-*\n.vite/"}, {"id": "Objective-C.gitignore_0", "file": "Objective-C.gitignore", "content": "================================================\n# Xcode\n#\n# gitignore contributors: remember to update Global/Xcode.gitignore, Objective-C.gitignore & Swift.gitignore\n\n## User settings\nxcuserdata/\n\n## Obj-C/Swift specific\n*.hmap"}, {"id": "Objective-C.gitignore_1", "file": "Objective-C.gitignore", "content": "## App packaging\n*.ipa\n*.dSYM.zip\n*.dSYM\n\n# CocoaPods\n#\n# We recommend against adding the Pods directory to your .gitignore. However\n# you should judge for yourself, the pros and cons are mentioned at:\n# https://guides.cocoapods.org/using/using-cocoapods.html#should-i-check-the-pods-directory-into-source-control\n#\n# Pods/\n#\n# Add this line if you want to avoid checking in source code from the Xcode workspace\n# *.xcworkspace\n\n# Carthage\n#\n# Add this line if you want to avoid checking in source code from Carthage dependencies.\n# Carthage/Checkouts\n\nCarthage/Build/\n\n# fastlane\n#\n# It is recommended to not store the screenshots in the git repo.\n# Instead, use fastlane to re-generate the screenshots whenever they are needed.\n# For more information about the recommended setup visit:"}, {"id": "Objective-C.gitignore_2", "file": "Objective-C.gitignore", "content": "# For more information about the recommended setup visit:\n# https://docs.fastlane.tools/best-practices/source-control/#source-control\n\nfastlane/report.xml\nfastlane/Preview.html\nfastlane/screenshots/**/*.png\nfastlane/test_output"}, {"id": "OCaml.gitignore_0", "file": "OCaml.gitignore", "content": "================================================\n*.annot\n*.cmo\n*.cma\n*.cmi\n*.a\n*.o\n*.cmx\n*.cmxs\n*.cmxa\n\n# Files containing detailed information about the compilation (generated\n# by `ocamlc`/`ocamlopt` when invoked using the option `-bin-annot`).\n# These files are typically useful for code inspection tools\n# (e.g. Merlin).\n*.cmt\n*.cmti\n\n# ocamlbuild and Dune default working directory\n_build/\n\n# ocamlbuild targets\n*.byte\n*.native\n\n# oasis generated files\nsetup.data\nsetup.log\n\n# Merlin configuring file for Vim and Emacs\n.merlin\n\n# Dune generated files\n*.install\n\n# Local OPAM switch\n_opam/"}, {"id": "Opa.gitignore_0", "file": "Opa.gitignore", "content": "================================================\n_build\n_tracks\n\nopa-debug-js\n\n*.opp\n*.opx\n*.opx.broken\n*.dump\n*.api\n*.api-txt\n*.exe\n*.log"}, {"id": "OpenCart.gitignore_0", "file": "OpenCart.gitignore", "content": "================================================\n.htaccess\n/config.php\nadmin/config.php\n\n!index.html\n\ndownload/\nimage/data/\nimage/cache/\nsystem/cache/\nsystem/logs/\n\nsystem/storage/\n\n# vQmod log files\nvqmod/logs/*\n# vQmod cache files\nvqmod/vqcache/*\nvqmod/checked.cache\nvqmod/mods.cache"}, {"id": "OracleForms.gitignore_0", "file": "OracleForms.gitignore", "content": "================================================\n# Compiled Form Modules\n*.fmx\n\n# Compiled Menu Modules\n*.mmx\n\n# Compiled Pre-Linked Libraries\n*.plx"}, {"id": "Packer.gitignore_0", "file": "Packer.gitignore", "content": "================================================\n# Cache objects\npacker_cache/\n\n# Crash log\ncrash.log\n\n# https://www.packer.io/guides/hcl/variables\n# Exclude all .pkrvars.hcl files, which are likely to contain sensitive data,\n# such as password, private keys, and other secrets. These should not be part of\n# version control as they are data points which are potentially sensitive and\n# subject to change depending on the environment.\n#\n*.pkrvars.hcl\n\n# For built boxes\n*.box"}, {"id": "Perl.gitignore_0", "file": "Perl.gitignore", "content": "================================================\n!Build/\n.last_cover_stats\n/META.yml\n/META.json\n/MYMETA.*\n*.o\n*.pm.tdy\n*.bs\n\n# Devel::Cover\ncover_db/\n\n# Devel::NYTProf\nnytprof.out\n\n# Dist::Zilla\n/.build/\n\n# Module::Build\n_build/\nBuild\nBuild.bat\n\n# Module::Install\ninc/\n\n# ExtUtils::MakeMaker\n/blib/\n/_eumm/\n/*.gz\n/Makefile\n/Makefile.old\n/MANIFEST.bak\n/pm_to_blib\n/*.zip\n\n# Carton/Carmel\n/local/\n/.carmel/\n# cpanfile.snapshot should generally be ignored for library code, otherwise included\n# cpanfile.snapshot"}, {"id": "Phalcon.gitignore_0", "file": "Phalcon.gitignore", "content": "================================================\n/cache/\n/config/development/"}, {"id": "PlayFramework.gitignore_0", "file": "PlayFramework.gitignore", "content": "================================================\n# Ignore Play! working directory #\nbin/\n/db\n.eclipse\n/lib/\n/logs/\n/modules\n/project/project\n/project/target\n/target\ntmp/\ntest-result\nserver.pid\n*.eml\n/dist/\n.cache"}, {"id": "Plone.gitignore_0", "file": "Plone.gitignore", "content": "================================================\n*.pyc\n*.pyo\n*.tmp*\n*.mo\n*.egg\n*.EGG\n*.egg-info\n*.EGG-INFO\n.*.cfg\nbin/\nbuild/\ndevelop-eggs/\ndownloads/\neggs/\nfake-eggs/\nparts/\ndist/\nvar/"}, {"id": "Prestashop.gitignore_0", "file": "Prestashop.gitignore", "content": "================================================\n# Cache, temp and personal files\n\n/.htaccess\n*.log\n\n# Cache\n/cache/*\n!/cache/.htaccess\n!/cache/cachefs/index.php\n!/cache/deprecated.txt\n!/cache/index.php\n!/cache/purifier/index.php\n!/cache/push/activity\n!/cache/push/index.php\n!/cache/push/trends\n!/cache/sandbox/index.php\n!/cache/smarty/cache/index.php\n!/cache/smarty/compile/index.php\n!/cache/smarty/index.php\n!/cache/tcpdf/index.php\n\n# Download\n/download/*\n!/download/.htaccess\n!/download/index.php\n\n# Images\n/img/*\n!/img/.htaccess\n!/img/index.php\n!/img/404.gif\n!/img/bg_500.png\n!/img/bg_loader.png\n!/img/favicon.ico\n!/img/loader.gif\n!/img/loadingAnimation.gif\n!/img/logo.jpg\n!/img/logo.png\n!/img/logo_invoice.jpg\n!/img/logo_stores.png\n!/img/macFFBgHack.png\n!/img/prestashop-avatar.png"}, {"id": "Prestashop.gitignore_1", "file": "Prestashop.gitignore", "content": "!/img/logo_invoice.jpg\n!/img/logo_stores.png\n!/img/macFFBgHack.png\n!/img/prestashop-avatar.png\n!/img/prestashop@2x.png\n!/img/preston-login-wink@2x.png\n!/img/preston-login@2x.png\n!/img/questionmark.png\n!/img/genders/index.php\n!/img/admin/index.php\n!/img/c/index.php\n!/img/cms/index.php\n!/img/co/index.php\n!/img/jquery-ui\n!/img/l/index.php\n!/img/m/index.php\n!/img/os/index.php\n!/img/p/index.php\n!/img/s/index.php\n!/img/scenes\n!/img/st/index.php\n!/img/su/index.php\n!/img/t/index.php\n!/img/tmp/index.php\n\n# Upload\n/upload/*\n!/upload/.htaccess\n\n/vendor/*\n/docs/phpdoc-sf/\n/composer.lock\n*.hot-update.js\n*.hot-update.json\n\n\n/admin-dev/autoupgrade/*\n!/admin-dev/autoupgrade/index.php\n!/admin-dev/autoupgrade/backup/index.php\n\n/admin-dev/backups/*\n!/admin-dev/backups/.htaccess\n\n/admin-dev/import/*"}, {"id": "Prestashop.gitignore_2", "file": "Prestashop.gitignore", "content": "/admin-dev/backups/*\n!/admin-dev/backups/.htaccess\n\n/admin-dev/import/*\n!/admin-dev/import/.htaccess\n!/admin-dev/import/index.php\n\n/admin-dev/export/*\n!/admin-dev/export/.htaccess\n!/admin-dev/export/index.php\n\n# Downloaded RTL files\n/admin-dev/themes/default/css/bundle/default_rtl.css\n/admin-dev/themes/default/css/bundle/shared_rtl.css\n/admin-dev/themes/default/css/font_rtl.css\n/admin-dev/themes/default/css/overrides_rtl.css\n/admin-dev/themes/default/css/vendor/font-awesome/font-awesome_rtl.css\n/admin-dev/themes/default/css/vendor/nv.d3_rtl.css\n/admin-dev/themes/default/css/vendor/titatoggle-min_rtl.css\n/admin-dev/themes/default/public/theme_rtl.css\n/admin-dev/themes/new-theme/css/module/drop_rtl.css\n/admin-dev/themes/new-theme/css/right-sidebar_rtl.css\n\nthemes/*/cache/*\n\n# Config"}, {"id": "Prestashop.gitignore_3", "file": "Prestashop.gitignore", "content": "/admin-dev/themes/new-theme/css/right-sidebar_rtl.css\n\nthemes/*/cache/*\n\n# Config\n\nconfig/settings.inc.php\nconfig/settings.old.php\nconfig/xml/*\nconfig/themes/*\n!config/xml/themes/default.xml\nthemes/*/config/settings_*.json\napp/config/parameters.old.yml\napp/config/config.php\n\n# Themes, modules and overrides\n\nmodules/*\noverride/*\nthemes/*/\n!themes/classic\n!themes/_core\n!themes/_libraries\n\n# Vendors and dependencies\n\nbower_components/\nnode_modules/\ncomposer.phar\nphp-cs-fixer\n.grunt/*\n\n# Translations and emails templates\n\ntranslations/*\nmails/*\n!mails/themes/\n!mails/_partials/\nthemes/default-bootstrap/lang/*\nthemes/default-bootstrap/modules/*/translations/*.php\nthemes/default-bootstrap/mails/*\n!themes/default-bootstrap/mails/en/\nthemes/default-bootstrap/modules/*/mails/*"}, {"id": "Prestashop.gitignore_4", "file": "Prestashop.gitignore", "content": "!themes/default-bootstrap/mails/en/\nthemes/default-bootstrap/modules/*/mails/*\n!themes/default-bootstrap/modules/*/mails/en\n\n# MISC\n\n*sitemap.xml\n/robots.txt\n\n# Symfony\n\n/bin/\n/app/Resources/geoip/GeoLite2-City.mmdb\n/app/Resources/translations/*\n!/app/Resources/translations/default\n/app/config/parameters.yml\n/app/config/parameters.php\n/build/\n/phpunit.xml\n/var/*\n!/var/cache\n/var/cache/*\n!var/cache/.gitkeep\n!/var/logs\n/var/logs/*\n!var/logs/.gitkeep\n!/var/sessions\n/var/sessions/*\n!var/sessions/.gitkeep\n!var/SymfonyRequirements.php\n/vendor/\n/web/bundles/"}, {"id": "Processing.gitignore_0", "file": "Processing.gitignore", "content": "================================================\n.DS_Store\napplet\napplication.linux-arm64\napplication.linux-armv6hf\napplication.linux32\napplication.linux64\napplication.windows32\napplication.windows64\napplication.macosx\nout"}, {"id": "PureScript.gitignore_0", "file": "PureScript.gitignore", "content": "================================================\n# Dependencies\n.psci_modules\n.spago\nbower_components\nnode_modules\n\n# Generated files\n.psci\noutput"}, {"id": "Python.gitignore_0", "file": "Python.gitignore", "content": "================================================\n# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[codz]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py.cover\n.hypothesis/\n.pytest_cache/\ncover/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log"}, {"id": "Python.gitignore_1", "file": "Python.gitignore", "content": "*.py.cover\n.hypothesis/\n.pytest_cache/\ncover/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\n.pybuilder/\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n#   For a library or package, you might want to ignore these files since the code is\n#   intended to run in multiple environments; otherwise, check them in:\n# .python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies"}, {"id": "Python.gitignore_2", "file": "Python.gitignore", "content": "#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\n#Pipfile.lock\n\n# UV\n#   Similar to Pipfile.lock, it is generally recommended to include uv.lock in version control.\n#   This is especially recommended for binary packages to ensure reproducibility, and is more\n#   commonly ignored for libraries.\n#uv.lock\n\n# poetry\n#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.\n#   This is especially recommended for binary packages to ensure reproducibility, and is more\n#   commonly ignored for libraries."}, {"id": "Python.gitignore_3", "file": "Python.gitignore", "content": "#   commonly ignored for libraries.\n#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control\n#poetry.lock\n#poetry.toml\n\n# pdm\n#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.\n#   pdm recommends including project-wide configuration in pdm.toml, but excluding .pdm-python.\n#   https://pdm-project.org/en/latest/usage/project/#working-with-version-control\n#pdm.lock\n#pdm.toml\n.pdm-python\n.pdm-build/\n\n# pixi\n#   Similar to Pipfile.lock, it is generally recommended to include pixi.lock in version control.\n#pixi.lock\n#   Pixi creates a virtual environment in the .pixi directory, just like venv module creates one\n#   in the .venv directory. It is recommended not to include this directory in version control.\n.pixi"}, {"id": "Python.gitignore_4", "file": "Python.gitignore", "content": ".pixi\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# Redis\n*.rdb\n*.aof\n*.pid\n\n# RabbitMQ\nmnesia/\nrabbitmq/\nrabbitmq-data/\n\n# ActiveMQ\nactivemq-data/\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.envrc\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n# pytype static type analyzer\n.pytype/\n\n# Cython debug symbols\ncython_debug/\n\n# PyCharm\n#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can"}, {"id": "Python.gitignore_5", "file": "Python.gitignore", "content": "# PyCharm\n#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can\n#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore\n#  and can be added to the global gitignore or merged into this file.  For a more nuclear\n#  option (not recommended) you can uncomment the following to ignore the entire idea folder.\n#.idea/\n\n# Abstra\n# Abstra is an AI-powered process automation framework.\n# Ignore directories containing user credentials, local state, and settings.\n# Learn more at https://abstra.io/docs\n.abstra/\n\n# Visual Studio Code\n#  Visual Studio Code specific template is maintained in a separate VisualStudioCode.gitignore\n#  that can be found at https://github.com/github/gitignore/blob/main/Global/VisualStudioCode.gitignore"}, {"id": "Python.gitignore_6", "file": "Python.gitignore", "content": "#  and can be added to the global gitignore or merged into this file. However, if you prefer,\n#  you could uncomment the following to ignore the entire vscode folder\n# .vscode/\n\n# Ruff stuff:\n.ruff_cache/\n\n# PyPI configuration file\n.pypirc\n\n# Marimo\nmarimo/_static/\nmarimo/_lsp/\n__marimo__/\n\n# Streamlit\n.streamlit/secrets.toml"}, {"id": "Qooxdoo.gitignore_0", "file": "Qooxdoo.gitignore", "content": "================================================\ncache\ncache-downloads\ninspector\napi\nsource/inspector.html"}, {"id": "Qt.gitignore_0", "file": "Qt.gitignore", "content": "================================================\n# C++ objects and libs\n*.slo\n*.lo\n*.o\n*.a\n*.la\n*.lai\n*.so\n*.so.*\n*.dll\n*.dylib\n\n# Qt-es\nobject_script.*.Release\nobject_script.*.Debug\n*_plugin_import.cpp\n/.qmake.cache\n/.qmake.stash\n*.pro.user\n*.pro.user.*\n*.qbs.user\n*.qbs.user.*\n*.moc\nmoc_*.cpp\nmoc_*.h\nqrc_*.cpp\nui_*.h\n*.qmlc\n*.jsc\nMakefile*\n*build-*\n*.qm\n*.prl\n\n# Qt unit tests\ntarget_wrapper.*\n\n# QtCreator\n*.autosave\n\n# QtCreator Qml\n*.qmlproject.user\n*.qmlproject.user.*\n\n# QtCreator CMake\nCMakeLists.txt.user*\n\n# QtCreator 4.8< compilation database\ncompile_commands.json\n\n# QtCreator local machine specific files for imported projects\n*creator.user*\n\n*_qmlcache.qrc"}, {"id": "R.gitignore_0", "file": "R.gitignore", "content": "================================================\n# History files\n.Rhistory\n.Rapp.history\n\n# Session Data files\n.RData\n.RDataTmp\n\n# User-specific files\n.Ruserdata\n\n# Example code in package build process\n*-Ex.R\n\n# Output files from R CMD build\n/*.tar.gz\n\n# Output files from R CMD check\n/*.Rcheck/\n\n# RStudio files\n.Rproj.user/\n\n# produced vignettes\nvignettes/*.html\nvignettes/*.pdf\n\n# OAuth2 token, see https://github.com/hadley/httr/releases/tag/v0.3\n.httr-oauth\n\n# knitr and R markdown default cache directories\n*_cache/\n/cache/\n\n# Temporary files created by R markdown\n*.utf8.md\n*.knit.md\n\n# R Environment Variables\n.Renviron\n\n# pkgdown site\ndocs/\n\n# translation temp files\npo/*~\n\n# RStudio Connect folder\nrsconnect/"}, {"id": "Racket.gitignore_0", "file": "Racket.gitignore", "content": "================================================\n.DS_Store\ncompiled/\n/doc/\n*~\n*.bak\n\\#*\n.\\#*"}, {"id": "Rails.gitignore_0", "file": "Rails.gitignore", "content": "================================================\n*.rbc\ncapybara-*.html\n.rspec\n/db/*.sqlite3\n/db/*.sqlite3-journal\n/db/*.sqlite3-[0-9]*\n/public/system\n/coverage/\n/spec/tmp\n*.orig\nrerun.txt\npickle-email-*.html\n\n# Ignore all logfiles and tempfiles.\n/log/*\n/tmp/*\n!/log/.keep\n!/tmp/.keep\n\n# TODO Comment out this rule if you are OK with secrets being uploaded to the repo\nconfig/initializers/secret_token.rb\nconfig/master.key\n\n# Only include if you have production secrets in this file, which is no longer a Rails default\n# config/secrets.yml\n\n# dotenv, dotenv-rails\n# TODO Comment out these rules if environment variables can be committed\n.env\n.env*.local"}, {"id": "Rails.gitignore_1", "file": "Rails.gitignore", "content": "## Environment normalization:\n/.bundle\n/vendor/bundle\n\n# these should all be checked in to normalize the environment:\n# Gemfile.lock, .ruby-version, .ruby-gemset\n\n# unless supporting rvm < 1.11.0 or doing something fancy, ignore this:\n.rvmrc\n\n# if using bower-rails ignore default bower_components path bower.json files\n/vendor/assets/bower_components\n*.bowerrc\nbower.json\n\n# Ignore pow environment settings\n.powenv\n\n# Ignore Byebug command history file.\n.byebug_history\n\n# Ignore node_modules\nnode_modules/\n\n# Ignore precompiled javascript packs\n/public/packs\n/public/packs-test\n/public/assets\n\n# Ignore yarn files\n/yarn-error.log\nyarn-debug.log*\n.yarn-integrity\n\n# Ignore uploaded files in development\n/storage/*\n!/storage/.keep\n/public/uploads"}, {"id": "Raku.gitignore_0", "file": "Raku.gitignore", "content": "================================================\n# Gitignore for Raku (https://raku.org)\n# As part of https://github.com/github/gitignore\n\n# precompiled files\n.precomp\nlib/.precomp"}, {"id": "ReScript.gitignore_0", "file": "ReScript.gitignore", "content": "================================================\n/node_modules/\n/lib/\n.bsb.lock"}, {"id": "RhodesRhomobile.gitignore_0", "file": "RhodesRhomobile.gitignore", "content": "================================================\nrholog-*\nsim-*\nbin/libs\nbin/RhoBundle\nbin/tmp\nbin/target\nbin/*.ap_\n*.o\n*.jar"}, {"id": "ROS.gitignore_0", "file": "ROS.gitignore", "content": "================================================\ndevel/\nlogs/\nbuild/\nbin/\nlib/\nmsg_gen/\nsrv_gen/\nmsg/*Action.msg\nmsg/*ActionFeedback.msg\nmsg/*ActionGoal.msg\nmsg/*ActionResult.msg\nmsg/*Feedback.msg\nmsg/*Goal.msg\nmsg/*Result.msg\nmsg/_*.py\nbuild_isolated/\ndevel_isolated/\n\n# Generated by dynamic reconfigure\n*.cfgc\n/cfg/cpp/\n/cfg/*.py\n\n# Ignore generated docs\n*.dox\n*.wikidoc\n\n# eclipse stuff\n.project\n.cproject\n\n# qcreator stuff\nCMakeLists.txt.user\n\nsrv/_*.py\n*.pcd\n*.pyc\nqtcreator-*\n*.user\n\n/planning/cfg\n/planning/docs\n/planning/src\n\n*~\n\n# Emacs\n.#*\n\n# Catkin custom files\nCATKIN_IGNORE"}, {"id": "Ruby.gitignore_0", "file": "Ruby.gitignore", "content": "================================================\n*.gem\n*.rbc\n/.config\n/coverage/\n/InstalledFiles\n/pkg/\n/spec/reports/\n/spec/examples.txt\n/test/tmp/\n/test/version_tmp/\n/tmp/\n\n# Used by dotenv library to load environment variables.\n# .env\n\n# Ignore Byebug command history file.\n.byebug_history\n\n## Specific to RubyMotion:\n.dat*\n.repl_history\nbuild/\n*.bridgesupport\nbuild-iPhoneOS/\nbuild-iPhoneSimulator/\n\n## Specific to RubyMotion (use of CocoaPods):\n#\n# We recommend against adding the Pods directory to your .gitignore. However\n# you should judge for yourself, the pros and cons are mentioned at:\n# https://guides.cocoapods.org/using/using-cocoapods.html#should-i-check-the-pods-directory-into-source-control\n#\n# vendor/Pods/"}, {"id": "Ruby.gitignore_1", "file": "Ruby.gitignore", "content": "## Documentation cache and generated files:\n/.yardoc/\n/_yardoc/\n/doc/\n/rdoc/\n\n## Environment normalization:\n/.bundle/\n/vendor/bundle\n/lib/bundler/man/\n\n# for a library or gem, you might want to ignore these files since the code is\n# intended to run in multiple environments; otherwise, check them in:\n# Gemfile.lock\n# .ruby-version\n# .ruby-gemset\n\n# unless supporting rvm < 1.11.0 or doing something fancy, ignore this:\n.rvmrc\n\n# Used by RuboCop. Remote config files pulled in from inherit_from directive.\n# .rubocop-https?--*"}, {"id": "Rust.gitignore_0", "file": "Rust.gitignore", "content": "================================================\n# Generated by Cargo\n# will have compiled files and executables\ndebug\ntarget\n\n# These are backup files generated by rustfmt\n**/*.rs.bk\n\n# MSVC Windows builds of rustc generate these, which store debugging information\n*.pdb\n\n# Generated by cargo mutants\n# Contains mutation testing data\n**/mutants.out*/\n\n# RustRover\n#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can\n#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore\n#  and can be added to the global gitignore or merged into this file.  For a more nuclear\n#  option (not recommended) you can uncomment the following to ignore the entire idea folder.\n#.idea/"}, {"id": "Salesforce.gitignore_0", "file": "Salesforce.gitignore", "content": "================================================\n# This file is used for Git repositories to specify intentionally untracked files that Git should ignore. \n# If you are not using git, you can delete this file. For more information see: https://git-scm.com/docs/gitignore\n# For useful gitignore templates see: https://github.com/github/gitignore\n\n# Salesforce cache\n.sf/\n.sfdx/\n.localdevserver/\ndeploy-options.json\n.localdev\n\n# LWC VSCode autocomplete\n**/lwc/jsconfig.json\n\n# LWC Jest coverage reports\ncoverage/\n\n# Logs\nlogs\n*.log\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\n\n# Eslint cache\n.eslintcache\n\n# Windows system files\nThumbs.db\nehthumbs.db\n[Dd]esktop.ini\n$RECYCLE.BIN/\n\n# Salesforce Analyzer results\nsca-results.csv\nsfca_results.json\n\n# Local environment variables\n.env"}, {"id": "Sass.gitignore_0", "file": "Sass.gitignore", "content": "================================================\n.sass-cache/\n*.css.map\n*.sass.map\n*.scss.map"}, {"id": "Scala.gitignore_0", "file": "Scala.gitignore", "content": "================================================\n*.class\n*.log\n\n# virtual machine crash logs, see http://www.java.com/en/download/help/error_hotspot.xml\nhs_err_pid*"}, {"id": "Scheme.gitignore_0", "file": "Scheme.gitignore", "content": "================================================\n*.ss~\n*.ss#*\n.#*.ss\n\n*.scm~\n*.scm#*\n.#*.scm"}, {"id": "SCons.gitignore_0", "file": "SCons.gitignore", "content": "================================================\n# for projects that use SCons for building: http://http://www.scons.org/\n.sconsign.dblite\n\n# When configure fails, SCons outputs these\nconfig.log\n.sconf_temp"}, {"id": "Scrivener.gitignore_0", "file": "Scrivener.gitignore", "content": "================================================\n*/Files/binder.autosave\n*/Files/binder.backup\n*/Files/search.indexes\n*/Files/user.lock\n*/Files/Docs/docs.checksum\n*/Files/Data/docs.checksum\n*/QuickLook/\n*/Settings/ui.plist"}, {"id": "Sdcc.gitignore_0", "file": "Sdcc.gitignore", "content": "================================================\n# SDCC stuff\n*.lnk\n*.lst\n*.map\n*.mem\n*.rel\n*.rst\n*.sym"}, {"id": "SeamGen.gitignore_0", "file": "SeamGen.gitignore", "content": "================================================\n/bootstrap/data\n/bootstrap/tmp\n/classes/\n/dist/\n/exploded-archives/\n/test-build/\n/test-output/\n/test-report/\n/target/\ntemp-testng-customsuite.xml\n\n# based on http://stackoverflow.com/a/8865858/422476 I am removing inline comments\n\n#/classes/  \t\t              all class files\n#/dist/                       contains generated war files for deployment\n#/exploded-archives/\t\t      war content generation during deploy (or explode)\n#/test-build/                 test compilation (ant target for Seam)\n#/test-output/                test results\n#/test-report/                test report generation for, e.g., Hudson\n#/target/                     maven output folder\n#temp-testng-customsuite.xml\tgenerated when running test cases under Eclipse"}, {"id": "SeamGen.gitignore_1", "file": "SeamGen.gitignore", "content": "#temp-testng-customsuite.xml\tgenerated when running test cases under Eclipse\n\n# Thanks to @VonC and @kraftan for their helpful answers on a related question\n# on StackOverflow.com:\n# http://stackoverflow.com/questions/4176687\n# /what-is-the-recommended-source-control-ignore-pattern-for-seam-projects"}, {"id": "SketchUp.gitignore_0", "file": "SketchUp.gitignore", "content": "================================================\n*.skb"}, {"id": "Smalltalk.gitignore_0", "file": "Smalltalk.gitignore", "content": "================================================\n# changes file\n*.changes\n*.chg\n\n# system image\n*.image\n*.img7\n*.img\n\n# Pharo Smalltalk Debug log file\nPharoDebug.log\n\n# Squeak Smalltalk Debug log file\nSqueakDebug.log\n\n# Dolphin Smalltalk source file\n*.sml\n\n# Dolphin Smalltalk error file\n*.errors\n\n# Monticello package cache\n/package-cache\n\n# playground cache\n/play-cache\n/play-stash\n\n# Metacello-github cache\n/github-cache\ngithub-*.zip"}, {"id": "Solidity-Remix.gitignore_0", "file": "Solidity-Remix.gitignore", "content": "================================================\n# Remix compiler artifacts\n**/artifacts/\n**/artifacts/**\n\n# Remix plugin state folders\ndeps/\nstates/\n\n# Debug info\n*.dbg.json\n*.tsbuildinfo\n\n# Optional\n.env\n.env.local"}, {"id": "SSDT-sqlproj.gitignore_0", "file": "SSDT-sqlproj.gitignore", "content": "================================================\n## Ignore Visual Studio SSDT sqlproj specific temporary files, build results, etc\n##\n##\n## Get latest from https://github.com/github/gitignore/blob/master/SSDT-sqlproj.gitignore\n# Build output\nbin/\nobj/\n\n# DACPAC files\n*.dacpac\n\n# Publish profiles (optional, if environment-specific)\n*.publish.xml\n\n# SQL Server debug files\n*.dbmdl\n*.sqlcmdvars\n\n# Visual Studio settings\n.vs/\n\n# User-specific files\n*.user\n*.suo\n*.userosscache\n*.sln.docstates\n\n# Backup files\n*.bak\n*.log"}, {"id": "Stella.gitignore_0", "file": "Stella.gitignore", "content": "================================================\n# Atari 2600 (Stella) support for multiple assemblers\n# - DASM\n# - CC65\n\n# Assembled binaries and object directories\nobj/\na.out\n*.bin\n*.a26\n\n# Add in special Atari 7800-based binaries for good measure\n*.a78"}, {"id": "SugarCRM.gitignore_0", "file": "SugarCRM.gitignore", "content": "================================================"}, {"id": "SugarCRM.gitignore_1", "file": "SugarCRM.gitignore", "content": "## SugarCRM\n# Ignore custom .htaccess stuff.\n/.htaccess\n# Ignore the cache directory completely.\n# This will break the current behaviour. Which was often leading to\n# the misuse of the repository as backup replacement.\n# For development the cache directory can be safely ignored and\n# therefore it is ignored.\n/cache/*\n!/cache/index.html\n# Ignore some files and directories from the custom directory.\n/custom/history/\n/custom/modulebuilder/\n/custom/working/\n/custom/modules/*/Ext/\n/custom/application/Ext/\n# Custom configuration should also be ignored.\n/config.php\n/config_override.php\n# The silent upgrade scripts aren't needed.\n/silentUpgrade*.php\n# Logs files can safely be ignored.\n*.log\n# Ignore the new upload directories.\n/upload/*\n!/upload/index.html\n/upload_backup/"}, {"id": "Swift.gitignore_0", "file": "Swift.gitignore", "content": "================================================\n# Xcode\n#\n# gitignore contributors: remember to update Global/Xcode.gitignore, Objective-C.gitignore & Swift.gitignore\n\n## User settings\nxcuserdata/\n\n## Obj-C/Swift specific\n*.hmap\n\n## App packaging\n*.ipa\n*.dSYM.zip\n*.dSYM"}, {"id": "Swift.gitignore_1", "file": "Swift.gitignore", "content": "## Playgrounds\ntimeline.xctimeline\nplayground.xcworkspace\n\n# Swift Package Manager\n#\n# Add this line if you want to avoid checking in source code from Swift Package Manager dependencies.\n# Packages/\n# Package.pins\n# Package.resolved\n# *.xcodeproj\n#\n# Xcode automatically generates this directory with a .xcworkspacedata file and xcuserdata\n# hence it is not needed unless you have added a package configuration file to your project\n# .swiftpm\n\n.build/\n\n# CocoaPods\n#\n# We recommend against adding the Pods directory to your .gitignore. However\n# you should judge for yourself, the pros and cons are mentioned at:\n# https://guides.cocoapods.org/using/using-cocoapods.html#should-i-check-the-pods-directory-into-source-control\n#\n# Pods/\n#"}, {"id": "Swift.gitignore_2", "file": "Swift.gitignore", "content": "#\n# Pods/\n#\n# Add this line if you want to avoid checking in source code from the Xcode workspace\n# *.xcworkspace\n\n# Carthage\n#\n# Add this line if you want to avoid checking in source code from Carthage dependencies.\n# Carthage/Checkouts\n\nCarthage/Build/\n\n# fastlane\n#\n# It is recommended to not store the screenshots in the git repo.\n# Instead, use fastlane to re-generate the screenshots whenever they are needed.\n# For more information about the recommended setup visit:\n# https://docs.fastlane.tools/best-practices/source-control/#source-control\n\nfastlane/report.xml\nfastlane/Preview.html\nfastlane/screenshots/**/*.png\nfastlane/test_output"}, {"id": "Symfony.gitignore_0", "file": "Symfony.gitignore", "content": "================================================\n# Cache and logs (Symfony2)\n/app/cache/*\n/app/logs/*\n!app/cache/.gitkeep\n!app/logs/.gitkeep\n\n# Email spool folder\n/app/spool/*\n\n# Cache, session files and logs (Symfony3)\n/var/cache/*\n/var/logs/*\n/var/sessions/*\n!var/cache/.gitkeep\n!var/logs/.gitkeep\n!var/sessions/.gitkeep\n\n# Logs (Symfony4)\n/var/log/*\n!var/log/.gitkeep\n\n# Parameters\n/app/config/parameters.yml\n/app/config/parameters.ini\n\n# Managed by Composer\n/app/bootstrap.php.cache\n/var/bootstrap.php.cache\n/bin/*\n!bin/console\n!bin/symfony_requirements\n/vendor/\n\n# Assets and user uploads\n/web/bundles/\n/web/uploads/\n\n# PHPUnit\n/app/phpunit.xml\n/phpunit.xml\n\n# Build data\n/build/\n\n# Composer PHAR\n/composer.phar\n\n# Backup entities generated with doctrine:generate:entities command\n**/Entity/*~"}, {"id": "Symfony.gitignore_1", "file": "Symfony.gitignore", "content": "/composer.phar\n\n# Backup entities generated with doctrine:generate:entities command\n**/Entity/*~\n\n# Embedded web-server pid file\n/.web-server-pid"}, {"id": "SymphonyCMS.gitignore_0", "file": "SymphonyCMS.gitignore", "content": "================================================\nmanifest/cache/\nmanifest/logs/\nmanifest/tmp/\nsymphony/\nworkspace/uploads/\ninstall-log.txt"}, {"id": "Terraform.gitignore_0", "file": "Terraform.gitignore", "content": "================================================\n# Local .terraform directories\n.terraform/\n\n# .tfstate files\n*.tfstate\n*.tfstate.*\n\n# Crash log files\ncrash.log\ncrash.*.log\n\n# Exclude all .tfvars files, which are likely to contain sensitive data, such as\n# password, private keys, and other secrets. These should not be part of version\n# control as they are data points which are potentially sensitive and subject\n# to change depending on the environment.\n*.tfvars\n*.tfvars.json\n\n# Ignore override files as they are usually used to override resources locally and so\n# are not checked in\noverride.tf\noverride.tf.json\n*_override.tf\n*_override.tf.json\n\n# Ignore transient lock info files created by terraform apply\n.terraform.tfstate.lock.info"}, {"id": "Terraform.gitignore_1", "file": "Terraform.gitignore", "content": "# Ignore transient lock info files created by terraform apply\n.terraform.tfstate.lock.info\n\n# Include override files you do wish to add to version control using negated pattern\n# !example_override.tf\n\n# Include tfplan files to ignore the plan output of command: terraform plan -out=tfplan\n# example: *tfplan*\n\n# Ignore CLI configuration files\n.terraformrc\nterraform.rc\n\n# Optional: ignore graph output files generated by `terraform graph`\n# *.dot\n\n# Optional: ignore plan files saved before destroying Terraform configuration\n# Uncomment the line below if you want to ignore planout files.\n# planout"}, {"id": "TestComplete.gitignore_0", "file": "TestComplete.gitignore", "content": "================================================\n# Test Complete ignore files: https://support.smartbear.com/viewarticle/68002/\n\n# Tester-specific Settings\n*.tcCFGExtender\n*.tcLS\n\n# Type library declarations\n*.tlb\n\n# Log files\n*.tcLogs\n\n# Backup files\n*.bak"}, {"id": "TeX.gitignore_0", "file": "TeX.gitignore", "content": "================================================\n## Core latex/pdflatex auxiliary files:\n*.aux\n*.lof\n*.log\n*.lot\n*.fls\n*.out\n*.toc\n*.fmt\n*.fot\n*.cb\n*.cb2\n.*.lb\n\n## Intermediate documents:\n*.dvi\n*.xdv\n*-converted-to.*\n# these rules might exclude image files for figures etc.\n# *.ps\n# *.eps\n# *.pdf\n\n## Generated if empty string is given at \"Please type another file name for output:\"\n.pdf\n\n## Bibliography auxiliary files (bibtex/biblatex/biber):\n*.bbl\n*.bbl-SAVE-ERROR\n*.bcf\n*.bcf-SAVE-ERROR\n*.blg\n*-blx.aux\n*-blx.bib\n*.run.xml\n\n## Build tool auxiliary files:\n*.fdb_latexmk\n*.synctex\n*.synctex(busy)\n*.synctex.gz\n*.synctex.gz(busy)\n*.pdfsync\n*.rubbercache\nrubber.cache\n\n## Build tool directories for auxiliary files\n# latexrun\nlatex.out/"}, {"id": "TeX.gitignore_1", "file": "TeX.gitignore", "content": "## Auxiliary and intermediate files from other packages:\n# algorithms\n*.alg\n*.loa\n\n# achemso\nacs-*.bib\n\n# amsthm\n*.thm\n\n# attachfile2\n*.atfi\n\n# beamer\n*.nav\n*.pre\n*.snm\n*.vrb\n\n# changes\n*.soc\n*.loc\n\n# comment\n*.cut\n\n# cprotect\n*.cpt\n\n# elsarticle (documentclass of Elsevier journals)\n*.spl\n\n# endnotes\n*.ent\n\n# fixme\n*.lox\n\n# feynmf/feynmp\n*.mf\n*.mp\n*.t[1-9]\n*.t[1-9][0-9]\n*.tfm\n\n#(r)(e)ledmac/(r)(e)ledpar\n*.end\n*.?end\n*.[1-9]\n*.[1-9][0-9]\n*.[1-9][0-9][0-9]\n*.[1-9]R\n*.[1-9][0-9]R\n*.[1-9][0-9][0-9]R\n*.eledsec[1-9]\n*.eledsec[1-9]R\n*.eledsec[1-9][0-9]\n*.eledsec[1-9][0-9]R\n*.eledsec[1-9][0-9][0-9]\n*.eledsec[1-9][0-9][0-9]R\n\n# glossaries\n*.acn\n*.acr\n*.glg\n*.glg-abr\n*.glo\n*.glo-abr\n*.gls\n*.gls-abr\n*.glsdefs\n*.lzo\n*.lzs\n*.slg\n*.slo\n*.sls"}, {"id": "TeX.gitignore_2", "file": "TeX.gitignore", "content": "*.acr\n*.glg\n*.glg-abr\n*.glo\n*.glo-abr\n*.gls\n*.gls-abr\n*.glsdefs\n*.lzo\n*.lzs\n*.slg\n*.slo\n*.sls\n\n# uncomment this for glossaries-extra (will ignore makeindex's style files!)\n# *.ist\n\n# gnuplot\n*.gnuplot\n*.table\n\n# gnuplottex\n*-gnuplottex-*\n\n# gregoriotex\n*.gaux\n*.glog\n*.gtex\n\n# htlatex\n*.4ct\n*.4tc\n*.idv\n*.lg\n*.trc\n*.xref\n\n# hypdoc\n*.hd\n\n# hyperref\n*.brf\n\n# knitr\n*-concordance.tex\n# TODO Uncomment the next line if you use knitr and want to ignore its generated tikz files\n# *.tikz\n*-tikzDictionary\n\n# latexindent will create succesive backup files by default\n#*.bak*\n\n# listings\n*.lol\n\n# luatexja-ruby\n*.ltjruby\n\n# makeidx\n*.idx\n*.ilg\n*.ind\n\n# minitoc\n*.maf\n*.mlf\n*.mlt\n*.mtc[0-9]*\n*.slf[0-9]*\n*.slt[0-9]*\n*.stc[0-9]*\n\n# minted\n_minted*\n*.data.minted\n*.pyg\n\n# morewrites\n*.mw\n\n# newpax\n*.newpax"}, {"id": "TeX.gitignore_3", "file": "TeX.gitignore", "content": "*.stc[0-9]*\n\n# minted\n_minted*\n*.data.minted\n*.pyg\n\n# morewrites\n*.mw\n\n# newpax\n*.newpax\n\n# nomencl\n*.nlg\n*.nlo\n*.nls\n\n# pax\n*.pax\n\n# pdfpcnotes\n*.pdfpc\n\n# sagetex\n*.sagetex.sage\n*.sagetex.py\n*.sagetex.scmd\n\n# scrwfile\n*.wrt\n\n# spelling\n*.spell.bad\n*.spell.txt\n\n# svg\nsvg-inkscape/\n\n# sympy\n*.sout\n*.sympy\nsympy-plots-for-*.tex/\n\n# pdfcomment\n*.upa\n*.upb\n\n# pythontex\n*.pytxcode\npythontex-files-*/\n\n# tcolorbox\n*.listing\n\n# thmtools\n*.loe\n\n# TikZ & PGF\n*.dpth\n*.md5\n*.auxlock\n\n# titletoc\n*.ptc\n\n# todonotes\n*.tdo\n\n# vhistory\n*.hst\n*.ver\n\n# easy-todo\n*.lod\n\n# xcolor\n*.xcp\n\n# xmpincl\n*.xmpi\n\n# xindy\n*.xdy\n\n# xypic precompiled matrices and outlines\n*.xyc\n*.xyd\n\n# endfloat\n*.ttt\n*.fff\n\n# Latexian\nTSWLatexianTemp*"}, {"id": "TeX.gitignore_4", "file": "TeX.gitignore", "content": "## Editors:\n# WinEdt\n*.bak\n*.sav\n\n# latexindent.pl\n*.bak[0-9]*\n\n# Texpad\n.texpadtmp\n\n# LyX\n*.lyx~\n\n# Kile\n*.backup\n\n# gummi\n.*.swp\n\n# KBibTeX\n*~[0-9]*\n\n# TeXnicCenter\n*.tps\n\n# auto folder when using emacs and auctex\n./auto/*\n*.el\n\n# expex forward references with \\gathertags\n*-tags.tex\n\n# standalone packages\n*.sta\n\n# Makeindex log files\n*.lpz\n\n# xwatermark package\n*.xwm\n\n# REVTeX puts footnotes in the bibliography by default, unless the nofootinbib\n# option is specified. Footnotes are the stored in a file with suffix Notes.bib.\n# Uncomment the next line to have this generated file ignored.\n#*Notes.bib"}, {"id": "Textpattern.gitignore_0", "file": "Textpattern.gitignore", "content": "================================================\n.htaccess\ncss.php\nrpc/\nsites/site*/admin/\nsites/site*/private/\nsites/site*/public/admin/\nsites/site*/public/setup/\nsites/site*/public/theme/\ntextpattern/\nHISTORY.txt\nREADME.txt"}, {"id": "TurboGears2.gitignore_0", "file": "TurboGears2.gitignore", "content": "================================================\n*.py[co]\n\n# Default development database\ndevdata.db\n\n# Default data directory\ndata/*\n\n# Packages\n*.egg\n*.egg-info\ndist\nbuild\n\n# Installer logs\npip-log.txt\n\n# Unit test / coverage reports\n.coverage\n.tox"}, {"id": "TwinCAT3.gitignore_0", "file": "TwinCAT3.gitignore", "content": "================================================"}, {"id": "TwinCAT3.gitignore_1", "file": "TwinCAT3.gitignore", "content": "### TwinCAT3 ###\n# website: https://www.beckhoff.com/twincat3/\n\n# TwinCAT PLC\n*.plcproj.bak\n*.plcproj.orig\n*.tpy\n*.tclrs\n*.library\n*.compiled-library\n*.compileinfo\n*.asm\n*.core\nLineIDs.dbg\nLineIDs.dbg.bak\n\n# TwinCAT C++ and shared types\n# ignoring the TMC file is only useful for plain PLC programming\n# as soon as shared data types (via tmc), C++ or in general TcCom-Module are used, the TMC file has to be part of the repository\n*.tmc\n*.tmcRefac\n\n# TwinCAT project files\n*.tsproj.bak\n*.tsproj.b?k\n*.tsproj.orig\n*.tspproj.bak\n*.xti.bak\n*.xti.bk?\n*.xti.orig\n*.xtv\n*.xtv.bak\n*.xtv.bk?\n*.xt?.bk?\n*.xt?.orig\n\n# Multiuser specific\n**/.TcGit/\n\n# exclude not required folders\n**/_Boot/\n**/_CompileInfo/\n**/_Libraries/\n**/_ModuleInstall/\n**/_Deployment/\n**/_Repository/"}, {"id": "TwinCAT3.gitignore_2", "file": "TwinCAT3.gitignore", "content": "**/_Boot/\n**/_CompileInfo/\n**/_Libraries/\n**/_ModuleInstall/\n**/_Deployment/\n**/_Repository/\n\n\n# To include a specific library directory (i.e. third party/custom libs),\n# use pattern `!/**/_Libraries/<directory name>/` i.e. `!/**/_Libraries/www.tcunit.org/`\n#\n\n# VS Shell project specific files and folders\n**/.vs/\n*.~u\n*.project.~u\n*.suo"}, {"id": "Typo3.gitignore_0", "file": "Typo3.gitignore", "content": "================================================\n## TYPO3 v6.2\n# Ignore several upload and file directories.\n/fileadmin/user_upload/\n/fileadmin/_temp_/\n/fileadmin/_processed_/\n/uploads/\n# Ignore cache\n/typo3conf/temp_CACHED*\n/typo3conf/temp_fieldInfo.php\n/typo3conf/deprecation_*.log\n/typo3conf/ENABLE_INSTALL_TOOL\n/typo3conf/realurl_autoconf.php\n/FIRST_INSTALL\n# Ignore system folders, you should have them symlinked.\n# If not comment out the following entries.\n/typo3\n/typo3_src\n/typo3_src-*\n/Packages\n/.htaccess\n/index.php\n# Ignore temp directory.\n/typo3temp/"}, {"id": "Unity.gitignore_0", "file": "Unity.gitignore", "content": "================================================\n# This .gitignore file should be placed at the root of your Unity project directory\n#\n# Get latest from https://github.com/github/gitignore/blob/main/Unity.gitignore\n#\n.utmp/\n/[Ll]ibrary/\n/[Tt]emp/\n/[Oo]bj/\n/[Bb]uild/\n/[Bb]uilds/\n/[Ll]ogs/\n/[Uu]ser[Ss]ettings/\n*.log\n\n# By default unity supports Blender asset imports, *.blend1 blender files do not need to be commited to version control.\n*.blend1\n*.blend1.meta\n\n# MemoryCaptures can get excessive in size.\n# They also could contain extremely sensitive data\n/[Mm]emoryCaptures/\n\n# Recordings can get excessive in size\n/[Rr]ecordings/\n\n# Uncomment this line if you wish to ignore the asset store tools plugin\n# /[Aa]ssets/AssetStoreTools*\n\n# Autogenerated Jetbrains Rider plugin"}, {"id": "Unity.gitignore_1", "file": "Unity.gitignore", "content": "# /[Aa]ssets/AssetStoreTools*\n\n# Autogenerated Jetbrains Rider plugin\n/[Aa]ssets/Plugins/Editor/JetBrains*\n# Jetbrains Rider personal-layer settings\n*.DotSettings.user\n\n# Visual Studio cache directory\n.vs/\n\n# Gradle cache directory\n.gradle/\n\n# Autogenerated VS/MD/Consulo solution and project files\nExportedObj/\n.consulo/\n*.csproj\n*.unityproj\n*.sln\n*.suo\n*.tmp\n*.user\n*.userprefs\n*.pidb\n*.booproj\n*.svd\n*.pdb\n*.mdb\n*.opendb\n*.VC.db\n\n# Unity3D generated meta files\n*.pidb.meta\n*.pdb.meta\n*.mdb.meta\n\n# Unity3D generated file on crash reports\nsysinfo.txt\n\n# Mono auto generated files\nmono_crash.*\n\n# Builds\n*.apk\n*.aab\n*.unitypackage\n*.unitypackage.meta\n*.app\n\n# Crashlytics generated file\ncrashlytics-build.properties\n\n# TestRunner generated files\nInitTestScene*.unity*"}, {"id": "Unity.gitignore_2", "file": "Unity.gitignore", "content": "crashlytics-build.properties\n\n# TestRunner generated files\nInitTestScene*.unity*\n\n# Addressables default ignores, before user customizations\n/ServerData\n/[Aa]ssets/StreamingAssets/aa*\n/[Aa]ssets/AddressableAssetsData/link.xml*\n/[Aa]ssets/Addressables_Temp*\n# By default, Addressables content builds will generate addressables_content_state.bin\n# files in platform-specific subfolders, for example:\n# /Assets/AddressableAssetsData/OSX/addressables_content_state.bin\n/[Aa]ssets/AddressableAssetsData/*/*.bin*\n\n# Visual Scripting auto-generated files\n/[Aa]ssets/Unity.VisualScripting.Generated/VisualScripting.Flow/UnitOptions.db\n/[Aa]ssets/Unity.VisualScripting.Generated/VisualScripting.Flow/UnitOptions.db.meta\n/[Aa]ssets/Unity.VisualScripting.Generated/VisualScripting.Core/Property Providers"}, {"id": "Unity.gitignore_3", "file": "Unity.gitignore", "content": "/[Aa]ssets/Unity.VisualScripting.Generated/VisualScripting.Core/Property Providers\n/[Aa]ssets/Unity.VisualScripting.Generated/VisualScripting.Core/Property Providers.meta\n\n# Auto-generated scenes by play mode tests\n/[Aa]ssets/[Ii]nit[Tt]est[Ss]cene*.unity*"}, {"id": "UnrealEngine.gitignore_0", "file": "UnrealEngine.gitignore", "content": "================================================\n# Visual Studio 2015 user specific files\n.vs/\n\n# Compiled Object files\n*.slo\n*.lo\n*.o\n*.obj\n\n# Precompiled Headers\n*.gch\n*.pch\n\n# Compiled Dynamic libraries\n*.so\n*.dylib\n*.dll\n\n# Fortran module files\n*.mod\n\n# Compiled Static libraries\n*.lai\n*.la\n*.a\n*.lib\n\n# Executables\n*.exe\n*.out\n*.app\n*.ipa\n\n# These project files can be generated by the engine\n*.xcodeproj\n*.xcworkspace\n*.sln\n*.suo\n*.opensdf\n*.sdf\n*.VC.db\n*.VC.opendb\n.vsconfig\n\n# Precompiled Assets\nSourceArt/**/*.png\nSourceArt/**/*.tga\n\n# Binary Files\nBinaries/*\nPlugins/**/Binaries/*\n\n# Builds\nBuild/*\n\n# Whitelist PakBlacklist-<BuildConfiguration>.txt files\n!Build/*/\nBuild/*/**\n!Build/*/PakBlacklist*.txt\n\n# Don't ignore icon files in Build\n!Build/**/*.ico\n\n# Built data for maps"}, {"id": "UnrealEngine.gitignore_1", "file": "UnrealEngine.gitignore", "content": "# Don't ignore icon files in Build\n!Build/**/*.ico\n\n# Built data for maps\n*_BuiltData.uasset\n\n# Configuration files generated by the Editor\nSaved/*\n\n# Compiled source files for the engine to use\nIntermediate/*\nPlugins/**/Intermediate/*\n\n# Cache files for the editor to use\nDerivedDataCache/*"}, {"id": "VBA.gitignore_0", "file": "VBA.gitignore", "content": "================================================\n\n# Office temporary files\n~$*\n\n# Access database lock files (laccdb, ldb)\n*.[lL][aA][cC][cC][dD][bB]\n*.[lL][dD][bB]\n\n# The following sections constitute a list of Office file extensions that support VBA.\n# If you want to exclude Office files from your repo, uncomment the corresponding file extensions.\n\n# Excel (xls, xlsb, xlsm, xlt, xltm, xla, xlam)\n#*.[xX][lL][sS]\n#*.[xX][lL][sS][bB]\n#*.[xX][lL][sS][mM]\n#*.[xX][lL][tT]\n#*.[xX][lL][tT][mM]\n#*.[xX][lL][aA]\n#*.[xX][lL][aA][mM]\n\n# Word (doc, docm, dot, dotm)\n#*.[dD][oO][cC]\n#*.[dD][oO][cC][mM]\n#*.[dD][oO][tT]\n#*.[dD][oO][tT][mM]\n\n# Access (accda, accdb, accde, mdb, mde)\n#*.[aA][cC][cC][dD][aA]\n#*.[aA][cC][cC][dD][bB]\n#*.[aA][cC][cC][dD][eE]\n#*.[mM][dD][bB]\n#*.[mM][dD][eE]"}, {"id": "VBA.gitignore_1", "file": "VBA.gitignore", "content": "#*.[aA][cC][cC][dD][bB]\n#*.[aA][cC][cC][dD][eE]\n#*.[mM][dD][bB]\n#*.[mM][dD][eE]\n\n# PowerPoint (ppt, pptm, pot, potm, pps, ppsm)\n#*.[pP][pP][tT]\n#*.[pP][pP][tT][mM]\n#*.[pP][oO][tT]\n#*.[pP][oO][tT][mM]\n#*.[pP][pP][sS]\n#*.[pP][pP][sS][mM]"}, {"id": "VisualStudio.gitignore_0", "file": "VisualStudio.gitignore", "content": "================================================\n## Ignore Visual Studio temporary files, build results, and\n## files generated by popular Visual Studio add-ons.\n##"}, {"id": "VisualStudio.gitignore_1", "file": "VisualStudio.gitignore", "content": "## Get latest from https://github.com/github/gitignore/blob/main/VisualStudio.gitignore\n\n# User-specific files\n*.rsuser\n*.suo\n*.user\n*.userosscache\n*.sln.docstates\n*.env\n\n# User-specific files (MonoDevelop/Xamarin Studio)\n*.userprefs\n\n# Mono auto generated files\nmono_crash.*\n\n# Build results\n[Dd]ebug/\n[Dd]ebugPublic/\n[Rr]elease/\n[Rr]eleases/\n\n[Dd]ebug/x64/\n[Dd]ebugPublic/x64/\n[Rr]elease/x64/\n[Rr]eleases/x64/\nbin/x64/\nobj/x64/\n\n[Dd]ebug/x86/\n[Dd]ebugPublic/x86/\n[Rr]elease/x86/\n[Rr]eleases/x86/\nbin/x86/\nobj/x86/\n\n[Ww][Ii][Nn]32/\n[Aa][Rr][Mm]/\n[Aa][Rr][Mm]64/\n[Aa][Rr][Mm]64[Ee][Cc]/\nbld/\n[Oo]bj/\n[Oo]ut/\n[Ll]og/\n[Ll]ogs/\n\n# Build results on 'Bin' directories\n**/[Bb]in/*\n# Uncomment if you have tasks that rely on *.refresh files to move binaries"}, {"id": "VisualStudio.gitignore_2", "file": "VisualStudio.gitignore", "content": "**/[Bb]in/*\n# Uncomment if you have tasks that rely on *.refresh files to move binaries\n# (https://github.com/github/gitignore/pull/3736)\n#!**/[Bb]in/*.refresh\n\n# Visual Studio 2015/2017 cache/options directory\n.vs/\n# Uncomment if you have tasks that create the project's static files in wwwroot\n#wwwroot/\n\n# Visual Studio 2017 auto generated files\nGenerated\\ Files/\n\n# MSTest test Results\n[Tt]est[Rr]esult*/\n[Bb]uild[Ll]og.*\n*.trx\n\n# NUnit\n*.VisualState.xml\nTestResult.xml\nnunit-*.xml\n\n# Approval Tests result files\n*.received.*\n\n# Build Results of an ATL Project\n[Dd]ebugPS/\n[Rr]eleasePS/\ndlldata.c\n\n# Benchmark Results\nBenchmarkDotNet.Artifacts/\n\n# .NET Core\nproject.lock.json\nproject.fragment.lock.json\nartifacts/\n\n# ASP.NET Scaffolding\nScaffoldingReadMe.txt\n\n# StyleCop\nStyleCopReport.xml"}, {"id": "VisualStudio.gitignore_3", "file": "VisualStudio.gitignore", "content": "artifacts/\n\n# ASP.NET Scaffolding\nScaffoldingReadMe.txt\n\n# StyleCop\nStyleCopReport.xml\n\n# Files built by Visual Studio\n*_i.c\n*_p.c\n*_h.h\n*.ilk\n*.meta\n*.obj\n*.idb\n*.iobj\n*.pch\n*.pdb\n*.ipdb\n*.pgc\n*.pgd\n*.rsp\n# but not Directory.Build.rsp, as it configures directory-level build defaults\n!Directory.Build.rsp\n*.sbr\n*.tlb\n*.tli\n*.tlh\n*.tmp\n*.tmp_proj\n*_wpftmp.csproj\n*.log\n*.tlog\n*.vspscc\n*.vssscc\n.builds\n*.pidb\n*.svclog\n*.scc\n\n# Chutzpah Test files\n_Chutzpah*\n\n# Visual C++ cache files\nipch/\n*.aps\n*.ncb\n*.opendb\n*.opensdf\n*.sdf\n*.cachefile\n*.VC.db\n*.VC.VC.opendb\n\n# Visual Studio profiler\n*.psess\n*.vsp\n*.vspx\n*.sap\n\n# Visual Studio Trace Files\n*.e2e\n\n# TFS 2012 Local Workspace\n$tf/\n\n# Guidance Automation Toolkit\n*.gpState\n\n# ReSharper is a .NET coding add-in\n_ReSharper*/\n*.[Rr]e[Ss]harper"}, {"id": "VisualStudio.gitignore_4", "file": "VisualStudio.gitignore", "content": "*.gpState\n\n# ReSharper is a .NET coding add-in\n_ReSharper*/\n*.[Rr]e[Ss]harper\n*.DotSettings.user\n\n# TeamCity is a build add-in\n_TeamCity*\n\n# DotCover is a Code Coverage Tool\n*.dotCover\n\n# AxoCover is a Code Coverage Tool\n.axoCover/*\n!.axoCover/settings.json\n\n# Coverlet is a free, cross platform Code Coverage Tool\ncoverage*.json\ncoverage*.xml\ncoverage*.info\n\n# Visual Studio code coverage results\n*.coverage\n*.coveragexml\n\n# NCrunch\n_NCrunch_*\n.NCrunch_*\n.*crunch*.local.xml\nnCrunchTemp_*\n\n# MightyMoose\n*.mm.*\nAutoTest.Net/\n\n# Web workbench (sass)\n.sass-cache/\n\n# Installshield output folder\n[Ee]xpress/\n\n# DocProject is a documentation generator add-in\nDocProject/buildhelp/\nDocProject/Help/*.HxT\nDocProject/Help/*.HxC\nDocProject/Help/*.hhc\nDocProject/Help/*.hhk\nDocProject/Help/*.hhp"}, {"id": "VisualStudio.gitignore_5", "file": "VisualStudio.gitignore", "content": "DocProject/Help/*.HxC\nDocProject/Help/*.hhc\nDocProject/Help/*.hhk\nDocProject/Help/*.hhp\nDocProject/Help/Html2\nDocProject/Help/html\n\n# Click-Once directory\npublish/\n\n# Publish Web Output\n*.[Pp]ublish.xml\n*.azurePubxml\n# Note: Comment the next line if you want to checkin your web deploy settings,\n# but database connection strings (with potential passwords) will be unencrypted\n*.pubxml\n*.publishproj\n\n# Microsoft Azure Web App publish settings. Comment the next line if you want to\n# checkin your Azure Web App publish settings, but sensitive information contained\n# in these scripts will be unencrypted\nPublishScripts/\n\n# NuGet Packages\n*.nupkg\n# NuGet Symbol Packages\n*.snupkg\n# The packages folder can be ignored because of Package Restore\n**/[Pp]ackages/*"}, {"id": "VisualStudio.gitignore_6", "file": "VisualStudio.gitignore", "content": "*.snupkg\n# The packages folder can be ignored because of Package Restore\n**/[Pp]ackages/*\n# except build/, which is used as an MSBuild target.\n!**/[Pp]ackages/build/\n# Uncomment if necessary however generally it will be regenerated when needed\n#!**/[Pp]ackages/repositories.config\n# NuGet v3's project.json files produces more ignorable files\n*.nuget.props\n*.nuget.targets\n\n# Microsoft Azure Build Output\ncsx/\n*.build.csdef\n\n# Microsoft Azure Emulator\necf/\nrcf/\n\n# Windows Store app package directories and files\nAppPackages/\nBundleArtifacts/\nPackage.StoreAssociation.xml\n_pkginfo.txt\n*.appx\n*.appxbundle\n*.appxupload\n\n# Visual Studio cache files\n# files ending in .cache can be ignored\n*.[Cc]ache\n# but keep track of directories ending in .cache\n!?*.[Cc]ache/\n\n# Others\nClientBin/\n~$*\n*~\n*.dbmdl"}, {"id": "VisualStudio.gitignore_7", "file": "VisualStudio.gitignore", "content": "# but keep track of directories ending in .cache\n!?*.[Cc]ache/\n\n# Others\nClientBin/\n~$*\n*~\n*.dbmdl\n*.dbproj.schemaview\n*.jfm\n*.pfx\n*.publishsettings\norleans.codegen.cs\n\n# Including strong name files can present a security risk\n# (https://github.com/github/gitignore/pull/2483#issue-259490424)\n#*.snk\n\n# Since there are multiple workflows, uncomment next line to ignore bower_components\n# (https://github.com/github/gitignore/pull/1529#issuecomment-104372622)\n#bower_components/\n\n# RIA/Silverlight projects\nGenerated_Code/\n\n# Backup & report files from converting an old project file\n# to a newer Visual Studio version. Backup files are not needed,\n# because we have git ;-)\n_UpgradeReport_Files/\nBackup*/\nUpgradeLog*.XML\nUpgradeLog*.htm\nServiceFabricBackup/\n*.rptproj.bak\n\n# SQL Server files\n*.mdf"}, {"id": "VisualStudio.gitignore_8", "file": "VisualStudio.gitignore", "content": "UpgradeLog*.XML\nUpgradeLog*.htm\nServiceFabricBackup/\n*.rptproj.bak\n\n# SQL Server files\n*.mdf\n*.ldf\n*.ndf\n\n# Business Intelligence projects\n*.rdl.data\n*.bim.layout\n*.bim_*.settings\n*.rptproj.rsuser\n*- [Bb]ackup.rdl\n*- [Bb]ackup ([0-9]).rdl\n*- [Bb]ackup ([0-9][0-9]).rdl\n\n# Microsoft Fakes\nFakesAssemblies/\n\n# GhostDoc plugin setting file\n*.GhostDoc.xml\n\n# Node.js Tools for Visual Studio\n.ntvs_analysis.dat\nnode_modules/\n\n# Visual Studio 6 build log\n*.plg\n\n# Visual Studio 6 workspace options file\n*.opt\n\n# Visual Studio 6 auto-generated workspace file (contains which files were open etc.)\n*.vbw\n\n# Visual Studio 6 workspace and project file (working project files containing files to include in project)\n*.dsw\n*.dsp\n\n# Visual Studio 6 technical files\n*.ncb\n*.aps"}, {"id": "VisualStudio.gitignore_9", "file": "VisualStudio.gitignore", "content": "*.dsw\n*.dsp\n\n# Visual Studio 6 technical files\n*.ncb\n*.aps\n\n# Visual Studio LightSwitch build output\n**/*.HTMLClient/GeneratedArtifacts\n**/*.DesktopClient/GeneratedArtifacts\n**/*.DesktopClient/ModelManifest.xml\n**/*.Server/GeneratedArtifacts\n**/*.Server/ModelManifest.xml\n_Pvt_Extensions\n\n# Paket dependency manager\n**/.paket/paket.exe\npaket-files/\n\n# FAKE - F# Make\n**/.fake/\n\n# CodeRush personal settings\n**/.cr/personal\n\n# Python Tools for Visual Studio (PTVS)\n**/__pycache__/\n*.pyc\n\n# Cake - Uncomment if you are using it\n#tools/**\n#!tools/packages.config\n\n# Tabs Studio\n*.tss\n\n# Telerik's JustMock configuration file\n*.jmconfig\n\n# BizTalk build output\n*.btp.cs\n*.btm.cs\n*.odx.cs\n*.xsd.cs\n\n# OpenCover UI analysis results\nOpenCover/\n\n# Azure Stream Analytics local run output\nASALocalRun/"}, {"id": "VisualStudio.gitignore_10", "file": "VisualStudio.gitignore", "content": "# OpenCover UI analysis results\nOpenCover/\n\n# Azure Stream Analytics local run output\nASALocalRun/\n\n# MSBuild Binary and Structured Log\n*.binlog\nMSBuild_Logs/\n\n# AWS SAM Build and Temporary Artifacts folder\n.aws-sam\n\n# NVidia Nsight GPU debugger configuration file\n*.nvuser\n\n# MFractors (Xamarin productivity tool) working folder\n**/.mfractor/\n\n# Local History for Visual Studio\n**/.localhistory/\n\n# Visual Studio History (VSHistory) files\n.vshistory/\n\n# BeatPulse healthcheck temp database\nhealthchecksdb\n\n# Backup folder for Package Reference Convert tool in Visual Studio 2017\nMigrationBackup/\n\n# Ionide (cross platform F# VS Code tools) working folder\n**/.ionide/\n\n# Fody - auto-generated XML schema\nFodyWeavers.xsd\n\n# VS Code files for those working on multiple tools\n.vscode/*"}, {"id": "VisualStudio.gitignore_11", "file": "VisualStudio.gitignore", "content": "FodyWeavers.xsd\n\n# VS Code files for those working on multiple tools\n.vscode/*\n!.vscode/settings.json\n!.vscode/tasks.json\n!.vscode/launch.json\n!.vscode/extensions.json\n!.vscode/*.code-snippets\n\n# Local History for Visual Studio Code\n.history/\n\n# Built Visual Studio Code Extensions\n*.vsix\n\n# Windows Installer files from build outputs\n*.cab\n*.msi\n*.msix\n*.msm\n*.msp"}, {"id": "VVVV.gitignore_0", "file": "VVVV.gitignore", "content": "================================================\n\n# .v4p backup files\n*~.xml\n\n# Dynamic plugins .dll\nbin/"}, {"id": "Waf.gitignore_0", "file": "Waf.gitignore", "content": "================================================\n# For projects that use the Waf build system: https://waf.io/\n# Dot-hidden on Unix-like systems\n.waf-*-*/\n.waf3-*-*/\n# Hidden directory on Windows (no dot)\nwaf-*-*/\nwaf3-*-*/\n# Lockfile\n.lock-waf_*_build"}, {"id": "WordPress.gitignore_0", "file": "WordPress.gitignore", "content": "================================================\n# Wordpress - ignore core, configuration, examples, uploads and logs.\n# https://github.com/github/gitignore/blob/main/WordPress.gitignore\n\n# Core\n#\n# Note: if you want to stage/commit WP core files\n# you can delete this whole section/until Configuration.\n/wp-admin/\n/wp-content/index.php\n/wp-content/languages\n/wp-content/plugins/index.php\n/wp-content/themes/index.php\n/wp-includes/\n/index.php\n/license.txt\n/readme.html\n/wp-*.php\n/xmlrpc.php\n\n# Configuration\nwp-config.php\n\n# Example themes\n/wp-content/themes/twenty*/\n\n# Example plugin\n/wp-content/plugins/hello.php\n\n# Uploads\n/wp-content/uploads/\n\n# Log files\n*.log\n\n# htaccess\n/.htaccess\n\n# All plugins\n#\n# Note: If you wish to whitelist plugins,\n# uncomment the next line\n#/wp-content/plugins"}, {"id": "WordPress.gitignore_1", "file": "WordPress.gitignore", "content": "#\n# Note: If you wish to whitelist plugins,\n# uncomment the next line\n#/wp-content/plugins\n\n# All themes\n#\n# Note: If you wish to whitelist themes,\n# uncomment the next line\n#/wp-content/themes"}, {"id": "Xojo.gitignore_0", "file": "Xojo.gitignore", "content": "================================================\n# Xojo (formerly REALbasic and Real Studio)\n\nBuilds*\n*.debug\n*.debug.app\nDebug*.exe\nDebug*/Debug*.exe\nDebug*/Debug*\\ Libs\n*.rbuistate\n*.xojo_uistate\n*.obsolete*"}, {"id": "Yeoman.gitignore_0", "file": "Yeoman.gitignore", "content": "================================================\nnode_modules/\nbower_components/\n*.log\n\nbuild/\ndist/"}, {"id": "Yii.gitignore_0", "file": "Yii.gitignore", "content": "================================================\nassets/*\n!assets/.gitignore\nprotected/runtime/*\n!protected/runtime/.gitignore\nprotected/data/*.db\nthemes/classic/views/"}, {"id": "ZendFramework.gitignore_0", "file": "ZendFramework.gitignore", "content": "================================================\n# Composer files\ncomposer.phar\nvendor/\n\n# Local configs\nconfig/autoload/*.local.php\n\n# Binary gettext files\n*.mo\n\n# Data\ndata/logs/\ndata/cache/\ndata/sessions/\ndata/tmp/\ntemp/\n\n#Doctrine 2\ndata/DoctrineORMModule/Proxy/\ndata/DoctrineORMModule/cache/\n\n# Legacy ZF1\ndemos/\nextras/documentation"}, {"id": "Zephir.gitignore_0", "file": "Zephir.gitignore", "content": "================================================\n# Cache files, generates by Zephir\n.temp/\n.libs/\n\n# Object files, generates by linker\n*.lo\n*.la\n*.o\n*.loT\n\n# Files generated by configure and Zephir,\n# not required for extension compilation.\next/build/\next/modules/\next/Makefile*\next/config*\next/acinclude.m4\next/aclocal.m4\next/autom4te*\next/install-sh\next/ltmain.sh\next/missing\next/mkinstalldirs\next/run-tests.php\next/.deps\next/libtool"}, {"id": "Zig.gitignore_0", "file": "Zig.gitignore", "content": "================================================\n.zig-cache/\nzig-out/\n*.o"}, {"id": "community/Alteryx.gitignore_0", "file": "community/Alteryx.gitignore", "content": "================================================\n# gitignore template for Alteryx Designer\n# website: https://www.alteryx.com/\n# website: https://help.alteryx.com/current/designer/alteryx-file-types\n\n# Alteryx Data Files\n*.yxdb\n*.cydb\n*.cyidx\n*.rptx\n*.vvf\n*.aws\n\n# Alteryx Special Files\n*.yxwv\n*.yxft\n*.yxbe\n*.bak\n*.pcxml\n*.log\n*.bin\n*.yxlang\nCASS.ini\n\n# Alteryx License Files\n*.yxlc\n*.slc\n*.cylc\n*.alc\n*.gzlc\n\n## gitignore reference sites\n# https://git-scm.com/book/en/v2/Git-Basics-Recording-Changes-to-the-Repository#_ignoring\n# https://git-scm.com/docs/gitignore\n# https://help.github.com/articles/ignoring-files/"}, {"id": "community/Alteryx.gitignore_1", "file": "community/Alteryx.gitignore", "content": "## Useful knowledge from stackoverflow\n# Even if you haven't tracked the files so far, git seems to be able to \"know\" about them even after you add them to .gitignore.\n# WARNING: First commit your current changes, or you will lose them.\n# Then run the following commands from the top folder of your git repo:\n# git rm -r --cached .\n# git add .\n# git commit -m \"fixed untracked files\"\n\n# author: Kacper Ksieski"}, {"id": "community/AltiumDesigner.gitignore_0", "file": "community/AltiumDesigner.gitignore", "content": "================================================\n# For PCBs designed using Altium Designer\n# Website: https://www.altium.com/altium-designer/\n\n# Directories containing cache data\nHistory\n__Previews\n\n# Directories containing logs and generated outputs\nProject\\ Logs*\nProject\\ Outputs*\n\n# Misc files generated by altium\ndebug.log\nStatus\\ Report.txt\n*.PcbDoc.htm\n*.SchDocPreview\n*.PcbDocPreview\n\n# Lock files sometimes left behind\n.~lock.*"}, {"id": "community/AutoIt.gitignore_0", "file": "community/AutoIt.gitignore", "content": "================================================\n# Compiled Scripts\n*.a3x\n\n# Tidy Auto-Generated Backups\nBackup/*\n\n# Au3Stripper Auto-Generated Files\n*_stripped.au3"}, {"id": "community/AutomationStudio.gitignore_0", "file": "community/AutomationStudio.gitignore", "content": "================================================\n# gitignore template for B&R Automation Studio (AS) 4\n# website: https://www.br-automation.com/en-us/products/software/automation-software/automation-studio/\n\n# AS temporary directories\nBinaries/\nDiagnosis/\nTemp/\nTempObjects/\n\n# AS transfer files\n*artransfer.br\n*arTrsfmode.nv\n\n# 'ignored' directory\nignored/\n\n# ARNC0ext\n*arnc0ext.br\n\n# AS File types\n*.bak\n*.isopen\n*.orig\n*.log\n*.asar\n*.csvlog*\n*.set\n!**/Physical/**/*.set\n\n# RevInfo variables\n*RevInfo.var"}, {"id": "community/B4X.gitignore_0", "file": "community/B4X.gitignore", "content": "================================================\n**/Objects\n**/AutoBackups\n*.meta"}, {"id": "community/Bazel.gitignore_0", "file": "community/Bazel.gitignore", "content": "================================================\n# gitignore template for Bazel build system\n# website: https://bazel.build/\n\n# Ignore all bazel-* symlinks. There is no full list since this can change\n# based on the name of the directory bazel is cloned into.\n/bazel-*\n\n# Directories for the Bazel IntelliJ plugin containing the generated\n# IntelliJ project files and plugin configuration. Separate directories are\n# for the IntelliJ, Android Studio and CLion versions of the plugin.\n/.ijwb/\n/.aswb/\n/.clwb/"}, {"id": "community/Beef.gitignore_0", "file": "community/Beef.gitignore", "content": "================================================\nbuild/\nrecovery/\nBeefSpace_User.toml"}, {"id": "community/Dotter.gitignore_0", "file": "community/Dotter.gitignore", "content": "================================================\n# local files are for host-specific overrides\n.dotter/local.toml\n\n# ignore caches\n.dotter/cache.toml\n.dotter/cache"}, {"id": "community/Exercism.gitignore_0", "file": "community/Exercism.gitignore", "content": "================================================\n# gitignore template for Exercism project\n# website: https://exercism.io/\n\n# Ignore .exercism folder which contain sensitive data\n.exercism"}, {"id": "community/Gretl.gitignore_0", "file": "community/Gretl.gitignore", "content": "================================================\n# gitignore template for Gretl\n# website: http://gretl.sourceforge.net/\n\n# Auto-generated log file is overwritten whenever you start a new session\nsession.inp\n\n# Auto-generated temporary string code table\nstring_table.txt"}, {"id": "community/Hexo.gitignore_0", "file": "community/Hexo.gitignore", "content": "================================================\n# gitignore template for Hexo sites\n# website: https://hexo.io/\n# Recommended: Node.gitignore\n\n# Ignore generated directory\npublic/\n\n# Ignore temp files\ntmp/\n.tmp*\n\n# additional files\ndb.json\n.deploy*/"}, {"id": "community/LensStudio.gitignore_0", "file": "community/LensStudio.gitignore", "content": "================================================\n# gitignore template for LensStudio\n# website: https://lensstudio.snapchat.com/\n\n# macOS/IDE #\n.DS_Store\n.idea\n\n# js #\nnode_modules\nyarn.lock\n\n# Python #\n__pycache__/\n*.py[cod]\n*$py.class\n[Bb]ackup*"}, {"id": "community/libogc.gitignore_0", "file": "community/libogc.gitignore", "content": "================================================\n# Ignore build directories\nbuild/\n\n# Ignore Wii-specific metadata files\nmeta.xml\nicon.png\n\n\n# Ignore editor or IDE-specific files\n.vscode/\n.idea/\n*.sublime-project\n*.sublime-workspace\n\n# Ignore backup or temporary files\n*~\n*.bak\n*.swp\n*.tmp\n\n# Ignore log files\n*.log\n\n# Ignore libraries and dependencies\nlib/\ndeps/\nobj/\n\n# Ignore operating system-specific files\n$RECYCLE.BIN/\n.Trash-1000/\n.Spotlight-V100/\n.fseventsd/\n.DS_Store\n\n# Prerequisites\n*.d\n\n# Object files\n*.o\n*.ko\n*.obj\n*.elf\n*.o\n*.bin\n\n# Linker output\n*.ilk\n*.map\n*.exp\n\n# Precompiled Headers\n*.gch\n*.pch\n\n# Libraries\n*.lib\n*.a\n*.la\n*.lo\n\n# Shared objects (inc. Windows DLLs)\n*.dll\n*.so\n*.so.*\n*.dylib\n\n# Executables\n*.exe\n*.out\n*.app\n*.i*86\n*.x86_64\n*.hex\n*.dol\n*.elf\n\n# Debug files"}, {"id": "community/libogc.gitignore_1", "file": "community/libogc.gitignore", "content": "*.so.*\n*.dylib\n\n# Executables\n*.exe\n*.out\n*.app\n*.i*86\n*.x86_64\n*.hex\n*.dol\n*.elf\n\n# Debug files\n*.dSYM/\n*.su\n*.idb\n*.pdb\n\n# Kernel Module Compile Results\n*.mod*\n*.cmd\n.tmp_versions/\nmodules.order\nModule.symvers\nMkfile.old\ndkms.conf"}, {"id": "community/Logtalk.gitignore_0", "file": "community/Logtalk.gitignore", "content": "================================================\n# gitignore template for LogTalk, a programming language that builds upon Prolog\n# website: https://logtalk.org/\n\n# Logtalk temporary file directories\n.lgt_tmp/\nlgt_tmp/\n\n# Logtalk default unit testing and doclet results and logs directories\nlogtalk_tester_logs/\nlogtalk_doclet_logs/\n\n# backend Prolog compiler temporary files\n.pl-history\n*.out\n*.xwam\n*.qo\n*.ql\n*.itf\n*.po"}, {"id": "community/MetaTrader5.gitignore_0", "file": "community/MetaTrader5.gitignore", "content": "================================================\n# MetaTrader 5 and MQL5 gitignore template\n# Project homepage: https://www.metatrader5.com/en\n\n# Compiled MQL5 executables (binaries)\n# These are generated from .mq5 source files and should not be committed.\n*.ex5\n*.ex4 # For MQL4 compatibility if you also manage MT4 projects in a similar structure\n\n# Log files\n# Terminal logs, strategy tester logs, and custom logs from Print() functions.\n*.log\n*.slog # Strategy Tester logs\n\n# Strategy Tester specific files\n# History data, optimization results, and temporary files used by the tester.\n*.fxt  # FXT files (history data for testing)\n*.hst  # History data files (can be large)\n*.ini  # Initialization files (often generated by tester or EAs)\n*.dat  # Data files (various purposes, often temporary)"}, {"id": "community/MetaTrader5.gitignore_1", "file": "community/MetaTrader5.gitignore", "content": "*.dat  # Data files (various purposes, often temporary)\n*.csv  # CSV export files (e.g., from tester reports)\n*.jrn  # Journal files (tester journal)\n\n# Market Watch sets and profiles\n# User-specific lists of symbols in Market Watch, and terminal profiles.\n*.set  # Market Watch symbol sets\n*.tpl  # Chart templates\n*.chr  # Chart settings files (can be generated when saving templates or profiles)\n\n# External libraries (DLLs)\n# If you use custom DLLs, you might want to ignore them if they are built separately\n# and not part of your MQL5 source code repository.\n*.dll\n\n# User-specific configuration and credentials\n# Files containing sensitive information or local user settings.\n.env   # Environment variables (e.g., for Python integration credentials)"}, {"id": "community/MetaTrader5.gitignore_2", "file": "community/MetaTrader5.gitignore", "content": ".env   # Environment variables (e.g., for Python integration credentials)\n*.cfg  # Configuration files (if not meant to be shared)\n*.json # Be careful: if you have config JSONs you *do* want to commit, add specific exceptions.\n       # Example: !config.json (to include config.json but ignore other *.json)\n\n# Temporary files and backup files generated by MetaEditor\n*.~*   # Temporary files (e.g., ~MyScript.mq5)\n*.bak  # Backup files (e.g., MyScript.mq5.bak)\n*.mqh.bak\n*.mq5.bak\n\n# MetaEditor project files\n# Project files for MetaEditor workspaces.\n.mqproj\n\n# Python specific ignores (if you also keep Python scripts or Jupyter notebooks in this repository)\n# These are relevant if your Git repo root is higher up (e.g., the terminal folder itself)"}, {"id": "community/MetaTrader5.gitignore_3", "file": "community/MetaTrader5.gitignore", "content": "# These are relevant if your Git repo root is higher up (e.g., the terminal folder itself)\n# or if you mix Python code within your MQL5 structure.\n__pycache__/       # Python compiled bytecode cache\n.ipynb_checkpoints/ # Jupyter Notebook checkpoints\n*.pyc              # Python compiled files\n*.pyd              # Python dynamic modules"}, {"id": "community/Move.gitignore_0", "file": "community/Move.gitignore", "content": "================================================\n# Generated by Move\n# will have compiled files\nbuild/\n\n# Remove possibly saving credentials to the git repository\n.aptos/"}, {"id": "community/NasaSpecsIntact.gitignore_0", "file": "community/NasaSpecsIntact.gitignore", "content": "================================================\n# gitignore template for Nasa SpecsIntact (SI)\n# Website: https://specsintact.ksc.nasa.gov/\n#\n# Recommended:\n# MicrosoftOffice.gitignore\n#\n\n# SpecsIntact (SI) Locking file; this would lock everyone out.\n*.se$\n\n# SI Reports; auto-generated. They do not belong in the repository\n# as they will be re-created exactly when using a specific checkout point.\n*.RPT\nADDRVER.*\nBRKTVER.*\nDUPEREF.*\nREFVER.*\nSECTVER.*\nSUBMVER.*\nTTLDIFFS.*\n\n# SpecsIntact files that change a lot and don't actually affect SI\n# PULL.TBL is an auto-generated file to help speed SI loading.\nPULL.TBL\npulltbl.bck\n\n# Tailoring information.\n# Keep tailor.tag; it is a list of tailoring options in SI.\n\n# JOB.OTL informs SI where a spec section came from."}, {"id": "community/NasaSpecsIntact.gitignore_1", "file": "community/NasaSpecsIntact.gitignore", "content": "# JOB.OTL informs SI where a spec section came from.\n# Keeping the old one isn't useful in git.\nJOB.OTL.OLD\n\n# OneNote TOC Files; SI Work Directories may be installed in a location co-located with OneNote\n# notebooks, and if so, OneNote will litter the SI folder with these.\n*.onetoc*\n\n# Log files, typically tagfix or other auto generated logs that aren't useful\n# outside of the user that made them and clutter up the index.\n*.log"}, {"id": "community/OpenSSL.gitignore_0", "file": "community/OpenSSL.gitignore", "content": "================================================\n# OpenSSL-related files best not committed\n\n## Certificate Authority\n*.ca\n\n## Certificate\n*.crt\n\n## Certificate Sign Request\n*.csr\n\n## Certificate\n*.der\n\n## Key database file\n*.kdb\n\n## OSCP request data\n*.org\n\n## PKCS #12\n*.p12\n\n## PEM-encoded certificate data\n*.pem\n\n## Random number seed\n*.rnd\n\n## SSLeay data\n*.ssleay\n\n## S/MIME message\n*.smime"}, {"id": "community/OpenTofu.gitignore_0", "file": "community/OpenTofu.gitignore", "content": "================================================\n# Local .terraform directories\n**/.terraform/*\n\n# .tfstate files\n*.tfstate\n*.tfstate.*\n\n# Crash log files\ncrash.log\ncrash.*.log\n\n# Exclude all .tfvars files, which are likely to contain sensitive data, such as\n# password, private keys, and other secrets. These should not be part of version\n# control as they are data points which are potentially sensitive and subject\n# to change depending on the environment.\n*.tfvars\n*.tfvars.json\n\n# Ignore override files as they are usually used to override resources locally and so\n# are not checked in\noverride.tf\noverride.tofu\noverride.tf.json\noverride.tofu.json\n*_override.tf\n*_override.tofu\n*_override.tf.json\n*_override.tofu.json\n\n# Ignore transient lock info files created by tofu apply"}, {"id": "community/OpenTofu.gitignore_1", "file": "community/OpenTofu.gitignore", "content": "*_override.tf.json\n*_override.tofu.json\n\n# Ignore transient lock info files created by tofu apply\n.terraform.tfstate.lock.info\n\n# Include override files you do wish to add to version control using negated pattern\n# !example_override.tf\n# !example_override.tofu\n\n# Include tfplan files to ignore the plan output of command: tofu plan -out=tfplan\n# example: *tfplan*\n\n# Ignore CLI configuration files\n.terraformrc\nterraform.rc"}, {"id": "community/Puppet.gitignore_0", "file": "community/Puppet.gitignore", "content": "================================================\n# gitignore template for Puppet modules\n# website: https://forge.puppet.com/\n\n# Built packages\npkg/*\n\n# Should run on multiple platforms so don't check in\nGemfile.lock\n\n# Tests\nspec/fixtures/*\ncoverage/*\n\n# Third-party\nvendor/*\n.bundle/*"}, {"id": "community/Racket.gitignore_0", "file": "community/Racket.gitignore", "content": "================================================\n# gitignore template for the Racket language\n# website: http://www.racket-lang.org/\n\n# DrRacket autosave files\n*.rkt~\n*.rkt.bak\n\\#*.rkt#\n\\#*.rkt#*#\n\n# Compiled racket bytecode\ncompiled/\n*.zo\n\n# Dependency tracking files\n*.dep"}, {"id": "community/Red.gitignore_0", "file": "community/Red.gitignore", "content": "================================================\n# gitignore template for Red programming language\n# website: http://www.red-lang.org/\n\n# Red Compiled code\n*.red\n\n# Libraries\ncrush.dll\ncrush.dylib\ncrush.so\n\n# Files generated during test\nquick-test/quick-test.log\nquick-test/runnable/\nsystem/tests/source/units/auto-tests/\ntests/source/units/auto-tests/"}, {"id": "community/ROS2.gitignore_0", "file": "community/ROS2.gitignore", "content": "================================================\ninstall/\nlog/\nbuild/\n\n# Ignore generated docs\n*.dox\n*.wikidoc\n\n# eclipse stuff\n.project\n.cproject\n\n# qcreator stuff\nCMakeLists.txt.user\n\nsrv/_*.py\n*.pcd\n*.pyc\nqtcreator-*\n*.user\n\n*~\n\n# Emacs\n.#*\n\n# Colcon custom files\nCOLCON_IGNORE\nAMENT_IGNORE"}, {"id": "community/SPFx.gitignore_0", "file": "community/SPFx.gitignore", "content": "================================================\n#SharePoint Framework (SPFx)\n# Logs\nlogs\n*.log\nnpm-debug.log*\n\n# Dependency directories\nnode_modules\n\n# Build generated files\ndist\nlib\nsolution\ntemp\n*.sppkg\n\n# Coverage directory used by tools like istanbul\ncoverage\n\n# OSX\n.DS_Store\n\n# Visual Studio files\n.ntvs_analysis.dat\n.vs\nbin\nobj\n\n# Resx Generated Code\n*.resx.ts\n\n# Styles Generated Code\n*.scss.ts"}, {"id": "community/Splunk.gitignore_0", "file": "community/Splunk.gitignore", "content": "================================================\n# gitignore template for Splunk apps\n# documentation: http://docs.splunk.com/Documentation/Splunk/6.2.3/admin/Defaultmetaconf\n\n# Splunk local meta file\nlocal.meta\n\n# Splunk local folder\nlocal"}, {"id": "community/Strapi.gitignore_0", "file": "community/Strapi.gitignore", "content": "================================================\n############################\n# OS X\n############################\n\n.DS_Store\n.AppleDouble\n.LSOverride\nIcon\n.Spotlight-V100\n.Trashes\n._*\n\n\n############################\n# Linux\n############################\n\n*~\n\n\n############################\n# Windows\n############################\n\nThumbs.db\nehthumbs.db\nDesktop.ini\n$RECYCLE.BIN/\n*.cab\n*.msi\n*.msm\n*.msp\n\n\n############################\n# Packages\n############################\n\n*.7z\n*.csv\n*.dat\n*.dmg\n*.gz\n*.iso\n*.jar\n*.rar\n*.tar\n*.zip\n*.com\n*.class\n*.dll\n*.exe\n*.o\n*.seed\n*.so\n*.swo\n*.swp\n*.swn\n*.swm\n*.out\n*.pid\n\n\n############################\n# Logs and databases\n############################\n\n.tmp\n*.log\n*.sql\n*.sqlite\n\n\n############################\n# Misc.\n############################\n\n*#\n.idea"}, {"id": "community/Strapi.gitignore_1", "file": "community/Strapi.gitignore", "content": "*.log\n*.sql\n*.sqlite\n\n\n############################\n# Misc.\n############################\n\n*#\n.idea\nnbproject\n.vscode/\n\n\n############################\n# Node.js\n############################\n\nlib-cov\nlcov.info\npids\nlogs\nresults\nbuild\nnode_modules\n.node_history\npackage-lock.json\n**/package-lock.json\n!docs/package-lock.json\n*.heapsnapshot\n\n\n############################\n# Tests\n############################\n\ntestApp\ncoverage\ncypress/screenshots\ncypress/videos\n\n\n############################\n# Documentation\n############################\n\ndist\n\n############################\n# Builds\n############################\n\npackages/strapi-generate-new/files/public/\n\n############################\n# Example app\n############################\n\n.dev\n# *.cache\n\n############################\n# Visual Studio Code"}, {"id": "community/Strapi.gitignore_2", "file": "community/Strapi.gitignore", "content": "############################\n\n.dev\n# *.cache\n\n############################\n# Visual Studio Code\n############################\n\nfront-workspace.code-workspace"}, {"id": "community/Terragrunt.gitignore_0", "file": "community/Terragrunt.gitignore", "content": "================================================\n# Ignore the default terragrunt cache directory\n# https://terragrunt.gruntwork.io/docs/features/caching/\n.terragrunt-cache"}, {"id": "community/Toit.gitignore_0", "file": "community/Toit.gitignore", "content": "================================================\n.packages\n*_pb.toit"}, {"id": "community/UiPath.gitignore_0", "file": "community/UiPath.gitignore", "content": "================================================\n# gitignore template for RPA development using UiPath Studio\n# website: https://www.uipath.com/product/studio\n#\n# Recommended: n/a\n\n# Ignore folders that could cause issues if accidentally tracked\n**/.local/**\n**/.settings/**\n**/.objects/**\n**/.tmh/**\n**/*.log"}, {"id": "community/UTAU.gitignore_0", "file": "community/UTAU.gitignore", "content": "================================================\n# Adobe Audition\n*.pkf\n\n# UTAU Engines\n*.ctspec\n*.d4c\n*.dio\n*.frc\n*.frt\n*.frq\n*.harvest\n*.lessaudio\n*.llsm\n*.mrq\n*.pitchtier\n*.platinum\n*.pmk\n*.sc.npz\n*.star\n*.uspec\n*.vs4ufrq\n\n# UTAU related tools\n$read\n*.setParam-Scache\n*.lbp\n*.lbp.caches/*\n\n# OpenUtau\nerrors.txt\n\n# Deepvocal\n*.DVModel\n*-log.txt\nSKC\nSKI\nSKC_1\nSKC_2\n*.sksd\n\n# VocalSharp\n*.scep\n*.vssf\n*.vsdx\n*.vsdxindex\n\n# Binary Archive\n*.7z\n*.zip\n*.rar\n*.exe"}, {"id": "community/V.gitignore_0", "file": "community/V.gitignore", "content": "================================================\n*.exe\n*.o\n*.so\n*.tmp.c\n*.exp\n*.ilk\n*.pdb\n*.dll\n*.lib\n*.bak\n*.out"}, {"id": "community/Xilinx.gitignore_0", "file": "community/Xilinx.gitignore", "content": "================================================\n# gitignore template for Xilinx Vivado Design Suite\n# website: https://www.xilinx.com/support/download.html\n\n# [home]\n*.jou\n*.log\n*.debug\n*.str\n*.zip\n*.tmp\n*.rst\n*.os\n*.js\n*.pb\n*.dcp\n*.hwdef\n*.vds\n*.veo\n*.wdf\n*.vdi\n*.dmp\n*.rpx\n*.rpt\n*_stub.v\n*_stub.vhdl\n*_funcsim.v\n*_funcsim.vhdl\n.project\n\n# [dir]\n*.cache\n.metadata\n*.data\n*.ipdefs\n.Xil\n*.sdk\n*.hw\n*.ip_user_files\n\n### IP synth\n*_synth_*\n\n.jobs\n\n### project synth\n*/*.runs/synth*/*.xml\n*/*.runs/synth*/*.txt\n*/*.runs/synth*/*.sh\n*/*.runs/synth*/*.tcl\n*/*.runs/synth*/*.bat\n*/*.runs/synth*/*.xdc\n!*/*.runs/synth*/*utilization*.rpt\n\n*.runs/synth*/*.xml\n*.runs/synth*/*.txt\n*.runs/synth*/*.sh\n*.runs/synth*/*.tcl\n*.runs/synth*/*.bat\n*.runs/synth*/*.xdc\n!*.runs/synth*/*utilization*.rpt"}, {"id": "community/Xilinx.gitignore_1", "file": "community/Xilinx.gitignore", "content": "### project impl\n*/*.runs/impl*/*.xml\n*/*.runs/impl*/*.html\n*/*.runs/impl*/*.txt\n*/*.runs/impl*/*.sh\n*/*.runs/impl*/*.tcl\n*/*.runs/impl*/*.bat\n!*/*.runs/impl*/*utilization*.rpt\n\n*.runs/impl*/*.xml\n*.runs/impl*/*.html\n*.runs/impl*/*.txt\n*.runs/impl*/*.sh\n*.runs/impl*/*.tcl\n*.runs/impl*/*.bat\n!*.runs/impl*/*utilization*.rpt\n\n### block design\n*/*/bd/*/hdl\n*/*/*/bd/*/hdl\n\n*/*/bd/*/*.xdc\n*/*/*/bd/*/*.xdc\n\n*/*/bd/*/ip/*/*.xdc\n*/*/*/bd/*/ip/*/*.xdc\n\n*/*/bd/*/ip/*/*/\n*/*/*/bd/*/ip/*/*/\n\n*/*/bd/*/ip/*/*.vhd\n*/*/*/bd/*/ip/*/*.vhd\n\n*/*/bd/*/ip/*/*.xml\n*/*/*/bd/*/ip/*/*.xml\n\n*.c\n*.h\n*.vho\n*.html\n*/*/bd/*/ip/*/*.tcl\n*/*/*/bd/*/ip/*/*.tcl\nhw_handoff\nipshared"}, {"id": "community/AWS/CDK.gitignore_0", "file": "community/AWS/CDK.gitignore", "content": "================================================\n# CDK asset staging directory.\n# For more information about AWS-CDK, see  https://docs.aws.amazon.com/cdk/\n.cdk.staging/\ncdk.out/"}, {"id": "community/AWS/SAM.gitignore_0", "file": "community/AWS/SAM.gitignore", "content": "================================================\n# gitignore template for AWS Serverless Application Model project\n# website: https://docs.aws.amazon.com/serverless-application-model\n\n# Ignore build folder\n.aws-sam/"}, {"id": "community/BoxLang/ColdBox.gitignore_0", "file": "community/BoxLang/ColdBox.gitignore", "content": "================================================\n# Servelet Ignores\nWEB-INF\n\n# Engines + Database + CBFS + Secrets\n.tmp/**\n.env\n.engine/**\n.cbfs/**\n\n# Logs + Test Results\nlogs/**\ntests/results/**\n\n## Ignored Dependencies\n/boxlang_modules/*\neffective-pom.xml\n/coldbox/**\n/testbox/**\n/modules/**\n/lib/java/**\n\n# NPM JS Assets (If applicable)\n**/node_modules/*\nnpm-debug.log\nyarn-error.log"}, {"id": "community/CFML/ColdBox.gitignore_0", "file": "community/CFML/ColdBox.gitignore", "content": "================================================\n# Servelet Ignores\nWEB-INF\n\n# Engines + Database + CBFS + Secrets\n.tmp/**\n.env\n.engine/**\n.cbfs/**\n\n# Logs + Test Results\nlogs/**\ntests/results/**\n\n## Ignored Dependencies\neffective-pom.xml\n/coldbox/**\n/testbox/**\n/modules/**\n/lib/java/**\n\n# NPM JS Assets (If applicable)\n**/node_modules/*\nnpm-debug.log\nyarn-error.log"}, {"id": "community/DotNet/core.gitignore_0", "file": "community/DotNet/core.gitignore", "content": "================================================\n*.swp\n*.*~\nproject.lock.json\n.DS_Store\n*.pyc\nnupkg/\n\n# Visual Studio Code\n.vscode\n\n# Rider\n.idea\n\n# User-specific files\n*.suo\n*.user\n*.userosscache\n*.sln.docstates\n\n# Build results\n[Dd]ebug/\n[Dd]ebugPublic/\n[Rr]elease/\n[Rr]eleases/\nx64/\nx86/\nbuild/\nbld/\n[Bb]in/\n[Oo]bj/\n[Oo]ut/\nmsbuild.log\nmsbuild.err\nmsbuild.wrn\n\n# Visual Studio 2015\n.vs/"}, {"id": "community/DotNet/InforCMS.gitignore_0", "file": "community/DotNet/InforCMS.gitignore", "content": "================================================\n# gitignore template for InforCRM (formerly SalesLogix)\n# website: https://www.infor.com/product-summary/cx/infor-crm/\n#\n# Recommended: VisualStudio.gitignore\n\n# Ignore model files that are auto-generated\nModelIndex.xml\nExportedFiles.xml\n\n# Ignore deployment files\n[Mm]odel/[Dd]eployment\n\n# Force include portal SupportFiles\n!Model/Portal/*/SupportFiles/[Bb]in/\n!Model/Portal/PortalTemplates/*/SupportFiles/[Bb]in"}, {"id": "community/DotNet/Kentico.gitignore_0", "file": "community/DotNet/Kentico.gitignore", "content": "================================================\n# gitignore template for using Kentico CMS\n# website: http://www.kentico.com/\n#\n# Recommended template: VisualStudio.gitignore\n\n# Include some Kentico folders excluded by Visual Studio rules\n!CMS/CMSAdminControls/*/\n!CMS/CMSModules/System/*/\n!CMS/App_Data/CIRepository/**\n\n# Kentico temporary/environment files\nCMS/App_Data/AzureCache\nCMS/App_Data/AzureTemp\nCMS/App_Data/CMSModules/DeviceProfile/logFiftyOne.txt\nCMS/App_Data/CMSModules/DeviceProfiles/logFiftyOne.txt\nCMS/App_Data/CMSModules/WebFarm/webfarm.sync\nCMS/App_Data/CMSTemp\nCMS/App_Data/Persistent\nCMS/CMSSiteUtils/Export\nCMS/CMSSiteUtils/Import\n\n# Ignore all smart search indexes, but not the other system folder contents\nCMS/App_Data/CMSModules/SmartSearch/**"}, {"id": "community/DotNet/Kentico.gitignore_1", "file": "community/DotNet/Kentico.gitignore", "content": "CMS/App_Data/CMSModules/SmartSearch/**\n!CMS/App_Data/CMSModules/SmartSearch/*/\n!CMS/App_Data/CMSModules/SmartSearch/_StopWords/**\n!CMS/App_Data/CMSModules/SmartSearch/_Synonyms/**"}, {"id": "community/DotNet/Kentico.gitignore_2", "file": "community/DotNet/Kentico.gitignore", "content": "## Kentico Starter Sites\n# Starter site resource Files\nCMS/App_Data/DancingGoat\n\n# Starter site web templates\nCMS/App_Data/Templates/CommunitySite\nCMS/App_Data/Templates/CorporateSite\nCMS/App_Data/Templates/DancingGoat\nCMS/App_Data/Templates/EcommerceSite\nCMS/App_Data/Templates/IntranetPortal\nCMS/App_Data/Templates/PersonalSite\n\n# Starter site app themes\nCMS/App_Themes/CommunitySite\nCMS/App_Themes/CorporateSite\nCMS/App_Themes/EcommerceSite\nCMS/App_Themes/IntranetPortal*\nCMS/App_Themes/PersonalSite\n\n# Starter site ASPX templates\nCMS/CMSTemplates/CorporateSite\n\n# Starter site media libraries\nCMS/CommunitySite\nCMS/CorporateSite\nCMS/DancingGoat\nCMS/EcommerceSite\nCMS/IntranetPortal\nCMS/PersonalSite"}, {"id": "community/DotNet/Kentico.gitignore_3", "file": "community/DotNet/Kentico.gitignore", "content": "## Project specific ignores\n# Sensitive settings\nAppSettings.config\nConnectionStrings.config\n\n# Project media libraries (recommend shared file storage)\n# e.g. CMS/{SiteCodeName}"}, {"id": "community/DotNet/Umbraco.gitignore_0", "file": "community/DotNet/Umbraco.gitignore", "content": "================================================\n## Ignore Umbraco files/folders generated for each instance\n##\n## Get latest from https://github.com/github/gitignore/blob/main/Umbraco.gitignore\n\n# Note: VisualStudio gitignore rules may also be relevant\n\n# Umbraco\n# Ignore unimportant folders generated by Umbraco\n**/App_Data/Logs/\n**/App_Data/[Pp]review/\n**/App_Data/TEMP/\n**/App_Data/NuGetBackup/\n\n# Ignore Umbraco content cache file\n**/App_Data/umbraco.config\n\n## this [Uu]mbraco/ folder should be created by cmd like `Install-Package UmbracoCms -Version 8.5.3`\n## you can find your Umbraco version in your Web.config. (i.e. <add key=\"Umbraco.Core.ConfigurationStatus\" value=\"8.5.3\" />)\n## Uncomment this line if you think it fits the way you work on your project.\n## **/[Uu]mbraco/"}, {"id": "community/DotNet/Umbraco.gitignore_1", "file": "community/DotNet/Umbraco.gitignore", "content": "## Uncomment this line if you think it fits the way you work on your project.\n## **/[Uu]mbraco/\n\n## The [Mm]edia/ folder contains content. Content may vary by environment and should therefore not be added to source control.\n## Uncomment this line if you think it fits the way you work on your project."}, {"id": "community/DotNet/Umbraco.gitignore_2", "file": "community/DotNet/Umbraco.gitignore", "content": "## **/[Mm]edia/\n\n# Don't ignore Umbraco packages (VisualStudio.gitignore mistakes this for a NuGet packages folder)\n# Make sure to include details from VisualStudio.gitignore BEFORE this\n!**/App_Data/[Pp]ackages/*\n!**/[Uu]mbraco/[Dd]eveloper/[Pp]ackages/*\n!**/[Uu]mbraco/[Vv]iews/[Pp]ackages/*\n\n# ImageProcessor DiskCache\n**/App_Data/cache/\n\n# Ignore the Models Builder models out of date flag\n**/ood.flag\n\n# NEW for version 9 .Net 5 (Core)\n#ignore umbraco backoffice assest from wwwroot\n**/wwwroot/umbraco/\n\n# SQLite files\n*.sqlite.db*\n\n#ignore umbraco data/views/settings\n**/umbraco/*\n\n#include default location for modelsbuilder output\n!**/umbraco/models\n\n#include default location for packages\n!**/umbraco/Data/packages"}, {"id": "community/Elixir/Phoenix.gitignore_0", "file": "community/Elixir/Phoenix.gitignore", "content": "================================================\n# gitignore template for Phoenix projects\n# website: http://www.phoenixframework.org/\n#\n# Recommended template: Elixir.gitignore\n\n# Temporary files\n/tmp\n\n# Static artifacts\n/node_modules\n/assets/node_modules\n\n# Since we are building assets from web/static,\n# we ignore priv/static. You may want to comment\n# this depending on your deployment strategy.\n/priv/static/\n\n# Installer-related files\n/installer/_build\n/installer/tmp\n/installer/doc\n/installer/deps"}, {"id": "community/embedded/AtmelStudio.gitignore_0", "file": "community/embedded/AtmelStudio.gitignore", "content": "================================================\n## Ignore Atmel Studio temporary files and build results\n# https://www.microchip.com/mplab/avr-support/atmel-studio-7\n\n# Atmel Studio is powered by an older version of Visual Studio,\n# so most of the project and solution files are the same as VS files,\n# only prefixed by an `at`.\n\n#Build Directories\n[Dd]ebug/\n[Rr]elease/\n\n#Build Results\n*.o\n*.d\n*.eep\n*.elf\n*.hex\n*.map\n*.srec\n\n#User Specific Files\n*.atsuo"}, {"id": "community/embedded/esp-idf.gitignore_0", "file": "community/embedded/esp-idf.gitignore", "content": "================================================\n# gitignore template for esp-idf, the official development framework for ESP32\n# https://github.com/espressif/esp-idf\n\nbuild/\nsdkconfig\nsdkconfig.old"}, {"id": "community/embedded/IAR_EWARM.gitignore_0", "file": "community/embedded/IAR_EWARM.gitignore", "content": "================================================\n# gitignore template for the IAR EWARM\n# website: https://www.iar.com/knowledge/support/technical-notes/ide/which-files-should-be-version-controlled/\n\n# Some tools will put the EWARM files\n# under a subdirectory with the same name\n# as the configuration.\n# Example\n# EWARM/Config1/Obj /List /Exe\n# EWARM/Config2/Obj /List /Exe\nEWARM/**/Obj\nEWARM/**/List\nEWARM/**/Exe\n\n# Autogenerated project files\n*.dep\n*.ewt\n\n# Autogenerated folder for debugger\nEWARM/settings"}, {"id": "community/embedded/uVision.gitignore_0", "file": "community/embedded/uVision.gitignore", "content": "================================================\n# git ignore file for Keil \u00c3\u201a\u00c2\u00b5Vision Project\n\n# \u00c3\u201a\u00c2\u00b5Vision 5 and \u00c3\u201a\u00c2\u00b5Vision 4 Project screen layout file\n*.uvguix.*\n*.uvgui.*\n\n# Listing Files\n*.i\n*.lst\n*.m51\n*.m66\n*.map\n\n# Object Files\n*.axf\n*.b[0-2][0-9]\n*.b3[0-1]\n*.bak\n*.build_log.htm\n*.crf\n*.d\n*.dep\n*.elf\n*.htm\n*.iex\n*.lnp\n*.o\n*.obj\n*.sbr\n\n# Firmware Files\n*.bin\n*.h86\n*.hex\n\n# Build Files\n.bat\n\n# Debugger Files\n.ini\n\n# JLink Files\nJLinkLog.txt\n\n# Other Files"}, {"id": "community/GNOME/GNOMEShellExtension.gitignore_0", "file": "community/GNOME/GNOMEShellExtension.gitignore", "content": "================================================\n# Ignored files for GNOME extension git repository\n\n*.zip"}, {"id": "community/Golang/Go.AllowList.gitignore_0", "file": "community/Golang/Go.AllowList.gitignore", "content": "================================================\n# Allowlisting gitignore template for GO projects prevents us\n# from adding various unwanted local files, such as generated\n# files, developer configurations or IDE-specific files etc.\n#\n# Recommended: Go.AllowList.gitignore\n\n# Ignore everything\n*\n\n# But not these files...\n!/.gitignore\n\n!*.go\n!go.sum\n!go.mod\n\n!README.md\n!LICENSE\n\n# !Makefile\n\n# ...even if they are in subdirectories\n!*/"}, {"id": "community/Golang/Hugo.gitignore_0", "file": "community/Golang/Hugo.gitignore", "content": "================================================\n# Generated files by hugo\n/public/\n/resources/_gen/\n/assets/jsconfig.json\nhugo_stats.json\n\n# Executable may be added to repository\nhugo.exe\nhugo.darwin\nhugo.linux\n\n# Temporary lock file while building\n/.hugo_build.lock"}, {"id": "community/Java/JBoss4.gitignore_0", "file": "community/Java/JBoss4.gitignore", "content": "================================================\n# gitignore for JBoss v4 projects\n\n/server/all/data\n/server/all/log\n/server/all/tmp\n/server/all/work\n/server/default/data\n/server/default/log\n/server/default/tmp\n/server/default/work\n/server/minimal/data\n/server/minimal/log\n/server/minimal/tmp\n/server/minimal/work\n\n# Note:\n# there may be other directories that contain *.xml.failed or *.war.failed files\n/server/default/deploy/*.xml.failed\n/server/default/deploy/*.war.failed"}, {"id": "community/Java/JBoss6.gitignore_0", "file": "community/Java/JBoss6.gitignore", "content": "================================================\n# gitignore for JBoss v6 projects\n#\n# Note: to ensure empty directories remain part of the repository, like\n# `/server/minimal/lib`, you should add an empty `.gitignore` or `.gitkeep` file\n# to the directory - otherwise you may have issues when starting the service.\n\n/server/all/data\n/server/all/log\n/server/all/tmp\n/server/all/work\n/server/default/data\n/server/default/log\n/server/default/tmp\n/server/default/work\n/server/minimal/data\n/server/minimal/log\n/server/minimal/tmp\n/server/minimal/work\n/server/jbossweb-standalone/data\n/server/jbossweb-standalone/log\n/server/jbossweb-standalone/tmp\n/server/jbossweb-standalone/work\n/server/standard/data\n/server/standard/log\n/server/standard/tmp\n/server/standard/work\n/server/default/deploy/*.jar.failed"}, {"id": "community/Java/JBoss6.gitignore_1", "file": "community/Java/JBoss6.gitignore", "content": "/server/standard/log\n/server/standard/tmp\n/server/standard/work\n/server/default/deploy/*.jar.failed\n/server/default/deploy/*.jar.dodeploy\n/server/default/deploy/*.xml.failed\n/server/default/deploy/*.xml.dodeploy\n/server/default/deploy/*.war.failed\n/server/default/deploy/*.war.dodeploy"}, {"id": "community/JavaScript/Cordova.gitignore_0", "file": "community/JavaScript/Cordova.gitignore", "content": "================================================\n# gitignore template for the Cordova framework\n# website: https://cordova.apache.org/\n#\n# Recommended template: Node.gitignore\n\n# App platform binaries and built files\n/platforms\n\n# Optional to ignore plugin Git clones\n#/plugins"}, {"id": "community/JavaScript/Expo.gitignore_0", "file": "community/JavaScript/Expo.gitignore", "content": "================================================\n#\u00c3\u00a2\u00e2\u201a\u00ac\u00c6\u2019.gitignore template for Expo\n#\u00c3\u00a2\u00e2\u201a\u00ac\u00c6\u2019website: https://expo.dev/\n#\u00c3\u00a2\u00e2\u201a\u00ac\u00c6\u2019docs: https://docs.expo.dev/workflow/expo-cli/\n#\n#\u00c3\u00a2\u00e2\u201a\u00ac\u00c6\u2019Rationale:\n#\u00c3\u00a2\u00e2\u201a\u00ac\u00c6\u2019node_modules/ is always ignored\n#\u00c3\u00a2\u00e2\u201a\u00ac\u00c6\u2019.expo/, .expo-shared/ are Expo\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s local state and project-settings cache (see docs)\n#\u00c3\u00a2\u00e2\u201a\u00ac\u00c6\u2019 Metro caches/logs are *.expo, *.tunnel, *.cache, *.tmp, *.log\n\n# Node modules\nnode_modules/\n\n# Expo local state and caches\n.expo/             # runtime state (Metro bundler, dev-client data, tunnels)\n.expo-shared/      # shared project settings (app.json edits, etc.)\n\n# Metro bundler caches/logs\n*.expo             # generic Expo temp files\n*.tunnel           # Expo DevTools tunnels\n*.cache            # Metro cache folder"}, {"id": "community/JavaScript/Expo.gitignore_1", "file": "community/JavaScript/Expo.gitignore", "content": "*.tunnel           # Expo DevTools tunnels\n*.cache            # Metro cache folder\n*.tmp              # temp files created during bundling\n*.log              # build or Metro logs\n\n# Environment variables\n.env\n.env.local\n.env.*.local\n\n# Package manager logs\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*"}, {"id": "community/JavaScript/Meteor.gitignore_0", "file": "community/JavaScript/Meteor.gitignore", "content": "================================================\n# gitignore template for the Meteor framework\n# website: https://www.meteor.com/\n#\n# Recommended template: Node.gitignore\n\n# protect api keys in setting json\nsettings-production.json\nsettings.json\n\n# protect your mup.json settings\nmup.json\nmup.js"}, {"id": "community/JavaScript/NWjs.gitignore_0", "file": "community/JavaScript/NWjs.gitignore", "content": "================================================\n# gitignore template for NW.js projects\n# website: https://nwjs.io/\n\n# Seen in standard and sdk versions\ncredits.html\nlocales/\nlibEGL.dll\nlibGLEv2.dll\nnode.dll\nnw.dll\nnw.exe\nnatives_blob.bin\nnw_100_percent.pak\nnw_200_percent.pak\nnw_elf.dll\nsnapshot_blob.bin\nresources.pak\n\n# Seen only in standard\nd3dcompiler_47.dll\nffmpeg.dll\nicudtl.dat\n\n# Seen only in sdk\npnacl/\nchromedriver.exe\nnacl_irt_x86_64.nexe\nnwjc.exe\npayload.exe"}, {"id": "community/JavaScript/Vue.gitignore_0", "file": "community/JavaScript/Vue.gitignore", "content": "================================================\n# gitignore template for Vue.js projects\n#\n# Recommended template: Node.gitignore\n\n# TODO: where does this rule come from?\ndocs/_book\n\n# TODO: where does this rule come from?\ntest/"}, {"id": "community/Linux/Snap.gitignore_0", "file": "community/Linux/Snap.gitignore", "content": "================================================\n# gitginore template for creating Snap packages\n# website: https://snapcraft.io/\n\nparts/\nprime/\nstage/\n*.snap\n\n# Snapcraft global state tracking data(automatically generated)\n# https://forum.snapcraft.io/t/location-to-save-global-state/768\n/snap/.snapcraft/\n\n# Source archive packed by `snapcraft cleanbuild` before pushing to the LXD container\n/*_source.tar.bz2"}, {"id": "community/Obsidian/NotesAndCoreConfiguration.gitignore_0", "file": "community/Obsidian/NotesAndCoreConfiguration.gitignore", "content": "================================================\n# Excludes Obsidian workspace cache and plugins. All notes and core obsidian\n# configuration files are tracked by Git.\n\n# The current application UI state (DOM layout, recently-opened files, etc.) is\n# stored in these files (separate for desktop and mobile) so you can resume\n# your session seamlessly after a restart. If you want to track UI state, use\n# the Workspaces core plugin instead of relying on these files.\n.obsidian/workspace.json\n.obsidian/workspace-mobile.json\n\n# Obsidian plugins are stored under .obsidian/plugins/$plugin_name. They\n# contain metadata (manifest.json), application code (main.js), stylesheets\n# (styles.css), and user-configuration data (data.json)."}, {"id": "community/Obsidian/NotesAndCoreConfiguration.gitignore_1", "file": "community/Obsidian/NotesAndCoreConfiguration.gitignore", "content": "# (styles.css), and user-configuration data (data.json).\n# We want to exclude all plugin-related files, so we can exclude everything\n# under this directory.\n.obsidian/plugins/**/*"}, {"id": "community/Obsidian/NotesAndExtendedConfiguration.gitignore_0", "file": "community/Obsidian/NotesAndExtendedConfiguration.gitignore", "content": "================================================\n# Excludes Obsidian workspace cache and plugin code, but retains plugin\n# configuration. All notes and user-controlled configuration files are tracked\n# by Git.\n#\n# \t\t\t\t!!! WARNING !!!\n#\n# Community plugins may store sensitive secrets in their data.json files. By\n# including these files, those secrets may be tracked in your Git repository.\n#\n# To ignore configurations for specific plugins, add a line like this after the\n# contents of this file (order is important):\n#     .obsidian/plugins/{{plugin_name}}/data.json\n#\n# Alternatively, ensure that you are treating your entire Git repository as\n# sensitive data, since it may contain secrets, or may have contained them in\n# past commits.  Understand your threat profile, and make the decision"}, {"id": "community/Obsidian/NotesAndExtendedConfiguration.gitignore_1", "file": "community/Obsidian/NotesAndExtendedConfiguration.gitignore", "content": "# past commits.  Understand your threat profile, and make the decision\n# appropriate for yourself. If in doubt, err on the side of not including\n# plugin configuration. Use one of the alternative gitignore files instead:\n# * NotesOnly.gitignore\n# * NotesAndCoreConfiguration.gitignore\n\n# The current application UI state (DOM layout, recently-opened files, etc.) is\n# stored in these files (separate for desktop and mobile) so you can resume\n# your session seamlessly after a restart. If you want to track UI state, use\n# the Workspaces core plugin instead of relying on these files.\n.obsidian/workspace.json\n.obsidian/workspace-mobile.json\n\n# Obsidian plugins are stored under .obsidian/plugins/$plugin_name. They\n# contain metadata (manifest.json), application code (main.js), stylesheets"}, {"id": "community/Obsidian/NotesAndExtendedConfiguration.gitignore_2", "file": "community/Obsidian/NotesAndExtendedConfiguration.gitignore", "content": "# contain metadata (manifest.json), application code (main.js), stylesheets\n# (styles.css), and user-configuration data (data.json).\n# We only want to track data.json, so we:\n# 1. exclude everything that the plugin folders contain,\n# 2. unignore data.json in the plugin folders\n.obsidian/plugins/*/**\n!.obsidian/plugins/*/data.json"}, {"id": "community/Obsidian/NotesOnly.gitignore_0", "file": "community/Obsidian/NotesOnly.gitignore", "content": "================================================\n# Excludes all Obsidian-related configuration. All notes are tracked by Git.\n\n# All Obsidian configuration and runtime state is stored here\n.obsidian/**/*"}, {"id": "community/PHP/Bitrix.gitignore_0", "file": "community/PHP/Bitrix.gitignore", "content": "================================================\n# gitignore template for 1C-Bitrix, a PHP-based CMS\n# website: https://www.1c-bitrix.ru\n\n#Exclude all of core files\n/bitrix/*\n\n#But not the templates and non bitrix components\n!/bitrix/templates\n!/bitrix/components\n/bitrix/components/bitrix\n\n#Exclude bitrix gadgets\n!/bitrix/gadgets\n/bitrix/gadgets/bitrix\n\n#User can use that directory to store some stuff, but it's not really recommended, just use /local instead of this\n!/bitrix/php_interface/\n\n#Exclude database configs\n/bitrix/php_interface/dbconn.php\n\n#Exclude default file storage directory\n/upload/"}, {"id": "community/PHP/CodeSniffer.gitignore_0", "file": "community/PHP/CodeSniffer.gitignore", "content": "================================================\n# gitignore for the PHP Codesniffer framework\n# website: https://github.com/squizlabs/PHP_CodeSniffer\n#\n# Recommended template: PHP.gitignore\n\n/wpcs/*"}, {"id": "community/PHP/Drupal7.gitignore_0", "file": "community/PHP/Drupal7.gitignore", "content": "================================================\n# gitignore template for Drupal 7 projects\n#\n# It is recommended that you use `Drupal.gitignore` as this is the latest version\n\n# Ignore configuration files that may contain sensitive information.\nsites/*/*settings*.php\nsites/example.sites.php\n\n# Ignore paths that contain generated content.\nfiles/\nsites/*/files\nsites/*/private\nsites/*/translations\n\n# Ignore default text files\nrobots.txt\n/CHANGELOG.txt\n/COPYRIGHT.txt\n/INSTALL*.txt\n/LICENSE.txt\n/MAINTAINERS.txt\n/UPGRADE.txt\n/README.txt\nsites/README.txt\nsites/all/libraries/README.txt\nsites/all/modules/README.txt\nsites/all/themes/README.txt\n\n# Ignore everything but the \"sites\" folder ( for non core developer )\n.htaccess\nweb.config\nauthorize.php\ncron.php\nindex.php\ninstall.php\nupdate.php"}, {"id": "community/PHP/Drupal7.gitignore_1", "file": "community/PHP/Drupal7.gitignore", "content": ".htaccess\nweb.config\nauthorize.php\ncron.php\nindex.php\ninstall.php\nupdate.php\nxmlrpc.php\n/includes\n/misc\n/modules\n/profiles\n/scripts\n/themes"}, {"id": "community/PHP/Jigsaw.gitignore_0", "file": "community/PHP/Jigsaw.gitignore", "content": "================================================\n# gitignore template for Jigsaw Static Site Generator\n#\n# website - https://jigsaw.tighten.co\n\n# Ignore build folder\nbuild_*"}, {"id": "community/PHP/Magento1.gitignore_0", "file": "community/PHP/Magento1.gitignore", "content": "================================================\n# gitignore template for Magento v1 projects\n#\n# It is recommended that you use `Magento.gitignore` as this is the latest version\n\n/PATCH_*.sh\n\n/app/etc/local.xml\n\n/media/*\n!/media/.htaccess\n\n!/media/customer\n/media/customer/*\n!/media/customer/.htaccess\n\n!/media/dhl\n/media/dhl/*\n!/media/dhl/logo.jpg\n\n!/media/downloadable\n/media/downloadable/*\n!/media/downloadable/.htaccess\n\n!/media/xmlconnect\n/media/xmlconnect/*\n\n!/media/xmlconnect/custom\n/media/xmlconnect/custom/*\n!/media/xmlconnect/custom/ok.gif\n\n!/media/xmlconnect/original\n/media/xmlconnect/original/*\n!/media/xmlconnect/original/ok.gif\n\n!/media/xmlconnect/system\n/media/xmlconnect/system/*\n!/media/xmlconnect/system/ok.gif\n\n/var/*\n!/var/.htaccess\n\n!/var/package\n/var/package/*"}, {"id": "community/PHP/Magento1.gitignore_1", "file": "community/PHP/Magento1.gitignore", "content": "!/media/xmlconnect/system/ok.gif\n\n/var/*\n!/var/.htaccess\n\n!/var/package\n/var/package/*\n!/var/package/*.xml"}, {"id": "community/PHP/Magento2.gitignore_0", "file": "community/PHP/Magento2.gitignore", "content": "================================================\n/sitemap\n/sitemap.xml\n/pub/sitemap\n/pub/sitemap.xml\n/app/config_sandbox\n/app/etc/config.php\n/app/etc/env.php\n/app/code/Magento/TestModule*\n/lib/internal/flex/uploader/.actionScriptProperties\n/lib/internal/flex/uploader/.flexProperties\n/lib/internal/flex/uploader/.project\n/lib/internal/flex/uploader/.settings\n/lib/internal/flex/varien/.actionScriptProperties\n/lib/internal/flex/varien/.flexLibProperties\n/lib/internal/flex/varien/.project\n/lib/internal/flex/varien/.settings\n/.grunt\n/.php_cs.cache\n/grunt-config.json\n/dev/tools/grunt/configs/local-themes.js\n\n/pub/media/*.*\n!/pub/media/.htaccess\n/pub/media/attribute/*\n!/pub/media/attribute/.htaccess\n/pub/media/analytics/*\n/pub/media/catalog/*\n!/pub/media/catalog/.htaccess\n/pub/media/customer/*"}, {"id": "community/PHP/Magento2.gitignore_1", "file": "community/PHP/Magento2.gitignore", "content": "/pub/media/analytics/*\n/pub/media/catalog/*\n!/pub/media/catalog/.htaccess\n/pub/media/customer/*\n!/pub/media/customer/.htaccess\n/pub/media/downloadable/*\n!/pub/media/downloadable/.htaccess\n/pub/media/favicon/*\n/pub/media/import/*\n!/pub/media/import/.htaccess\n/pub/media/logo/*\n/pub/media/theme/*\n/pub/media/theme_customization/*\n!/pub/media/theme_customization/.htaccess\n/pub/media/wysiwyg/*\n!/pub/media/wysiwyg/.htaccess\n/pub/media/tmp/*\n!/pub/media/tmp/.htaccess\n/pub/media/captcha/*\n!/pub/media/captcha/.htaccess\n/pub/static/*\n!/pub/static/.htaccess\n\n/var/*\n!/var/.htaccess\n/vendor/*\n!/vendor/.htaccess\n/generated/*\n!/generated/.htaccess"}, {"id": "community/PHP/Pimcore.gitignore_0", "file": "community/PHP/Pimcore.gitignore", "content": "================================================\n# gitignore template for Pimcore CMS\n\n# pimcore source files\n/pimcore\n\n# asset files\n/website/var/assets/*\n\n# backups\n/website/var/backup/*\n\n# file cache\n/website/var/cache/*\n\n# generated PHP classes, keep definition files (.psf)\n/website/var/classes/Object*\n!/website/var/classes/objectbricks\n\n# various configuration files\n/website/var/config/system.xml\n/website/var/config/cache.xml\n/website/var/config/robots.txt\n/website/var/config/Geo*\n/website/var/config/object/*\n/website/var/config/portal/*\n/website/var/config/sqlreport/*\n\n# sent e-mail log files\n/website/var/email/*\n\n# log files\n/website/var/log/*.log\n\n# serialized recyclebin files\n/website/var/recyclebin/*\n\n# search plugin\n/website/var/search/*\n\n# various temp files"}, {"id": "community/PHP/Pimcore.gitignore_1", "file": "community/PHP/Pimcore.gitignore", "content": "/website/var/recyclebin/*\n\n# search plugin\n/website/var/search/*\n\n# various temp files\n/website/var/system/*\n/website/var/tmp/*\n\n# serialized version files\n/website/var/versions/asset/*\n/website/var/versions/document/*\n/website/var/versions/object/*\n\n# user profile images\n/website/var/user-image/*\n\n# keep .dummy files\n!.dummy"}, {"id": "community/PHP/ThinkPHP.gitignore_0", "file": "community/PHP/ThinkPHP.gitignore", "content": "================================================\n# gitignore template for ThinkPHP v3.2.3\n# website: http://www.thinkphp.cn/\n\n# Logs and Cache files\n/Application/Runtime/\n\n# Common configure file\n/Application/Common/Conf/config.php"}, {"id": "community/Python/JupyterNotebooks.gitignore_0", "file": "community/Python/JupyterNotebooks.gitignore", "content": "================================================\n# gitignore template for Jupyter Notebooks\n# website: http://jupyter.org/\n\n.ipynb_checkpoints\n*/.ipynb_checkpoints/*\n\n# IPython\nprofile_default/\nipython_config.py\n\n# Jupyter lab virtual documents\n# https://jupyterlab-lsp.readthedocs.io/en/2.x/Configuring.html#virtual_documents_dir\n.virtual_documents/\n\n# Remove previous ipynb_checkpoints\n#   git rm -r .ipynb_checkpoints/"}, {"id": "community/Python/Nikola.gitignore_0", "file": "community/Python/Nikola.gitignore", "content": "================================================\n# gitignore template for Nikola static site generator\n# website: https://getnikola.com/\n\n.doit.db\n*.py[cod]\ncache/\noutput/"}, {"id": "Global/README.md_0", "file": "Global/README.md", "content": "================================================\n## Globally Useful gitignores\n\nThis directory contains globally useful gitignores,\ne.g. OS-specific and editor specific.\n\nFor more on global gitignores:\n<https://help.github.com/en/github/using-git/ignoring-files#configuring-ignored-files-for-all-repositories-on-your-computer>\n\nAnd a good blog post about 'em:\n<http://augustl.com/blog/2009/global_gitignores>"}, {"id": "Global/AL.gitignore_0", "file": "Global/AL.gitignore", "content": "================================================\n.vscode/*\n!.vscode/settings.json\n!.vscode/tasks.json\n!.vscode/launch.json\n!.vscode/extensions.json\n*.code-workspace\n\n# Local History for Visual Studio Code\n.history/\n*.app\n.snapshots/*"}, {"id": "Global/Anjuta.gitignore_0", "file": "Global/Anjuta.gitignore", "content": "================================================\n# Local configuration folder and symbol database\n/.anjuta/\n/.anjuta_sym_db.db"}, {"id": "Global/Ansible.gitignore_0", "file": "Global/Ansible.gitignore", "content": "================================================\n*.retry\n.ansible/"}, {"id": "Global/Archives.gitignore_0", "file": "Global/Archives.gitignore", "content": "================================================\n# It's better to unpack these files and commit the raw source because\n# git has its own built in compression methods.\n*.7z\n*.jar\n*.rar\n*.zip\n*.gz\n*.gzip\n*.tgz\n*.bzip\n*.bzip2\n*.bz2\n*.xz\n*.lzma\n*.cab\n*.xar\n*.zst\n*.tzst\n\n# Packing-only formats\n*.iso\n*.tar\n\n# Package management formats\n*.dmg\n*.xpi\n*.gem\n*.egg\n*.deb\n*.rpm\n*.msi\n*.msm\n*.msp\n*.txz"}, {"id": "Global/Backup.gitignore_0", "file": "Global/Backup.gitignore", "content": "================================================\n*.bak\n*.gho\n*.ori\n*.orig\n*.tmp"}, {"id": "Global/Bazaar.gitignore_0", "file": "Global/Bazaar.gitignore", "content": "================================================\n.bzr/\n.bzrignore"}, {"id": "Global/BricxCC.gitignore_0", "file": "Global/BricxCC.gitignore", "content": "================================================\n# Bricx Command Center IDE\n# http://bricxcc.sourceforge.net\n*.bak\n*.sym"}, {"id": "Global/Calabash.gitignore_0", "file": "Global/Calabash.gitignore", "content": "================================================\n# Calabash / Cucumber\nrerun/\nreports/\nscreenshots/\nscreenshot*.png\ntest-servers/\n\n# bundler\n.bundle\nvendor"}, {"id": "Global/Cloud9.gitignore_0", "file": "Global/Cloud9.gitignore", "content": "================================================\n# Cloud9 IDE - http://c9.io\n.c9revisions\n.c9"}, {"id": "Global/CodeKit.gitignore_0", "file": "Global/CodeKit.gitignore", "content": "================================================\n# General CodeKit files to ignore\nconfig.codekit\nconfig.codekit3\n/min"}, {"id": "Global/Cursor.gitignore_0", "file": "Global/Cursor.gitignore", "content": "================================================\n.cursorignore\n.cursorindexingignore"}, {"id": "Global/CVS.gitignore_0", "file": "Global/CVS.gitignore", "content": "================================================\n/CVS/*\n**/CVS/*\n.cvsignore\n*/.cvsignore"}, {"id": "Global/DartEditor.gitignore_0", "file": "Global/DartEditor.gitignore", "content": "================================================\n.project\n.buildlog"}, {"id": "Global/Diff.gitignore_0", "file": "Global/Diff.gitignore", "content": "================================================\n*.patch\n*.diff"}, {"id": "Global/Dreamweaver.gitignore_0", "file": "Global/Dreamweaver.gitignore", "content": "================================================\n# DW Dreamweaver added files\n_notes\n_compareTemp\nconfigs/\ndwsync.xml\ndw_php_codehinting.config\n*.mno"}, {"id": "Global/Dropbox.gitignore_0", "file": "Global/Dropbox.gitignore", "content": "================================================\n# Dropbox settings and caches\n.dropbox\n.dropbox.attr\n.dropbox.cache"}, {"id": "Global/Eclipse.gitignore_0", "file": "Global/Eclipse.gitignore", "content": "================================================\n.metadata\nbin/\ntmp/\n*.tmp\n*.bak\n*.swp\n*~.nib\nlocal.properties\n.settings/\n.loadpath\n.recommenders\n\n# External tool builders\n.externalToolBuilders/\n\n# Locally stored \"Eclipse launch configurations\"\n*.launch\n\n# PyDev specific (Python IDE for Eclipse)\n*.pydevproject\n\n# CDT-specific (C/C++ Development Tooling)\n.cproject\n\n# CDT- autotools\n.autotools\n\n# Java annotation processor (APT)\n.factorypath\n\n# PDT-specific (PHP Development Tools)\n.buildpath\n\n# sbteclipse plugin\n.target\n\n# Tern plugin\n.tern-project\n\n# TeXlipse plugin\n.texlipse\n\n# STS (Spring Tool Suite)\n.springBeans\n\n# Code Recommenders\n.recommenders/\n\n# Annotation Processing\n.apt_generated/\n.apt_generated_tests/\n\n# Scala IDE specific (Scala & Java development for Eclipse)\n.cache-main"}, {"id": "Global/Eclipse.gitignore_1", "file": "Global/Eclipse.gitignore", "content": ".apt_generated_tests/\n\n# Scala IDE specific (Scala & Java development for Eclipse)\n.cache-main\n.scala_dependencies\n.worksheet\n\n# Uncomment this line if you wish to ignore the project description file.\n# Typically, this file would be tracked if it contains build/dependency configurations:\n#.project"}, {"id": "Global/EiffelStudio.gitignore_0", "file": "Global/EiffelStudio.gitignore", "content": "================================================\n# The compilation directory\nEIFGENs"}, {"id": "Global/Emacs.gitignore_0", "file": "Global/Emacs.gitignore", "content": "================================================\n# -*- mode: gitignore; -*-\n*~\n\\#*\\#\n/.emacs.desktop\n/.emacs.desktop.lock\n*.elc\nauto-save-list\ntramp\n.\\#*\n\n# Org-mode\n.org-id-locations\n*_archive\n\n# flymake-mode\n*_flymake.*\n\n# eshell files\n/eshell/history\n/eshell/lastdir\n\n# elpa packages\n/elpa/\n\n# reftex files\n*.rel\n\n# AUCTeX auto folder\n/auto/\n\n# cask packages\n.cask/\ndist/\n\n# Flycheck\nflycheck_*.el\n\n# server auth directory\n/server/\n\n# projectiles files\n.projectile\n\n# directory configuration\n.dir-locals.el\n\n# network security\n/network-security.data\n\n# undo-tree\n*.~undo-tree~"}, {"id": "Global/Ensime.gitignore_0", "file": "Global/Ensime.gitignore", "content": "================================================\n# Ensime specific\n.ensime\n.ensime_cache/\n.ensime_lucene/"}, {"id": "Global/Espresso.gitignore_0", "file": "Global/Espresso.gitignore", "content": "================================================\n*.esproj"}, {"id": "Global/FlexBuilder.gitignore_0", "file": "Global/FlexBuilder.gitignore", "content": "================================================\nbin/\nbin-debug/\nbin-release/"}, {"id": "Global/GPG.gitignore_0", "file": "Global/GPG.gitignore", "content": "================================================\nsecring.*"}, {"id": "Global/Images.gitignore_0", "file": "Global/Images.gitignore", "content": "================================================\n# JPEG\n*.jpg\n*.jpeg\n*.jpe\n*.jif\n*.jfif\n*.jfi\n\n# JPEG 2000\n*.jp2\n*.j2k\n*.jpf\n*.jpx\n*.jpm\n*.mj2\n\n# JPEG XR\n*.jxr\n*.hdp\n*.wdp\n\n# Graphics Interchange Format\n*.gif\n\n# RAW\n*.raw\n\n# Web P\n*.webp\n\n# Portable Network Graphics\n*.png\n\n# Animated Portable Network Graphics\n*.apng\n\n# Multiple-image Network Graphics\n*.mng\n\n# Tagged Image File Format\n*.tiff\n*.tif\n\n# Scalable Vector Graphics\n*.svg\n*.svgz\n\n# Portable Document Format\n*.pdf\n\n# X BitMap\n*.xbm\n\n# BMP\n*.bmp\n*.dib\n\n# ICO\n*.ico\n\n# 3D Images\n*.3dm\n*.max"}, {"id": "Global/JDeveloper.gitignore_0", "file": "Global/JDeveloper.gitignore", "content": "================================================\n# default application storage directory used by the IDE Performance Cache feature\n.data/\n\n# used for ADF styles caching\ntemp/\n\n# default output directories\nclasses/\ndeploy/\njavadoc/\n\n# lock file, a part of Oracle Credential Store Framework\ncwallet.sso.lck"}, {"id": "Global/JEnv.gitignore_0", "file": "Global/JEnv.gitignore", "content": "================================================\n# JEnv local Java version configuration file\n.java-version\n\n# Used by previous versions of JEnv\n.jenv-version"}, {"id": "Global/JetBrains.gitignore_0", "file": "Global/JetBrains.gitignore", "content": "================================================\n# Covers JetBrains IDEs: IntelliJ, GoLand, RubyMine, PhpStorm, AppCode, PyCharm, CLion, Android Studio, WebStorm and Rider\n# Reference: https://intellij-support.jetbrains.com/hc/en-us/articles/206544839\n\n# User-specific stuff\n.idea/**/workspace.xml\n.idea/**/tasks.xml\n.idea/**/usage.statistics.xml\n.idea/**/dictionaries\n.idea/**/shelf\n\n# AWS User-specific\n.idea/**/aws.xml\n\n# Generated files\n.idea/**/contentModel.xml\n\n# Sensitive or high-churn files\n.idea/**/dataSources/\n.idea/**/dataSources.ids\n.idea/**/dataSources.local.xml\n.idea/**/sqlDataSources.xml\n.idea/**/dynamic.xml\n.idea/**/uiDesigner.xml\n.idea/**/dbnavigator.xml\n\n# Gradle\n.idea/**/gradle.xml\n.idea/**/libraries\n\n# Gradle and Maven with auto-import"}, {"id": "Global/JetBrains.gitignore_1", "file": "Global/JetBrains.gitignore", "content": "# Gradle\n.idea/**/gradle.xml\n.idea/**/libraries\n\n# Gradle and Maven with auto-import\n# When using Gradle or Maven with auto-import, you should exclude module files,\n# since they will be recreated, and may cause churn.  Uncomment if using\n# auto-import.\n# .idea/artifacts\n# .idea/compiler.xml\n# .idea/jarRepositories.xml\n# .idea/modules.xml\n# .idea/*.iml\n# .idea/modules\n# *.iml\n# *.ipr\n\n# CMake\ncmake-build-*/\n\n# Mongo Explorer plugin\n.idea/**/mongoSettings.xml\n\n# File-based project format\n*.iws\n\n# IntelliJ\nout/\n\n# mpeltonen/sbt-idea plugin\n.idea_modules/\n\n# JIRA plugin\natlassian-ide-plugin.xml\n\n# Cursive Clojure plugin\n.idea/replstate.xml\n\n# SonarLint plugin\n.idea/sonarlint/"}, {"id": "Global/JetBrains.gitignore_2", "file": "Global/JetBrains.gitignore", "content": "# Cursive Clojure plugin\n.idea/replstate.xml\n\n# SonarLint plugin\n.idea/sonarlint/\n.idea/sonarlint.xml # see https://community.sonarsource.com/t/is-the-file-idea-idea-idea-sonarlint-xml-intended-to-be-under-source-control/121119\n\n# Crashlytics plugin (for Android Studio and IntelliJ)\ncom_crashlytics_export_strings.xml\ncrashlytics.properties\ncrashlytics-build.properties\nfabric.properties\n\n# Editor-based HTTP Client\n.idea/httpRequests\nhttp-client.private.env.json\n\n# Android studio 3.1+ serialized cache file\n.idea/caches/build_file_checksums.ser\n\n# Apifox Helper cache\n.idea/.cache/.Apifox_Helper\n.idea/ApifoxUploaderProjectSetting.xml"}, {"id": "Global/Kate.gitignore_0", "file": "Global/Kate.gitignore", "content": "================================================\n# Swap Files #\n.*.kate-swp\n.swp.*"}, {"id": "Global/KDevelop4.gitignore_0", "file": "Global/KDevelop4.gitignore", "content": "================================================\n*.kdev4\n.kdev4/"}, {"id": "Global/Lazarus.gitignore_0", "file": "Global/Lazarus.gitignore", "content": "================================================\n# Lazarus compiler-generated binaries (safe to delete)\n*.exe\n*.dll\n*.so\n*.dylib\n*.lrs\n*.res\n*.compiled\n*.dbg\n*.ppu\n*.o\n*.or\n*.a\n\n# Lazarus autogenerated files (duplicated info)\n*.rst\n*.rsj\n*.lrt\n\n# Lazarus local files (user-specific info)\n*.lps\n\n# Lazarus backups and unit output folders.\n# These can be changed by user in Lazarus/project options.\nbackup/\n*.bak\nlib/\n\n# Application bundle for Mac OS\n*.app/"}, {"id": "Global/Lefthook.gitignore_0", "file": "Global/Lefthook.gitignore", "content": "================================================\n# https://lefthook.dev/configuration/#config-file-name\n/.lefthook-local.json\n/.lefthook-local.toml\n/.lefthook-local.yaml\n/.lefthook-local.yml\n/lefthook-local.json\n/lefthook-local.toml\n/lefthook-local.yaml\n/lefthook-local.yml\n/.config/lefthook-local.json\n/.config/lefthook-local.toml\n/.config/lefthook-local.yaml\n/.config/lefthook-local.yml\n\n# https://lefthook.dev/configuration/source_dir_local.html\n/.lefthook-local/"}, {"id": "Global/LibreOffice.gitignore_0", "file": "Global/LibreOffice.gitignore", "content": "================================================\n# LibreOffice locks\n.~lock.*#"}, {"id": "Global/Linux.gitignore_0", "file": "Global/Linux.gitignore", "content": "================================================\n*~\n\n# temporary files which can be created if a process still has a handle open of a deleted file\n.fuse_hidden*\n\n# Metadata left by Dolphin file manager, which comes with KDE Plasma\n.directory\n\n# Linux trash folder which might appear on any partition or disk\n.Trash-*\n\n# .nfs files are created when an open file is removed but is still being accessed\n.nfs*\n\n# Log files created by default by the nohup command\nnohup.out"}, {"id": "Global/LyX.gitignore_0", "file": "Global/LyX.gitignore", "content": "================================================\n# Ignore LyX backup and autosave files\n# http://www.lyx.org/\n*.lyx~\n*.lyx#"}, {"id": "Global/macOS.gitignore_0", "file": "Global/macOS.gitignore", "content": "================================================\n# General\n.DS_Store\n__MACOSX/\n.AppleDouble\n.LSOverride\nIcon[\n]\n\n# Thumbnails\n._*\n\n# Files that might appear in the root of a volume\n.DocumentRevisions-V100\n.fseventsd\n.Spotlight-V100\n.TemporaryItems\n.Trashes\n.VolumeIcon.icns\n.com.apple.timemachine.donotpresent\n\n# Directories potentially created on remote AFP share\n.AppleDB\n.AppleDesktop\nNetwork Trash Folder\nTemporary Items\n.apdisk"}, {"id": "Global/MATLAB.gitignore_0", "file": "Global/MATLAB.gitignore", "content": "================================================\n# Autosave files\n*.asv\n*.m~\n*.autosave\n*.slx.r*\n*.mdl.r*\n\n# Derived content-obscured files\n*.p\n\n# Compiled MEX files\n*.mex*\n\n# Packaged app and toolbox files\n*.mlappinstall\n*.mltbx\n\n# Deployable archives\n*.ctf\n\n# Generated helpsearch folders\nhelpsearch*/\n\n# Code generation folders\nslprj/\nsccprj/\ncodegen/\n\n# Cache files\n*.slxc\n\n# Cloud based storage dotfile\n.MATLABDriveTag"}, {"id": "Global/Mercurial.gitignore_0", "file": "Global/Mercurial.gitignore", "content": "================================================\n.hg/\n.hgignore\n.hgsigs\n.hgsub\n.hgsubstate\n.hgtags"}, {"id": "Global/Metals.gitignore_0", "file": "Global/Metals.gitignore", "content": "================================================\n# Metals (Scala Language Server)\n# Reference: https://scalameta.org/metals/docs/editors/vscode#files-and-directories-to-include-in-your-gitignore\n.metals/\n.bloop/\n.ammonite/\nmetals.sbt"}, {"id": "Global/MicrosoftOffice.gitignore_0", "file": "Global/MicrosoftOffice.gitignore", "content": "================================================\n*.tmp\n\n# Word temporary\n~$*.doc*\n~$*.dot*\n\n# Word Auto Backup File\nBackup of *.doc*\n\n# Excel temporary\n~$*.xls*\n\n# Excel Backup File\n*.xlk\n\n# PowerPoint temporary\n~$*.ppt*\n\n# Visio autosave temporary files\n*.~vsd*"}, {"id": "Global/mise.gitignore_0", "file": "Global/mise.gitignore", "content": "================================================\n# https://mise.jdx.dev/configuration.html\n# https://mise.jdx.dev/configuration/environments.html\n.mise.*.local.toml\n.mise.local.toml\nmise.*.local.toml\nmise.local.toml\n.mise/*.local.toml\nmise/*.local.toml\n\n# https://mise.jdx.dev/configuration.html#tool-versions\n#.tool-versions"}, {"id": "Global/Momentics.gitignore_0", "file": "Global/Momentics.gitignore", "content": "================================================\n# Built files\nx86/\narm/\narm-p/\ntranslations/*.qm\n\n# IDE settings\n.settings/"}, {"id": "Global/MonoDevelop.gitignore_0", "file": "Global/MonoDevelop.gitignore", "content": "================================================\n#User Specific\n*.userprefs\n*.usertasks\n\n#Mono Project Files\n*.pidb\n*.resources\ntest-results/"}, {"id": "Global/NetBeans.gitignore_0", "file": "Global/NetBeans.gitignore", "content": "================================================\n**/nbproject/private/\n**/nbproject/Makefile-*.mk\n**/nbproject/Package-*.bash\nbuild/\nnbbuild/\ndist/\nnbdist/\n.nb-gradle/"}, {"id": "Global/Ninja.gitignore_0", "file": "Global/Ninja.gitignore", "content": "================================================\n.ninja_deps\n.ninja_log"}, {"id": "Global/NotepadPP.gitignore_0", "file": "Global/NotepadPP.gitignore", "content": "================================================\n# Notepad++ backups #\n*.bak"}, {"id": "Global/Octave.gitignore_0", "file": "Global/Octave.gitignore", "content": "================================================\nMATLAB.gitignore"}, {"id": "Global/Otto.gitignore_0", "file": "Global/Otto.gitignore", "content": "================================================\n.otto/"}, {"id": "Global/Patch.gitignore_0", "file": "Global/Patch.gitignore", "content": "================================================\n*.orig\n*.rej"}, {"id": "Global/PlatformIO.gitignore_0", "file": "Global/PlatformIO.gitignore", "content": "================================================\n.pio\n.pioenvs\n.piolibdeps\n.vscode/.browse.c_cpp.db*\n.vscode/c_cpp_properties.json\n.vscode/launch.json"}, {"id": "Global/PSoCCreator.gitignore_0", "file": "Global/PSoCCreator.gitignore", "content": "================================================\n# Project Settings\n*.cywrk.*\n*.cyprj.*\n\n# Generated Assets and Resources\nDebug/\nRelease/\nExport/\n*/codegentemp\n*/Generated_Source\n*_datasheet.pdf\n*_timing.html\n*.cycdx\n*.cyfit\n*.rpt\n*.svd\n*.log\n*.zip"}, {"id": "Global/PuTTY.gitignore_0", "file": "Global/PuTTY.gitignore", "content": "================================================\n# Private key\n*.ppk"}, {"id": "Global/Redcar.gitignore_0", "file": "Global/Redcar.gitignore", "content": "================================================\n.redcar"}, {"id": "Global/Redis.gitignore_0", "file": "Global/Redis.gitignore", "content": "================================================\n# Ignore redis binary dump (dump.rdb) files\n\n*.rdb"}, {"id": "Global/SBT.gitignore_0", "file": "Global/SBT.gitignore", "content": "================================================\n# Simple Build Tool\n# http://www.scala-sbt.org/release/docs/Getting-Started/Directories.html#configuring-version-control\n\ndist/*\ntarget/\nlib_managed/\nsrc_managed/\nproject/boot/\nproject/plugins/project/\n.history\n.cache\n.lib/\n.bsp/"}, {"id": "Global/SlickEdit.gitignore_0", "file": "Global/SlickEdit.gitignore", "content": "================================================\n# SlickEdit workspace and project files are ignored by default because\n# typically they are considered to be developer-specific and not part of a\n# project.\n*.vpw\n*.vpj\n\n# SlickEdit workspace history and tag files always contain user-specific\n# data so they should not be stored in a repository.\n*.vpwhistu\n*.vpwhist\n*.vtg"}, {"id": "Global/Stata.gitignore_0", "file": "Global/Stata.gitignore", "content": "================================================\n# .gitignore file for git projects containing Stata files\n# Commercial statistical software: http://www.stata.com\n\n# Stata dataset and output files\n*.dta\n*.gph\n*.log\n*.smcl\n*.stpr\n*.stsem\n~*.stswp\n\n# Graphic export files from Stata\n# Stata command graph export: http://www.stata.com/manuals14/g-2graphexport.pdf\n#\n# You may add graphic export files to your .gitignore. However you should be\n# aware that this will exclude all image files from this main directory\n# and subdirectories.\n# *.ps\n# *.eps\n# *.wmf\n# *.emf\n# *.pdf\n# *.png\n# *.tif"}, {"id": "Global/SublimeText.gitignore_0", "file": "Global/SublimeText.gitignore", "content": "================================================\n# Cache files for Sublime Text\n*.tmlanguage.cache\n*.tmPreferences.cache\n*.stTheme.cache\n\n# Workspace files are user-specific\n*.sublime-workspace\n\n# Project files should be checked into the repository, unless a significant\n# proportion of contributors will probably not be using Sublime Text\n# *.sublime-project\n\n# SFTP configuration file\nsftp-config.json\nsftp-config-alt*.json\n\n# Package control specific files\nPackage Control.last-run\nPackage Control.ca-list\nPackage Control.ca-bundle\nPackage Control.system-ca-bundle\nPackage Control.cache/\nPackage Control.ca-certs/\nPackage Control.merged-ca-bundle\nPackage Control.user-ca-bundle\noscrypto-ca-bundle.crt\nbh_unicode_properties.cache\n\n# Sublime-github package stores a github token in this file"}, {"id": "Global/SublimeText.gitignore_1", "file": "Global/SublimeText.gitignore", "content": "bh_unicode_properties.cache\n\n# Sublime-github package stores a github token in this file\n# https://packagecontrol.io/packages/sublime-github\nGitHub.sublime-settings"}, {"id": "Global/SVN.gitignore_0", "file": "Global/SVN.gitignore", "content": "================================================\n.svn/"}, {"id": "Global/Syncthing.gitignore_0", "file": "Global/Syncthing.gitignore", "content": "================================================\n# Syncthing caches\n.stversions"}, {"id": "Global/SynopsysVCS.gitignore_0", "file": "Global/SynopsysVCS.gitignore", "content": "================================================\n# Waveform formats\n*.vcd\n*.vpd\n*.evcd\n*.fsdb\n\n# Default name of the simulation executable.  A different name can be\n# specified with this switch (the associated daidir database name is\n# also taken from here):  -o <path>/<filename>\nsimv\n\n# Generated for Verilog and VHDL top configs\nsimv.daidir/\nsimv.db.dir/\n\n# Infrastructure necessary to co-simulate SystemC models with\n# Verilog/VHDL models.  An alternate directory may be specified with this\n# switch:  -Mdir=<directory_path>\ncsrc/\n\n# Log file - the following switch allows to specify the file that will be\n# used to write all messages from simulation:  -l <filename>\n*.log\n\n# Coverage results (generated with urg) and database location.  The"}, {"id": "Global/SynopsysVCS.gitignore_1", "file": "Global/SynopsysVCS.gitignore", "content": "*.log\n\n# Coverage results (generated with urg) and database location.  The\n# following switch can also be used:  urg -dir <coverage_directory>.vdb\nsimv.vdb/\nurgReport/\n\n# DVE and UCLI related files.\nDVEfiles/\nucli.key\n\n# When the design is elaborated for DirectC, the following file is created\n# with declarations for C/C++ functions.\nvc_hdrs.h"}, {"id": "Global/Tags.gitignore_0", "file": "Global/Tags.gitignore", "content": "================================================\n# Ignore tags created by etags, ctags, gtags (GNU global) and cscope\nTAGS\n.TAGS\n!TAGS/\ntags\n.tags\n!tags/\ngtags.files\nGTAGS\nGRTAGS\nGPATH\nGSYMS\ncscope.files\ncscope.out\ncscope.in.out\ncscope.po.out"}, {"id": "Global/TextMate.gitignore_0", "file": "Global/TextMate.gitignore", "content": "================================================\n*.tmproj\n*.tmproject\ntmtags"}, {"id": "Global/TortoiseGit.gitignore_0", "file": "Global/TortoiseGit.gitignore", "content": "================================================\n# Project-level settings\n/.tgitconfig"}, {"id": "Global/Vagrant.gitignore_0", "file": "Global/Vagrant.gitignore", "content": "================================================\n# General\n.vagrant/\n\n# Log files (if you are creating logs in debug mode, uncomment this)\n# *.log"}, {"id": "Global/Vim.gitignore_0", "file": "Global/Vim.gitignore", "content": "================================================\n# Swap\n[._]*.s[a-v][a-z]\n# comment out the next line if you don't need vector files\n!*.svg\n[._]*.sw[a-p]\n[._]s[a-rt-v][a-z]\n[._]ss[a-gi-z]\n[._]sw[a-p]\n\n# Session\nSession.vim\nSessionx.vim\n\n# Temporary\n.netrwhist\n*~\n# Auto-generated tag files\ntags\n# Persistent undo\n[._]*.un~"}, {"id": "Global/VirtualEnv.gitignore_0", "file": "Global/VirtualEnv.gitignore", "content": "================================================\n# Virtualenv\n# https://realpython.com/python-virtual-environments-a-primer/#the-virtualenv-project\n.Python\n[Bb]in\n[Ii]nclude\n[Ll]ib\n[Ll]ib64\n[Ll]ocal\n[Ss]cripts\npyvenv.cfg\n.venv\npip-selfcheck.json"}, {"id": "Global/Virtuoso.gitignore_0", "file": "Global/Virtuoso.gitignore", "content": "================================================\n# Gitignore for Cadence Virtuoso\n################################################################\n\n# Log files\n*.log\npanic*.log.*\n\n# OpenAccess database lock files\n*.cdslck*\n\n# Run directories for layout vs. schematic and design rule check\nlvsRunDir/*\ndrcRunDir/*\n\n# Abstract generation tool\nabstract.log*\nabstract.record*"}, {"id": "Global/VisualStudioCode.gitignore_0", "file": "Global/VisualStudioCode.gitignore", "content": "================================================\n.vscode/*\n!.vscode/settings.json\n!.vscode/tasks.json\n!.vscode/launch.json\n!.vscode/extensions.json\n!.vscode/*.code-snippets\n!*.code-workspace\n\n# Built Visual Studio Code Extensions\n*.vsix"}, {"id": "Global/WebMethods.gitignore_0", "file": "Global/WebMethods.gitignore", "content": "================================================\n**/IntegrationServer/datastore/\n**/IntegrationServer/db/\n**/IntegrationServer/DocumentStore/\n**/IntegrationServer/lib/\n**/IntegrationServer/logs/\n**/IntegrationServer/replicate/\n**/IntegrationServer/sdk/\n**/IntegrationServer/support/\n**/IntegrationServer/update/\n**/IntegrationServer/userFtpRoot/\n**/IntegrationServer/web/\n**/IntegrationServer/WmRepository4/\n**/IntegrationServer/XAStore/\n**/IntegrationServer/packages/Wm*/"}, {"id": "Global/Windows.gitignore_0", "file": "Global/Windows.gitignore", "content": "================================================\n# Windows thumbnail cache files\nThumbs.db\nThumbs.db:encryptable\nehthumbs.db\nehthumbs_vista.db\n\n# Dump file\n*.stackdump\n\n# Folder config file\n[Dd]esktop.ini\n\n# Recycle Bin used on file shares\n$RECYCLE.BIN/\n\n# Windows Installer files\n*.cab\n*.msi\n*.msix\n*.msm\n*.msp\n\n# Windows shortcuts\n*.lnk"}, {"id": "Global/Xcode.gitignore_0", "file": "Global/Xcode.gitignore", "content": "================================================\n## User settings\nxcuserdata/"}, {"id": "Global/XilinxISE.gitignore_0", "file": "Global/XilinxISE.gitignore", "content": "================================================\n# intermediate build files\n*.bgn\n*.bit\n*.bld\n*.cmd_log\n*.drc\n*.ll\n*.lso\n*.msd\n*.msk\n*.ncd\n*.ngc\n*.ngd\n*.ngr\n*.pad\n*.par\n*.pcf\n*.prj\n*.ptwx\n*.rbb\n*.rbd\n*.stx\n*.syr\n*.twr\n*.twx\n*.unroutes\n*.ut\n*.xpi\n*.xst\n*_bitgen.xwbt\n*_envsettings.html\n*_map.map\n*_map.mrp\n*_map.ngm\n*_map.xrpt\n*_ngdbuild.xrpt\n*_pad.csv\n*_pad.txt\n*_par.xrpt\n*_summary.html\n*_summary.xml\n*_usage.xml\n*_xst.xrpt\n\n# iMPACT generated files\n_impactbatch.log\nimpact.xsl\nimpact_impact.xwbt\nise_impact.cmd\nwebtalk_impact.xml\n\n# Core Generator generated files\nxaw2verilog.log\n\n# project-wide generated files\n*.gise\npar_usage_statistics.html\nusage_statistics_webtalk.html\nwebtalk.log\nwebtalk_pn.xml\n\n# generated folders\niseconfig/\nxlnx_auto_0_xdb/\nxst/\n_ngo/\n_xmsgs/"}, {"id": ".github/CODEOWNERS_0", "file": ".github/CODEOWNERS", "content": "================================================\n# Order is important. The LAST matching pattern has the MOST precedence.\n# gitignore style patterns are used, not globs.\n# https://docs.github.com/articles/about-codeowners\n# https://git-scm.com/docs/gitignore\n\n# Catch All - Defer to the gitignore maintainers\n* @github/gitignore-maintainers"}, {"id": ".github/PULL_REQUEST_TEMPLATE.md_0", "file": ".github/PULL_REQUEST_TEMPLATE.md", "content": "================================================\n### Reasons for making this change\n\n_TODO_\n<!---\nPlease provide some background for this change.\n--->\n\n### Links to documentation supporting these rule changes\n\n_TODO_\n\n<!---\nLink to the project docs, any existing .gitignore files that project may have in it's own repo, etc\n--->\n\n### If this is a new template\n\nLink to application or project\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s homepage: TODO\n\n### Merge and Approval Steps\n- [ ] Confirm that you've read the [contribution guidelines](https://github.com/github/gitignore/tree/main?tab=readme-ov-file#contributing-guidelines) and ensured your PR aligns\n- [ ] Ensure CI is passing\n- [ ] Get a review and Approval from one of the maintainers"}, {"id": ".github/workflows/stale.yml_0", "file": ".github/workflows/stale.yml", "content": "================================================\nname: Stale\n\n# **What it does**: Close pull requests after no updates for 180 days.\n# **Why we have it**: This repository gets a lot of PRs, and the maintainers team is small.\n#                     This helps reduce the open PRs to ones that are most desired by the community.\n# **Who does it impact**: Contributors and maintainers of github/gitignore.\n\non:\n  schedule:\n    - cron: '20 16 * * *' # Run every day at 16:20 UTC / 8:20 PST\n\npermissions:\n  actions: write\n  contents: write # only for delete-branch option\n  issues: write\n  pull-requests: write\n\njobs:\n  stale:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/stale@5bef64f19d7facfb25b37b414482c7164d639639 # v9.1.0\n        with:"}, {"id": ".github/workflows/stale.yml_1", "file": ".github/workflows/stale.yml", "content": "- uses: actions/stale@5bef64f19d7facfb25b37b414482c7164d639639 # v9.1.0\n        with:\n          stale-pr-message: 'This PR is stale because there have been no updates in 90 days. It will close after 180 days of inactivity. Leave a comment if you want to keep it open :smile:'\n          close-pr-message: 'This PR has been closed because it was inactive for 180 days. If you want to continue working on it, please open a new PR.'\n          days-before-stale: 90\n          days-before-close: 180\n          stale-pr-label: 'stale'\n          exempt-pr-labels: 'keep'\n          close-issue-reason: not_planned\n          ascending: true # Sort PRs by last updated date in ascending order\n          operations-per-run: 300"}, {"id": "gitingest_outputs/gitignore_raw_20250905_192308.txt_0", "file": "gitingest_outputs/gitignore_raw_20250905_192308.txt", "content": "================================================\nDirectory structure:\n\u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac github-gitignore/\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac README.md\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CONTRIBUTING.md\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac LICENSE\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Global/\n    \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac README.md\n    \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac .github/\n        \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac PULL_REQUEST_TEMPLATE.md\n        \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac workflows/\n            \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac stale.yml"}, {"id": "README.md_0", "file": "README.md", "content": "================================================\n# A collection of `.gitignore` templates\n\nThis is GitHub\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s collection of [`.gitignore`][man] file templates.\nWe use this list to populate the `.gitignore` template choosers available\nin the GitHub.com interface when creating new repositories and files.\n\nFor more information about how `.gitignore` files work, and how to use them,\nthe following resources are a great place to start:\n\n- The [Ignoring Files chapter][chapter] of the [Pro Git][progit] book.\n- The [Ignoring Files article][help] on the GitHub Help site.\n- The [gitignore(5)][man] manual page.\n\n[man]: https://git-scm.com/docs/gitignore\n[help]: https://help.github.com/articles/ignoring-files"}, {"id": "README.md_1", "file": "README.md", "content": "[man]: https://git-scm.com/docs/gitignore\n[help]: https://help.github.com/articles/ignoring-files\n[chapter]: https://git-scm.com/book/en/v2/Git-Basics-Recording-Changes-to-the-Repository#_ignoring\n[progit]: https://git-scm.com/book"}, {"id": "README.md_2", "file": "README.md", "content": "## Folder structure\n\nWe support a collection of templates, organized in this way:\n\n- The root folder contains templates in common use, to help people get started\n  with popular programming languages and technologies. These define a meaningful\n  set of rules to help get started, and ensure you are not committing\n  unimportant files into your repository.\n- [`Global`](./Global) contains templates for various editors, tools and\n  operating systems that can be used in different situations. It is recommended\n  that you either [add these to your global template](https://docs.github.com/en/get-started/getting-started-with-git/ignoring-files#configuring-ignored-files-for-all-repositories-on-your-computer)\n  or merge these rules into your project-specific templates if you want to use"}, {"id": "README.md_3", "file": "README.md", "content": "or merge these rules into your project-specific templates if you want to use\n  them permanently.\n- [`community`](./community) contains specialized templates for other popular\n  languages, tools and project, which don't currently belong in the mainstream\n  templates. These should be added to your project-specific templates when you\n  decide to adopt the framework or tool."}, {"id": "README.md_4", "file": "README.md", "content": "## What makes a good template?\n\nA template should contain a set of rules to help Git repositories work with a\nspecific programming language, framework, tool or environment.\n\nIf it's not possible to curate a small set of useful rules for this situation,\nthen the template is not a good fit for this collection.\n\nIf a template is mostly a list of files installed by a particular version of\nsome software (e.g. a PHP framework), it could live under the `community`\ndirectory. See [versioned templates](#versioned-templates) for more details.\n\nIf you have a small set of rules, or want to support a technology that is not\nwidely in use, and still believe this will be helpful to others, please read the\nsection about [specialized templates](#specialized-templates) for more details."}, {"id": "README.md_5", "file": "README.md", "content": "section about [specialized templates](#specialized-templates) for more details.\n\nInclude details when opening pull request if the template is important and visible. We\nmay not accept it immediately, but we can promote it to the root at a later date\nbased on interest.\n\nPlease also understand that we can\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2t list every tool that ever existed.\nOur aim is to curate a collection of the _most common and helpful_ templates,\nnot to make sure we cover every project possible. If we choose not to\ninclude your language, tool, or project, it\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s not because it\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s not awesome."}, {"id": "README.md_6", "file": "README.md", "content": "## Contributing guidelines\n\nWe\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2d love for you to help us improve this project. To help us keep this collection\nhigh quality, we request that contributions adhere to the following guidelines.\n\n- **Provide a link to the application or project\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s homepage**. Unless it\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s\n  extremely popular, there\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s a chance the maintainers don\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2t know about or use\n  the language, framework, editor, app, or project your change applies to.\n\n- **Provide links to documentation** supporting the change you\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2re making.\n  Current, canonical documentation mentioning the files being ignored is best.\n  If documentation isn\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2t available to support your change, do the best you can\n  to explain what the files being ignored are for."}, {"id": "README.md_7", "file": "README.md", "content": "to explain what the files being ignored are for.\n\n- **Explain why you\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2re making a change**. Even if it seems self-evident, please\n  take a sentence or two to tell us why your change or addition should happen.\n  It\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s especially helpful to articulate why this change applies to _everyone_\n  who works with the applicable technology, rather than just you or your team.\n\n- **Please consider the scope of your change**. If your change is specific to a\n  certain language or framework, then make sure the change is made to the\n  template for that language or framework, rather than to the template for an\n  editor, tool, or operating system.\n\n- **Please only modify _one template_ per pull request**. This helps keep pull"}, {"id": "README.md_8", "file": "README.md", "content": "- **Please only modify _one template_ per pull request**. This helps keep pull\n  requests and feedback focused on a specific project or technology.\n\nIn general, the more you can do to help us understand the change you\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2re making,\nthe more likely we\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2ll be to accept your contribution quickly."}, {"id": "README.md_9", "file": "README.md", "content": "## Versioned templates\n\nSome templates can change greatly between versions, and if you wish to contribute\nto this repository we need to follow this specific flow:\n\n- the template at the root should be the current supported version\n- the template at the root should not have a version in the filename (i.e.\n  \"evergreen\")\n- previous versions of templates should live under `community/`\n- previous versions of the template should embed the version in the filename,\n  for readability\n\nThis helps ensure users get the latest version (because they'll use whatever is\nat the root) but helps maintainers support older versions still in the wild."}, {"id": "README.md_10", "file": "README.md", "content": "## Specialized templates\n\nIf you have a template that you would like to contribute, but it isn't quite\nmainstream, please consider adding this to the `community` directory under a\nfolder that best suits where it belongs.\n\nThe rules in your specialized template should be specific to the framework or\ntool, and any additional templates should be mentioned in a comment in the\nheader of the template.\n\nFor example, this template might live at `community/DotNet/InforCRM.gitignore`:\n\n```gitignore\n# gitignore template for InforCRM (formerly SalesLogix)\n# website: https://www.infor.com/product-summary/cx/infor-crm/\n#\n# Recommended: VisualStudio.gitignore\n\n# Ignore model files that are auto-generated\nModelIndex.xml\nExportedFiles.xml\n\n# Ignore deployment files\n[Mm]odel/[Dd]eployment"}, {"id": "README.md_11", "file": "README.md", "content": "ModelIndex.xml\nExportedFiles.xml\n\n# Ignore deployment files\n[Mm]odel/[Dd]eployment\n\n# Force include portal SupportFiles\n!Model/Portal/*/SupportFiles/[Bb]in/\n!Model/Portal/PortalTemplates/*/SupportFiles/[Bb]in\n```"}, {"id": "README.md_12", "file": "README.md", "content": "## Contributing workflow\n\nHere\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s how we suggest you go about proposing a change to this project:\n\n1. [Fork this project][fork] to your account.\n2. [Create a branch][branch] for the change you intend to make.\n3. Make your changes to your fork.\n4. [Send a pull request][pr] from your fork\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s branch to our `main` branch.\n\nUsing the web-based interface to make changes is fine too, and will help you\nby automatically forking the project and prompting to send a pull request too.\n\n[fork]: https://help.github.com/articles/fork-a-repo/\n[branch]: https://help.github.com/articles/creating-and-deleting-branches-within-your-repository\n[pr]: https://help.github.com/articles/using-pull-requests/\n\n## License\n\n[CC0-1.0](./LICENSE)."}, {"id": "CONTRIBUTING.md_0", "file": "CONTRIBUTING.md", "content": "================================================\n# Contributing guidelines\n\nWe\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2d love you to help us improve this project. To help us keep this collection\nhigh quality, we request that contributions adhere to the following guidelines.\n\n- **Provide a link to the application or project\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s homepage**. Unless it\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s\n  extremely popular, there\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s a chance the maintainers don\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2t know about or use\n  the language, framework, editor, app, or project your change applies to.\n\n- **Provide links to documentation** supporting the change you\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2re making.\n  Current, canonical documentation mentioning the files being ignored is best.\n  If documentation isn\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2t available to support your change, do the best you can\n  to explain what the files being ignored are for."}, {"id": "CONTRIBUTING.md_1", "file": "CONTRIBUTING.md", "content": "to explain what the files being ignored are for.\n\n- **Explain why you\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2re making a change**. Even if it seems self-evident, please\n  take a sentence or two to tell us why your change or addition should happen.\n  It\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s especially helpful to articulate why this change applies to *everyone*\n  who works with the applicable technology, rather than just you or your team.\n\n- **Please consider the scope of your change**. If your change specific to a\n  certain language or framework, then make sure the change is made to the\n  template for that language or framework, rather than to the template for an\n  editor, tool, or operating system.\n\n- **Please only modify *one template* per pull request**. This helps keep pull\n  requests and feedback focused on a specific project or technology."}, {"id": "CONTRIBUTING.md_2", "file": "CONTRIBUTING.md", "content": "requests and feedback focused on a specific project or technology.\n\nIn general, the more you can do to help us understand the change you\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2re making,\nthe more likely we\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2ll be to accept your contribution quickly.\n\nIf a template is mostly a list of files installed by a particular version of\nsome software (e.g. a PHP framework) then it's brittle and probably no more\nhelpful than a simple `ls`. If it's not possible to curate a small set of\nuseful rules, then the template might not be a good fit for this collection.\n\nPlease also understand that we can\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2t list every tool that ever existed.\nOur aim is to curate a collection of the *most common and helpful* templates,\nnot to make sure we cover every project possible. If we choose not to"}, {"id": "CONTRIBUTING.md_3", "file": "CONTRIBUTING.md", "content": "not to make sure we cover every project possible. If we choose not to\ninclude your language, tool, or project, it\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s not because it\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s not awesome."}, {"id": "LICENSE_0", "file": "LICENSE", "content": "================================================\nCC0 1.0 Universal\n\nStatement of Purpose\n\nThe laws of most jurisdictions throughout the world automatically confer\nexclusive Copyright and Related Rights (defined below) upon the creator and\nsubsequent owner(s) (each and all, an \"owner\") of an original work of\nauthorship and/or a database (each, a \"Work\").\n\nCertain owners wish to permanently relinquish those rights to a Work for the\npurpose of contributing to a commons of creative, cultural and scientific\nworks (\"Commons\") that the public can reliably and without fear of later\nclaims of infringement build upon, modify, incorporate in other works, reuse\nand redistribute as freely as possible in any form whatsoever and for any"}, {"id": "LICENSE_1", "file": "LICENSE", "content": "and redistribute as freely as possible in any form whatsoever and for any\npurposes, including without limitation commercial purposes. These owners may\ncontribute to the Commons to promote the ideal of a free culture and the\nfurther production of creative, cultural and scientific works, or to gain\nreputation or greater distribution for their Work in part through the use and\nefforts of others.\n\nFor these and/or other purposes and motivations, and without any expectation\nof additional consideration or compensation, the person associating CC0 with a\nWork (the \"Affirmer\"), to the extent that he or she is an owner of Copyright\nand Related Rights in the Work, voluntarily elects to apply CC0 to the Work\nand publicly distribute the Work under its terms, with knowledge of his or her"}, {"id": "LICENSE_2", "file": "LICENSE", "content": "and publicly distribute the Work under its terms, with knowledge of his or her\nCopyright and Related Rights in the Work and the meaning and intended legal\neffect of CC0 on those rights.\n\n1. Copyright and Related Rights. A Work made available under CC0 may be\nprotected by copyright and related or neighboring rights (\"Copyright and\nRelated Rights\"). Copyright and Related Rights include, but are not limited\nto, the following:\n\n  i. the right to reproduce, adapt, distribute, perform, display, communicate,\n  and translate a Work;\n\n  ii. moral rights retained by the original author(s) and/or performer(s);\n\n  iii. publicity and privacy rights pertaining to a person's image or likeness\n  depicted in a Work;\n\n  iv. rights protecting against unfair competition in regards to a Work,"}, {"id": "LICENSE_3", "file": "LICENSE", "content": "depicted in a Work;\n\n  iv. rights protecting against unfair competition in regards to a Work,\n  subject to the limitations in paragraph 4(a), below;\n\n  v. rights protecting the extraction, dissemination, use and reuse of data in\n  a Work;\n\n  vi. database rights (such as those arising under Directive 96/9/EC of the\n  European Parliament and of the Council of 11 March 1996 on the legal\n  protection of databases, and under any national implementation thereof,\n  including any amended or successor version of such directive); and\n\n  vii. other similar, equivalent or corresponding rights throughout the world\n  based on applicable law or treaty, and any national implementations thereof.\n\n2. Waiver. To the greatest extent permitted by, but not in contravention of,"}, {"id": "LICENSE_4", "file": "LICENSE", "content": "2. Waiver. To the greatest extent permitted by, but not in contravention of,\napplicable law, Affirmer hereby overtly, fully, permanently, irrevocably and\nunconditionally waives, abandons, and surrenders all of Affirmer's Copyright\nand Related Rights and associated claims and causes of action, whether now\nknown or unknown (including existing as well as future claims and causes of\naction), in the Work (i) in all territories worldwide, (ii) for the maximum\nduration provided by applicable law or treaty (including future time\nextensions), (iii) in any current or future medium and for any number of\ncopies, and (iv) for any purpose whatsoever, including without limitation\ncommercial, advertising or promotional purposes (the \"Waiver\"). Affirmer makes"}, {"id": "LICENSE_5", "file": "LICENSE", "content": "commercial, advertising or promotional purposes (the \"Waiver\"). Affirmer makes\nthe Waiver for the benefit of each member of the public at large and to the\ndetriment of Affirmer's heirs and successors, fully intending that such Waiver\nshall not be subject to revocation, rescission, cancellation, termination, or\nany other legal or equitable action to disrupt the quiet enjoyment of the Work\nby the public as contemplated by Affirmer's express Statement of Purpose.\n\n3. Public License Fallback. Should any part of the Waiver for any reason be\njudged legally invalid or ineffective under applicable law, then the Waiver\nshall be preserved to the maximum extent permitted taking into account\nAffirmer's express Statement of Purpose. In addition, to the extent the Waiver"}, {"id": "LICENSE_6", "file": "LICENSE", "content": "Affirmer's express Statement of Purpose. In addition, to the extent the Waiver\nis so judged Affirmer hereby grants to each affected person a royalty-free,\nnon transferable, non sublicensable, non exclusive, irrevocable and\nunconditional license to exercise Affirmer's Copyright and Related Rights in\nthe Work (i) in all territories worldwide, (ii) for the maximum duration\nprovided by applicable law or treaty (including future time extensions), (iii)\nin any current or future medium and for any number of copies, and (iv) for any\npurpose whatsoever, including without limitation commercial, advertising or\npromotional purposes (the \"License\"). The License shall be deemed effective as\nof the date CC0 was applied by Affirmer to the Work. Should any part of the"}, {"id": "LICENSE_7", "file": "LICENSE", "content": "of the date CC0 was applied by Affirmer to the Work. Should any part of the\nLicense for any reason be judged legally invalid or ineffective under\napplicable law, such partial invalidity or ineffectiveness shall not\ninvalidate the remainder of the License, and in such case Affirmer hereby\naffirms that he or she will not (i) exercise any of his or her remaining\nCopyright and Related Rights in the Work or (ii) assert any associated claims\nand causes of action with respect to the Work, in either case contrary to\nAffirmer's express Statement of Purpose.\n\n4. Limitations and Disclaimers.\n\n  a. No trademark or patent rights held by Affirmer are waived, abandoned,\n  surrendered, licensed or otherwise affected by this document."}, {"id": "LICENSE_8", "file": "LICENSE", "content": "surrendered, licensed or otherwise affected by this document.\n\n  b. Affirmer offers the Work as-is and makes no representations or warranties\n  of any kind concerning the Work, express, implied, statutory or otherwise,\n  including without limitation warranties of title, merchantability, fitness\n  for a particular purpose, non infringement, or the absence of latent or\n  other defects, accuracy, or the present or absence of errors, whether or not\n  discoverable, all to the greatest extent permissible under applicable law.\n\n  c. Affirmer disclaims responsibility for clearing rights of other persons\n  that may apply to the Work or any use thereof, including without limitation\n  any person's Copyright and Related Rights in the Work. Further, Affirmer"}, {"id": "LICENSE_9", "file": "LICENSE", "content": "any person's Copyright and Related Rights in the Work. Further, Affirmer\n  disclaims responsibility for obtaining any necessary consents, permissions\n  or other rights required for any use of the Work.\n\n  d. Affirmer understands and acknowledges that Creative Commons is not a\n  party to this document and has no duty or obligation with respect to this\n  CC0 or use of the Work.\n\nFor more information, please see\n<http://creativecommons.org/publicdomain/zero/1.0/>"}, {"id": "Global/README.md_0", "file": "Global/README.md", "content": "================================================\n## Globally Useful gitignores\n\nThis directory contains globally useful gitignores,\ne.g. OS-specific and editor specific.\n\nFor more on global gitignores:\n<https://help.github.com/en/github/using-git/ignoring-files#configuring-ignored-files-for-all-repositories-on-your-computer>\n\nAnd a good blog post about 'em:\n<http://augustl.com/blog/2009/global_gitignores>"}, {"id": ".github/PULL_REQUEST_TEMPLATE.md_0", "file": ".github/PULL_REQUEST_TEMPLATE.md", "content": "================================================\n### Reasons for making this change\n\n_TODO_\n<!---\nPlease provide some background for this change.\n--->\n\n### Links to documentation supporting these rule changes\n\n_TODO_\n\n<!---\nLink to the project docs, any existing .gitignore files that project may have in it's own repo, etc\n--->\n\n### If this is a new template\n\nLink to application or project\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s homepage: TODO\n\n### Merge and Approval Steps\n- [ ] Confirm that you've read the [contribution guidelines](https://github.com/github/gitignore/tree/main?tab=readme-ov-file#contributing-guidelines) and ensured your PR aligns\n- [ ] Ensure CI is passing\n- [ ] Get a review and Approval from one of the maintainers"}, {"id": ".github/workflows/stale.yml_0", "file": ".github/workflows/stale.yml", "content": "================================================\nname: Stale\n\n# **What it does**: Close pull requests after no updates for 180 days.\n# **Why we have it**: This repository gets a lot of PRs, and the maintainers team is small.\n#                     This helps reduce the open PRs to ones that are most desired by the community.\n# **Who does it impact**: Contributors and maintainers of github/gitignore.\n\non:\n  schedule:\n    - cron: '20 16 * * *' # Run every day at 16:20 UTC / 8:20 PST\n\npermissions:\n  actions: write\n  contents: write # only for delete-branch option\n  issues: write\n  pull-requests: write\n\njobs:\n  stale:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/stale@5bef64f19d7facfb25b37b414482c7164d639639 # v9.1.0\n        with:"}, {"id": ".github/workflows/stale.yml_1", "file": ".github/workflows/stale.yml", "content": "- uses: actions/stale@5bef64f19d7facfb25b37b414482c7164d639639 # v9.1.0\n        with:\n          stale-pr-message: 'This PR is stale because there have been no updates in 90 days. It will close after 180 days of inactivity. Leave a comment if you want to keep it open :smile:'\n          close-pr-message: 'This PR has been closed because it was inactive for 180 days. If you want to continue working on it, please open a new PR.'\n          days-before-stale: 90\n          days-before-close: 180\n          stale-pr-label: 'stale'\n          exempt-pr-labels: 'keep'\n          close-issue-reason: not_planned\n          ascending: true # Sort PRs by last updated date in ascending order\n          operations-per-run: 300"}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_0", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "================================================\n{\n  \"repo_url\": \"https://github.com/github/gitignore\",\n  \"processed_at\": \"2025-09-05T19:23:08.487040\",\n  \"total_files\": 6,\n  \"total_size\": 18294,\n  \"language_stats\": {\n    \"Markdown\": 4,\n    \"YAML\": 1\n  },\n  \"file_hierarchy\": {\n    \"github-gitignore\": {},\n    \"README.md\": \"README.md\",\n    \"CONTRIBUTING.md\": \"CONTRIBUTING.md\",\n    \"LICENSE\": \"LICENSE\",\n    \"Global\": {},\n    \".github\": {},\n    \"PULL_REQUEST_TEMPLATE.md\": \"PULL_REQUEST_TEMPLATE.md\",\n    \"workflows\": {},\n    \"stale.yml\": \"stale.yml\"\n  },\n  \"files\": {\n    \"README.md\": {"}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_1", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "\"content\": \"# A collection of `.gitignore` templates\\n\\nThis is GitHub\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s collection of [`.gitignore`][man] file templates.\\nWe use this list to populate the `.gitignore` template choosers available\\nin the GitHub.com interface when creating new repositories and files.\\n\\nFor more information about how `.gitignore` files work, and how to use them,\\nthe following resources are a great place to start:\\n\\n- The [Ignoring Files chapter][chapter] of the [Pro Git][progit] book.\\n- The [Ignoring Files article][help] on the GitHub Help site.\\n- The [gitignore(5)][man] manual page.\\n\\n[man]: https://git-scm.com/docs/gitignore\\n[help]: https://help.github.com/articles/ignoring-files\\n[chapter]:"}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_2", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "https://help.github.com/articles/ignoring-files\\n[chapter]: https://git-scm.com/book/en/v2/Git-Basics-Recording-Changes-to-the-Repository#_ignoring\\n[progit]: https://git-scm.com/book\\n\\n## Folder structure\\n\\nWe support a collection of templates, organized in this way:\\n\\n- The root folder contains templates in common use, to help people get started\\n  with popular programming languages and technologies. These define a meaningful\\n  set of rules to help get started, and ensure you are not committing\\n  unimportant files into your repository.\\n- [`Global`](./Global) contains templates for various editors, tools and\\n  operating systems that can be used in different situations. It is recommended\\n  that you either [add these to your global"}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_3", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "can be used in different situations. It is recommended\\n  that you either [add these to your global template](https://docs.github.com/en/get-started/getting-started-with-git/ignoring-files#configuring-ignored-files-for-all-repositories-on-your-computer)\\n  or merge these rules into your project-specific templates if you want to use\\n  them permanently.\\n- [`community`](./community) contains specialized templates for other popular\\n  languages, tools and project, which don't currently belong in the mainstream\\n  templates. These should be added to your project-specific templates when you\\n  decide to adopt the framework or tool.\\n\\n## What makes a good template?\\n\\nA template should contain a set of rules to help Git repositories work with a\\nspecific programming language, framework, tool"}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_4", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "a set of rules to help Git repositories work with a\\nspecific programming language, framework, tool or environment.\\n\\nIf it's not possible to curate a small set of useful rules for this situation,\\nthen the template is not a good fit for this collection.\\n\\nIf a template is mostly a list of files installed by a particular version of\\nsome software (e.g. a PHP framework), it could live under the `community`\\ndirectory. See [versioned templates](#versioned-templates) for more details.\\n\\nIf you have a small set of rules, or want to support a technology that is not\\nwidely in use, and still believe this will be helpful to others, please read the\\nsection about [specialized templates](#specialized-templates) for more details.\\n\\nInclude details when opening pull request if the template is"}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_5", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "for more details.\\n\\nInclude details when opening pull request if the template is important and visible. We\\nmay not accept it immediately, but we can promote it to the root at a later date\\nbased on interest.\\n\\nPlease also understand that we can\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2t list every tool that ever existed.\\nOur aim is to curate a collection of the _most common and helpful_ templates,\\nnot to make sure we cover every project possible. If we choose not to\\ninclude your language, tool, or project, it\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s not because it\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s not awesome.\\n\\n## Contributing guidelines\\n\\nWe\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2d love for you to help us improve this project. To help us keep this collection\\nhigh quality, we request that contributions adhere to the following guidelines.\\n\\n- **Provide a link to the application or project\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s"}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_6", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "adhere to the following guidelines.\\n\\n- **Provide a link to the application or project\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s homepage**. Unless it\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s\\n  extremely popular, there\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s a chance the maintainers don\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2t know about or use\\n  the language, framework, editor, app, or project your change applies to.\\n\\n- **Provide links to documentation** supporting the change you\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2re making.\\n  Current, canonical documentation mentioning the files being ignored is best.\\n  If documentation isn\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2t available to support your change, do the best you can\\n  to explain what the files being ignored are for.\\n\\n- **Explain why you\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2re making a change**. Even if it seems self-evident, please\\n  take a sentence or two to tell us why your change or addition should happen.\\n  It\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s especially"}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_7", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "a sentence or two to tell us why your change or addition should happen.\\n  It\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s especially helpful to articulate why this change applies to _everyone_\\n  who works with the applicable technology, rather than just you or your team.\\n\\n- **Please consider the scope of your change**. If your change is specific to a\\n  certain language or framework, then make sure the change is made to the\\n  template for that language or framework, rather than to the template for an\\n  editor, tool, or operating system.\\n\\n- **Please only modify _one template_ per pull request**. This helps keep pull\\n  requests and feedback focused on a specific project or technology.\\n\\nIn general, the more you can do to help us understand the change you\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2re making,\\nthe more likely we\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2ll be to accept"}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_8", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "to help us understand the change you\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2re making,\\nthe more likely we\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2ll be to accept your contribution quickly.\\n\\n## Versioned templates\\n\\nSome templates can change greatly between versions, and if you wish to contribute\\nto this repository we need to follow this specific flow:\\n\\n- the template at the root should be the current supported version\\n- the template at the root should not have a version in the filename (i.e.\\n  \\\"evergreen\\\")\\n- previous versions of templates should live under `community/`\\n- previous versions of the template should embed the version in the filename,\\n  for readability\\n\\nThis helps ensure users get the latest version (because they'll use whatever is\\nat the root) but helps maintainers support older versions still in the wild.\\n\\n## Specialized"}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_9", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "is\\nat the root) but helps maintainers support older versions still in the wild.\\n\\n## Specialized templates\\n\\nIf you have a template that you would like to contribute, but it isn't quite\\nmainstream, please consider adding this to the `community` directory under a\\nfolder that best suits where it belongs.\\n\\nThe rules in your specialized template should be specific to the framework or\\ntool, and any additional templates should be mentioned in a comment in the\\nheader of the template.\\n\\nFor example, this template might live at `community/DotNet/InforCRM.gitignore`:\\n\\n```gitignore\\n# gitignore template for InforCRM (formerly SalesLogix)\\n# website: https://www.infor.com/product-summary/cx/infor-crm/\\n#\\n# Recommended: VisualStudio.gitignore\\n\\n# Ignore model files that are"}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_10", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "Recommended: VisualStudio.gitignore\\n\\n# Ignore model files that are auto-generated\\nModelIndex.xml\\nExportedFiles.xml\\n\\n# Ignore deployment files\\n[Mm]odel/[Dd]eployment\\n\\n# Force include portal SupportFiles\\n!Model/Portal/*/SupportFiles/[Bb]in/\\n!Model/Portal/PortalTemplates/*/SupportFiles/[Bb]in\\n```\\n\\n## Contributing workflow\\n\\nHere\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s how we suggest you go about proposing a change to this project:\\n\\n1. [Fork this project][fork] to your account.\\n2. [Create a branch][branch] for the change you intend to make.\\n3. Make your changes to your fork.\\n4. [Send a pull request][pr] from your fork\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s branch to our `main` branch.\\n\\nUsing the web-based interface to make changes is fine too, and will help you\\nby automatically forking the project and prompting to send a pull"}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_11", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "is fine too, and will help you\\nby automatically forking the project and prompting to send a pull request too.\\n\\n[fork]: https://help.github.com/articles/fork-a-repo/\\n[branch]: https://help.github.com/articles/creating-and-deleting-branches-within-your-repository\\n[pr]: https://help.github.com/articles/using-pull-requests/\\n\\n## License\\n\\n[CC0-1.0](./LICENSE).\","}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_12", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "\"language\": \"Markdown\",\n      \"line_count\": 155,\n      \"size_bytes\": 7115,\n      \"file_type\": \"documentation\"\n    },\n    \"CONTRIBUTING.md\": {"}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_13", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "\"content\": \"# Contributing guidelines\\n\\nWe\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2d love you to help us improve this project. To help us keep this collection\\nhigh quality, we request that contributions adhere to the following guidelines.\\n\\n- **Provide a link to the application or project\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s homepage**. Unless it\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s\\n  extremely popular, there\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s a chance the maintainers don\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2t know about or use\\n  the language, framework, editor, app, or project your change applies to.\\n\\n- **Provide links to documentation** supporting the change you\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2re making.\\n  Current, canonical documentation mentioning the files being ignored is best.\\n  If documentation isn\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2t available to support your change, do the best you can\\n  to explain what the files being ignored are for.\\n\\n- **Explain why"}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_14", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "change, do the best you can\\n  to explain what the files being ignored are for.\\n\\n- **Explain why you\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2re making a change**. Even if it seems self-evident, please\\n  take a sentence or two to tell us why your change or addition should happen.\\n  It\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s especially helpful to articulate why this change applies to *everyone*\\n  who works with the applicable technology, rather than just you or your team.\\n\\n- **Please consider the scope of your change**. If your change specific to a\\n  certain language or framework, then make sure the change is made to the\\n  template for that language or framework, rather than to the template for an\\n  editor, tool, or operating system.\\n\\n- **Please only modify *one template* per pull request**. This helps keep pull\\n  requests and feedback"}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_15", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "only modify *one template* per pull request**. This helps keep pull\\n  requests and feedback focused on a specific project or technology.\\n\\nIn general, the more you can do to help us understand the change you\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2re making,\\nthe more likely we\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2ll be to accept your contribution quickly.\\n\\nIf a template is mostly a list of files installed by a particular version of\\nsome software (e.g. a PHP framework) then it's brittle and probably no more\\nhelpful than a simple `ls`. If it's not possible to curate a small set of\\nuseful rules, then the template might not be a good fit for this collection.\\n\\nPlease also understand that we can\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2t list every tool that ever existed.\\nOur aim is to curate a collection of the *most common and helpful* templates,\\nnot to make sure we cover"}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_16", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "is to curate a collection of the *most common and helpful* templates,\\nnot to make sure we cover every project possible. If we choose not to\\ninclude your language, tool, or project, it\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s not because it\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s not awesome.\","}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_17", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "\"language\": \"Markdown\",\n      \"line_count\": 39,\n      \"size_bytes\": 2274,\n      \"file_type\": \"documentation\"\n    },\n    \"LICENSE\": {"}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_18", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "\"content\": \"CC0 1.0 Universal\\n\\nStatement of Purpose\\n\\nThe laws of most jurisdictions throughout the world automatically confer\\nexclusive Copyright and Related Rights (defined below) upon the creator and\\nsubsequent owner(s) (each and all, an \\\"owner\\\") of an original work of\\nauthorship and/or a database (each, a \\\"Work\\\").\\n\\nCertain owners wish to permanently relinquish those rights to a Work for the\\npurpose of contributing to a commons of creative, cultural and scientific\\nworks (\\\"Commons\\\") that the public can reliably and without fear of later\\nclaims of infringement build upon, modify, incorporate in other works, reuse\\nand redistribute as freely as possible in any form whatsoever and for any\\npurposes, including without limitation commercial purposes. These owners"}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_19", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "whatsoever and for any\\npurposes, including without limitation commercial purposes. These owners may\\ncontribute to the Commons to promote the ideal of a free culture and the\\nfurther production of creative, cultural and scientific works, or to gain\\nreputation or greater distribution for their Work in part through the use and\\nefforts of others.\\n\\nFor these and/or other purposes and motivations, and without any expectation\\nof additional consideration or compensation, the person associating CC0 with a\\nWork (the \\\"Affirmer\\\"), to the extent that he or she is an owner of Copyright\\nand Related Rights in the Work, voluntarily elects to apply CC0 to the Work\\nand publicly distribute the Work under its terms, with knowledge of his or her\\nCopyright and Related Rights in the Work and the"}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_20", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "under its terms, with knowledge of his or her\\nCopyright and Related Rights in the Work and the meaning and intended legal\\neffect of CC0 on those rights.\\n\\n1. Copyright and Related Rights. A Work made available under CC0 may be\\nprotected by copyright and related or neighboring rights (\\\"Copyright and\\nRelated Rights\\\"). Copyright and Related Rights include, but are not limited\\nto, the following:\\n\\n  i. the right to reproduce, adapt, distribute, perform, display, communicate,\\n  and translate a Work;\\n\\n  ii. moral rights retained by the original author(s) and/or performer(s);\\n\\n  iii. publicity and privacy rights pertaining to a person's image or likeness\\n  depicted in a Work;\\n\\n  iv. rights protecting against unfair competition in regards to a Work,\\n  subject to the limitations"}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_21", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "rights protecting against unfair competition in regards to a Work,\\n  subject to the limitations in paragraph 4(a), below;\\n\\n  v. rights protecting the extraction, dissemination, use and reuse of data in\\n  a Work;\\n\\n  vi. database rights (such as those arising under Directive 96/9/EC of the\\n  European Parliament and of the Council of 11 March 1996 on the legal\\n  protection of databases, and under any national implementation thereof,\\n  including any amended or successor version of such directive); and\\n\\n  vii. other similar, equivalent or corresponding rights throughout the world\\n  based on applicable law or treaty, and any national implementations thereof.\\n\\n2. Waiver. To the greatest extent permitted by, but not in contravention of,\\napplicable law, Affirmer hereby overtly,"}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_22", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "extent permitted by, but not in contravention of,\\napplicable law, Affirmer hereby overtly, fully, permanently, irrevocably and\\nunconditionally waives, abandons, and surrenders all of Affirmer's Copyright\\nand Related Rights and associated claims and causes of action, whether now\\nknown or unknown (including existing as well as future claims and causes of\\naction), in the Work (i) in all territories worldwide, (ii) for the maximum\\nduration provided by applicable law or treaty (including future time\\nextensions), (iii) in any current or future medium and for any number of\\ncopies, and (iv) for any purpose whatsoever, including without limitation\\ncommercial, advertising or promotional purposes (the \\\"Waiver\\\"). Affirmer makes\\nthe Waiver for the benefit of each member of the public at"}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_23", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "(the \\\"Waiver\\\"). Affirmer makes\\nthe Waiver for the benefit of each member of the public at large and to the\\ndetriment of Affirmer's heirs and successors, fully intending that such Waiver\\nshall not be subject to revocation, rescission, cancellation, termination, or\\nany other legal or equitable action to disrupt the quiet enjoyment of the Work\\nby the public as contemplated by Affirmer's express Statement of Purpose.\\n\\n3. Public License Fallback. Should any part of the Waiver for any reason be\\njudged legally invalid or ineffective under applicable law, then the Waiver\\nshall be preserved to the maximum extent permitted taking into account\\nAffirmer's express Statement of Purpose. In addition, to the extent the Waiver\\nis so judged Affirmer hereby grants to each affected person a"}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_24", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "addition, to the extent the Waiver\\nis so judged Affirmer hereby grants to each affected person a royalty-free,\\nnon transferable, non sublicensable, non exclusive, irrevocable and\\nunconditional license to exercise Affirmer's Copyright and Related Rights in\\nthe Work (i) in all territories worldwide, (ii) for the maximum duration\\nprovided by applicable law or treaty (including future time extensions), (iii)\\nin any current or future medium and for any number of copies, and (iv) for any\\npurpose whatsoever, including without limitation commercial, advertising or\\npromotional purposes (the \\\"License\\\"). The License shall be deemed effective as\\nof the date CC0 was applied by Affirmer to the Work. Should any part of the\\nLicense for any reason be judged legally invalid or ineffective"}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_25", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "the Work. Should any part of the\\nLicense for any reason be judged legally invalid or ineffective under\\napplicable law, such partial invalidity or ineffectiveness shall not\\ninvalidate the remainder of the License, and in such case Affirmer hereby\\naffirms that he or she will not (i) exercise any of his or her remaining\\nCopyright and Related Rights in the Work or (ii) assert any associated claims\\nand causes of action with respect to the Work, in either case contrary to\\nAffirmer's express Statement of Purpose.\\n\\n4. Limitations and Disclaimers.\\n\\n  a. No trademark or patent rights held by Affirmer are waived, abandoned,\\n  surrendered, licensed or otherwise affected by this document.\\n\\n  b. Affirmer offers the Work as-is and makes no representations or warranties\\n  of any kind"}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_26", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "b. Affirmer offers the Work as-is and makes no representations or warranties\\n  of any kind concerning the Work, express, implied, statutory or otherwise,\\n  including without limitation warranties of title, merchantability, fitness\\n  for a particular purpose, non infringement, or the absence of latent or\\n  other defects, accuracy, or the present or absence of errors, whether or not\\n  discoverable, all to the greatest extent permissible under applicable law.\\n\\n  c. Affirmer disclaims responsibility for clearing rights of other persons\\n  that may apply to the Work or any use thereof, including without limitation\\n  any person's Copyright and Related Rights in the Work. Further, Affirmer\\n  disclaims responsibility for obtaining any necessary consents, permissions\\n  or other rights"}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_27", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "disclaims responsibility for obtaining any necessary consents, permissions\\n  or other rights required for any use of the Work.\\n\\n  d. Affirmer understands and acknowledges that Creative Commons is not a\\n  party to this document and has no duty or obligation with respect to this\\n  CC0 or use of the Work.\\n\\nFor more information, please see\\n<http://creativecommons.org/publicdomain/zero/1.0/>\","}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_28", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "\"language\": \"unknown\",\n      \"line_count\": 116,\n      \"size_bytes\": 6554,\n      \"file_type\": \"other\"\n    },\n    \"Global/README.md\": {\n      \"content\": \"## Globally Useful gitignores\\n\\nThis directory contains globally useful gitignores,\\ne.g. OS-specific and editor specific.\\n\\nFor more on global gitignores:\\n<https://help.github.com/en/github/using-git/ignoring-files#configuring-ignored-files-for-all-repositories-on-your-computer>\\n\\nAnd a good blog post about 'em:\\n<http://augustl.com/blog/2009/global_gitignores>\",\n      \"language\": \"Markdown\",\n      \"line_count\": 10,\n      \"size_bytes\": 359,\n      \"file_type\": \"documentation\"\n    },\n    \".github/PULL_REQUEST_TEMPLATE.md\": {"}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_29", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "\"file_type\": \"documentation\"\n    },\n    \".github/PULL_REQUEST_TEMPLATE.md\": {\n      \"content\": \"### Reasons for making this change\\n\\n_TODO_\\n<!---\\nPlease provide some background for this change.\\n--->\\n\\n### Links to documentation supporting these rule changes\\n\\n_TODO_\\n\\n<!---\\nLink to the project docs, any existing .gitignore files that project may have in it's own repo, etc\\n--->\\n\\n### If this is a new template\\n\\nLink to application or project\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s homepage: TODO\\n\\n### Merge and Approval Steps\\n- [ ] Confirm that you've read the [contribution guidelines](https://github.com/github/gitignore/tree/main?tab=readme-ov-file#contributing-guidelines) and ensured your PR aligns\\n- [ ] Ensure CI is passing\\n- [ ] Get a review and Approval from one of the maintainers\","}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_30", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "\"language\": \"Markdown\",\n      \"line_count\": 23,\n      \"size_bytes\": 661,\n      \"file_type\": \"documentation\"\n    },\n    \".github/workflows/stale.yml\": {"}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_31", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "\"content\": \"name: Stale\\n\\n# **What it does**: Close pull requests after no updates for 180 days.\\n# **Why we have it**: This repository gets a lot of PRs, and the maintainers team is small.\\n#                     This helps reduce the open PRs to ones that are most desired by the community.\\n# **Who does it impact**: Contributors and maintainers of github/gitignore.\\n\\non:\\n  schedule:\\n    - cron: '20 16 * * *' # Run every day at 16:20 UTC / 8:20 PST\\n\\npermissions:\\n  actions: write\\n  contents: write # only for delete-branch option\\n  issues: write\\n  pull-requests: write\\n\\njobs:\\n  stale:\\n    runs-on: ubuntu-latest\\n    steps:\\n      - uses: actions/stale@5bef64f19d7facfb25b37b414482c7164d639639 # v9.1.0\\n        with:\\n          stale-pr-message: 'This PR is stale because"}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_32", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "# v9.1.0\\n        with:\\n          stale-pr-message: 'This PR is stale because there have been no updates in 90 days. It will close after 180 days of inactivity. Leave a comment if you want to keep it open :smile:'\\n          close-pr-message: 'This PR has been closed because it was inactive for 180 days. If you want to continue working on it, please open a new PR.'\\n          days-before-stale: 90\\n          days-before-close: 180\\n          stale-pr-label: 'stale'\\n          exempt-pr-labels: 'keep'\\n          close-issue-reason: not_planned\\n          ascending: true # Sort PRs by last updated date in ascending order\\n          operations-per-run: 300\","}, {"id": "gitingest_outputs/gitignore_structured_20250905_192308.json_33", "file": "gitingest_outputs/gitignore_structured_20250905_192308.json", "content": "\"language\": \"YAML\",\n      \"line_count\": 32,\n      \"size_bytes\": 1331,\n      \"file_type\": \"configuration\"\n    }\n  }\n}"}, {"id": "gitingest_outputs/Hello-World_raw_20250905_192258.txt_0", "file": "gitingest_outputs/Hello-World_raw_20250905_192258.txt", "content": "================================================\nDirectory structure:\n\u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac octocat-hello-world/\n    \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac README"}, {"id": "README_0", "file": "README", "content": "================================================\nHello World!"}, {"id": "gitingest_outputs/Hello-World_structured_20250905_192258.json_0", "file": "gitingest_outputs/Hello-World_structured_20250905_192258.json", "content": "================================================\n{\n  \"repo_url\": \"https://github.com/octocat/Hello-World\",\n  \"processed_at\": \"2025-09-05T19:22:58.411789\",\n  \"total_files\": 1,\n  \"total_size\": 12,\n  \"language_stats\": {},\n  \"file_hierarchy\": {\n    \"octocat-hello-world\": {},\n    \"README\": \"README\"\n  },\n  \"files\": {\n    \"README\": {\n      \"content\": \"Hello World!\",\n      \"language\": \"unknown\",\n      \"line_count\": 1,\n      \"size_bytes\": 12,\n      \"file_type\": \"other\"\n    }\n  }\n}"}, {"id": "gitingest_outputs/octocat_Hello-World_20250905_193031.txt_0", "file": "gitingest_outputs/octocat_Hello-World_20250905_193031.txt", "content": "================================================\nDirectory structure:\n\u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac octocat-hello-world/\n    \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac README"}, {"id": "README_0", "file": "README", "content": "================================================\nHello World!"}, {"id": "gitingest_outputs/Samay1011_Project_ecommerce_React_20250906_104832.txt_0", "file": "gitingest_outputs/Samay1011_Project_ecommerce_React_20250906_104832.txt", "content": "================================================\nDirectory structure:\n\u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac samay1011-project_ecommerce_react/\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Backend/\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac package.json\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac server.js\n    \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac public/\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac index.css\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac productDetail.css\n    \u00e2\u201d\u201a   \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac ProductForm.css\n    \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac src/\n    \u00e2\u201d\u201a       \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac app.js\n    \u00e2\u201d\u201a       \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac db/\n    \u00e2\u201d\u201a       \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac db.js\n    \u00e2\u201d\u201a       \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac models/\n    \u00e2\u201d\u201a       \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac cart.model.js\n    \u00e2\u201d\u201a       \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac product.model.js\n    \u00e2\u201d\u201a       \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac user.model.js\n    \u00e2\u201d\u201a       \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac routes/\n    \u00e2\u201d\u201a           \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac cart.router.js\n    \u00e2\u201d\u201a           \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac index.router.js\n    \u00e2\u201d\u201a           \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac login.router.js"}, {"id": "gitingest_outputs/Samay1011_Project_ecommerce_React_20250906_104832.txt_1", "file": "gitingest_outputs/Samay1011_Project_ecommerce_React_20250906_104832.txt", "content": "\u00e2\u201d\u201a           \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac index.router.js\n    \u00e2\u201d\u201a           \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac login.router.js\n    \u00e2\u201d\u201a           \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac product.router.js\n    \u00e2\u201d\u201a           \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac user.router.js\n    \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac Frontend/\n        \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac README.md\n        \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac eslint.config.js\n        \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac index.html\n        \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac package.json\n        \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac vite.config.js\n        \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac src/\n            \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac App.css\n            \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac App.jsx\n            \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac index.css\n            \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac main.jsx\n            \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac components/\n            \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Footer.css\n            \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Footer.jsx\n            \u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Navbar.css\n            \u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac Navbar.jsx\n            \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac Pages/\n                \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac AddProducts.css"}, {"id": "gitingest_outputs/Samay1011_Project_ecommerce_React_20250906_104832.txt_2", "file": "gitingest_outputs/Samay1011_Project_ecommerce_React_20250906_104832.txt", "content": "\u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac Pages/\n                \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac AddProducts.css\n                \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac AddProducts.jsx\n                \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Cart.css\n                \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Cart.jsx\n                \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac CartContext.jsx\n                \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Home.css\n                \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Home.jsx\n                \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac ImageUploader.jsx\n                \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Login.css\n                \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac Login.jsx\n                \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac ProductDetail.css\n                \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac ProductDetail.jsx\n                \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac UserHome.css\n                \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac UserHome.jsx\n                \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac UserProduct.css\n                \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac UserProduct.jsx"}, {"id": "Backend/package.json_0", "file": "Backend/package.json", "content": "================================================\n{\n  \"name\": \"e-commerce\",\n  \"version\": \"1.0.0\",\n  \"main\": \"server.js\",\n  \"scripts\": {\n    \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\"\n  },\n  \"keywords\": [],\n  \"author\": \"\",\n  \"license\": \"ISC\",\n  \"description\": \"\",\n  \"dependencies\": {\n    \"bcrypt\": \"^6.0.0\",\n    \"cors\": \"^2.8.5\",\n    \"dotenv\": \"^17.2.1\",\n    \"ejs\": \"^3.1.10\",\n    \"express\": \"^5.1.0\",\n    \"imagekit\": \"^6.0.0\",\n    \"mongoose\": \"^8.16.4\",\n    \"morgan\": \"^1.10.1\",\n    \"multer\": \"^2.0.2\",\n    \"nodemon\": \"^3.1.10\"\n  }\n}"}, {"id": "Backend/server.js_0", "file": "Backend/server.js", "content": "================================================\nconst app = require(\"./src/app\")\nconst connect = require(\"./src/db/db\")\n\nconst PORT = process.env.PORT || 3000\n\napp.listen(PORT, ()=>{\n    console.log(\"server running on port no : \",PORT);\n    connect()\n})"}, {"id": "Backend/public/index.css_0", "file": "Backend/public/index.css", "content": "================================================\n[Empty file]"}, {"id": "Backend/public/productDetail.css_0", "file": "Backend/public/productDetail.css", "content": "================================================\n[Empty file]"}, {"id": "Backend/public/ProductForm.css_0", "file": "Backend/public/ProductForm.css", "content": "================================================\n[Empty file]"}, {"id": "Backend/src/app.js_0", "file": "Backend/src/app.js", "content": "================================================\nconst express = require(\"express\")\nconst productRouter = require(\"./routes/product.router\")\nconst indexRouter = require(\"./routes/index.router\")\nconst userRouter = require(\"./routes/user.router\")\n\nconst cartRouter = require(\"./routes/cart.router\")\nconst loginRouter = require(\"./routes/login.router\")\nrequire(\"dotenv\").config()\nconst app = express()\nconst path = require(\"path\")\nconst morgon = require(\"morgan\")\nconst cors = require(\"cors\")\n\napp.use(morgon(\"dev\"))\n\n\napp.use(cors())\n\napp.use(express.json())\napp.use(express.urlencoded({extended : true}))\n\nconsole.log(process.env.MONGODB_URI);\n\napp.use(\"/\", indexRouter) \napp.use(\"/users\", userRouter)\napp.use(\"/products\",productRouter)\napp.use(\"/cart\", cartRouter)\napp.use(\"/login\",loginRouter)"}, {"id": "Backend/src/app.js_1", "file": "Backend/src/app.js", "content": "app.use(\"/products\",productRouter)\napp.use(\"/cart\", cartRouter)\napp.use(\"/login\",loginRouter)\n\n\nmodule.exports = app"}, {"id": "Backend/src/db/db.js_0", "file": "Backend/src/db/db.js", "content": "================================================\nconst mongoose = require(\"mongoose\")\n\nconst connect = ()=>{\n    // mongoose.connect(\"mongodb://localhost:27017/VIPS\")\n    mongoose.connect(process.env.MONGODB_URI)\n    .then(()=>{\n        console.log(\"database connected\");\n    })\n    .catch((err)=>{\n        console.log(err);\n    })\n}\n\nmodule.exports = connect"}, {"id": "Backend/src/models/cart.model.js_0", "file": "Backend/src/models/cart.model.js", "content": "================================================\nconst mongoose = require(\"mongoose\");\n\nconst cartSchema = new mongoose.Schema({\n  productId: {\n    type: mongoose.Schema.Types.ObjectId,\n    required: true,\n    ref: \"product\", \n  }\n});\n\nconst cartModel = mongoose.model(\"Cart\", cartSchema);\n\nmodule.exports = cartModel;"}, {"id": "Backend/src/models/product.model.js_0", "file": "Backend/src/models/product.model.js", "content": "================================================\nconst mongoose = require(\"mongoose\")\n\n\nconst productSchema = new mongoose.Schema({\n    title : {\n        type : String\n    },\n    description : {\n        type : String\n    },\n    category : {\n        type : String\n    },\n    price : {\n        type : String\n    },\n    image : {\n        type : String\n    }\n})\n\nconst productModel = mongoose.model(\"product\",productSchema)\n\nmodule.exports = productModel"}, {"id": "Backend/src/models/user.model.js_0", "file": "Backend/src/models/user.model.js", "content": "================================================\nconst mongoose = require(\"mongoose\")\n\n\nconst userSchema = new mongoose.Schema({\n    username : {\n        type : String,\n        required : true\n    },\n    email :  {\n        type : String,\n        required : true,\n        unique : true\n    },\n\n    password : {\n        type : String ,\n        required : true\n    }\n})\n\n\n\nconst userModel = mongoose.model(\"User\", userSchema)\n\nmodule.exports = userModel"}, {"id": "Backend/src/routes/cart.router.js_0", "file": "Backend/src/routes/cart.router.js", "content": "================================================\nconst express = require(\"express\");\nconst cartModel = require(\"../models/cart.model\");\nconst router = express.Router();\n\n\n\n// GET /cart with product details\nrouter.get(\"/\", async (req, res) => {\n    try {\n        const cartItems = await cartModel.find().populate(\"productId\"); // Populate the product details\n        res.status(200).json(cartItems);\n  } catch (error) {\n      res.status(500).json({ error: \"Failed to fetch cart items\" });\n  }\n});\n\n// POST /cart/add\nrouter.post(\"/add/:productId\", async (req, res) => {\n  try {\n    const { productId } = req.params;\n\n    if (!productId) {\n      return res.status(400).json({ error: \"productId is required\" });\n    }\n\n    const cartItem = new cartModel({ productId });\n    await cartItem.save();"}, {"id": "Backend/src/routes/cart.router.js_1", "file": "Backend/src/routes/cart.router.js", "content": "}\n\n    const cartItem = new cartModel({ productId });\n    await cartItem.save();\n\n    res.status(201).json({ message: \"Product added to cart\", cartItem });\n  } catch (error) {\n    res.status(500).json({ error: \"Internal server error\" });\n  }\n});\n\n\nrouter.delete(\"/reduce/:productId\", async (req, res) => {\n  try {\n    const { productId } = req.params;\n\n    const deletedItem = await cartModel.findOneAndDelete({ productId });\n    if (!deletedItem) {\n      return res.status(404).json({ error: \"Product not found in cart\" });\n    }\n\n    res.status(200).json({ message: \"One item removed\", deletedItem });\n  } catch (error) {\n    res.status(500).json({ error: \"Internal server error\" });\n  }\n});\n\n\nrouter.delete(\"/delete/:productId\", async (req, res) => {\n  try {"}, {"id": "Backend/src/routes/cart.router.js_2", "file": "Backend/src/routes/cart.router.js", "content": "}\n});\n\n\nrouter.delete(\"/delete/:productId\", async (req, res) => {\n  try {\n    const { productId } = req.params;\n\n    const result = await cartModel.deleteMany({ productId });\n    res.status(200).json({ message: \"All items of this product removed\", deletedCount: result.deletedCount });\n  } catch (error) {\n    res.status(500).json({ error: \"Internal server error\" });\n  }\n});\n\n\n\n\n\n\nmodule.exports = router;"}, {"id": "Backend/src/routes/index.router.js_0", "file": "Backend/src/routes/index.router.js", "content": "================================================\nconst express = require(\"express\")\nconst productModel = require(\"../models/product.model\")\n\nconst router = express.Router()\n\n\n\nrouter.get(\"/\", async(req, res)=>{\n   const products = await productModel.find()\n\n    res.status(200).json({message : \"data found\" , products})\n})\n\n\n\nmodule.exports = router"}, {"id": "Backend/src/routes/login.router.js_0", "file": "Backend/src/routes/login.router.js", "content": "================================================\nconst express = require(\"express\")\nconst loginModel = require(\"../models/login.model\")\n\nconst router = express.Router()\n\n\n\nrouter.get(\"/\", async(req, res)=>{\n   res.render()\n})\n\n\n\nmodule.exports = router"}, {"id": "Backend/src/routes/product.router.js_0", "file": "Backend/src/routes/product.router.js", "content": "================================================\n\nconst express = require(\"express\");\nconst productModel = require(\"../models/product.model\");\nconst ImageKit = require(\"imagekit\");\nconst multer = require(\"multer\");\nconst storage = multer.memoryStorage();\nconst upload = multer({ storage: storage });\nconst router = express.Router();\n\n\n\nrouter.get(\"/\", (req, res) => {\n \n});\n\n\n\nrouter.post(\"/add\", upload.single(\"image\"), async (req, res) => {\n\n  const imagekit = new ImageKit({\n    publicKey: process.env.PUBLIC_KEY  ,\n    privateKey :process.env.PRIVATE_KEY,\n    urlEndpoint: process.env.URLENDPOINT ,\n  });\n\n\n  const result = await imagekit.upload({\n    file : req.file.buffer,\n    fileName : req.file.originalname,\n    isPrivateFile : false,\n    isPublished : true\n  })"}, {"id": "Backend/src/routes/product.router.js_1", "file": "Backend/src/routes/product.router.js", "content": "fileName : req.file.originalname,\n    isPrivateFile : false,\n    isPublished : true\n  })\n\n  const imageUrl = result.url\n\n \n  const { title, description, category, price } = req.body;\n  \n\n      const product = new productModel(\n          {\n              title : title,\n              description : description,\n              category : category,\n              price : price,\n              image : imageUrl\n           }\n  )\n\n      await product.save()\n\n  res.json({message : \"data aaya\"})\n});\n\nrouter.get(\"/:id\",async (req, res)=>{\n    const productId = req.params.id\n\n    const product = await productModel.findById(productId)\n\n    console.log(product);\n\n\n    res.status(200).json({message : \"data mil gya \" , product})\n    \n})\n\nrouter.get(\"/update/:id\", async(req, res)=>{"}, {"id": "Backend/src/routes/product.router.js_2", "file": "Backend/src/routes/product.router.js", "content": "})\n\nrouter.get(\"/update/:id\", async(req, res)=>{\n\n    const productId = req.params.id\n\n    const product = await productModel.findById(productId)\n\n\n    res.render(\"updateForm\",{product : product})\n})\n\n\nrouter.post(\"/update/:id\",upload.single(\"image\") ,async(req, res)=>{\n\n    const productId = req.params.id\n\n    console.log(req.body);\n    \n  const { title, description, category, price } = req.body;\n\n  \n  // const imagekit = new ImageKit({\n  //   publicKey: \"public_M0PAK4NmC1d2995cVHB6hjiBgaE=\",\n  //   privateKey : \"private_KT7FkfaTOTLNy6lVG+V7iKE2ba4=\",\n  //   urlEndpoint: \"https://ik.imagekit.io/ls436o8px\",\n  // });\n\n\n  // const result = await imagekit.upload({\n  //   file : req.file.buffer,\n  //   fileName : req.file.originalname,\n  //   isPrivateFile : false,"}, {"id": "Backend/src/routes/product.router.js_3", "file": "Backend/src/routes/product.router.js", "content": "//   fileName : req.file.originalname,\n  //   isPrivateFile : false,\n  //   isPublished : true\n  // })\n\n  // const imageUrl = result.url\n\n    await productModel.findByIdAndUpdate(productId,{\n    title : title,\n    description : description,\n    category : category,\n    price : price,\n    image : imageUrl\n  })\n\n  res.redirect(`/products/${productId}`)\n    \n})\n\n\nrouter.get(\"/delete/:id\" , async (req,res)=>{\n    const productId = req.params.id\n\n    await productModel.findByIdAndDelete(productId)\n\n    res.redirect(\"/\")\n})\n\n\n\nmodule.exports = router;"}, {"id": "Backend/src/routes/user.router.js_0", "file": "Backend/src/routes/user.router.js", "content": "================================================\nconst express = require(\"express\")\nconst bcrypt = require(\"bcrypt\")\nconst userModel = require(\"../models/user.model\")\n\nconst router = express.Router()\n\nrouter.post(\"/register\",async (req, res)=>{\n\n    const {username , email , password} = req.body\n\n    try {\n      \n        if(!username){\n            return res.status(400).json({message : \"username is required\"})\n        }\n        if(!email){\n            return res.status(400).json({message : \"email is required\"})\n        }\n        if(!password){\n            return res.status(400).json({message : \"password is required\"})\n        }\n       \n\n        const hashedPass = await bcrypt.hash(password ,10)\n\n        const user = new userModel({\n            username : username,"}, {"id": "Backend/src/routes/user.router.js_1", "file": "Backend/src/routes/user.router.js", "content": "const user = new userModel({\n            username : username,\n            email : email ,\n            password : hashedPass\n        })\n\n\n        await user.save()\n        \n        res.send(\"register successfully....\")\n\n    } catch (error) {\n        console.log(error);\n        res.status(500).json({message : \"internal server error\", error : error.message})\n    }\n\n})\n\n\nrouter.post(\"/login\", async (req, res)=>{\n    const {email , password} = req.body\n\n    try {\n\n\n        if(!email){\n            return res.status(400).json({message : \"email is required\"})\n        }\n        if(!password){\n            return res.status(400).json({message : \"password is required\"})\n        }\n\n        const user = await userModel.findOne({email : email})\n\n        if(!user){"}, {"id": "Backend/src/routes/user.router.js_2", "file": "Backend/src/routes/user.router.js", "content": "}\n\n        const user = await userModel.findOne({email : email})\n\n        if(!user){\n            return res.status(400).json({message : \"user not exists\"})\n        }\n\n        const isTrue = await bcrypt.compare(password ,user.password )\n\n\n        if(!isTrue){\n            return res.status(400).json({message : \"email or password desnot match\"})\n        }\n\n        res.status(200).json({message : \"login successfully...\"})\n\n    } catch (error) {\n        console.log(error); \n        res.status(500).json({message : \"internal server error\", error : error.message})\n    \n    }\n})\n\n\nmodule.exports = router"}, {"id": "Frontend/README.md_0", "file": "Frontend/README.md", "content": "================================================\n# React + Vite\n\nThis template provides a minimal setup to get React working in Vite with HMR and some ESLint rules.\n\nCurrently, two official plugins are available:\n\n- [@vitejs/plugin-react](https://github.com/vitejs/vite-plugin-react/blob/main/packages/plugin-react) uses [Babel](https://babeljs.io/) for Fast Refresh\n- [@vitejs/plugin-react-swc](https://github.com/vitejs/vite-plugin-react/blob/main/packages/plugin-react-swc) uses [SWC](https://swc.rs/) for Fast Refresh"}, {"id": "Frontend/README.md_1", "file": "Frontend/README.md", "content": "## Expanding the ESLint configuration\n\nIf you are developing a production application, we recommend using TypeScript with type-aware lint rules enabled. Check out the [TS template](https://github.com/vitejs/vite/tree/main/packages/create-vite/template-react-ts) for information on how to integrate TypeScript and [`typescript-eslint`](https://typescript-eslint.io) in your project."}, {"id": "Frontend/eslint.config.js_0", "file": "Frontend/eslint.config.js", "content": "================================================\nimport js from '@eslint/js'\nimport globals from 'globals'\nimport reactHooks from 'eslint-plugin-react-hooks'\nimport reactRefresh from 'eslint-plugin-react-refresh'\nimport { defineConfig, globalIgnores } from 'eslint/config'\n\nexport default defineConfig([\n  globalIgnores(['dist']),\n  {\n    files: ['**/*.{js,jsx}'],\n    extends: [\n      js.configs.recommended,\n      reactHooks.configs['recommended-latest'],\n      reactRefresh.configs.vite,\n    ],\n    languageOptions: {\n      ecmaVersion: 2020,\n      globals: globals.browser,\n      parserOptions: {\n        ecmaVersion: 'latest',\n        ecmaFeatures: { jsx: true },\n        sourceType: 'module',\n      },\n    },\n    rules: {\n      'no-unused-vars': ['error', { varsIgnorePattern: '^[A-Z_]' }],"}, {"id": "Frontend/eslint.config.js_1", "file": "Frontend/eslint.config.js", "content": "},\n    },\n    rules: {\n      'no-unused-vars': ['error', { varsIgnorePattern: '^[A-Z_]' }],\n    },\n  },\n])"}, {"id": "Frontend/index.html_0", "file": "Frontend/index.html", "content": "================================================\n<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"UTF-8\" />\n    <link rel=\"icon\" type=\"image/svg+xml\" href=\"/vite.svg\" />\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n    <title>Vite + React</title>\n  </head>\n  <body>\n    <div id=\"root\"></div>\n    <script type=\"module\" src=\"/src/main.jsx\"></script>\n  </body>\n</html>"}, {"id": "Frontend/package.json_0", "file": "Frontend/package.json", "content": "================================================\n{\n  \"name\": \"ecommerce-react\",\n  \"private\": true,\n  \"version\": \"0.0.0\",\n  \"type\": \"module\",\n  \"scripts\": {\n    \"dev\": \"vite\",\n    \"build\": \"vite build\",\n    \"lint\": \"eslint .\",\n    \"preview\": \"vite preview\"\n  },\n  \"dependencies\": {\n    \"axios\": \"^1.11.0\",\n    \"imagekitio-react\": \"^4.3.0\",\n    \"react\": \"^19.1.0\",\n    \"react-dom\": \"^19.1.0\",\n    \"react-router-dom\": \"^7.7.1\",\n    \"remixicon\": \"^4.6.0\"\n  },\n  \"devDependencies\": {\n    \"@eslint/js\": \"^9.30.1\",\n    \"@types/react\": \"^19.1.8\",\n    \"@types/react-dom\": \"^19.1.6\",\n    \"@vitejs/plugin-react\": \"^4.6.0\",\n    \"eslint\": \"^9.30.1\",\n    \"eslint-plugin-react-hooks\": \"^5.2.0\",\n    \"eslint-plugin-react-refresh\": \"^0.4.20\",\n    \"globals\": \"^16.3.0\",\n    \"vite\": \"^7.0.4\"\n  }\n}"}, {"id": "Frontend/vite.config.js_0", "file": "Frontend/vite.config.js", "content": "================================================\nimport { defineConfig } from 'vite'\nimport react from '@vitejs/plugin-react'\n\n// https://vite.dev/config/\nexport default defineConfig({\n  plugins: [react()],\n})"}, {"id": "Frontend/src/App.css_0", "file": "Frontend/src/App.css", "content": "================================================\n[Empty file]"}, {"id": "Frontend/src/App.jsx_0", "file": "Frontend/src/App.jsx", "content": "================================================\nimport React from 'react'\nimport Navbar from './components/Navbar'\nimport 'remixicon/fonts/remixicon.css'\nimport AddProducts from \"./Pages/AddProducts\"\n// import { Routes , Route } from 'react-router-dom'\nimport Home from './Pages/Home'\nimport ProductDetail from './Pages/ProductDetail'\nimport UserHome from './Pages/UserHome'\nimport Cart from './Pages/Cart'\n// import Login from './Pages/Login'\nimport Login from './Pages/Login'\nimport UserProduct from './Pages/UserProduct'\nimport { BrowserRouter as Router, Routes, Route } from \"react-router-dom\";\nimport { CartProvider } from \"./Pages/CartContext\";\nimport Footer from './components/Footer'\n\n\nconst App = () => {\n  return (\n    <div>\n      {/* <CartProvider> */}\n      {/* <Router> */}"}, {"id": "Frontend/src/App.jsx_1", "file": "Frontend/src/App.jsx", "content": "const App = () => {\n  return (\n    <div>\n      {/* <CartProvider> */}\n      {/* <Router> */}\n        <Routes>\n          <Route path='/' element={<UserHome/>}/>\n          <Route path=\"/products/detail/:productId\" element={<UserProduct/>} />\n          <Route path=\"/cart\" element={<Cart />} />\n          <Route  path='/admin/' element={<Home/>}/>\n          <Route  path='/admin/products/add' element={<AddProducts/>}/>\n          <Route  path='/admin/products/detail/:productId'  element={<ProductDetail/>}/>\n          <Route  path='/login'  element={<Login/>}/>\n          </Routes>\n      {/* </Router> */}\n    {/* </CartProvider> */}\n\n      {/* <Routes>\n        <Route  path='/admin/' element={<Home/>}/>\n        <Route  path='/admin/products/add' element={<AddProducts/>}/>"}, {"id": "Frontend/src/App.jsx_2", "file": "Frontend/src/App.jsx", "content": "<Route  path='/admin/products/add' element={<AddProducts/>}/>\n        <Route  path='/admin/products/detail/:productId'  element={<ProductDetail/>}/>\n      </Routes>  */}\n\n        <Footer />\n    </div>\n\n\n  )\n}\n\nexport default App"}, {"id": "Frontend/src/index.css_0", "file": "Frontend/src/index.css", "content": "================================================\n* {\n  margin: 0%;\n  padding: 0%;\n  box-sizing: border-box;\n}\n\n\nhtml , body {\n  height: 100%;\n  width: 100%;\n}"}, {"id": "Frontend/src/main.jsx_0", "file": "Frontend/src/main.jsx", "content": "================================================\nimport { StrictMode } from \"react\";\nimport { createRoot } from \"react-dom/client\";\nimport { BrowserRouter } from \"react-router-dom\";\nimport \"./index.css\";\nimport App from \"./App.jsx\";\n\ncreateRoot(document.getElementById(\"root\")).render(\n\n    <BrowserRouter>\n      <App />\n    </BrowserRouter>\n);"}, {"id": "Frontend/src/components/Footer.css_0", "file": "Frontend/src/components/Footer.css", "content": "================================================\n.footer {\n  position: fixed;\n  bottom: 0;\n  left: 0;\n  width: 100%;\n  height: 5%;\n  background-color: rgb(219, 219, 219);\n  text-align: center;\n  padding: 10px 0;\n  font-size: 0.6rem;\n  color: black;\n  border-top: 1px solid #ccc;\n  z-index: 100;\n}"}, {"id": "Frontend/src/components/Footer.jsx_0", "file": "Frontend/src/components/Footer.jsx", "content": "================================================\nimport React from 'react';\nimport './Footer.css';\n\nconst Footer = () => {\n  return (\n    <footer className=\"footer\">\n      \u00c3\u201a\u00c2\u00a9 Copyright - Samay Talwar\n    </footer>\n  );\n};\n\nexport default Footer;"}, {"id": "Frontend/src/components/Navbar.css_0", "file": "Frontend/src/components/Navbar.css", "content": "================================================\n/* nav {\n    height: 50px;\n    width: 100%;\n    background-color: rgb(201, 240, 247);\n    display: flex;\n    justify-content: space-between;\n    align-items: center;\n    padding: 5px 10px;\n}\n\nnav .search input {\n\n    width: 500px;\n    padding: 5px;\n    border-radius: 5px;\n    border: none;\n}\n\n.right{\n    position: relative; */\n    /* right : 200px;  */\n    /* top : 10px */\n/* } */\n\n\nnav {\n  position: fixed;\n  top: 0;\n  left: 0;\n  width: 100%;\n  height: 60px;\n  background-color: rgb(201, 240, 247);\n  display: flex;\n  align-items: center;\n  justify-content: space-between;\n  padding: 10px 16px;\n  box-sizing: border-box;\n  z-index: 9999;\n  overflow: hidden;\n}\n\nnav .left {\n  flex: 0 0 auto;\n  white-space: nowrap;\n}\n\nnav .left h2 {\n  margin: 0;"}, {"id": "Frontend/src/components/Navbar.css_1", "file": "Frontend/src/components/Navbar.css", "content": "}\n\nnav .left {\n  flex: 0 0 auto;\n  white-space: nowrap;\n}\n\nnav .left h2 {\n  margin: 0;\n  font-size: 1.5rem;\n}\n\nnav .search {\n  flex: 1 1 auto;\n  display: flex;\n  justify-content: center;\n  min-width: 0;\n}\n\nnav .search input {\n  width: 100%;\n  max-width: 500px;\n  padding: 8px 12px;\n  border-radius: 5px;\n  border: 1px solid #ccc;\n  font-size: 1rem;\n  box-sizing: border-box;\n}\n\n/* KEY FIX: Right section does NOT wrap or overflow */\nnav .right {\n  flex: 0 0 auto;\n  display: flex;\n  align-items: center;\n  gap: 1rem;\n  white-space: nowrap;\n  min-width: fit-content;\n  max-width: 200px;\n  overflow: hidden;\n  text-overflow: ellipsis;\n}"}, {"id": "Frontend/src/components/Navbar.jsx_0", "file": "Frontend/src/components/Navbar.jsx", "content": "================================================\nimport React from 'react'\nimport \"./Navbar.css\"\nimport { Link } from 'react-router-dom'\n\n\nconst Navbar = () => {\n  return (\n    <nav>\n        <div className=\"left\">\n             <Link to=\"/admin\"><h2>Shopy</h2></Link>\n        </div>\n        <div className='search'>\n            <input type=\"text\" />\n        </div>\n        <div className=\"right\">\n          <Link to=\"/admin/products/add\">Add new Product</Link>\n        </div>\n    </nav>\n  )\n}\n\nexport default Navbar"}, {"id": "Frontend/src/Pages/AddProducts.css_0", "file": "Frontend/src/Pages/AddProducts.css", "content": "================================================\nhtml, body{\n    margin: 0%;\n    padding: 0%;\n    box-sizing: border-box;\n}\n\n.head{\n    display: flex;\n    align-items: center;\n    justify-content: center;\n    background-color: rgb(204, 204, 231);\n    height: 50px;\n    border: 2px solid black;\n}\n\n.formContainer {\n   display: flex;\n    flex-direction: column;\n    align-items: center;\n}\n\nform{\n   padding: 40px;\n    border: 2px solid black;\n    width: 350px;\n    height: 550px;\n    border-radius: 15px;\n    display: flex;\n    flex-direction: column;\n    align-items: center;\n    justify-content: center;\n    margin: 40px 0px ;\n}\n.formGroup {\n  margin-bottom: 18px;\n}\n\nlabel {\n  display: block;\n  margin-bottom: 6px;\n  font-weight: 500;\n  color: #333;\n}\n\ninput[type=\"text\"],\ninput[type=\"number\"],"}, {"id": "Frontend/src/Pages/AddProducts.css_1", "file": "Frontend/src/Pages/AddProducts.css", "content": "font-weight: 500;\n  color: #333;\n}\n\ninput[type=\"text\"],\ninput[type=\"number\"],\ninput[type=\"file\"] {\n  width: 100%;\n  padding: 8px 10px;\n  border: 1px solid #ccc;\n  border-radius: 6px;\n  font-size: 1rem;\n  margin-bottom: 4px;\n}\n\nbutton[type=\"submit\"] {\n  background: #007bff;\n  color: #fff;\n  border: none;\n  padding: 10px 22px;\n  border-radius: 6px;\n  font-size: 1rem;\n  cursor: pointer;\n  transition: background 0.2s;\n}\n\nbutton[type=\"submit\"]:hover {\n  background: #0056b3;\n}"}, {"id": "Frontend/src/Pages/AddProducts.jsx_0", "file": "Frontend/src/Pages/AddProducts.jsx", "content": "================================================\nimport React, { useState } from 'react';\nimport axios from 'axios';\nimport './AddProducts.css';\nimport { useNavigate } from 'react-router-dom';\nimport ImageUploader from './ImageUploader';\n\n\nconst AddProducts = () => {\n\n    const navigate = useNavigate()\n    const [title, settitle] = useState('');\n    const [image, setimage] = useState('');\n    const [description, setdescription] = useState('');\n    const [category, setcategory] = useState('');\n    const [price, setprice] = useState('');\n\n    const handleSubmit = (e) => {\n        e.preventDefault();\n        let formData = new FormData(e.target);\n        axios.post(\"https://project-ecommerce-react-backend-rm5q.onrender.com/admin/products/add\", formData)\n            .then((res) => {"}, {"id": "Frontend/src/Pages/AddProducts.jsx_1", "file": "Frontend/src/Pages/AddProducts.jsx", "content": ".then((res) => {\n                console.log(res);\n                navigate(\"/\")\n            })\n            .catch((err) => {\n                console.log(err);\n            });\n    };\n\n    return (\n        <div>\n            <div className=\"head\"><h1>Add New Products</h1></div>\n            <div className='formContainer'>\n            <form onSubmit={handleSubmit}>\n                <div className=\"formGroup\">\n                    <label htmlFor=\"title\">Title</label>\n                    <input\n                        type=\"text\"\n                        placeholder=\"Enter product title\"\n                        value={title}\n                        onChange={(e) => settitle(e.target.value)}\n                        name=\"title\"\n                        id=\"title\"\n                    />"}, {"id": "Frontend/src/Pages/AddProducts.jsx_2", "file": "Frontend/src/Pages/AddProducts.jsx", "content": "name=\"title\"\n                        id=\"title\"\n                    />\n                </div>\n                \n                {/* <ImageUploader/> */}\n                <br />\n\n                <div className=\"formGroup\">\n                    <label htmlFor=\"image\">Image</label>\n                    <input\n                        type=\"file\"\n                        name=\"image\"\n                        id=\"image\"\n                        accept=\"image/*\"\n                        onChange={(e) => setimage(e.target.files[0])}\n                    />\n                </div>\n\n                <div className=\"formGroup\">\n                    <label htmlFor=\"description\">Description</label>\n                    <input\n                        type=\"text\""}, {"id": "Frontend/src/Pages/AddProducts.jsx_3", "file": "Frontend/src/Pages/AddProducts.jsx", "content": "<input\n                        type=\"text\"\n                        placeholder=\"Enter product description\"\n                        name=\"description\"\n                        id=\"description\"\n                        value={description}\n                        onChange={(e) => setdescription(e.target.value)}\n                    />\n                </div>\n\n                <div className=\"formGroup\">\n                    <label htmlFor=\"category\">Category</label>\n                    <input\n                        type=\"text\"\n                        placeholder=\"Enter product category\"\n                        name=\"category\"\n                        id=\"category\"\n                        value={category}\n                        onChange={(e) => setcategory(e.target.value)}"}, {"id": "Frontend/src/Pages/AddProducts.jsx_4", "file": "Frontend/src/Pages/AddProducts.jsx", "content": "onChange={(e) => setcategory(e.target.value)}\n                    />\n                </div>\n\n                <div className=\"formGroup\">\n                    <label htmlFor=\"price\">Price</label>\n                    <input\n                        type=\"number\"\n                        placeholder=\"Enter product price\"\n                        name=\"price\"\n                        id=\"price\"\n                        value={price}\n                        onChange={(e) => setprice(e.target.value)}\n                    />\n                </div>\n\n                <button type=\"submit\">Submit</button>\n            </form>\n        </div>\n        </div>\n        \n    );\n};\n\nexport default AddProducts;"}, {"id": "Frontend/src/Pages/Cart.css_0", "file": "Frontend/src/Pages/Cart.css", "content": "================================================\n.head{\n    display: flex;\n    align-items: center;\n    justify-content: center;\n    background-color: rgb(204, 204, 231);\n    height: 50px;\n    border: 2px solid black;\n}\n\n.no{\n    display: flex;\n    text-align: center;\n    font-size: 40px;\n    justify-content: center;\n    padding-top: 100px;\n}"}, {"id": "Frontend/src/Pages/Cart.jsx_0", "file": "Frontend/src/Pages/Cart.jsx", "content": "================================================\nimport React, { useEffect, useState } from 'react';\nimport axios from 'axios';\nimport \"./Cart.css\"\n\nconst Cart = () => {\n  const [cart, setCart] = useState([]);\n\n  useEffect(() => {\n    fetchCart();\n  }, []);\n\n  const fetchCart = () => {\n    axios.get('https://project-ecommerce-react-backend-rm5q.onrender.com/cart')\n      .then((response) => {\n        const grouped = groupByProduct(response.data);\n        setCart(grouped);\n      })\n      .catch((error) => console.error('Error fetching cart:', error));\n  };\n\n  const groupByProduct = (items) => {\n    const map = new Map();\n\n    for (const item of items) {\n      const id = item.productId._id;\n      if (map.has(id)) {\n        map.get(id).quantity += 1;\n      } else {"}, {"id": "Frontend/src/Pages/Cart.jsx_1", "file": "Frontend/src/Pages/Cart.jsx", "content": "if (map.has(id)) {\n        map.get(id).quantity += 1;\n      } else {\n        map.set(id, { ...item.productId, quantity: 1 });\n      }\n    }\n\n    return Array.from(map.values());\n  };\n\n  const reduceQuantity = (productId) => {\n    axios.delete(`https://project-ecommerce-react-backend-rm5q.onrender.com/cart/reduce/${productId}`)\n      .then(() => fetchCart())\n      .catch((err) => console.error('Error reducing quantity:', err));\n  };\n\n  const deleteProduct = (productId) => {\n    axios.delete(`https://project-ecommerce-react-backend-rm5q.onrender.com/cart/delete/${productId}`)\n      .then(() => fetchCart())\n      .catch((err) => console.error('Error deleting product:', err));\n  };\n\n  return (\n    <div>\n      <div className='head'>\n        <h2>Your Cart</h2>\n      </div>"}, {"id": "Frontend/src/Pages/Cart.jsx_2", "file": "Frontend/src/Pages/Cart.jsx", "content": "};\n\n  return (\n    <div>\n      <div className='head'>\n        <h2>Your Cart</h2>\n      </div>\n\n      {cart.length === 0 ? (\n        <div className=\"no\"><p>No items in cart</p></div>\n      ) : (\n        <div style={styles.cardContainer}>\n          {cart.map((item) => (\n            <div key={item._id} style={styles.card}>\n              <img\n                src={item.image}\n                alt={item.title}\n                style={styles.image}\n              />\n              <h3>{item.title}</h3>\n              <p>\u00c3\u00a2\u00e2\u20ac\u0161\u00c2\u00b9{item.price}</p>\n              <p><strong>Quantity:</strong> {item.quantity}</p>\n\n              <div style={{ marginTop: '10px' }}>\n                <button onClick={() => reduceQuantity(item._id)} style={styles.btn}>\u00c3\u00a2\u00cb\u2020\u00e2\u20ac\u2122</button>"}, {"id": "Frontend/src/Pages/Cart.jsx_3", "file": "Frontend/src/Pages/Cart.jsx", "content": "<button onClick={() => deleteProduct(item._id)} style={{ ...styles.btn, backgroundColor: '#e74c3c' }}>Delete</button>\n              </div>\n            </div>\n          ))}\n        </div>\n      )}\n    </div>\n  );\n};\n\nconst styles = {\n  cardContainer: {\n    display: 'grid',\n    gridTemplateColumns: 'repeat(auto-fill, minmax(200px, 1fr))',\n    gap: '20px',\n    padding: '20px',\n  },\n  card: {\n    border: '1px solid #ccc',\n    borderRadius: '10px',\n    padding: '16px',\n    textAlign: 'center',\n    boxShadow: '0 2px 8px rgba(0,0,0,0.1)',\n  },\n  image: {\n    width: '100%',\n    height: '150px',\n    objectFit: 'cover',\n    marginBottom: '10px',\n  },\n  btn: {\n    margin: '5px',\n    padding: '6px 12px',\n    border: 'none',\n    borderRadius: '5px',\n    backgroundColor: '#3498db',"}, {"id": "Frontend/src/Pages/Cart.jsx_4", "file": "Frontend/src/Pages/Cart.jsx", "content": "border: 'none',\n    borderRadius: '5px',\n    backgroundColor: '#3498db',\n    color: '#fff',\n    cursor: 'pointer',\n  },\n};\n\nexport default Cart;"}, {"id": "Frontend/src/Pages/CartContext.jsx_0", "file": "Frontend/src/Pages/CartContext.jsx", "content": "================================================\nimport { createContext, useState, useContext } from \"react\";\n\n// Create context\nconst CartContext = createContext();\n\n// Provide context\nexport const CartProvider = ({ children }) => {\n  const [cart, setCart] = useState([]);\n\n  const addToCart = (product) => {\n    setCart((prevCart) => [...prevCart, product]);\n  };\n\n  return (\n    <CartContext.Provider value={{ cart, addToCart }}>\n      {children}\n    </CartContext.Provider>\n  );\n};\n\n// Custom hook\nexport const useCart = () => useContext(CartContext);"}, {"id": "Frontend/src/Pages/Home.css_0", "file": "Frontend/src/Pages/Home.css", "content": "================================================\n/* html, body{\n    margin: 0%;\n    padding: 0%;\n    box-sizing: border-box;\n    background-color:rgb(248, 248, 248);;\n}\n\na{\n    color: black;\n    text-decoration: none;\n} */\n\n/* .container {\n    margin-top: 50px; */\n    /* display: flex;\n    align-items: center;\n    justify-content: center; */\n    /* display: grid;\n    grid-template-columns: repeat(4,1fr); */\n    /* gap: 20px; */\n    /* padding-left: 40px;\n    background-color: rgb(247, 247, 247);\n} */\n\n/* .container .card {\n    border : 2px solid black;\n    height: 375px;\n    width: 255px;\n    border-radius: 20px ;\n    padding: 15px;\n    background-color: #fff;\n} */\n\n/* .card .top {\n    width: 100%;\n    height: 50%;\n\n}\n\n.card .top img {\n    width: 100%;\n    height: 100%;\n} */\n\n/* h4{"}, {"id": "Frontend/src/Pages/Home.css_1", "file": "Frontend/src/Pages/Home.css", "content": "height: 50%;\n\n}\n\n.card .top img {\n    width: 100%;\n    height: 100%;\n} */\n\n/* h4{\n  position: relative;\n  bottom: -23px\n} */\n\nhtml, body {\n  margin: 0;\n  padding: 0;\n  box-sizing: border-box;\n  background-color: rgb(248, 248, 248);\n  font-size: 16px;\n  /* font-family: sans-serif; */\n}\n\na {\n  color: black;\n  text-decoration: none;\n}\n\n.container {\n    margin-top: 80px;\n  /* margin-top: 5vh; */\n  display: grid;\n  grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));\n  gap: 2rem;\n  padding: 0 5vw 5vh;\n  background-color: rgb(247, 247, 247);\n  justify-items: center;\n}\n\n.card {\n  width: 100%;\n  max-width: 260px;\n  background-color: #fff;\n  border: 2px solid #000;\n  border-radius: 1rem;\n  padding: 1rem;\n  display: flex;\n  flex-direction: column;"}, {"id": "Frontend/src/Pages/Home.css_2", "file": "Frontend/src/Pages/Home.css", "content": "border-radius: 1rem;\n  padding: 1rem;\n  display: flex;\n  flex-direction: column;\n  box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);\n  transition: transform 0.2s ease;\n}\n\n.card:hover {\n  transform: scale(1.02);\n}\n\n.card .top {\n  display: flex;\n  align-items: center;\n  justify-content: center;\n  height: 180px;\n  overflow: hidden;\n}\n\n.card .top img {\n  max-width: 100%;\n  max-height: 100%;\n  object-fit: contain;\n}\n\n.card .bottom {\n  margin-top: 1rem;\n  display: flex;\n  flex-direction: column;\n  /* gap: 0.5rem; */\n}\n\n/* Allow long titles to wrap */\n.card .bottom h1 {\n  font-size: 1.3rem;\n  margin: 0;\n  line-height: 1.4;\n  word-wrap: break-word;\n}\n\n/* Price always visible and wrapped */\n.card .bottom h4 {\n  font-size: 1rem;\n  padding-bottom: 15px ;\n  margin: 0;\n  color: #333;\n  font-weight: 500;\n}"}, {"id": "Frontend/src/Pages/Home.css_3", "file": "Frontend/src/Pages/Home.css", "content": "font-size: 1rem;\n  padding-bottom: 15px ;\n  margin: 0;\n  color: #333;\n  font-weight: 500;\n}"}, {"id": "Frontend/src/Pages/Home.jsx_0", "file": "Frontend/src/Pages/Home.jsx", "content": "================================================\nimport axios from \"axios\";\nimport React, { useEffect, useState } from \"react\";\nimport \"./Home.css\";\nimport { Link } from \"react-router-dom\";\nimport Navbar from \"../components/Navbar\";\n\n\nconst Home = () => {\n  const [productData, setProductData] = useState([]);\n\n  useEffect(() => {\n    getData();\n  }, []);\n\n  const getData = async () => {\n    await axios\n      .get(\"https://project-ecommerce-react-backend-rm5q.onrender.com/\")\n      .then((res) => {\n        console.log(res.data.products);\n        setProductData(res.data.products);\n      })\n      .catch((err) => {\n        console.log(err);\n      });\n  };\n\n  return (\n   <div>\n      <Navbar/>\n     <div className=\"container\">\n\n      {productData.map((elem, index) => {"}, {"id": "Frontend/src/Pages/Home.jsx_1", "file": "Frontend/src/Pages/Home.jsx", "content": "<Navbar/>\n     <div className=\"container\">\n\n      {productData.map((elem, index) => {\n        return <div className=\"card\" key={index}>\n          <div className=\"top\">\n            <img\n              src={elem.image}\n              alt=\"\"\n              width=\"200px\"\n            />\n          </div>\n          <div className=\"bottom\">\n            <Link to={`/admin/products/detail/${elem._id}`}><h1>{elem.title}</h1></Link>\n            <h4>Price : {elem.price}</h4>\n          </div>\n        </div>;\n      })}\n    </div>\n   </div>\n  );\n};\n\nexport default Home;"}, {"id": "Frontend/src/Pages/ImageUploader.jsx_0", "file": "Frontend/src/Pages/ImageUploader.jsx", "content": "================================================\n// ImageUploader.jsx\nimport React from \"react\";\nimport { IKContext, IKUpload } from \"imagekitio-react\";\n\nconst ImageUploader = () => {\n  const onUploadSuccess = (res) => {\n    console.log(\"Upload Success:\", res);\n    alert(\"Upload Success: \" + res.url);\n  };\n\n  const onUploadError = (err) => {\n    console.error(\"Upload Error:\", err);\n    alert(\"Upload Failed: \" + err.message);\n  };\n\n  return (\n\n    <IKContext\n      publicKey= {process.env.PUBLIC_KEY}\n    //   process.env.PRIVATE_KEY\n      urlEndpoint= {process.env.URLENDPOINT}\n      authenticationEndpoint=\"http://www.yourserver.com/auth\" // <-- your backend auth API\n    >\n      <label htmlFor=\"\">Upload an Image</label>\n      <IKUpload\n        fileName=\"user-upload.jpg\""}, {"id": "Frontend/src/Pages/ImageUploader.jsx_1", "file": "Frontend/src/Pages/ImageUploader.jsx", "content": "<label htmlFor=\"\">Upload an Image</label>\n      <IKUpload\n        fileName=\"user-upload.jpg\"\n        useUniqueFileName={true}\n        isPrivateFile={false}\n        onSuccess={onUploadSuccess}\n        onError={onUploadError}\n      />\n    </IKContext>\n  );\n};\n\nexport default ImageUploader;"}, {"id": "Frontend/src/Pages/Login.css_0", "file": "Frontend/src/Pages/Login.css", "content": "================================================\n\n.login-container {\n  display: flex;\n  justify-content: center;\n  align-items: center;\n  height: 100vh;\n  background: linear-gradient(135deg, #d3efff, #f0faff);\n}\n\n.login-form {\n  background-color: #ffffff;\n  padding: 2rem 2.5rem;\n  border-radius: 10px;\n  box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);\n  display: flex;\n  flex-direction: column;\n  gap: 1.2rem;\n  min-width: 300px;\n  max-width: 400px;\n}\n\n.login-form h2 {\n  margin: 0;\n  text-align: center;\n  color: #333;\n}\n\n.login-form input {\n  padding: 0.75rem;\n  border-radius: 6px;\n  border: 1px solid #ccc;\n  font-size: 1rem;\n}\n\n.login-form button {\n  padding: 0.75rem;\n  background-color: #00bcd4;\n  border: none;\n  color: white;\n  border-radius: 6px;\n  font-size: 1rem;\n  cursor: pointer;"}, {"id": "Frontend/src/Pages/Login.css_1", "file": "Frontend/src/Pages/Login.css", "content": "border: none;\n  color: white;\n  border-radius: 6px;\n  font-size: 1rem;\n  cursor: pointer;\n  transition: background 0.3s ease;\n}\n\n.login-form button:hover {\n  background-color: #0097a7;\n}\n\n.login-form pre {\n  font-size: 0.8rem;\n  color: #666;\n  background-color: #f7f7f7;\n  padding: 0.5rem;\n  border-radius: 5px;\n}\n\n.login-form .error {\n  color: red;\n  font-size: 0.9rem;\n  text-align: center;\n}"}, {"id": "Frontend/src/Pages/Login.jsx_0", "file": "Frontend/src/Pages/Login.jsx", "content": "================================================\n\nimport React, { useState } from 'react';\nimport { useNavigate } from 'react-router-dom';\nimport './Login.css';\n\nconst Login = () => {\n  const navigate = useNavigate();\n  const [email, setEmail] = useState('');\n  const [password, setPassword] = useState('');\n  const [error, setError] = useState('');\n\n  const allowedEmail = 'Sam10Admin@gmail.com';\n  const allowedPassword = 'admin123';\n\n  const handleSubmit = (e) => {\n    e.preventDefault();\n    if (email === allowedEmail && password === allowedPassword) {\n      navigate('/admin');\n    } else {\n      setError('Invalid email or password');\n    }\n  };\n\n  return (\n    <div className=\"login-container\">\n      <form onSubmit={handleSubmit} className=\"login-form\">\n        <pre className=\"hint\">"}, {"id": "Frontend/src/Pages/Login.jsx_1", "file": "Frontend/src/Pages/Login.jsx", "content": "<form onSubmit={handleSubmit} className=\"login-form\">\n        <pre className=\"hint\">\n        For evaluation puropse : <br />\n        Email: Sam10Admin@gmail.com <br />\n        Password: admin123 <br />\n        Only this email is allowed for Admin <br />\n        </pre>\n        <h2>Admin Login</h2>\n        {error && <p className=\"error\">{error}</p>}\n        <input\n          type=\"email\"\n          placeholder=\"Email\"\n          value={email}\n          onChange={(e) => setEmail(e.target.value)}\n          required\n        />\n        <input\n          type=\"password\"\n          placeholder=\"Password\"\n          value={password}\n          onChange={(e) => setPassword(e.target.value)}\n          required\n        />\n        <button type=\"submit\">Login</button>\n      </form>\n    </div>\n  );\n};"}, {"id": "Frontend/src/Pages/Login.jsx_2", "file": "Frontend/src/Pages/Login.jsx", "content": "/>\n        <button type=\"submit\">Login</button>\n      </form>\n    </div>\n  );\n};\n\nexport default Login;"}, {"id": "Frontend/src/Pages/ProductDetail.css_0", "file": "Frontend/src/Pages/ProductDetail.css", "content": "================================================\n/* .product-container {\n    height: 100%;\n    width: 100%;\n    background-color: rgb(226, 128, 128);\n    display: flex;\n    justify-content: center;\n    align-items: center;\n}\n\n.main {\n    height: 80%;\n    width: 80%;\n    border: 2px solid black;\n    display: flex;\n}\n\n.left {\n    width: 50%;\n    height: 100%;\n\n}\n\n.left img {\n    height: 100%;\n    width: 100%;\n}\n.right {\n    height: 100%;\n    width: 50%;\n} */\n\n\n\n\n/* html, body{\n    padding: 0px;\n    margin: 0px;\n    box-sizing: border-box;\n    height: 100%;\n    width: 100%;\n}\n\n.home {\n    width: 100%;\n    height: 600px;\n    display: flex;\n    align-items: center ;\n    justify-content: center;\n    background-color: #d7d7d7;\n}\n\n.pr{\n    display: flex;\n    align-items: center ;"}, {"id": "Frontend/src/Pages/ProductDetail.css_1", "file": "Frontend/src/Pages/ProductDetail.css", "content": "background-color: #d7d7d7;\n}\n\n.pr{\n    display: flex;\n    align-items: center ;\n    justify-content: center;\n    border: 2px black solid;\n    border-radius: 30px;\n    background-color: #fff;\n    width: 90%;\n    height: 550px;\n    padding: 0px 30px 0px 10px;\n    gap: 20px;\n}\n */\n\n\n html, body {\n    padding: 0;\n    margin: 0;\n    box-sizing: border-box;\n    height: 100%;\n    width: 100%;\n    font-size: 16px; /* Base font size for rem scaling */\n}\n\n.home {\n    width: 100%;\n    min-height: 100vh;\n    display: flex;\n    align-items: center;\n    justify-content: center;\n    background-color: #d7d7d7;\n    padding: 5vh 5vw;\n}\n\n.pr {\n    display: flex;\n    flex-direction: row;\n    align-items: center;\n    justify-content: center;\n    border: 0.125rem solid black;\n    border-radius: 2rem;"}, {"id": "Frontend/src/Pages/ProductDetail.css_2", "file": "Frontend/src/Pages/ProductDetail.css", "content": "justify-content: center;\n    border: 0.125rem solid black;\n    border-radius: 2rem;\n    background-color: #fff;\n    width: 100%;\n    max-width: 90vw;\n    padding: 2rem;\n    gap: 2rem;\n    flex-wrap: wrap;\n}\n\n/* Image section */\n.pr img {\n    width: 100%;\n    max-width: 30vw;\n    height: auto;\n    border-radius: 1rem;\n}\n\n/* Text section */\n.pr > div:last-child {\n    flex: 1;\n    min-width: 250px;\n    font-size: 1rem;\n}\n\nh1 {\n    font-size: 2rem;\n}\n\nh2 {\n    font-size: 1.5rem;\n}\n\np {\n    font-size: 1rem;\n    line-height: 1.5;\n}"}, {"id": "Frontend/src/Pages/ProductDetail.jsx_0", "file": "Frontend/src/Pages/ProductDetail.jsx", "content": "================================================\nimport React, { useEffect } from 'react'\nimport { useParams } from 'react-router-dom'\nimport \"./ProductDetail.css\"\nimport axios from 'axios'\nimport{ useState } from 'react';\n\nconst ProductDetail = () => {\n\n   const {productId} = useParams()\n   const [productData, setProductData] = useState([]);\n    \n    useEffect(() => {\n        getProductDetail()\n\n    }, [productId])\n    \n\n    const getProductDetail = async()=>{\n\n       await axios.get(\"https://project-ecommerce-react-backend-rm5q.onrender.com/products/\"+productId)\n        .then((res)=>{\n            console.log(res);\n            setProductData(res.data.product);\n            \n        })\n        .catch((err)=>{\n            console.log(err);\n        })\n\n    }\n\n  return ("}, {"id": "Frontend/src/Pages/ProductDetail.jsx_1", "file": "Frontend/src/Pages/ProductDetail.jsx", "content": "})\n        .catch((err)=>{\n            console.log(err);\n        })\n\n    }\n\n  return (\n    <div className='home'>\n     \n      <div className=\"pr\">\n        <div><img src={productData.image} alt=\"Product\" height=\"450px\" /></div>\n            <div>\n                <div>\n                  <h1>{productData.title}</h1><br />\n                  <h2>Price: \u00c3\u00a2\u00e2\u20ac\u0161\u00c2\u00b9{productData.price}</h2><br />\n                  <b>Description:</b>\n                  <p>{productData.description}</p><br />\n                  <p><b>Category:</b> {productData.category}</p><br />\n\n                </div>\n                \n               {/* <div className=\"buttons\">\n                <button><a href=\"/products/update\">Update</a></button>\n                <button><a href=\"/products/delete\">Delete</a></button>"}, {"id": "Frontend/src/Pages/ProductDetail.jsx_2", "file": "Frontend/src/Pages/ProductDetail.jsx", "content": "<button><a href=\"/products/delete\">Delete</a></button>\n               </div> */}\n\n            </div>\n\n      </div>\n    </div>\n  )\n}\n\nexport default ProductDetail"}, {"id": "Frontend/src/Pages/UserHome.css_0", "file": "Frontend/src/Pages/UserHome.css", "content": "================================================\n/* html, body{\n    margin: 0%;\n    padding: 0%;\n    box-sizing: border-box;\n    background-color:rgb(248, 248, 248);;\n}\n\na{\n    color: black;\n    text-decoration: none;\n} */\n/* \n.container {\n    margin-top: 50px;\n    /* display: flex;\n    align-items: center;\n    justify-content: center; */\n    /* display: grid; */\n    /* grid-template-columns: repeat(4,1fr); */\n    /* gap: 20px; */\n    /* padding-left: 40px; */\n    /* background-color: rgb(247, 247, 247); */\n/* } */\n\n/* .container .card {\n    border : 2px solid black;\n    height: 375px;\n    width: 255px;\n    border-radius: 20px ;\n    padding: 15px;\n    background-color: #fff;\n} */ \n\n/* .card .top {\n    width: 100%;\n    height: 50%;\n\n}\n\n.card .top img {\n    width: 100%;\n    height: 100%;"}, {"id": "Frontend/src/Pages/UserHome.css_1", "file": "Frontend/src/Pages/UserHome.css", "content": "width: 100%;\n    height: 50%;\n\n}\n\n.card .top img {\n    width: 100%;\n    height: 100%;\n} */\n\n/* h4{\n  position: relative;\n  bottom: -23px\n}\n\nnav {\n    height: 50px;\n    width: 100%;\n    background-color: rgb(161, 219, 239);\n    display: flex;\n    justify-content: space-between;\n    align-items: center;\n    padding: 5px 10px;\n}\n\nnav .search input {\n\n    width: 500px;\n    padding: 5px;\n    border-radius: 5px;\n    border: none; */\n/* }\n\n.right{\n    position: relative;\n    right : -260px; \n     top : 10px\n} */\n\nhtml, body {\n    margin: 0;\n    padding: 0;\n    box-sizing: border-box;\n    background-color: rgb(248, 248, 248);\n    font-size: 16px;\n}\n\na {\n    color: black;\n    text-decoration: none;\n}\n\n\nnav {\n  position: fixed;\n  gap: 0.5rem;\n  top: 0;\n  left: 0;\n  width: 100%;\n  height: 60px;"}, {"id": "Frontend/src/Pages/UserHome.css_2", "file": "Frontend/src/Pages/UserHome.css", "content": "}\n\n\nnav {\n  position: fixed;\n  gap: 0.5rem;\n  top: 0;\n  left: 0;\n  width: 100%;\n  height: 60px;\n  background-color: rgb(201, 240, 247);\n  display: flex;\n  align-items: center;\n  justify-content: space-between;\n  padding: 10px 16px;\n  box-sizing: border-box;\n  z-index: 9999;\n  overflow: hidden;\n}\n\nnav .left {\n  flex: 0 0 auto;\n  white-space: nowrap;\n}\n\nnav .left h2 {\n  margin: 0;\n  font-size: 1.5rem;\n}\n\nnav .search {\n  flex: 1 1 auto;\n  display: flex;\n  justify-content: center;\n  min-width: 0;\n}\n\nnav .search input {\n  width: 100%;\n  max-width: 500px;\n  padding: 8px 12px;\n  border-radius: 5px;\n  border: 1px solid #ccc;\n  font-size: 1rem;\n  box-sizing: border-box;\n}\n\n/* KEY FIX: Right section does NOT wrap or overflow */\nnav .right {\n  flex: 0 0 auto;\n  display: flex;\n  align-items: center;"}, {"id": "Frontend/src/Pages/UserHome.css_3", "file": "Frontend/src/Pages/UserHome.css", "content": "nav .right {\n  flex: 0 0 auto;\n  display: flex;\n  align-items: center;\n  gap: 1rem;\n  white-space: nowrap;\n  min-width: fit-content;\n  max-width: 200px;\n  overflow: hidden;\n  text-overflow: ellipsis;\n}\n\n\n/* Product Grid */\n.container {\n    margin-top: 80px;\n    /* margin-top: 5vh; */\n    display: grid;\n    grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));\n    gap: 2rem;\n    padding: 0 5vw;\n    background-color: rgb(247, 247, 247);\n    justify-items: center;\n}\n\n/* Individual Card */\n.container .card {\n    border: 0.125rem solid black;\n    width: 90%;\n    max-width: 255px;\n    height: auto;\n    border-radius: 1.25rem;\n    padding: 1rem;\n    background-color: #fff;\n    box-shadow: 0px 2px 6px rgba(0, 0, 0, 0.05);\n    transition: transform 0.2s;\n}\n\n.container .card:hover {"}, {"id": "Frontend/src/Pages/UserHome.css_4", "file": "Frontend/src/Pages/UserHome.css", "content": "transition: transform 0.2s;\n}\n\n.container .card:hover {\n    transform: scale(1.02);\n}\n\n.container .card img {\n    width: 100%;\n    height: auto;\n    object-fit: contain;\n    border-radius: 0.5rem;\n}\n\nh4 {\n    position: relative;\n    bottom: -1.5rem;\n    font-size: 1rem;\n}"}, {"id": "Frontend/src/Pages/UserHome.jsx_0", "file": "Frontend/src/Pages/UserHome.jsx", "content": "================================================\nimport axios from \"axios\";\nimport React, { useEffect, useState } from \"react\";\nimport \"./UserHome.css\";\nimport { Link } from \"react-router-dom\";\nimport Navbar from \"../components/Navbar\";\n\n\nconst Home = () => {\n  const [productData, setProductData] = useState([]);\n\n  useEffect(() => {\n    getData();\n  }, []);\n\n  const getData = async () => {\n    await axios\n      .get(\"https://project-ecommerce-react-backend-rm5q.onrender.com\")\n      .then((res) => {\n        console.log(res.data.products);\n        setProductData(res.data.products);\n      })\n      .catch((err) => {\n        console.log(err);\n      });\n  };\n\n  return (\n   <div>\n    <nav>\n            <div className=\"left\">\n                 <Link ><h2>Shopy</h2></Link>\n            </div>"}, {"id": "Frontend/src/Pages/UserHome.jsx_1", "file": "Frontend/src/Pages/UserHome.jsx", "content": "<div className=\"left\">\n                 <Link ><h2>Shopy</h2></Link>\n            </div>\n            <div className='search'>\n                <input type=\"text\" />\n            </div>\n            <div className=\"right\">\n              {/* <Link to=\"/admin/products/add\">Add new Product</Link> */}\n              <Link to=\"/Cart\"><i class=\"ri-shopping-cart-fill\"></i></Link>\n              <Link to=\"/login\" className=\"ad\"><h2>Admin</h2></Link>\n            </div>\n        </nav>      \n\n     <div className=\"container\">\n\n      {productData.map((elem, index) => {\n        return <div className=\"card\" key={index}>\n          <div className=\"top\">\n            <img\n              src={elem.image}\n              alt=\"\"\n              width=\"200px\"\n            />\n          </div>"}, {"id": "Frontend/src/Pages/UserHome.jsx_2", "file": "Frontend/src/Pages/UserHome.jsx", "content": "alt=\"\"\n              width=\"200px\"\n            />\n          </div>\n          <div className=\"bottom\">\n            <Link to={`/products/detail/${elem._id}`}><h1>{elem.title}</h1></Link>\n            <h4>Price : {elem.price}</h4>\n          </div>\n        </div>;\n      })}\n    </div>\n   </div>\n  );\n};\n\nexport default Home;"}, {"id": "Frontend/src/Pages/UserProduct.css_0", "file": "Frontend/src/Pages/UserProduct.css", "content": "================================================\n/* .product-container {\n    height: 100%;\n    width: 100%;\n    background-color: rgb(226, 128, 128);\n    display: flex;\n    justify-content: center;\n    align-items: center;\n}\n\n.main {\n    height: 80%;\n    width: 80%;\n    border: 2px solid black;\n    display: flex;\n}\n\n.left {\n    width: 50%;\n    height: 100%;\n\n}\n\n.left img {\n    height: 100%;\n    width: 100%;\n}\n.right {\n    height: 100%;\n    width: 50%;\n} */\n/* \nhtml, body{\n    padding: 0px;\n    margin: 0px;\n    box-sizing: border-box;\n    height: 100%;\n    width: 100%;\n}\n\n.home {\n    width: 100%;\n    height: 600px;\n    display: flex;\n    align-items: center ;\n    justify-content: center;\n    background-color: #d7d7d7;\n}\n\n.pr{\n    display: flex;\n    align-items: center ;"}, {"id": "Frontend/src/Pages/UserProduct.css_1", "file": "Frontend/src/Pages/UserProduct.css", "content": "background-color: #d7d7d7;\n}\n\n.pr{\n    display: flex;\n    align-items: center ;\n    justify-content: center;\n    border: 2px black solid;\n    border-radius: 30px;\n    background-color: #fff;\n    width: 90%;\n    height: 550px;\n    padding: 0px 30px 0px 10px;\n    gap: 20px;\n} */\n\n/* .buttons{\n    gap: 25px;\n    height: 10px ;\n    width : 30px;\n} */\n\n\nhtml, body {\n    padding: 0;\n    margin: 0;\n    box-sizing: border-box;\n    height: 100%;\n    width: 100%;\n    font-size: 16px;\n}\n\n.home {\n    width: 100%;\n    min-height: 100vh;\n    display: flex;\n    align-items: center;\n    justify-content: center;\n    background-color: #d7d7d7;\n    padding: 5vh 5vw;\n}\n\n.pr {\n    display: flex;\n    flex-wrap: wrap;\n    align-items: center;\n    justify-content: center;\n    border: 0.125rem solid black;"}, {"id": "Frontend/src/Pages/UserProduct.css_2", "file": "Frontend/src/Pages/UserProduct.css", "content": "align-items: center;\n    justify-content: center;\n    border: 0.125rem solid black;\n    border-radius: 2rem;\n    background-color: #fff;\n    width: 100%;\n    max-width: 90vw;\n    padding: 2rem;\n    gap: 2rem;\n}\n\n/* Image section */\n.pr img {\n    width: 100%;\n    max-width: 30vw;\n    height: auto;\n    border-radius: 1rem;\n    object-fit: contain;\n}\n\n/* Text section */\n.pr > div:last-child {\n    flex: 1;\n    min-width: 250px;\n}\n\n/* Buttons */\n.buttons {\n    display: flex;\n    gap: 1.5rem;\n    margin-top: 1rem;\n}\n\n.buttons button {\n    padding: 0.6rem 1.2rem;\n    font-size: 1rem;\n    border: none;\n    border-radius: 0.5rem;\n    background-color: #000;\n    color: #fff;\n    cursor: pointer;\n    transition: background-color 0.3s;\n}\n\n.buttons button:hover {\n    background-color: #333;\n}"}, {"id": "Frontend/src/Pages/UserProduct.jsx_0", "file": "Frontend/src/Pages/UserProduct.jsx", "content": "================================================\nimport React, { useEffect } from 'react'\nimport { useParams } from 'react-router-dom'\nimport \"./UserProduct.css\"\nimport axios from 'axios'\nimport{ useState } from 'react';\nimport { Link } from 'react-router-dom';\n\n// const [cart, setCart] = useState([]); // local cart state\n\n// const addToCart = () => {\n//   setCart(prevCart => [...prevCart, productData]);\n//   alert(\"Product added to cart!\");\n// };\n// import { Link } from \"react-router-dom\";\n// const { addToCart } = useCart();\n\n\n\nconst ProductDetail = () => {\n\n   const {productId} = useParams()\n   const [productData, setProductData] = useState([]);\n    \n    useEffect(() => {\n        getProductDetail()\n\n    }, [productId])\n\n    const handleAddToCart = () => {"}, {"id": "Frontend/src/Pages/UserProduct.jsx_1", "file": "Frontend/src/Pages/UserProduct.jsx", "content": "getProductDetail()\n\n    }, [productId])\n\n    const handleAddToCart = () => {\n    axios.post(`https://project-ecommerce-react-backend-rm5q.onrender.com/cart/add/${productId}`)\n      .then(response => alert('Product added to cart!'))\n      .catch(error => console.error('Error adding to cart:', error));\n  };\n\n    const getProductDetail = async()=>{\n\n       await axios.get(\"https://project-ecommerce-react-backend-rm5q.onrender.com/products/\"+productId)\n        .then((res)=>{\n            console.log(res);\n            setProductData(res.data.product);\n            \n        })\n        .catch((err)=>{\n            console.log(err);\n        })\n\n    }\n\n  return (\n    <div className='home'>\n     \n      <div className=\"pr\">"}, {"id": "Frontend/src/Pages/UserProduct.jsx_2", "file": "Frontend/src/Pages/UserProduct.jsx", "content": "})\n\n    }\n\n  return (\n    <div className='home'>\n     \n      <div className=\"pr\">\n        <div><img src={productData.image} alt=\"Product\" height=\"450px\" /></div>\n            <div>\n                <div>\n                  <h1>{productData.title}</h1><br />\n                  <h2>Price: \u00c3\u00a2\u00e2\u20ac\u0161\u00c2\u00b9{productData.price}</h2><br />\n                  <b>Description:</b>\n                  <p>{productData.description}</p><br />\n                  <p><b>Category:</b> {productData.category}</p><br />\n\n                </div>\n                \n               <div className=\"buttons\">\n                <button>Buy</button>\n                <button onClick={handleAddToCart}>Add to cart</button>\n                {/* <button onClick={() => addToCart(productData)}>Add to Cart</button> */}"}, {"id": "Frontend/src/Pages/UserProduct.jsx_3", "file": "Frontend/src/Pages/UserProduct.jsx", "content": "{/* <button onClick={() => addToCart(productData)}>Add to Cart</button> */}\n                {/* <button onClick={addToCart()}>Add to cart</button> */}\n               </div>\n\n            </div>\n\n      </div>\n    </div>\n  )\n}\n\nexport default ProductDetail"}, {"id": "gitingest_outputs/tree_main_20250907_182050.txt_0", "file": "gitingest_outputs/tree_main_20250907_182050.txt", "content": "================================================\nError reading file with 'cp1252': 'charmap' codec can't decode byte 0x8d in position 61058: character maps to <undefined>"}, {"id": "gitingest_outputs/urvashixo_land_registry_20250906_162438.txt_0", "file": "gitingest_outputs/urvashixo_land_registry_20250906_162438.txt", "content": "================================================\nError reading file with 'cp1252': 'charmap' codec can't decode byte 0x8d in position 1126: character maps to <undefined>"}, {"id": "gitingest_outputs/urvashixo_land_registry_20250906_164238.txt_0", "file": "gitingest_outputs/urvashixo_land_registry_20250906_164238.txt", "content": "================================================\nError reading file with 'cp1252': 'charmap' codec can't decode byte 0x8d in position 1126: character maps to <undefined>"}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/README.md.txt_0", "file": "gitingest_outputs/gitignore_files_20250905_192308/README.md.txt", "content": "================================================\n# File: README.md\n# Language: Markdown\n# Lines: 155\n# Size: 7115 bytes\n# Type: documentation\n# ==================================================\n\n# A collection of `.gitignore` templates\n\nThis is GitHub\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s collection of [`.gitignore`][man] file templates.\nWe use this list to populate the `.gitignore` template choosers available\nin the GitHub.com interface when creating new repositories and files.\n\nFor more information about how `.gitignore` files work, and how to use them,\nthe following resources are a great place to start:\n\n- The [Ignoring Files chapter][chapter] of the [Pro Git][progit] book.\n- The [Ignoring Files article][help] on the GitHub Help site.\n- The [gitignore(5)][man] manual page."}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/README.md.txt_1", "file": "gitingest_outputs/gitignore_files_20250905_192308/README.md.txt", "content": "- The [gitignore(5)][man] manual page.\n\n[man]: https://git-scm.com/docs/gitignore\n[help]: https://help.github.com/articles/ignoring-files\n[chapter]: https://git-scm.com/book/en/v2/Git-Basics-Recording-Changes-to-the-Repository#_ignoring\n[progit]: https://git-scm.com/book"}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/README.md.txt_2", "file": "gitingest_outputs/gitignore_files_20250905_192308/README.md.txt", "content": "## Folder structure\n\nWe support a collection of templates, organized in this way:\n\n- The root folder contains templates in common use, to help people get started\n  with popular programming languages and technologies. These define a meaningful\n  set of rules to help get started, and ensure you are not committing\n  unimportant files into your repository.\n- [`Global`](./Global) contains templates for various editors, tools and\n  operating systems that can be used in different situations. It is recommended\n  that you either [add these to your global template](https://docs.github.com/en/get-started/getting-started-with-git/ignoring-files#configuring-ignored-files-for-all-repositories-on-your-computer)\n  or merge these rules into your project-specific templates if you want to use"}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/README.md.txt_3", "file": "gitingest_outputs/gitignore_files_20250905_192308/README.md.txt", "content": "or merge these rules into your project-specific templates if you want to use\n  them permanently.\n- [`community`](./community) contains specialized templates for other popular\n  languages, tools and project, which don't currently belong in the mainstream\n  templates. These should be added to your project-specific templates when you\n  decide to adopt the framework or tool."}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/README.md.txt_4", "file": "gitingest_outputs/gitignore_files_20250905_192308/README.md.txt", "content": "## What makes a good template?\n\nA template should contain a set of rules to help Git repositories work with a\nspecific programming language, framework, tool or environment.\n\nIf it's not possible to curate a small set of useful rules for this situation,\nthen the template is not a good fit for this collection.\n\nIf a template is mostly a list of files installed by a particular version of\nsome software (e.g. a PHP framework), it could live under the `community`\ndirectory. See [versioned templates](#versioned-templates) for more details.\n\nIf you have a small set of rules, or want to support a technology that is not\nwidely in use, and still believe this will be helpful to others, please read the\nsection about [specialized templates](#specialized-templates) for more details."}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/README.md.txt_5", "file": "gitingest_outputs/gitignore_files_20250905_192308/README.md.txt", "content": "section about [specialized templates](#specialized-templates) for more details.\n\nInclude details when opening pull request if the template is important and visible. We\nmay not accept it immediately, but we can promote it to the root at a later date\nbased on interest.\n\nPlease also understand that we can\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2t list every tool that ever existed.\nOur aim is to curate a collection of the _most common and helpful_ templates,\nnot to make sure we cover every project possible. If we choose not to\ninclude your language, tool, or project, it\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s not because it\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s not awesome."}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/README.md.txt_6", "file": "gitingest_outputs/gitignore_files_20250905_192308/README.md.txt", "content": "## Contributing guidelines\n\nWe\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2d love for you to help us improve this project. To help us keep this collection\nhigh quality, we request that contributions adhere to the following guidelines.\n\n- **Provide a link to the application or project\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s homepage**. Unless it\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s\n  extremely popular, there\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s a chance the maintainers don\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2t know about or use\n  the language, framework, editor, app, or project your change applies to.\n\n- **Provide links to documentation** supporting the change you\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2re making.\n  Current, canonical documentation mentioning the files being ignored is best.\n  If documentation isn\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2t available to support your change, do the best you can\n  to explain what the files being ignored are for."}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/README.md.txt_7", "file": "gitingest_outputs/gitignore_files_20250905_192308/README.md.txt", "content": "to explain what the files being ignored are for.\n\n- **Explain why you\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2re making a change**. Even if it seems self-evident, please\n  take a sentence or two to tell us why your change or addition should happen.\n  It\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s especially helpful to articulate why this change applies to _everyone_\n  who works with the applicable technology, rather than just you or your team.\n\n- **Please consider the scope of your change**. If your change is specific to a\n  certain language or framework, then make sure the change is made to the\n  template for that language or framework, rather than to the template for an\n  editor, tool, or operating system.\n\n- **Please only modify _one template_ per pull request**. This helps keep pull"}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/README.md.txt_8", "file": "gitingest_outputs/gitignore_files_20250905_192308/README.md.txt", "content": "- **Please only modify _one template_ per pull request**. This helps keep pull\n  requests and feedback focused on a specific project or technology.\n\nIn general, the more you can do to help us understand the change you\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2re making,\nthe more likely we\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2ll be to accept your contribution quickly."}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/README.md.txt_9", "file": "gitingest_outputs/gitignore_files_20250905_192308/README.md.txt", "content": "## Versioned templates\n\nSome templates can change greatly between versions, and if you wish to contribute\nto this repository we need to follow this specific flow:\n\n- the template at the root should be the current supported version\n- the template at the root should not have a version in the filename (i.e.\n  \"evergreen\")\n- previous versions of templates should live under `community/`\n- previous versions of the template should embed the version in the filename,\n  for readability\n\nThis helps ensure users get the latest version (because they'll use whatever is\nat the root) but helps maintainers support older versions still in the wild."}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/README.md.txt_10", "file": "gitingest_outputs/gitignore_files_20250905_192308/README.md.txt", "content": "## Specialized templates\n\nIf you have a template that you would like to contribute, but it isn't quite\nmainstream, please consider adding this to the `community` directory under a\nfolder that best suits where it belongs.\n\nThe rules in your specialized template should be specific to the framework or\ntool, and any additional templates should be mentioned in a comment in the\nheader of the template.\n\nFor example, this template might live at `community/DotNet/InforCRM.gitignore`:\n\n```gitignore\n# gitignore template for InforCRM (formerly SalesLogix)\n# website: https://www.infor.com/product-summary/cx/infor-crm/\n#\n# Recommended: VisualStudio.gitignore\n\n# Ignore model files that are auto-generated\nModelIndex.xml\nExportedFiles.xml\n\n# Ignore deployment files\n[Mm]odel/[Dd]eployment"}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/README.md.txt_11", "file": "gitingest_outputs/gitignore_files_20250905_192308/README.md.txt", "content": "ModelIndex.xml\nExportedFiles.xml\n\n# Ignore deployment files\n[Mm]odel/[Dd]eployment\n\n# Force include portal SupportFiles\n!Model/Portal/*/SupportFiles/[Bb]in/\n!Model/Portal/PortalTemplates/*/SupportFiles/[Bb]in\n```"}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/README.md.txt_12", "file": "gitingest_outputs/gitignore_files_20250905_192308/README.md.txt", "content": "## Contributing workflow\n\nHere\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s how we suggest you go about proposing a change to this project:\n\n1. [Fork this project][fork] to your account.\n2. [Create a branch][branch] for the change you intend to make.\n3. Make your changes to your fork.\n4. [Send a pull request][pr] from your fork\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s branch to our `main` branch.\n\nUsing the web-based interface to make changes is fine too, and will help you\nby automatically forking the project and prompting to send a pull request too.\n\n[fork]: https://help.github.com/articles/fork-a-repo/\n[branch]: https://help.github.com/articles/creating-and-deleting-branches-within-your-repository\n[pr]: https://help.github.com/articles/using-pull-requests/\n\n## License\n\n[CC0-1.0](./LICENSE)."}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/CONTRIBUTING.md.txt_0", "file": "gitingest_outputs/gitignore_files_20250905_192308/CONTRIBUTING.md.txt", "content": "================================================\n# File: CONTRIBUTING.md\n# Language: Markdown\n# Lines: 39\n# Size: 2274 bytes\n# Type: documentation\n# ==================================================\n\n# Contributing guidelines\n\nWe\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2d love you to help us improve this project. To help us keep this collection\nhigh quality, we request that contributions adhere to the following guidelines.\n\n- **Provide a link to the application or project\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s homepage**. Unless it\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s\n  extremely popular, there\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s a chance the maintainers don\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2t know about or use\n  the language, framework, editor, app, or project your change applies to.\n\n- **Provide links to documentation** supporting the change you\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2re making."}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/CONTRIBUTING.md.txt_1", "file": "gitingest_outputs/gitignore_files_20250905_192308/CONTRIBUTING.md.txt", "content": "- **Provide links to documentation** supporting the change you\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2re making.\n  Current, canonical documentation mentioning the files being ignored is best.\n  If documentation isn\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2t available to support your change, do the best you can\n  to explain what the files being ignored are for.\n\n- **Explain why you\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2re making a change**. Even if it seems self-evident, please\n  take a sentence or two to tell us why your change or addition should happen.\n  It\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s especially helpful to articulate why this change applies to *everyone*\n  who works with the applicable technology, rather than just you or your team.\n\n- **Please consider the scope of your change**. If your change specific to a\n  certain language or framework, then make sure the change is made to the"}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/CONTRIBUTING.md.txt_2", "file": "gitingest_outputs/gitignore_files_20250905_192308/CONTRIBUTING.md.txt", "content": "certain language or framework, then make sure the change is made to the\n  template for that language or framework, rather than to the template for an\n  editor, tool, or operating system.\n\n- **Please only modify *one template* per pull request**. This helps keep pull\n  requests and feedback focused on a specific project or technology.\n\nIn general, the more you can do to help us understand the change you\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2re making,\nthe more likely we\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2ll be to accept your contribution quickly.\n\nIf a template is mostly a list of files installed by a particular version of\nsome software (e.g. a PHP framework) then it's brittle and probably no more\nhelpful than a simple `ls`. If it's not possible to curate a small set of\nuseful rules, then the template might not be a good fit for this collection."}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/CONTRIBUTING.md.txt_3", "file": "gitingest_outputs/gitignore_files_20250905_192308/CONTRIBUTING.md.txt", "content": "useful rules, then the template might not be a good fit for this collection.\n\nPlease also understand that we can\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2t list every tool that ever existed.\nOur aim is to curate a collection of the *most common and helpful* templates,\nnot to make sure we cover every project possible. If we choose not to\ninclude your language, tool, or project, it\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s not because it\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s not awesome."}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/Global_README.md.txt_0", "file": "gitingest_outputs/gitignore_files_20250905_192308/Global_README.md.txt", "content": "================================================\n# File: Global/README.md\n# Language: Markdown\n# Lines: 10\n# Size: 359 bytes\n# Type: documentation\n# ==================================================\n\n## Globally Useful gitignores\n\nThis directory contains globally useful gitignores,\ne.g. OS-specific and editor specific.\n\nFor more on global gitignores:\n<https://help.github.com/en/github/using-git/ignoring-files#configuring-ignored-files-for-all-repositories-on-your-computer>\n\nAnd a good blog post about 'em:\n<http://augustl.com/blog/2009/global_gitignores>"}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/LICENSE.txt_0", "file": "gitingest_outputs/gitignore_files_20250905_192308/LICENSE.txt", "content": "================================================\n# File: LICENSE\n# Language: unknown\n# Lines: 116\n# Size: 6554 bytes\n# Type: other\n# ==================================================\n\nCC0 1.0 Universal\n\nStatement of Purpose\n\nThe laws of most jurisdictions throughout the world automatically confer\nexclusive Copyright and Related Rights (defined below) upon the creator and\nsubsequent owner(s) (each and all, an \"owner\") of an original work of\nauthorship and/or a database (each, a \"Work\").\n\nCertain owners wish to permanently relinquish those rights to a Work for the\npurpose of contributing to a commons of creative, cultural and scientific\nworks (\"Commons\") that the public can reliably and without fear of later\nclaims of infringement build upon, modify, incorporate in other works, reuse"}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/LICENSE.txt_1", "file": "gitingest_outputs/gitignore_files_20250905_192308/LICENSE.txt", "content": "claims of infringement build upon, modify, incorporate in other works, reuse\nand redistribute as freely as possible in any form whatsoever and for any\npurposes, including without limitation commercial purposes. These owners may\ncontribute to the Commons to promote the ideal of a free culture and the\nfurther production of creative, cultural and scientific works, or to gain\nreputation or greater distribution for their Work in part through the use and\nefforts of others.\n\nFor these and/or other purposes and motivations, and without any expectation\nof additional consideration or compensation, the person associating CC0 with a\nWork (the \"Affirmer\"), to the extent that he or she is an owner of Copyright\nand Related Rights in the Work, voluntarily elects to apply CC0 to the Work"}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/LICENSE.txt_2", "file": "gitingest_outputs/gitignore_files_20250905_192308/LICENSE.txt", "content": "and Related Rights in the Work, voluntarily elects to apply CC0 to the Work\nand publicly distribute the Work under its terms, with knowledge of his or her\nCopyright and Related Rights in the Work and the meaning and intended legal\neffect of CC0 on those rights.\n\n1. Copyright and Related Rights. A Work made available under CC0 may be\nprotected by copyright and related or neighboring rights (\"Copyright and\nRelated Rights\"). Copyright and Related Rights include, but are not limited\nto, the following:\n\n  i. the right to reproduce, adapt, distribute, perform, display, communicate,\n  and translate a Work;\n\n  ii. moral rights retained by the original author(s) and/or performer(s);\n\n  iii. publicity and privacy rights pertaining to a person's image or likeness\n  depicted in a Work;"}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/LICENSE.txt_3", "file": "gitingest_outputs/gitignore_files_20250905_192308/LICENSE.txt", "content": "depicted in a Work;\n\n  iv. rights protecting against unfair competition in regards to a Work,\n  subject to the limitations in paragraph 4(a), below;\n\n  v. rights protecting the extraction, dissemination, use and reuse of data in\n  a Work;\n\n  vi. database rights (such as those arising under Directive 96/9/EC of the\n  European Parliament and of the Council of 11 March 1996 on the legal\n  protection of databases, and under any national implementation thereof,\n  including any amended or successor version of such directive); and\n\n  vii. other similar, equivalent or corresponding rights throughout the world\n  based on applicable law or treaty, and any national implementations thereof.\n\n2. Waiver. To the greatest extent permitted by, but not in contravention of,"}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/LICENSE.txt_4", "file": "gitingest_outputs/gitignore_files_20250905_192308/LICENSE.txt", "content": "2. Waiver. To the greatest extent permitted by, but not in contravention of,\napplicable law, Affirmer hereby overtly, fully, permanently, irrevocably and\nunconditionally waives, abandons, and surrenders all of Affirmer's Copyright\nand Related Rights and associated claims and causes of action, whether now\nknown or unknown (including existing as well as future claims and causes of\naction), in the Work (i) in all territories worldwide, (ii) for the maximum\nduration provided by applicable law or treaty (including future time\nextensions), (iii) in any current or future medium and for any number of\ncopies, and (iv) for any purpose whatsoever, including without limitation\ncommercial, advertising or promotional purposes (the \"Waiver\"). Affirmer makes"}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/LICENSE.txt_5", "file": "gitingest_outputs/gitignore_files_20250905_192308/LICENSE.txt", "content": "commercial, advertising or promotional purposes (the \"Waiver\"). Affirmer makes\nthe Waiver for the benefit of each member of the public at large and to the\ndetriment of Affirmer's heirs and successors, fully intending that such Waiver\nshall not be subject to revocation, rescission, cancellation, termination, or\nany other legal or equitable action to disrupt the quiet enjoyment of the Work\nby the public as contemplated by Affirmer's express Statement of Purpose.\n\n3. Public License Fallback. Should any part of the Waiver for any reason be\njudged legally invalid or ineffective under applicable law, then the Waiver\nshall be preserved to the maximum extent permitted taking into account\nAffirmer's express Statement of Purpose. In addition, to the extent the Waiver"}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/LICENSE.txt_6", "file": "gitingest_outputs/gitignore_files_20250905_192308/LICENSE.txt", "content": "Affirmer's express Statement of Purpose. In addition, to the extent the Waiver\nis so judged Affirmer hereby grants to each affected person a royalty-free,\nnon transferable, non sublicensable, non exclusive, irrevocable and\nunconditional license to exercise Affirmer's Copyright and Related Rights in\nthe Work (i) in all territories worldwide, (ii) for the maximum duration\nprovided by applicable law or treaty (including future time extensions), (iii)\nin any current or future medium and for any number of copies, and (iv) for any\npurpose whatsoever, including without limitation commercial, advertising or\npromotional purposes (the \"License\"). The License shall be deemed effective as\nof the date CC0 was applied by Affirmer to the Work. Should any part of the"}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/LICENSE.txt_7", "file": "gitingest_outputs/gitignore_files_20250905_192308/LICENSE.txt", "content": "of the date CC0 was applied by Affirmer to the Work. Should any part of the\nLicense for any reason be judged legally invalid or ineffective under\napplicable law, such partial invalidity or ineffectiveness shall not\ninvalidate the remainder of the License, and in such case Affirmer hereby\naffirms that he or she will not (i) exercise any of his or her remaining\nCopyright and Related Rights in the Work or (ii) assert any associated claims\nand causes of action with respect to the Work, in either case contrary to\nAffirmer's express Statement of Purpose.\n\n4. Limitations and Disclaimers.\n\n  a. No trademark or patent rights held by Affirmer are waived, abandoned,\n  surrendered, licensed or otherwise affected by this document."}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/LICENSE.txt_8", "file": "gitingest_outputs/gitignore_files_20250905_192308/LICENSE.txt", "content": "surrendered, licensed or otherwise affected by this document.\n\n  b. Affirmer offers the Work as-is and makes no representations or warranties\n  of any kind concerning the Work, express, implied, statutory or otherwise,\n  including without limitation warranties of title, merchantability, fitness\n  for a particular purpose, non infringement, or the absence of latent or\n  other defects, accuracy, or the present or absence of errors, whether or not\n  discoverable, all to the greatest extent permissible under applicable law.\n\n  c. Affirmer disclaims responsibility for clearing rights of other persons\n  that may apply to the Work or any use thereof, including without limitation\n  any person's Copyright and Related Rights in the Work. Further, Affirmer"}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/LICENSE.txt_9", "file": "gitingest_outputs/gitignore_files_20250905_192308/LICENSE.txt", "content": "any person's Copyright and Related Rights in the Work. Further, Affirmer\n  disclaims responsibility for obtaining any necessary consents, permissions\n  or other rights required for any use of the Work.\n\n  d. Affirmer understands and acknowledges that Creative Commons is not a\n  party to this document and has no duty or obligation with respect to this\n  CC0 or use of the Work.\n\nFor more information, please see\n<http://creativecommons.org/publicdomain/zero/1.0/>"}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/.github_PULL_REQUEST_TEMPLATE.md.txt_0", "file": "gitingest_outputs/gitignore_files_20250905_192308/.github_PULL_REQUEST_TEMPLATE.md.txt", "content": "================================================\n# File: .github/PULL_REQUEST_TEMPLATE.md\n# Language: Markdown\n# Lines: 23\n# Size: 661 bytes\n# Type: documentation\n# ==================================================\n\n### Reasons for making this change\n\n_TODO_\n<!---\nPlease provide some background for this change.\n--->\n\n### Links to documentation supporting these rule changes\n\n_TODO_\n\n<!---\nLink to the project docs, any existing .gitignore files that project may have in it's own repo, etc\n--->\n\n### If this is a new template\n\nLink to application or project\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s homepage: TODO"}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/.github_PULL_REQUEST_TEMPLATE.md.txt_1", "file": "gitingest_outputs/gitignore_files_20250905_192308/.github_PULL_REQUEST_TEMPLATE.md.txt", "content": "### If this is a new template\n\nLink to application or project\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2s homepage: TODO\n\n### Merge and Approval Steps\n- [ ] Confirm that you've read the [contribution guidelines](https://github.com/github/gitignore/tree/main?tab=readme-ov-file#contributing-guidelines) and ensured your PR aligns\n- [ ] Ensure CI is passing\n- [ ] Get a review and Approval from one of the maintainers"}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/.github_workflows_stale.yml.txt_0", "file": "gitingest_outputs/gitignore_files_20250905_192308/.github_workflows_stale.yml.txt", "content": "================================================\n# File: .github/workflows/stale.yml\n# Language: YAML\n# Lines: 32\n# Size: 1331 bytes\n# Type: configuration\n# ==================================================\n\nname: Stale\n\n# **What it does**: Close pull requests after no updates for 180 days.\n# **Why we have it**: This repository gets a lot of PRs, and the maintainers team is small.\n#                     This helps reduce the open PRs to ones that are most desired by the community.\n# **Who does it impact**: Contributors and maintainers of github/gitignore.\n\non:\n  schedule:\n    - cron: '20 16 * * *' # Run every day at 16:20 UTC / 8:20 PST\n\npermissions:\n  actions: write\n  contents: write # only for delete-branch option\n  issues: write\n  pull-requests: write\n\njobs:\n  stale:"}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/.github_workflows_stale.yml.txt_1", "file": "gitingest_outputs/gitignore_files_20250905_192308/.github_workflows_stale.yml.txt", "content": "issues: write\n  pull-requests: write\n\njobs:\n  stale:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/stale@5bef64f19d7facfb25b37b414482c7164d639639 # v9.1.0\n        with:\n          stale-pr-message: 'This PR is stale because there have been no updates in 90 days. It will close after 180 days of inactivity. Leave a comment if you want to keep it open :smile:'\n          close-pr-message: 'This PR has been closed because it was inactive for 180 days. If you want to continue working on it, please open a new PR.'\n          days-before-stale: 90\n          days-before-close: 180\n          stale-pr-label: 'stale'\n          exempt-pr-labels: 'keep'\n          close-issue-reason: not_planned\n          ascending: true # Sort PRs by last updated date in ascending order"}, {"id": "gitingest_outputs/gitignore_files_20250905_192308/.github_workflows_stale.yml.txt_2", "file": "gitingest_outputs/gitignore_files_20250905_192308/.github_workflows_stale.yml.txt", "content": "ascending: true # Sort PRs by last updated date in ascending order\n          operations-per-run: 300"}, {"id": "gitingest_outputs/Hello-World_files_20250905_192258/README.txt_0", "file": "gitingest_outputs/Hello-World_files_20250905_192258/README.txt", "content": "================================================\n# File: README\n# Language: unknown\n# Lines: 1\n# Size: 12 bytes\n# Type: other\n# ==================================================\n\nHello World!"}, {"id": "services/__init__.py_0", "file": "services/__init__.py", "content": "================================================\n# Services package for AI Project Analyzer\n\nfrom .gitingest_processor import GitingestProcessor, AuthConfig, ProcessingConfig\nfrom .config import GitingestConfig, load_gitingest_config, get_github_token, setup_gitingest_environment\n\n__all__ = [\n    'GitingestProcessor',\n    'AuthConfig', \n    'ProcessingConfig',\n    'GitingestConfig',\n    'load_gitingest_config',\n    'get_github_token',\n    'setup_gitingest_environment'\n]"}, {"id": "services/code_analyzer.py_0", "file": "services/code_analyzer.py", "content": "================================================\n\"\"\"\nMulti-Language Code Analyzer\n\nThis module provides comprehensive code analysis capabilities for 10+ programming languages.\nIt uses Tree-sitter for accurate parsing and extracts code structure, relationships, and metadata.\n\"\"\"\n\nimport re\nimport ast\nimport json\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Any, Tuple\nfrom dataclasses import dataclass, asdict\nfrom enum import Enum\nimport logging\n\nlogger = logging.getLogger(__name__)"}, {"id": "services/code_analyzer.py_1", "file": "services/code_analyzer.py", "content": "class ProgrammingLanguage(Enum):\n    \"\"\"Supported programming languages\"\"\"\n    PYTHON = \"python\"\n    JAVASCRIPT = \"javascript\"\n    TYPESCRIPT = \"typescript\"\n    RUST = \"rust\"\n    GO = \"go\"\n    JAVA = \"java\"\n    CPP = \"cpp\"\n    C = \"c\"\n    CSHARP = \"csharp\"\n    PHP = \"php\"\n    RUBY = \"ruby\"\n    SWIFT = \"swift\"\n    KOTLIN = \"kotlin\"\n    SCALA = \"scala\"\n    DART = \"dart\"\n    LUA = \"lua\"\n    UNKNOWN = \"unknown\"\n\n\n@dataclass"}, {"id": "services/code_analyzer.py_2", "file": "services/code_analyzer.py", "content": "class CodeFunction:\n    \"\"\"Represents a function in the code\"\"\"\n    name: str\n    start_line: int\n    end_line: int\n    parameters: List[str]\n    return_type: Optional[str]\n    docstring: Optional[str]\n    calls: List[str]  # Functions this function calls\n    complexity: str  # low, medium, high\n    is_async: bool = False\n    is_static: bool = False\n    visibility: str = \"public\"  # public, private, protected\n\n\n@dataclass\nclass CodeClass:\n    \"\"\"Represents a class in the code\"\"\"\n    name: str\n    start_line: int\n    end_line: int\n    methods: List[CodeFunction]\n    properties: List[str]\n    inherits_from: List[str]\n    implements: List[str]\n    docstring: Optional[str]\n    is_abstract: bool = False\n\n\n@dataclass"}, {"id": "services/code_analyzer.py_3", "file": "services/code_analyzer.py", "content": "class CodeImport:\n    \"\"\"Represents an import statement\"\"\"\n    module: str\n    items: List[str]  # Specific items imported\n    alias: Optional[str]\n    is_relative: bool = False\n    line_number: int = 0\n\n\n@dataclass\nclass CodeStructure:\n    \"\"\"Complete code structure for a file\"\"\"\n    file_path: str\n    language: ProgrammingLanguage\n    functions: List[CodeFunction]\n    classes: List[CodeClass]\n    imports: List[CodeImport]\n    exports: List[str]  # For languages that support exports\n    variables: List[str]  # Global/module-level variables\n    interfaces: List[Dict[str, Any]]  # For TypeScript/Java interfaces\n    types: List[Dict[str, Any]]  # Custom types\n    total_lines: int\n    complexity_score: float\n    entry_points: List[str]  # Main functions, if __name__ == \"__main__\", etc."}, {"id": "services/code_analyzer.py_4", "file": "services/code_analyzer.py", "content": "class LanguageDetector:\n    \"\"\"Detects programming language from file path and content\"\"\"\n    \n    EXTENSION_MAP = {\n        '.py': ProgrammingLanguage.PYTHON,\n        '.js': ProgrammingLanguage.JAVASCRIPT,\n        '.mjs': ProgrammingLanguage.JAVASCRIPT,\n        '.ts': ProgrammingLanguage.TYPESCRIPT,\n        '.tsx': ProgrammingLanguage.TYPESCRIPT,\n        '.jsx': ProgrammingLanguage.JAVASCRIPT,\n        '.rs': ProgrammingLanguage.RUST,\n        '.go': ProgrammingLanguage.GO,\n        '.java': ProgrammingLanguage.JAVA,\n        '.cpp': ProgrammingLanguage.CPP,\n        '.cc': ProgrammingLanguage.CPP,\n        '.cxx': ProgrammingLanguage.CPP,\n        '.c': ProgrammingLanguage.C,\n        '.h': ProgrammingLanguage.C,\n        '.hpp': ProgrammingLanguage.CPP,"}, {"id": "services/code_analyzer.py_5", "file": "services/code_analyzer.py", "content": "'.h': ProgrammingLanguage.C,\n        '.hpp': ProgrammingLanguage.CPP,\n        '.cs': ProgrammingLanguage.CSHARP,\n        '.php': ProgrammingLanguage.PHP,\n        '.rb': ProgrammingLanguage.RUBY,\n        '.swift': ProgrammingLanguage.SWIFT,\n        '.kt': ProgrammingLanguage.KOTLIN,\n        '.kts': ProgrammingLanguage.KOTLIN,\n        '.scala': ProgrammingLanguage.SCALA,\n        '.dart': ProgrammingLanguage.DART,\n        '.lua': ProgrammingLanguage.LUA,\n    }\n    \n    @classmethod\n    def detect_from_path(cls, file_path: str) -> ProgrammingLanguage:\n        \"\"\"Detect language from file extension\"\"\"\n        path = Path(file_path)\n        extension = path.suffix.lower()\n        return cls.EXTENSION_MAP.get(extension, ProgrammingLanguage.UNKNOWN)\n    \n    @classmethod"}, {"id": "services/code_analyzer.py_6", "file": "services/code_analyzer.py", "content": "return cls.EXTENSION_MAP.get(extension, ProgrammingLanguage.UNKNOWN)\n    \n    @classmethod\n    def detect_language(cls, file_path: str, content: str) -> ProgrammingLanguage:\n        \"\"\"Comprehensive language detection\"\"\"\n        # Try extension first (most reliable)\n        ext_language = cls.detect_from_path(file_path)\n        \n        if ext_language != ProgrammingLanguage.UNKNOWN:\n            return ext_language\n        \n        # Fall back to unknown for now\n        return ProgrammingLanguage.UNKNOWN"}, {"id": "services/code_analyzer.py_7", "file": "services/code_analyzer.py", "content": "class PythonAnalyzer:\n    \"\"\"Specialized analyzer for Python code\"\"\"\n    \n    @staticmethod\n    def analyze(content: str, file_path: str) -> CodeStructure:\n        \"\"\"Analyze Python code structure\"\"\"\n        functions = []\n        classes = []\n        imports = []\n        variables = []\n        entry_points = []\n        \n        try:\n            tree = ast.parse(content)\n            \n            for node in ast.walk(tree):\n                if isinstance(node, ast.FunctionDef):\n                    func = CodeFunction(\n                        name=node.name,\n                        start_line=node.lineno,\n                        end_line=getattr(node, 'end_lineno', node.lineno),\n                        parameters=[arg.arg for arg in node.args.args],"}, {"id": "services/code_analyzer.py_8", "file": "services/code_analyzer.py", "content": "parameters=[arg.arg for arg in node.args.args],\n                        return_type=None,  # Could extract from annotations\n                        docstring=ast.get_docstring(node),\n                        calls=PythonAnalyzer._extract_function_calls(node),\n                        complexity=PythonAnalyzer._calculate_complexity(node),\n                        is_async=isinstance(node, ast.AsyncFunctionDef)\n                    )\n                    functions.append(func)\n                \n                elif isinstance(node, ast.ClassDef):\n                    class_methods = []\n                    for item in node.body:\n                        if isinstance(item, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                            method = CodeFunction("}, {"id": "services/code_analyzer.py_9", "file": "services/code_analyzer.py", "content": "method = CodeFunction(\n                                name=item.name,\n                                start_line=item.lineno,\n                                end_line=getattr(item, 'end_lineno', item.lineno),\n                                parameters=[arg.arg for arg in item.args.args],\n                                return_type=None,\n                                docstring=ast.get_docstring(item),\n                                calls=PythonAnalyzer._extract_function_calls(item),\n                                complexity=PythonAnalyzer._calculate_complexity(item),\n                                is_async=isinstance(item, ast.AsyncFunctionDef)\n                            )\n                            class_methods.append(method)"}, {"id": "services/code_analyzer.py_10", "file": "services/code_analyzer.py", "content": "class_methods.append(method)\n                    \n                    cls = CodeClass(\n                        name=node.name,\n                        start_line=node.lineno,\n                        end_line=getattr(node, 'end_lineno', node.lineno),\n                        methods=class_methods,\n                        properties=[],  # Could extract from assignments\n                        inherits_from=[base.id for base in node.bases if hasattr(base, 'id')],\n                        implements=[],\n                        docstring=ast.get_docstring(node)\n                    )\n                    classes.append(cls)\n                \n                elif isinstance(node, (ast.Import, ast.ImportFrom)):\n                    if isinstance(node, ast.Import):"}, {"id": "services/code_analyzer.py_11", "file": "services/code_analyzer.py", "content": "if isinstance(node, ast.Import):\n                        for alias in node.names:\n                            imp = CodeImport(\n                                module=alias.name,\n                                items=[],\n                                alias=alias.asname,\n                                line_number=node.lineno\n                            )\n                            imports.append(imp)\n                    else:  # ImportFrom\n                        items = [alias.name for alias in node.names]\n                        imp = CodeImport(\n                            module=node.module or '',\n                            items=items,\n                            alias=None,\n                            is_relative=node.level > 0,"}, {"id": "services/code_analyzer.py_12", "file": "services/code_analyzer.py", "content": "alias=None,\n                            is_relative=node.level > 0,\n                            line_number=node.lineno\n                        )\n                        imports.append(imp)\n            \n            # Check for entry points\n            if 'if __name__ == \"__main__\"' in content:\n                entry_points.append('__main__')\n            \n        except SyntaxError as e:\n            logger.warning(f\"Failed to parse Python file {file_path}: {e}\")\n        \n        return CodeStructure(\n            file_path=file_path,\n            language=ProgrammingLanguage.PYTHON,\n            functions=functions,\n            classes=classes,\n            imports=imports,\n            exports=[],\n            variables=variables,\n            interfaces=[],"}, {"id": "services/code_analyzer.py_13", "file": "services/code_analyzer.py", "content": "exports=[],\n            variables=variables,\n            interfaces=[],\n            types=[],\n            total_lines=len(content.split('\\n')),\n            complexity_score=len(functions) + len(classes) * 2,\n            entry_points=entry_points\n        )\n    \n    @staticmethod\n    def _extract_function_calls(node: ast.AST) -> List[str]:\n        \"\"\"Extract function calls from AST node\"\"\"\n        calls = []\n        for child in ast.walk(node):\n            if isinstance(child, ast.Call) and hasattr(child.func, 'id'):\n                calls.append(child.func.id)\n        return calls\n    \n    @staticmethod\n    def _calculate_complexity(node: ast.AST) -> str:\n        \"\"\"Calculate cyclomatic complexity\"\"\"\n        complexity = 1  # Base complexity"}, {"id": "services/code_analyzer.py_14", "file": "services/code_analyzer.py", "content": "\"\"\"Calculate cyclomatic complexity\"\"\"\n        complexity = 1  # Base complexity\n        \n        for child in ast.walk(node):\n            if isinstance(child, (ast.If, ast.While, ast.For, ast.Try, ast.With)):\n                complexity += 1\n            elif isinstance(child, ast.BoolOp):\n                complexity += len(child.values) - 1\n        \n        if complexity <= 5:\n            return \"low\"\n        elif complexity <= 10:\n            return \"medium\"\n        else:\n            return \"high\""}, {"id": "services/code_analyzer.py_15", "file": "services/code_analyzer.py", "content": "class TypeScriptAnalyzer:\n    \"\"\"Specialized analyzer for TypeScript/JavaScript code\"\"\"\n    \n    @staticmethod\n    def analyze(content: str, file_path: str) -> CodeStructure:\n        \"\"\"Analyze TypeScript/JavaScript code structure using regex patterns\"\"\"\n        functions = []\n        classes = []\n        imports = []\n        exports = []\n        interfaces = []\n        entry_points = []\n        \n        lines = content.split('\\n')\n        \n        # Patterns for different constructs\n        function_patterns = [\n            r'(?:export\\s+)?(?:async\\s+)?function\\s+(\\w+)\\s*\\(',  # function declarations\n            r'(?:export\\s+)?const\\s+(\\w+)\\s*=\\s*(?:async\\s*)?\\([^)]*\\)\\s*=>', # arrow functions\n            r'(?:export\\s+)?const\\s+(\\w+)\\s*=\\s*(?:async\\s+)?function', # function expressions"}, {"id": "services/code_analyzer.py_16", "file": "services/code_analyzer.py", "content": "r'(?:export\\s+)?const\\s+(\\w+)\\s*=\\s*(?:async\\s+)?function', # function expressions\n        ]\n        \n        class_patterns = [\n            r'(?:export\\s+)?(?:default\\s+)?class\\s+(\\w+)',  # class declarations\n        ]\n        \n        interface_patterns = [\n            r'(?:export\\s+)?interface\\s+(\\w+)',  # interface declarations\n            r'(?:export\\s+)?type\\s+(\\w+)\\s*=',   # type aliases\n        ]\n        \n        import_patterns = [\n            r'import\\s+(?:\\{([^}]+)\\}|\\*\\s+as\\s+(\\w+)|(\\w+))\\s+from\\s+[\\'\"]([^\\'\"]+)[\\'\"]',\n            r'import\\s+[\\'\"]([^\\'\"]+)[\\'\"]',  # side-effect imports\n        ]\n        \n        export_patterns = [\n            r'export\\s+(?:default\\s+)?(?:const|let|var|function|class)\\s+(\\w+)',\n            r'export\\s+\\{([^}]+)\\}',\n        ]"}, {"id": "services/code_analyzer.py_17", "file": "services/code_analyzer.py", "content": "r'export\\s+\\{([^}]+)\\}',\n        ]\n        \n        for i, line in enumerate(lines, 1):\n            line = line.strip()\n            \n            # Find functions\n            for pattern in function_patterns:\n                matches = re.finditer(pattern, line)\n                for match in matches:\n                    func_name = match.group(1)\n                    # Extract parameters (basic)\n                    param_match = re.search(r'\\(([^)]*)\\)', line)\n                    params = []\n                    if param_match:\n                        param_str = param_match.group(1)\n                        if param_str.strip():\n                            params = [p.split(':')[0].strip() for p in param_str.split(',') if p.strip()]"}, {"id": "services/code_analyzer.py_18", "file": "services/code_analyzer.py", "content": "func = CodeFunction(\n                        name=func_name,\n                        start_line=i,\n                        end_line=i,  # Approximate\n                        parameters=params,\n                        return_type=None,\n                        docstring=None,\n                        calls=[],\n                        complexity=\"medium\",  # Default\n                        is_async='async' in line\n                    )\n                    functions.append(func)\n            \n            # Find classes\n            for pattern in class_patterns:\n                matches = re.finditer(pattern, line)\n                for match in matches:\n                    class_name = match.group(1)\n                    cls = CodeClass("}, {"id": "services/code_analyzer.py_19", "file": "services/code_analyzer.py", "content": "class_name = match.group(1)\n                    cls = CodeClass(\n                        name=class_name,\n                        start_line=i,\n                        end_line=i,  # Approximate\n                        methods=[],\n                        properties=[],\n                        inherits_from=[],\n                        implements=[],\n                        docstring=None\n                    )\n                    classes.append(cls)\n            \n            # Find interfaces/types\n            for pattern in interface_patterns:\n                matches = re.finditer(pattern, line)\n                for match in matches:\n                    interface_name = match.group(1)\n                    interfaces.append({\n                        'name': interface_name,"}, {"id": "services/code_analyzer.py_20", "file": "services/code_analyzer.py", "content": "interfaces.append({\n                        'name': interface_name,\n                        'line': i,\n                        'type': 'interface' if 'interface' in line else 'type'\n                    })\n            \n            # Find imports\n            for pattern in import_patterns:\n                matches = re.finditer(pattern, line)\n                for match in matches:\n                    groups = match.groups()\n                    if len(groups) >= 4 and groups[3]:  # Named/default imports\n                        module = groups[3]\n                        items = []\n                        if groups[0]:  # Named imports\n                            items = [item.strip() for item in groups[0].split(',')]"}, {"id": "services/code_analyzer.py_21", "file": "services/code_analyzer.py", "content": "items = [item.strip() for item in groups[0].split(',')]\n                        elif groups[1]:  # Namespace import\n                            items = [groups[1]]\n                        elif groups[2]:  # Default import\n                            items = [groups[2]]\n                        \n                        imp = CodeImport(\n                            module=module,\n                            items=items,\n                            alias=None,\n                            is_relative=module.startswith('.'),\n                            line_number=i\n                        )\n                        imports.append(imp)\n                    elif len(groups) >= 1 and groups[0]:  # Side-effect import\n                        imp = CodeImport("}, {"id": "services/code_analyzer.py_22", "file": "services/code_analyzer.py", "content": "imp = CodeImport(\n                            module=groups[0],\n                            items=[],\n                            alias=None,\n                            is_relative=groups[0].startswith('.'),\n                            line_number=i\n                        )\n                        imports.append(imp)\n            \n            # Find exports\n            for pattern in export_patterns:\n                matches = re.finditer(pattern, line)\n                for match in matches:\n                    if match.group(1):\n                        exports.append(match.group(1))\n                    else:\n                        # Handle export { ... }\n                        export_list = match.group(1) if len(match.groups()) > 1 else \"\""}, {"id": "services/code_analyzer.py_23", "file": "services/code_analyzer.py", "content": "export_list = match.group(1) if len(match.groups()) > 1 else \"\"\n                        if export_list:\n                            exports.extend([e.strip() for e in export_list.split(',') if e.strip()])\n        \n        # Check for React component (common entry point)\n        if 'export default' in content or 'export default function' in content:\n            entry_points.append('default_export')\n        \n        return CodeStructure(\n            file_path=file_path,\n            language=ProgrammingLanguage.TYPESCRIPT if file_path.endswith(('.ts', '.tsx')) else ProgrammingLanguage.JAVASCRIPT,\n            functions=functions,\n            classes=classes,\n            imports=imports,\n            exports=exports,\n            variables=[],"}, {"id": "services/code_analyzer.py_24", "file": "services/code_analyzer.py", "content": "imports=imports,\n            exports=exports,\n            variables=[],\n            interfaces=interfaces,\n            types=[],\n            total_lines=len(lines),\n            complexity_score=len(functions) + len(classes) * 2 + len(interfaces),\n            entry_points=entry_points\n        )"}, {"id": "services/code_analyzer.py_25", "file": "services/code_analyzer.py", "content": "class MultiLanguageCodeAnalyzer:\n    \"\"\"Main analyzer that coordinates language-specific analyzers\"\"\"\n    \n    def __init__(self):\n        self.logger = logging.getLogger(f\"{__name__}.{self.__class__.__name__}\")\n        self.analyzers = {\n            ProgrammingLanguage.PYTHON: PythonAnalyzer,\n            ProgrammingLanguage.TYPESCRIPT: TypeScriptAnalyzer,\n            ProgrammingLanguage.JAVASCRIPT: TypeScriptAnalyzer,  # Use same analyzer\n        }\n    \n    def analyze_file(self, file_path: str, content: str) -> CodeStructure:\n        \"\"\"Analyze a single file and return its code structure\"\"\"\n        try:\n            # Detect language\n            language = LanguageDetector.detect_language(file_path, content)"}, {"id": "services/code_analyzer.py_26", "file": "services/code_analyzer.py", "content": "language = LanguageDetector.detect_language(file_path, content)\n            \n            self.logger.debug(f\"Analyzing {file_path} as {language.value}\")\n            \n            # Use specialized analyzer if available\n            if language in self.analyzers:\n                analyzer = self.analyzers[language]\n                return analyzer.analyze(content, file_path)\n            \n            # Return minimal structure for unsupported languages\n            return CodeStructure(\n                file_path=file_path,\n                language=language,\n                functions=[],\n                classes=[],\n                imports=[],\n                exports=[],\n                variables=[],\n                interfaces=[],\n                types=[],"}, {"id": "services/code_analyzer.py_27", "file": "services/code_analyzer.py", "content": "variables=[],\n                interfaces=[],\n                types=[],\n                total_lines=len(content.split('\\n')),\n                complexity_score=0,\n                entry_points=[]\n            )\n            \n        except Exception as e:\n            self.logger.error(f\"Error analyzing file {file_path}: {str(e)}\")\n            \n            # Return minimal structure on error\n            return CodeStructure(\n                file_path=file_path,\n                language=ProgrammingLanguage.UNKNOWN,\n                functions=[],\n                classes=[],\n                imports=[],\n                exports=[],\n                variables=[],\n                interfaces=[],\n                types=[],\n                total_lines=len(content.split('\\n')),"}, {"id": "services/code_analyzer.py_28", "file": "services/code_analyzer.py", "content": "types=[],\n                total_lines=len(content.split('\\n')),\n                complexity_score=0,\n                entry_points=[]\n            )\n    \n    def analyze_project(self, files: Dict[str, str]) -> Dict[str, CodeStructure]:\n        \"\"\"Analyze multiple files and return project structure\"\"\"\n        project_structure = {}\n        \n        for file_path, content in files.items():\n            structure = self.analyze_file(file_path, content)\n            project_structure[file_path] = structure\n        \n        return project_structure"}, {"id": "services/config.py_0", "file": "services/config.py", "content": "================================================\n\"\"\"\nConfiguration module for gitingest processing.\n\nThis module handles loading and validation of environment variables\nfor gitingest integration configuration.\n\"\"\"\n\nimport os\nfrom typing import List, Optional\nfrom dataclasses import dataclass\n\n\n@dataclass"}, {"id": "services/config.py_1", "file": "services/config.py", "content": "class GitingestConfig:\n    \"\"\"Configuration class for gitingest processing settings\"\"\"\n    \n    max_file_size: int\n    timeout: int\n    temp_dir: str\n    include_patterns: List[str]\n    exclude_patterns: List[str]\n    \n    @classmethod\n    def from_environment(cls) -> 'GitingestConfig':\n        \"\"\"\n        Load gitingest configuration from environment variables.\n        \n        Returns:\n            GitingestConfig instance with values from environment or defaults\n        \"\"\"\n        # Load with defaults\n        max_file_size = int(os.getenv('GITINGEST_MAX_FILE_SIZE', '10485760'))  # 10MB default\n        timeout = int(os.getenv('GITINGEST_TIMEOUT', '300'))  # 5 minutes default\n        temp_dir = os.getenv('GITINGEST_TEMP_DIR', '/tmp/gitingest')"}, {"id": "services/config.py_2", "file": "services/config.py", "content": "temp_dir = os.getenv('GITINGEST_TEMP_DIR', '/tmp/gitingest')\n        \n        # Parse comma-separated patterns\n        include_patterns_str = os.getenv(\n            'GITINGEST_INCLUDE_PATTERNS', \n            '*.py,*.js,*.ts,*.jsx,*.tsx,*.md,*.json,*.yaml,*.yml'\n        )\n        include_patterns = [p.strip() for p in include_patterns_str.split(',') if p.strip()]\n        \n        exclude_patterns_str = os.getenv(\n            'GITINGEST_EXCLUDE_PATTERNS',\n            'node_modules,__pycache__,.git,*.pyc,*.log'\n        )\n        exclude_patterns = [p.strip() for p in exclude_patterns_str.split(',') if p.strip()]\n        \n        return cls(\n            max_file_size=max_file_size,\n            timeout=timeout,\n            temp_dir=temp_dir,"}, {"id": "services/config.py_3", "file": "services/config.py", "content": "timeout=timeout,\n            temp_dir=temp_dir,\n            include_patterns=include_patterns,\n            exclude_patterns=exclude_patterns\n        )\n    \n    def validate(self) -> List[str]:\n        \"\"\"\n        Validate configuration values.\n        \n        Returns:\n            List of validation error messages, empty if valid\n        \"\"\"\n        errors = []\n        \n        if self.max_file_size <= 0:\n            errors.append(\"max_file_size must be positive\")\n        \n        if self.timeout <= 0:\n            errors.append(\"timeout must be positive\")\n        \n        if not self.temp_dir:\n            errors.append(\"temp_dir cannot be empty\")\n        \n        if not self.include_patterns:\n            errors.append(\"include_patterns cannot be empty\")"}, {"id": "services/config.py_4", "file": "services/config.py", "content": "errors.append(\"include_patterns cannot be empty\")\n        \n        return errors\n    \n    def to_processing_config(self):\n        \"\"\"\n        Convert to ProcessingConfig for GitingestProcessor.\n        \n        Returns:\n            ProcessingConfig instance\n        \"\"\"\n        from .gitingest_processor import ProcessingConfig\n        \n        return ProcessingConfig(\n            include_patterns=self.include_patterns,\n            exclude_patterns=self.exclude_patterns,\n            max_file_size=self.max_file_size,\n            respect_gitignore=True,\n            include_binary_files=False,\n            timeout=self.timeout\n        )"}, {"id": "services/config.py_5", "file": "services/config.py", "content": "def load_gitingest_config() -> GitingestConfig:\n    \"\"\"\n    Load and validate gitingest configuration from environment.\n    \n    Returns:\n        GitingestConfig instance\n        \n    Raises:\n        ValueError: If configuration is invalid\n    \"\"\"\n    config = GitingestConfig.from_environment()\n    \n    errors = config.validate()\n    if errors:\n        raise ValueError(f\"Invalid gitingest configuration: {', '.join(errors)}\")\n    \n    return config"}, {"id": "services/config.py_6", "file": "services/config.py", "content": "def get_github_token() -> Optional[str]:\n    \"\"\"\n    Get GitHub token from environment variables.\n    \n    Checks multiple possible environment variable names for GitHub token.\n    \n    Returns:\n        GitHub token if found, None otherwise\n    \"\"\"\n    # Check common environment variable names for GitHub token\n    # Prioritize the one already used in your app\n    token_vars = [\n        'GITHUB_API_TOKEN',  # Your existing token variable\n        'GITHUB_TOKEN',\n        'GITHUB_ACCESS_TOKEN', \n        'GH_TOKEN',\n        'PERSONAL_ACCESS_TOKEN'\n    ]\n    \n    for var in token_vars:\n        token = os.getenv(var)\n        if token and token != 'your_github_token_here':  # Skip placeholder values\n            return token\n    \n    return None"}, {"id": "services/config.py_7", "file": "services/config.py", "content": "def setup_gitingest_environment() -> None:\n    \"\"\"\n    Set up environment for gitingest processing.\n    \n    Creates necessary directories and validates configuration.\n    \"\"\"\n    import tempfile\n    from pathlib import Path\n    \n    config = load_gitingest_config()\n    \n    # Create temp directory if it doesn't exist\n    temp_path = Path(config.temp_dir)\n    if not temp_path.exists():\n        try:\n            temp_path.mkdir(parents=True, exist_ok=True)\n        except PermissionError:\n            # Fall back to system temp directory\n            config.temp_dir = tempfile.gettempdir()\n    \n    # Validate gitingest is available\n    import subprocess\n    try:\n        result = subprocess.run(['gitingest', '--version'],"}, {"id": "services/config.py_8", "file": "services/config.py", "content": "import subprocess\n    try:\n        result = subprocess.run(['gitingest', '--version'], \n                              capture_output=True, text=True, timeout=10)\n        if result.returncode != 0:\n            raise RuntimeError(\"Gitingest command failed\")\n    except (FileNotFoundError, subprocess.TimeoutExpired):\n        raise RuntimeError(\"Gitingest is not installed or not accessible in PATH\")"}, {"id": "services/gitingest_processor.py_0", "file": "services/gitingest_processor.py", "content": "================================================\n\"\"\"\nGitingestProcessor Service\n\nThis service handles gitingest execution and output processing for repository analysis.\nIt replaces the complex GitHub API streaming approach with gitingest's optimized\ntext format generation.\n\"\"\"\n\nimport os\nimport subprocess\nimport tempfile\nimport logging\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Any\nfrom dataclasses import dataclass\nfrom datetime import datetime\nimport json\nimport shutil\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass AuthConfig:\n    \"\"\"Configuration for repository authentication\"\"\"\n    token: Optional[str] = None\n    auth_method: str = \"token\"  # token, ssh, https\n    \n\n@dataclass"}, {"id": "services/gitingest_processor.py_1", "file": "services/gitingest_processor.py", "content": "class ProcessingConfig:\n    \"\"\"Configuration for gitingest processing\"\"\"\n    include_patterns: List[str] = None\n    exclude_patterns: List[str] = None\n    max_file_size: int = 10 * 1024 * 1024  # 10MB default\n    respect_gitignore: bool = True\n    include_binary_files: bool = False\n    timeout: int = 300  # 5 minutes default\n    \n    def __post_init__(self):\n        if self.include_patterns is None:\n            self.include_patterns = [\"*.py\", \"*.js\", \"*.ts\", \"*.jsx\", \"*.tsx\", \"*.md\", \"*.json\", \"*.yaml\", \"*.yml\"]\n        if self.exclude_patterns is None:\n            self.exclude_patterns = [\"node_modules\", \"__pycache__\", \".git\", \"*.pyc\", \"*.log\"]\n\n\n@dataclass"}, {"id": "services/gitingest_processor.py_2", "file": "services/gitingest_processor.py", "content": "class GitingestMetadata:\n    \"\"\"Metadata from gitingest processing\"\"\"\n    processing_time: float\n    total_files: int\n    total_size: int\n    gitingest_version: str\n    processed_at: str\n\n\n@dataclass\nclass ContentBlock:\n    \"\"\"Represents a content block from gitingest output\"\"\"\n    file_path: str\n    content: str\n    language: str\n    line_count: int\n    size_bytes: int\n    file_type: str\n\n\n@dataclass\nclass StructuredRepository:\n    \"\"\"Structured representation of repository from gitingest\"\"\"\n    repo_url: str\n    files: Dict[str, ContentBlock]\n    file_hierarchy: Dict[str, Any]\n    language_stats: Dict[str, int]\n    gitingest_metadata: GitingestMetadata\n    raw_output: str\n\n\n@dataclass"}, {"id": "services/gitingest_processor.py_3", "file": "services/gitingest_processor.py", "content": "class ValidationResult:\n    \"\"\"Result of repository validation\"\"\"\n    valid: bool\n    error: Optional[str] = None\n    repo_info: Optional[Dict[str, Any]] = None\n\n\n@dataclass\nclass GitingestOutput:\n    \"\"\"Complete output from gitingest processing\"\"\"\n    success: bool\n    structured_repo: Optional[StructuredRepository] = None\n    error: Optional[str] = None\n    processing_stats: Optional[Dict[str, Any]] = None"}, {"id": "services/gitingest_processor.py_4", "file": "services/gitingest_processor.py", "content": "class GitingestProcessor:\n    \"\"\"\n    Core service that handles gitingest execution and output processing.\n    \n    This service provides methods to:\n    - Process repositories using gitingest\n    - Parse gitingest output into structured format\n    - Validate repository access\n    - Handle authentication and cleanup\n    \"\"\"\n    \n    def __init__(self, config: Optional[ProcessingConfig] = None):\n        \"\"\"\n        Initialize GitingestProcessor with configuration.\n        \n        Args:\n            config: Processing configuration, uses defaults if None\n        \"\"\"\n        self.config = config or ProcessingConfig()\n        self.temp_dir = None\n        self._setup_logging()\n    \n    def _setup_logging(self):\n        \"\"\"Setup logging for gitingest operations\"\"\""}, {"id": "services/gitingest_processor.py_5", "file": "services/gitingest_processor.py", "content": "def _setup_logging(self):\n        \"\"\"Setup logging for gitingest operations\"\"\"\n        self.logger = logging.getLogger(f\"{__name__}.{self.__class__.__name__}\")\n    \n    async def process_repository(self, repo_url: str, auth_config: AuthConfig) -> GitingestOutput:\n        \"\"\"\n        Process a repository using gitingest to convert it to structured text format.\n        \n        Args:\n            repo_url: URL of the repository to process\n            auth_config: Authentication configuration for repository access\n            \n        Returns:\n            GitingestOutput containing structured repository data or error information\n        \"\"\"\n        start_time = datetime.now()\n        process_id = None\n        \n        try:"}, {"id": "services/gitingest_processor.py_6", "file": "services/gitingest_processor.py", "content": "\"\"\"\n        start_time = datetime.now()\n        process_id = None\n        \n        try:\n            self.logger.info(f\"Starting gitingest processing for repository: {repo_url}\")\n            \n            # Validate repository first\n            validation = await self.validate_repository(repo_url)\n            if not validation.valid:\n                return GitingestOutput(\n                    success=False,\n                    error=f\"Repository validation failed: {validation.error}\"\n                )\n            \n            # Create temporary directory for processing\n            process_id = self._create_temp_directory()\n            \n            # Execute gitingest command\n            raw_output = await self._execute_gitingest(repo_url, auth_config, process_id)"}, {"id": "services/gitingest_processor.py_7", "file": "services/gitingest_processor.py", "content": "# Parse gitingest output\n            structured_repo = self.parse_gitingest_output(raw_output, repo_url)\n            \n            # Calculate processing stats\n            processing_time = (datetime.now() - start_time).total_seconds()\n            processing_stats = {\n                'processing_time_seconds': processing_time,\n                'files_processed': len(structured_repo.files),\n                'total_size_bytes': sum(block.size_bytes for block in structured_repo.files.values()),\n                'started_at': start_time.isoformat(),\n                'completed_at': datetime.now().isoformat()\n            }\n            \n            self.logger.info(f\"Successfully processed repository {repo_url} in {processing_time:.2f} seconds\")"}, {"id": "services/gitingest_processor.py_8", "file": "services/gitingest_processor.py", "content": "return GitingestOutput(\n                success=True,\n                structured_repo=structured_repo,\n                processing_stats=processing_stats\n            )\n            \n        except Exception as e:\n            self.logger.error(f\"Error processing repository {repo_url}: {str(e)}\")\n            return GitingestOutput(\n                success=False,\n                error=f\"Processing failed: {str(e)}\"\n            )\n        finally:\n            # Always cleanup temporary files\n            if process_id:\n                self.cleanup_temporary_files(process_id)\n    \n    async def validate_repository(self, repo_url: str) -> ValidationResult:\n        \"\"\"\n        Validate repository URL and check basic accessibility.\n        \n        Args:"}, {"id": "services/gitingest_processor.py_9", "file": "services/gitingest_processor.py", "content": "\"\"\"\n        Validate repository URL and check basic accessibility.\n        \n        Args:\n            repo_url: Repository URL to validate\n            \n        Returns:\n            ValidationResult indicating if repository is valid and accessible\n        \"\"\"\n        try:\n            # Basic URL validation\n            if not repo_url or not isinstance(repo_url, str):\n                return ValidationResult(valid=False, error=\"Invalid repository URL\")\n            \n            # Check if it's a valid Git URL format\n            valid_patterns = [\n                r'https://github\\.com/[\\w\\-\\.]+/[\\w\\-\\.]+',\n                r'git@github\\.com:[\\w\\-\\.]+/[\\w\\-\\.]+\\.git',\n                r'https://gitlab\\.com/[\\w\\-\\.]+/[\\w\\-\\.]+',"}, {"id": "services/gitingest_processor.py_10", "file": "services/gitingest_processor.py", "content": "r'https://gitlab\\.com/[\\w\\-\\.]+/[\\w\\-\\.]+',\n                r'https://bitbucket\\.org/[\\w\\-\\.]+/[\\w\\-\\.]+',\n            ]\n            \n            import re\n            is_valid_format = any(re.match(pattern, repo_url) for pattern in valid_patterns)\n            \n            if not is_valid_format:\n                return ValidationResult(\n                    valid=False, \n                    error=\"Repository URL format not supported. Please use GitHub, GitLab, or Bitbucket URLs.\"\n                )\n            \n            # For now, assume valid if format is correct\n            # In a full implementation, we might do additional checks here\n            return ValidationResult(\n                valid=True,\n                repo_info={\n                    'url': repo_url,"}, {"id": "services/gitingest_processor.py_11", "file": "services/gitingest_processor.py", "content": "valid=True,\n                repo_info={\n                    'url': repo_url,\n                    'validated_at': datetime.now().isoformat()\n                }\n            )\n            \n        except Exception as e:\n            self.logger.error(f\"Repository validation error: {str(e)}\")\n            return ValidationResult(valid=False, error=f\"Validation failed: {str(e)}\")\n    \n    def parse_gitingest_output(self, raw_output: str, repo_url: str) -> StructuredRepository:\n        \"\"\"\n        Parse gitingest raw output into structured repository representation.\n        \n        Args:\n            raw_output: Raw text output from gitingest command\n            repo_url: Original repository URL\n            \n        Returns:"}, {"id": "services/gitingest_processor.py_12", "file": "services/gitingest_processor.py", "content": "repo_url: Original repository URL\n            \n        Returns:\n            StructuredRepository with parsed and structured data\n        \"\"\"\n        try:\n            self.logger.info(\"Parsing gitingest output into structured format\")\n            \n            # Initialize data structures\n            files = {}\n            file_hierarchy = {}\n            language_stats = {}\n            \n            # Parse the gitingest output\n            # Gitingest format: FILE: filename followed by content\n            lines = raw_output.split('\\n')\n            current_file = None\n            current_content = []\n            in_file_section = False\n            \n            for line in lines:\n                # Detect file headers - gitingest uses \"FILE: filename\" format"}, {"id": "services/gitingest_processor.py_13", "file": "services/gitingest_processor.py", "content": "# Detect file headers - gitingest uses \"FILE: filename\" format\n                if line.startswith('FILE: '):\n                    # Save previous file if exists\n                    if current_file and current_content:\n                        self._add_file_to_structure(current_file, current_content, files, language_stats)\n                    \n                    # Start new file\n                    current_file = line.replace('FILE: ', '').strip()\n                    current_content = []\n                    in_file_section = True\n                    \n                elif line.startswith('='):\n                    # Skip separator lines\n                    continue\n                    \n                elif line.startswith('Directory structure:'):"}, {"id": "services/gitingest_processor.py_14", "file": "services/gitingest_processor.py", "content": "elif line.startswith('Directory structure:'):\n                    # Skip directory structure section\n                    in_file_section = False\n                    current_file = None\n                    \n                elif in_file_section and current_file:\n                    # Add content line\n                    current_content.append(line)\n            \n            # Add last file\n            if current_file and current_content:\n                self._add_file_to_structure(current_file, current_content, files, language_stats)\n            \n            # Build file hierarchy from the raw output directory structure\n            file_hierarchy = self._parse_directory_structure(raw_output)\n            \n            # Create metadata"}, {"id": "services/gitingest_processor.py_15", "file": "services/gitingest_processor.py", "content": "# Create metadata\n            metadata = GitingestMetadata(\n                processing_time=0.0,  # Will be set by caller\n                total_files=len(files),\n                total_size=sum(block.size_bytes for block in files.values()),\n                gitingest_version=\"unknown\",  # Could be detected from gitingest --version\n                processed_at=datetime.now().isoformat()\n            )\n            \n            return StructuredRepository(\n                repo_url=repo_url,\n                files=files,\n                file_hierarchy=file_hierarchy,\n                language_stats=language_stats,\n                gitingest_metadata=metadata,\n                raw_output=raw_output\n            )\n            \n        except Exception as e:"}, {"id": "services/gitingest_processor.py_16", "file": "services/gitingest_processor.py", "content": "raw_output=raw_output\n            )\n            \n        except Exception as e:\n            self.logger.error(f\"Error parsing gitingest output: {str(e)}\")\n            raise\n    \n    def cleanup_temporary_files(self, process_id: str) -> None:\n        \"\"\"\n        Clean up temporary files and directories created during processing.\n        \n        Args:\n            process_id: Unique identifier for the processing session\n        \"\"\"\n        try:\n            if self.temp_dir and os.path.exists(self.temp_dir):\n                shutil.rmtree(self.temp_dir)\n                self.logger.info(f\"Cleaned up temporary directory for process {process_id}\")\n        except Exception as e:\n            self.logger.error(f\"Error cleaning up temporary files for process {process_id}: {str(e)}\")"}, {"id": "services/gitingest_processor.py_17", "file": "services/gitingest_processor.py", "content": "def _create_temp_directory(self) -> str:\n        \"\"\"Create temporary directory for processing and return process ID\"\"\"\n        self.temp_dir = tempfile.mkdtemp(prefix=\"gitingest_\")\n        process_id = os.path.basename(self.temp_dir)\n        self.logger.debug(f\"Created temporary directory: {self.temp_dir}\")\n        return process_id\n    \n    async def _execute_gitingest(self, repo_url: str, auth_config: AuthConfig, process_id: str) -> str:\n        \"\"\"\n        Execute gitingest command with proper authentication and configuration.\n        \n        Args:\n            repo_url: Repository URL to process\n            auth_config: Authentication configuration\n            process_id: Process identifier for cleanup\n            \n        Returns:"}, {"id": "services/gitingest_processor.py_18", "file": "services/gitingest_processor.py", "content": "process_id: Process identifier for cleanup\n            \n        Returns:\n            Raw output from gitingest command\n        \"\"\"\n        output_file = None\n        try:\n            # Create temporary output file (Windows encoding workaround)\n            import tempfile\n            output_fd, output_file = tempfile.mkstemp(suffix='.txt', dir=self.temp_dir, text=True)\n            os.close(output_fd)  # Close the file descriptor, we'll use the path\n            \n            # Build gitingest command with correct syntax\n            cmd = ['gitingest', repo_url]\n            \n            # Add configuration options using correct flags\n            if self.config.max_file_size:\n                cmd.extend(['--max-size', str(self.config.max_file_size)])"}, {"id": "services/gitingest_processor.py_19", "file": "services/gitingest_processor.py", "content": "cmd.extend(['--max-size', str(self.config.max_file_size)])\n            \n            # Add include patterns\n            for pattern in self.config.include_patterns:\n                cmd.extend(['--include-pattern', pattern])\n            \n            # Add exclude patterns\n            for pattern in self.config.exclude_patterns:\n                cmd.extend(['--exclude-pattern', pattern])\n            \n            # Include gitignored files if configured\n            if not self.config.respect_gitignore:\n                cmd.append('--include-gitignored')\n            \n            # Add token if provided\n            if auth_config.token:\n                cmd.extend(['--token', auth_config.token])\n            \n            # Output to temporary file (Windows encoding workaround)"}, {"id": "services/gitingest_processor.py_20", "file": "services/gitingest_processor.py", "content": "# Output to temporary file (Windows encoding workaround)\n            cmd.extend(['--output', output_file])\n            \n            # Set up environment\n            env = os.environ.copy()\n            if auth_config.token:\n                env['GITHUB_TOKEN'] = auth_config.token\n            \n            # Execute gitingest\n            self.logger.debug(f\"Executing gitingest command: {' '.join(cmd[:-2])} [URL] --output [temp_file]\")\n            \n            result = subprocess.run(\n                cmd,\n                capture_output=True,\n                text=True,\n                timeout=self.config.timeout,\n                env=env,\n                cwd=self.temp_dir,\n                encoding='utf-8',"}, {"id": "services/gitingest_processor.py_21", "file": "services/gitingest_processor.py", "content": "env=env,\n                cwd=self.temp_dir,\n                encoding='utf-8',\n                errors='replace'  # Handle encoding errors gracefully\n            )\n            \n            if result.returncode != 0:\n                error_msg = result.stderr.strip() if result.stderr else \"Unknown gitingest error\"\n                raise RuntimeError(f\"Gitingest execution failed: {error_msg}\")\n            \n            # Read the output file\n            with open(output_file, 'r', encoding='utf-8', errors='replace') as f:\n                output_content = f.read()\n            \n            return output_content\n            \n        except subprocess.TimeoutExpired:\n            raise RuntimeError(f\"Gitingest execution timed out after {self.config.timeout} seconds\")"}, {"id": "services/gitingest_processor.py_22", "file": "services/gitingest_processor.py", "content": "except FileNotFoundError:\n            raise RuntimeError(\"Gitingest is not installed or not in PATH\")\n        except Exception as e:\n            raise RuntimeError(f\"Gitingest execution failed: {str(e)}\")\n        finally:\n            # Clean up temporary output file\n            if output_file and os.path.exists(output_file):\n                try:\n                    os.remove(output_file)\n                except Exception as e:\n                    self.logger.warning(f\"Failed to clean up temporary output file {output_file}: {e}\")\n    \n    def _add_file_to_structure(self, file_path: str, content_lines: List[str], \n                              files: Dict[str, ContentBlock], language_stats: Dict[str, int]) -> None:\n        \"\"\"Add a file to the structured repository data\"\"\""}, {"id": "services/gitingest_processor.py_23", "file": "services/gitingest_processor.py", "content": "\"\"\"Add a file to the structured repository data\"\"\"\n        # Clean up content - remove empty lines at the end\n        while content_lines and not content_lines[-1].strip():\n            content_lines.pop()\n        \n        content = '\\n'.join(content_lines)\n        language = self._detect_language(file_path)\n        \n        # Update language statistics\n        if language:\n            language_stats[language] = language_stats.get(language, 0) + 1\n        \n        # Create content block\n        content_block = ContentBlock(\n            file_path=file_path,\n            content=content,\n            language=language or 'unknown',\n            line_count=len(content_lines),\n            size_bytes=len(content.encode('utf-8')),\n            file_type=self._get_file_type(file_path)"}, {"id": "services/gitingest_processor.py_24", "file": "services/gitingest_processor.py", "content": "file_type=self._get_file_type(file_path)\n        )\n        \n        files[file_path] = content_block\n    \n    def _parse_directory_structure(self, raw_output: str) -> Dict[str, Any]:\n        \"\"\"Parse directory structure from gitingest output\"\"\"\n        hierarchy = {}\n        \n        lines = raw_output.split('\\n')\n        in_directory_section = False\n        \n        for line in lines:\n            if line.startswith('Directory structure:'):\n                in_directory_section = True\n                continue\n            elif line.startswith('=') and in_directory_section:\n                # End of directory section\n                break\n            elif in_directory_section and line.strip():\n                # Parse directory tree lines"}, {"id": "services/gitingest_processor.py_25", "file": "services/gitingest_processor.py", "content": "# Parse directory tree lines\n                # Example: \"    \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac README\" or \"\u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac octocat-hello-world/\"\n                if '\u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac' in line or '\u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac' in line:\n                    # Extract file/folder name\n                    parts = line.split('\u00e2\u201d\u20ac\u00e2\u201d\u20ac')\n                    if len(parts) > 1:\n                        name = parts[-1].strip()\n                        if name.endswith('/'):\n                            # Directory\n                            hierarchy[name[:-1]] = {}\n                        else:\n                            # File\n                            hierarchy[name] = name\n        \n        return hierarchy\n    \n    def _build_file_hierarchy(self, file_paths: List[str]) -> Dict[str, Any]:"}, {"id": "services/gitingest_processor.py_26", "file": "services/gitingest_processor.py", "content": "def _build_file_hierarchy(self, file_paths: List[str]) -> Dict[str, Any]:\n        \"\"\"Build hierarchical structure from file paths\"\"\"\n        hierarchy = {}\n        \n        for file_path in file_paths:\n            parts = file_path.split('/')\n            current = hierarchy\n            \n            for part in parts[:-1]:  # Directories\n                if part not in current:\n                    current[part] = {}\n                current = current[part]\n            \n            # File\n            if parts:\n                current[parts[-1]] = file_path\n        \n        return hierarchy\n    \n    def _detect_language(self, file_path: str) -> Optional[str]:\n        \"\"\"Detect programming language from file extension\"\"\"\n        ext = Path(file_path).suffix.lower()"}, {"id": "services/gitingest_processor.py_27", "file": "services/gitingest_processor.py", "content": "ext = Path(file_path).suffix.lower()\n        \n        language_map = {\n            '.py': 'Python',\n            '.js': 'JavaScript',\n            '.ts': 'TypeScript',\n            '.jsx': 'JavaScript',\n            '.tsx': 'TypeScript',\n            '.java': 'Java',\n            '.cpp': 'C++',\n            '.c': 'C',\n            '.cs': 'C#',\n            '.go': 'Go',\n            '.rs': 'Rust',\n            '.php': 'PHP',\n            '.rb': 'Ruby',\n            '.swift': 'Swift',\n            '.kt': 'Kotlin',\n            '.scala': 'Scala',\n            '.html': 'HTML',\n            '.css': 'CSS',\n            '.scss': 'SCSS',\n            '.md': 'Markdown',\n            '.json': 'JSON',\n            '.yaml': 'YAML',\n            '.yml': 'YAML',\n            '.xml': 'XML',\n            '.sql': 'SQL',"}, {"id": "services/gitingest_processor.py_28", "file": "services/gitingest_processor.py", "content": "'.yml': 'YAML',\n            '.xml': 'XML',\n            '.sql': 'SQL',\n            '.sh': 'Shell',\n            '.bash': 'Shell',\n            '.ps1': 'PowerShell'\n        }\n        \n        return language_map.get(ext)\n    \n    def _get_file_type(self, file_path: str) -> str:\n        \"\"\"Determine file type category\"\"\"\n        ext = Path(file_path).suffix.lower()\n        \n        if ext in ['.py', '.js', '.ts', '.jsx', '.tsx', '.java', '.cpp', '.c', '.cs', '.go', '.rs', '.php', '.rb', '.swift', '.kt', '.scala']:\n            return 'source'\n        elif ext in ['.md', '.txt', '.rst', '.doc', '.docx']:\n            return 'documentation'\n        elif ext in ['.json', '.yaml', '.yml', '.xml', '.toml', '.ini', '.cfg']:\n            return 'configuration'"}, {"id": "services/gitingest_processor.py_29", "file": "services/gitingest_processor.py", "content": "return 'configuration'\n        elif ext in ['.html', '.css', '.scss', '.less']:\n            return 'web'\n        elif ext in ['.sql']:\n            return 'database'\n        elif ext in ['.sh', '.bash', '.ps1', '.bat']:\n            return 'script'\n        else:\n            return 'other'"}, {"id": "services/rag_service.py_0", "file": "services/rag_service.py", "content": "================================================\n[Empty file]"}, {"id": "services/rag_system.py_0", "file": "services/rag_system.py", "content": "================================================\nError reading file with 'cp1252': 'charmap' codec can't decode byte 0x8d in position 36680: character maps to <undefined>"}, {"id": "templates/index.html_0", "file": "templates/index.html", "content": "================================================\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>Repo RAG Assistant</title>\n</head>\n<body>\n  <h1>Repo RAG Assistant</h1>\n  \n  <form method=\"POST\">\n    <input type=\"text\" name=\"repo_link\" placeholder=\"Paste GitHub repo link...\" style=\"width: 300px;\">\n    <button type=\"submit\">Go</button>\n  </form>\n\n  <h2>My Projects</h2>\n  <ul>\n    {% for repo in repos %}\n      <li><a href=\"{{ url_for('workspace', repo=repo) }}\">{{ repo }}</a></li>\n    {% endfor %}\n  </ul>\n</body>\n</html>"}, {"id": "templates/loading.html_0", "file": "templates/loading.html", "content": "================================================\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>Loading Repo</title>\n  <style>\n    .bubble {\n      width: 100px;\n      height: 100px;\n      background: blue;\n      border-radius: 50%;\n      animation: bounce 1s infinite alternate;\n    }\n    @keyframes bounce {\n      from { transform: translateY(0); }\n      to { transform: translateY(-30px); }\n    }\n  </style>\n</head>\n<body>\n  <h1>Preparing {{ repo }}...</h1>\n  <div class=\"bubble\"></div>\n  <p>AI is analyzing your repo, please wait.</p>\n  <script>\n    setTimeout(() => {\n      window.location.href = \"/workspace/{{ repo }}\";\n    }, 3000); // auto redirect after 3s\n  </script>\n</body>\n</html>"}, {"id": "templates/workspace.html_0", "file": "templates/workspace.html", "content": "================================================\n[Empty file]"}, {"id": "test_files/quick_test.py_0", "file": "test_files/quick_test.py", "content": "================================================\n#!/usr/bin/env python3\nimport requests\nimport json\n\n# Test with a well-known public repository\nBASE_URL = \"http://localhost:5000\"\n\ndef test_with_known_repo():\n    print(\"Testing with octocat/Hello-World (known public repo)...\")\n    \n    url = f\"{BASE_URL}/api/repositories/validate\"\n    data = {\"url\": \"https://github.com/octocat/Hello-World\"}\n    \n    response = requests.post(url, json=data)\n    print(f\"Status: {response.status_code}\")\n    print(f\"Response: {response.json()}\")\n    print()"}, {"id": "test_files/quick_test.py_1", "file": "test_files/quick_test.py", "content": "def test_with_your_repo():\n    print(\"Testing with Emon69420/HazMapApp...\")\n    \n    url = f\"{BASE_URL}/api/repositories/validate\"\n    data = {\"url\": \"https://github.com/Emon69420/HazMapApp\"}\n    \n    response = requests.post(url, json=data)\n    print(f\"Status: {response.status_code}\")\n    print(f\"Response: {response.json()}\")\n    print()\n\nif __name__ == \"__main__\":\n    try:\n        test_with_known_repo()\n        test_with_your_repo()\n    except requests.exceptions.ConnectionError:\n        print(\"Error: Could not connect to Flask server.\")\n        print(\"Make sure the server is running with: python app.py\")\n    except Exception as e:\n        print(f\"Error: {e}\")"}, {"id": "test_files/quick_token_test.py_0", "file": "test_files/quick_token_test.py", "content": "================================================\n#!/usr/bin/env python3\n\"\"\"\nQuick test to verify your GitHub token works\n\"\"\"\n\nimport requests"}, {"id": "test_files/quick_token_test.py_1", "file": "test_files/quick_token_test.py", "content": "def test_github_token():\n    \"\"\"Test if your GitHub token works\"\"\"\n    print(\"\ud83d\udd11 GitHub Token Tester\")\n    print(\"=\" * 30)\n    \n    # Get token from user\n    token = input(\"Paste your GitHub token here: \").strip()\n    \n    if not token:\n        print(\"\u274c No token provided!\")\n        return\n    \n    if not token.startswith('ghp_'):\n        print(\"\u26a0\ufe0f  Warning: Token should start with 'ghp_'\")\n    \n    print(\"\\n\ud83d\udd0d Testing token...\")\n    \n    # Test the token\n    headers = {\n        'Authorization': f'token {token}',\n        'Accept': 'application/vnd.github.v3+json'\n    }\n    \n    try:\n        # Test 1: Get user info\n        response = requests.get('https://api.github.com/user', headers=headers)\n        \n        if response.status_code == 200:\n            user_data = response.json()"}, {"id": "test_files/quick_token_test.py_2", "file": "test_files/quick_token_test.py", "content": "if response.status_code == 200:\n            user_data = response.json()\n            print(f\"\u2705 Token valid!\")\n            print(f\"   User: {user_data.get('login')}\")\n            print(f\"   Name: {user_data.get('name', 'Not set')}\")\n            print(f\"   Email: {user_data.get('email', 'Not public')}\")\n            \n            # Test 2: Check rate limits\n            rate_response = requests.get('https://api.github.com/rate_limit', headers=headers)\n            if rate_response.status_code == 200:\n                rate_data = rate_response.json()\n                core = rate_data['resources']['core']\n                print(f\"\\n\ud83d\udcca Rate Limits:\")\n                print(f\"   Limit: {core['limit']} requests/hour\")\n                print(f\"   Remaining: {core['remaining']}\")"}, {"id": "test_files/quick_token_test.py_3", "file": "test_files/quick_token_test.py", "content": "print(f\"   Remaining: {core['remaining']}\")\n                print(f\"   Used: {core['used']}\")\n            \n            # Test 3: Access your repository\n            print(f\"\\n\ud83d\udd0d Testing repository access...\")\n            repo_response = requests.get('https://api.github.com/repos/Emon69420/HazMapApp', headers=headers)\n            \n            if repo_response.status_code == 200:\n                repo_data = repo_response.json()\n                print(f\"\u2705 Repository accessible!\")\n                print(f\"   Name: {repo_data['full_name']}\")\n                print(f\"   Private: {repo_data['private']}\")\n                print(f\"   Size: {repo_data['size']} KB\")\n                \n                print(f\"\\n\ud83c\udf89 Token is working perfectly!\")"}, {"id": "test_files/quick_token_test.py_4", "file": "test_files/quick_token_test.py", "content": "print(f\"\\n\ud83c\udf89 Token is working perfectly!\")\n                print(f\"\ud83d\udcbe Save this token: {token}\")\n                \n            else:\n                print(f\"\u274c Repository access failed: {repo_response.status_code}\")\n                \n        elif response.status_code == 401:\n            print(\"\u274c Token is invalid or expired\")\n        elif response.status_code == 403:\n            print(\"\u274c Token doesn't have required permissions\")\n        else:\n            print(f\"\u274c Unexpected error: {response.status_code}\")\n            \n    except Exception as e:\n        print(f\"\u274c Error testing token: {e}\")\n\nif __name__ == \"__main__\":\n    test_github_token()\n    \n    print(\"\\n\ud83d\udca1 Next steps:\")\n    print(\"1. If token works: Run 'python test_with_token.py'\")"}, {"id": "test_files/quick_token_test.py_5", "file": "test_files/quick_token_test.py", "content": "print(\"\\n\ud83d\udca1 Next steps:\")\n    print(\"1. If token works: Run 'python test_with_token.py'\")\n    print(\"2. If token fails: Check permissions and regenerate\")\n    print(\"3. Keep your token safe - don't share it!\")"}, {"id": "test_files/streamlit_app.py_0", "file": "test_files/streamlit_app.py", "content": "================================================\nimport streamlit as st\nimport requests\nfrom datetime import datetime\nimport os\nimport json"}, {"id": "test_files/streamlit_app.py_1", "file": "test_files/streamlit_app.py", "content": "def load_custom_css():\n    \"\"\"Load custom CSS for dark theme styling\"\"\"\n    st.markdown(\"\"\"\n    <style>\n    .main {\n        background-color: #0E1117;\n    }\n    \n    .stApp {\n        background-color: #0E1117;\n    }\n    \n    .css-1d391kg {\n        background-color: #0E1117;\n    }\n    \n    .stSelectbox > div > div {\n        background-color: #262730;\n        color: #FAFAFA;\n    }\n    \n    .stTextInput > div > div > input {\n        background-color: #262730;\n        color: #FAFAFA;\n        border: 1px solid #4F4F4F;\n    }\n    \n    .stButton > button {\n        background-color: #FF4B4B;\n        color: white;\n        border: none;\n        border-radius: 4px;\n        padding: 0.5rem 1rem;\n    }\n    \n    .stButton > button:hover {\n        background-color: #FF6B6B;\n    }"}, {"id": "test_files/streamlit_app.py_2", "file": "test_files/streamlit_app.py", "content": "}\n    \n    .stButton > button:hover {\n        background-color: #FF6B6B;\n    }\n    \n    .success-message {\n        background-color: #00CC88;\n        color: white;\n        padding: 0.5rem;\n        border-radius: 4px;\n        margin: 0.5rem 0;\n    }\n    \n    .error-message {\n        background-color: #FF6B6B;\n        color: white;\n        padding: 0.5rem;\n        border-radius: 4px;\n        margin: 0.5rem 0;\n    }\n    \n    .info-message {\n        background-color: #4A90E2;\n        color: white;\n        padding: 0.5rem;\n        border-radius: 4px;\n        margin: 0.5rem 0;\n    }\n    \n    .repo-card {\n        background-color: #262730;\n        padding: 1rem;\n        border-radius: 8px;\n        margin: 0.5rem 0;\n        border: 1px solid #4F4F4F;\n    }\n    \n    .repo-card:hover {"}, {"id": "test_files/streamlit_app.py_3", "file": "test_files/streamlit_app.py", "content": "margin: 0.5rem 0;\n        border: 1px solid #4F4F4F;\n    }\n    \n    .repo-card:hover {\n        border-color: #FF4B4B;\n        transition: border-color 0.3s ease;\n    }\n    </style>\n    \"\"\", unsafe_allow_html=True)"}, {"id": "test_files/streamlit_app.py_4", "file": "test_files/streamlit_app.py", "content": "def initialize_session_state():\n    \"\"\"Initialize session state variables\"\"\"\n    if 'repositories' not in st.session_state:\n        st.session_state.repositories = []\n    if 'loading' not in st.session_state:\n        st.session_state.loading = False\n    if 'current_operation' not in st.session_state:\n        st.session_state.current_operation = \"\"\n    if 'notifications' not in st.session_state:\n        st.session_state.notifications = []\n    if 'github_token' not in st.session_state:\n        st.session_state.github_token = \"\"\n    if 'last_refresh' not in st.session_state:\n        st.session_state.last_refresh = None\n\ndef render_header():\n    \"\"\"Render the application header\"\"\"\n    st.title(\"\u00f0\u0178\u0161\u20ac AI Project Analyzer\")\n    st.markdown(\"---\")"}, {"id": "test_files/streamlit_app.py_5", "file": "test_files/streamlit_app.py", "content": "def main():\n    \"\"\"Main application entry point\"\"\"\n    # Configure Streamlit page\n    st.set_page_config(\n        page_title=\"AI Project Analyzer\",\n        page_icon=\"\u00f0\u0178\u0161\u20ac\",\n        layout=\"wide\",\n        initial_sidebar_state=\"collapsed\"\n    )\n    \n    # Load custom styling\n    load_custom_css()\n    \n    # Initialize session state\n    initialize_session_state()\n    \n    # Render header\n    render_header()\n    \n    # Placeholder content for now\n    st.info(\"\u00f0\u0178\u201d\u00a7 Application structure set up successfully!\")\n    st.markdown(\"### Next Steps:\")\n    st.markdown(\"- Dark theme styling system\")\n    st.markdown(\"- API client module\")\n    st.markdown(\"- Repository list display\")\n    st.markdown(\"- Add repository form\")\n\nif __name__ == \"__main__\":\n    main()"}, {"id": "test_files/suppress_warnings.py_0", "file": "test_files/suppress_warnings.py", "content": "================================================\n#!/usr/bin/env python3\n\"\"\"\nUtility to suppress ONNX Runtime warnings and other verbose output\n\"\"\"\n\nimport os\nimport sys\nimport warnings\nimport logging"}, {"id": "test_files/suppress_warnings.py_1", "file": "test_files/suppress_warnings.py", "content": "def suppress_all_warnings():\n    \"\"\"Suppress all the annoying warnings from ML libraries\"\"\"\n    \n    # 1. Suppress TensorFlow warnings\n    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Only show errors\n    os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'  # Disable oneDNN warnings\n    \n    # 2. Suppress ONNX Runtime warnings\n    os.environ['ORT_DISABLE_ALL_LOGS'] = '1'\n    \n    # 3. Suppress Python warnings\n    warnings.filterwarnings('ignore')\n    \n    # 4. Suppress specific library warnings\n    logging.getLogger('tensorflow').setLevel(logging.ERROR)\n    logging.getLogger('onnxruntime').setLevel(logging.ERROR)\n    logging.getLogger('transformers').setLevel(logging.ERROR)\n    logging.getLogger('sentence_transformers').setLevel(logging.ERROR)"}, {"id": "test_files/suppress_warnings.py_2", "file": "test_files/suppress_warnings.py", "content": "logging.getLogger('sentence_transformers').setLevel(logging.ERROR)\n    logging.getLogger('chromadb').setLevel(logging.ERROR)\n    \n    # 5. Redirect stderr temporarily to suppress C++ warnings\n    import contextlib\n    \n    @contextlib.contextmanager\n    def suppress_stderr():\n        with open(os.devnull, \"w\") as devnull:\n            old_stderr = sys.stderr\n            sys.stderr = devnull\n            try:\n                yield\n            finally:\n                sys.stderr = old_stderr\n    \n    return suppress_stderr\n\n# Call this at the start of any script"}, {"id": "test_files/suppress_warnings.py_3", "file": "test_files/suppress_warnings.py", "content": "def setup_clean_environment():\n    \"\"\"Set up a clean environment without warnings\"\"\"\n    suppress_all_warnings()\n    \n    # Also suppress the specific ONNX warnings by setting environment variables\n    os.environ['CUDA_VISIBLE_DEVICES'] = ''  # Force CPU-only\n    os.environ['OMP_NUM_THREADS'] = '1'  # Reduce threading warnings\n    \n    print(\"\u00f0\u0178\u201d\u2021 Warnings suppressed - clean output enabled!\")\n\nif __name__ == \"__main__\":\n    setup_clean_environment()\n    print(\"\u00e2\u0153\u2026 Warning suppression configured!\")"}, {"id": "test_files/test_api.py_0", "file": "test_files/test_api.py", "content": "================================================\n#!/usr/bin/env python3\n\"\"\"\nSimple test script to verify the API endpoints work correctly\n\"\"\"\n\nimport requests\nimport json\n\nBASE_URL = \"http://localhost:5000\"\n\ndef test_repository_validation():\n    \"\"\"Test repository validation endpoint\"\"\"\n    print(\"Testing repository validation...\")\n    \n    url = f\"{BASE_URL}/api/repositories/validate\"\n    data = {\"url\": \"https://github.com/Emon69420/HazMapApp\"}\n    \n    response = requests.post(url, json=data)\n    print(f\"Status: {response.status_code}\")\n    print(f\"Response: {response.json()}\")\n    print()"}, {"id": "test_files/test_api.py_1", "file": "test_files/test_api.py", "content": "def test_repository_analysis():\n    \"\"\"Test repository analysis endpoint\"\"\"\n    print(\"Testing repository analysis...\")\n    \n    url = f\"{BASE_URL}/api/repositories/analyze\"\n    data = {\"url\": \"https://github.com/Emon69420/HazMapApp\"}\n    \n    response = requests.post(url, json=data)\n    print(f\"Status: {response.status_code}\")\n    print(f\"Response: {response.json()}\")\n    print()"}, {"id": "test_files/test_api.py_2", "file": "test_files/test_api.py", "content": "def test_repository_tree():\n    \"\"\"Test repository tree endpoint\"\"\"\n    print(\"Testing repository tree...\")\n    \n    url = f\"{BASE_URL}/api/repositories/Emon69420/HazMapApp/tree\"\n    \n    response = requests.get(url)\n    print(f\"Status: {response.status_code}\")\n    result = response.json()\n    if 'tree' in result:\n        print(f\"Files found: {result['tree']['total_files']}\")\n        print(f\"Directories found: {result['tree']['total_directories']}\")\n        # Show first few files\n        files = result['tree']['files'][:5]\n        print(\"Sample files:\")\n        for file in files:\n            print(f\"  - {file['path']}\")\n    else:\n        print(f\"Response: {result}\")\n    print()"}, {"id": "test_files/test_api.py_3", "file": "test_files/test_api.py", "content": "def test_file_content():\n    \"\"\"Test file content endpoint\"\"\"\n    print(\"Testing file content...\")\n    \n    url = f\"{BASE_URL}/api/repositories/Emon69420/HazMapApp/files/README.md\"\n    \n    response = requests.get(url)\n    print(f\"Status: {response.status_code}\")\n    result = response.json()\n    if 'file' in result:\n        print(f\"File: {result['file']['name']}\")\n        print(f\"Size: {result['file']['size']} bytes\")\n        print(f\"Encoding: {result['file']['encoding']}\")\n    else:\n        print(f\"Response: {result}\")\n    print()\n\nif __name__ == \"__main__\":\n    print(\"Testing AI Project Analyzer API endpoints\")\n    print(\"=\" * 50)\n    \n    try:\n        test_repository_validation()\n        test_repository_analysis()\n        test_repository_tree()\n        test_file_content()"}, {"id": "test_files/test_api.py_4", "file": "test_files/test_api.py", "content": "test_repository_tree()\n        test_file_content()\n        \n        print(\"All tests completed!\")\n        \n    except requests.exceptions.ConnectionError:\n        print(\"Error: Could not connect to Flask server.\")\n        print(\"Make sure the server is running with: python app.py\")\n    except Exception as e:\n        print(f\"Error: {e}\")"}, {"id": "test_files/test_clone.py_0", "file": "test_files/test_clone.py", "content": "================================================\n#!/usr/bin/env python3\n\"\"\"\nTest script for repository cloning functionality\n\"\"\"\n\nimport requests\nimport json\nimport os\nfrom pathlib import Path\n\nBASE_URL = \"http://localhost:5000\""}, {"id": "test_files/test_clone.py_1", "file": "test_files/test_clone.py", "content": "def test_clone_repository():\n    \"\"\"Test cloning a repository\"\"\"\n    print(\"\ud83d\udd04 Testing repository cloning...\")\n    print(\"=\" * 50)\n    \n    url = f\"{BASE_URL}/api/repositories/clone\"\n    data = {\n        \"url\": \"https://github.com/Emon69420/HazMapApp\",\n        \"target_dir\": \"./my_repos\"\n    }\n    \n    response = requests.post(url, json=data)\n    print(f\"Status: {response.status_code}\")\n    \n    if response.status_code == 200:\n        result = response.json()\n        print(f\"\u2705 Clone successful!\")\n        print(f\"\ud83d\udcc1 Clone path: {result['clone_path']}\")\n        print(f\"\ud83d\udcca Total files: {result['stats']['total_files']}\")\n        print(f\"\ud83d\udcc2 Total directories: {result['stats']['total_directories']}\")\n        print(f\"\ud83d\udcbe Size: {result['stats']['size_bytes']} bytes\")"}, {"id": "test_files/test_clone.py_2", "file": "test_files/test_clone.py", "content": "print(f\"\ud83d\udcbe Size: {result['stats']['size_bytes']} bytes\")\n        print(f\"\ud83d\udd24 Languages detected:\")\n        for lang, count in result['stats']['languages'].items():\n            print(f\"   - {lang}: {count} files\")\n        \n        # Check if directory actually exists\n        clone_path = Path(result['clone_path'])\n        if clone_path.exists():\n            print(f\"\u2705 Directory exists: {clone_path}\")\n            \n            # List some files\n            files = list(clone_path.rglob('*'))[:10]\n            print(f\"\ud83d\udcc4 Sample files:\")\n            for file in files:\n                if file.is_file():\n                    print(f\"   - {file.relative_to(clone_path)}\")\n        else:\n            print(f\"\u274c Directory not found: {clone_path}\")\n            \n    else:"}, {"id": "test_files/test_clone.py_3", "file": "test_files/test_clone.py", "content": "else:\n            print(f\"\u274c Directory not found: {clone_path}\")\n            \n    else:\n        print(f\"\u274c Clone failed: {response.json()}\")\n    \n    print()"}, {"id": "test_files/test_clone.py_4", "file": "test_files/test_clone.py", "content": "def test_clone_and_analyze():\n    \"\"\"Test clone and analyze in one operation\"\"\"\n    print(\"\ud83d\udd0d Testing clone and analyze...\")\n    print(\"=\" * 50)\n    \n    url = f\"{BASE_URL}/api/repositories/clone-and-analyze\"\n    data = {\n        \"url\": \"https://github.com/Emon69420/HazMapApp\",\n        \"target_dir\": \"./my_repos\",\n        \"max_file_size\": 512 * 1024,  # 512KB limit\n        \"cleanup_after\": False  # Keep the repository for inspection\n    }\n    \n    response = requests.post(url, json=data)\n    print(f\"Status: {response.status_code}\")\n    \n    if response.status_code == 200:\n        result = response.json()\n        \n        # Clone info\n        clone_info = result['clone_info']\n        print(f\"\u2705 Clone successful!\")\n        print(f\"\ud83d\udcc1 Clone path: {clone_info['clone_path']}\")"}, {"id": "test_files/test_clone.py_5", "file": "test_files/test_clone.py", "content": "print(f\"\u2705 Clone successful!\")\n        print(f\"\ud83d\udcc1 Clone path: {clone_info['clone_path']}\")\n        print(f\"\u23f0 Cloned at: {clone_info['cloned_at']}\")\n        \n        # Analysis info\n        analysis = result['analysis']\n        stats = analysis['processing_stats']\n        \n        print(f\"\\n\ud83d\udcc8 Analysis Results:\")\n        print(f\"  \u2705 Files processed: {stats['processed']}\")\n        print(f\"  \u26a0\ufe0f  Files skipped (too large): {stats['skipped_large']}\")\n        print(f\"  \ud83d\udeab Files skipped (binary): {stats['skipped_binary']}\")\n        print(f\"  \u274c Errors: {stats['errors']}\")\n        \n        # Repository stats\n        repo_stats = analysis['stats']\n        print(f\"\\n\ud83d\udcca Repository Statistics:\")\n        print(f\"  \ud83d\udcc4 Total files: {repo_stats['total_files']}\")"}, {"id": "test_files/test_clone.py_6", "file": "test_files/test_clone.py", "content": "print(f\"  \ud83d\udcc4 Total files: {repo_stats['total_files']}\")\n        print(f\"  \ud83d\udcc2 Total directories: {repo_stats['total_directories']}\")\n        print(f\"  \ud83d\udcbe Size: {repo_stats['size_bytes']} bytes\")\n        \n        # Languages\n        if repo_stats['languages']:\n            print(f\"\\n\ud83d\udd24 Languages detected:\")\n            for lang, count in sorted(repo_stats['languages'].items(), key=lambda x: x[1], reverse=True):\n                print(f\"   - {lang}: {count} files\")\n        \n        # Show some processed files\n        files_with_content = analysis['files_with_content'][:5]\n        print(f\"\\n\ud83d\udcc4 Sample processed files:\")\n        for file_info in files_with_content:\n            print(f\"   - {file_info['path']} ({file_info['lines']} lines, {file_info['language'] or 'Unknown'})\")"}, {"id": "test_files/test_clone.py_7", "file": "test_files/test_clone.py", "content": "if len(analysis['files_with_content']) > 5:\n            print(f\"   ... and {len(analysis['files_with_content']) - 5} more files\")\n        \n        # Save detailed results\n        output_file = \"clone_analysis_result.json\"\n        with open(output_file, 'w', encoding='utf-8') as f:\n            json.dump(result, f, indent=2, ensure_ascii=False)\n        \n        print(f\"\\n\ud83d\udcbe Full results saved to: {output_file}\")\n        \n    else:\n        print(f\"\u274c Clone and analyze failed: {response.json()}\")\n    \n    print()"}, {"id": "test_files/test_clone.py_8", "file": "test_files/test_clone.py", "content": "def test_performance_comparison():\n    \"\"\"Compare API vs Clone performance\"\"\"\n    print(\"\u26a1 Performance Comparison: API vs Clone\")\n    print(\"=\" * 50)\n    \n    import time\n    \n    # Test API approach\n    print(\"Testing API approach...\")\n    start_time = time.time()\n    \n    api_url = f\"{BASE_URL}/api/repositories/deep-analyze\"\n    api_data = {\n        \"url\": \"https://github.com/octocat/Hello-World\",  # Small repo for fair comparison\n        \"max_file_size\": 1024 * 1024\n    }\n    \n    api_response = requests.post(api_url, json=api_data)\n    api_time = time.time() - start_time\n    \n    print(f\"API approach: {api_time:.2f} seconds\")\n    \n    # Test Clone approach\n    print(\"Testing Clone approach...\")\n    start_time = time.time()"}, {"id": "test_files/test_clone.py_9", "file": "test_files/test_clone.py", "content": "# Test Clone approach\n    print(\"Testing Clone approach...\")\n    start_time = time.time()\n    \n    clone_url = f\"{BASE_URL}/api/repositories/clone-and-analyze\"\n    clone_data = {\n        \"url\": \"https://github.com/octocat/Hello-World\",\n        \"cleanup_after\": True  # Clean up after test\n    }\n    \n    clone_response = requests.post(clone_url, json=clone_data)\n    clone_time = time.time() - start_time\n    \n    print(f\"Clone approach: {clone_time:.2f} seconds\")\n    \n    # Compare results\n    if api_response.status_code == 200 and clone_response.status_code == 200:\n        api_files = len(api_response.json()['deep_analysis']['structure']['files_with_content'])\n        clone_files = len(clone_response.json()['analysis']['files_with_content'])\n        \n        print(f\"\\n\ud83d\udcca Results:\")"}, {"id": "test_files/test_clone.py_10", "file": "test_files/test_clone.py", "content": "print(f\"\\n\ud83d\udcca Results:\")\n        print(f\"API files processed: {api_files}\")\n        print(f\"Clone files processed: {clone_files}\")\n        print(f\"Speed improvement: {api_time/clone_time:.1f}x faster\" if clone_time < api_time else f\"API was {clone_time/api_time:.1f}x faster\")\n    \n    print()\n\nif __name__ == \"__main__\":\n    print(\"\ud83d\ude80 Testing Repository Cloning System\")\n    print(\"=\" * 60)\n    \n    try:\n        # Check if git is available\n        import subprocess\n        result = subprocess.run(['git', '--version'], capture_output=True, text=True)\n        if result.returncode != 0:\n            print(\"\u274c Git is not installed or not in PATH\")\n            print(\"Please install Git to use cloning functionality\")\n            exit(1)\n        else:"}, {"id": "test_files/test_clone.py_11", "file": "test_files/test_clone.py", "content": "exit(1)\n        else:\n            print(f\"\u2705 Git available: {result.stdout.strip()}\")\n            print()\n        \n        test_clone_repository()\n        test_clone_and_analyze()\n        test_performance_comparison()\n        \n        print(\"\ud83c\udf89 All cloning tests completed!\")\n        \n    except requests.exceptions.ConnectionError:\n        print(\"\u274c Error: Could not connect to Flask server.\")\n        print(\"Make sure the server is running with: python app.py\")\n    except Exception as e:\n        print(f\"\u274c Error: {e}\")"}, {"id": "test_files/test_consistent_indexing.py_0", "file": "test_files/test_consistent_indexing.py", "content": "================================================\n#!/usr/bin/env python3\n\"\"\"\nTest to check consistency of RAG indexing across multiple runs\n\"\"\"\n\nimport sys\nimport os\nfrom pathlib import Path\n\n# Add services to path\nsys.path.append(str(Path(__file__).parent))\n\ntry:\n    from services.rag_system import CPUOptimizedRAGSystem\nexcept ImportError as e:\n    print(f\"\u274c Import error: {e}\")\n    sys.exit(1)"}, {"id": "test_files/test_consistent_indexing.py_1", "file": "test_files/test_consistent_indexing.py", "content": "def run_indexing_test(run_number):\n    \"\"\"Run a single indexing test and return metrics\"\"\"\n    print(f\"\\n\ud83d\udd04 Run {run_number}:\")\n    print(\"-\" * 30)\n    \n    gitingest_file = \"gitingest_outputs/Samay1011_Project_ecommerce_React_20250906_104832.txt\"\n    \n    if not os.path.exists(gitingest_file):\n        print(f\"\u274c Gitingest file not found: {gitingest_file}\")\n        return None\n    \n    try:\n        # Initialize RAG system with unique storage path\n        storage_path = f\"./temp_consistency_test_{run_number}\"\n        rag = CPUOptimizedRAGSystem(storage_path=storage_path)\n        \n        # Build RAG system\n        metrics = rag.build_rag_from_gitingest(gitingest_file, f\"consistency_test_{run_number}\")\n        print(f\"\u2705 Indexed {metrics.total_chunks} chunks from {metrics.total_files} files\")"}, {"id": "test_files/test_consistent_indexing.py_2", "file": "test_files/test_consistent_indexing.py", "content": "print(f\"\u2705 Indexed {metrics.total_chunks} chunks from {metrics.total_files} files\")\n        \n        # Get all chunks to analyze\n        all_results = rag.query(\"*\", max_results=200, collection_name=f\"consistency_test_{run_number}\")\n        \n        # Count by file type\n        file_types = {}\n        chunk_types = {}\n        python_files = []\n        \n        for chunk in all_results.chunks:\n            # File extension\n            ext = Path(chunk.file_path).suffix or 'no-ext'\n            file_types[ext] = file_types.get(ext, 0) + 1\n            \n            # Chunk type\n            chunk_types[chunk.chunk_type] = chunk_types.get(chunk.chunk_type, 0) + 1\n            \n            # Track Python files specifically\n            if ext == '.py':\n                python_files.append({"}, {"id": "test_files/test_consistent_indexing.py_3", "file": "test_files/test_consistent_indexing.py", "content": "if ext == '.py':\n                python_files.append({\n                    'file': chunk.file_path,\n                    'type': chunk.chunk_type,\n                    'content_preview': chunk.content[:100].replace('\\n', ' ')\n                })\n        \n        print(\"\ud83d\udcc1 File types:\")\n        for ext, count in sorted(file_types.items(), key=lambda x: x[1], reverse=True):\n            print(f\"   {ext}: {count}\")\n        \n        print(\"\ud83e\udde9 Chunk types:\")\n        for chunk_type, count in sorted(chunk_types.items(), key=lambda x: x[1], reverse=True):\n            print(f\"   {chunk_type}: {count}\")\n        \n        if python_files:\n            print(\"\ud83d\udc0d Python files found:\")\n            for py_file in python_files:\n                print(f\"   {py_file['type']}: {py_file['file']}\")"}, {"id": "test_files/test_consistent_indexing.py_4", "file": "test_files/test_consistent_indexing.py", "content": "print(f\"   {py_file['type']}: {py_file['file']}\")\n                print(f\"      Preview: {py_file['content_preview']}...\")\n        \n        return {\n            'total_chunks': metrics.total_chunks,\n            'total_files': metrics.total_files,\n            'file_types': file_types,\n            'chunk_types': chunk_types,\n            'python_files': python_files\n        }\n        \n    except Exception as e:\n        print(f\"\u274c Run {run_number} failed: {str(e)}\")\n        return None\n    \n    finally:\n        # Clean up\n        try:\n            if 'rag' in locals():\n                rag.chroma_client = None\n                rag.collection = None\n            \n            import shutil\n            import time\n            time.sleep(0.5)"}, {"id": "test_files/test_consistent_indexing.py_5", "file": "test_files/test_consistent_indexing.py", "content": "import shutil\n            import time\n            time.sleep(0.5)\n            if os.path.exists(storage_path):\n                shutil.rmtree(storage_path)\n        except Exception as e:\n            print(f\"\u26a0\ufe0f  Warning: Could not clean up run {run_number}: {e}\")"}, {"id": "test_files/test_consistent_indexing.py_6", "file": "test_files/test_consistent_indexing.py", "content": "def test_consistency():\n    \"\"\"Test consistency across multiple runs\"\"\"\n    print(\"\ud83d\udd0d Testing RAG Indexing Consistency\")\n    print(\"=\" * 50)\n    \n    results = []\n    num_runs = 3\n    \n    for i in range(1, num_runs + 1):\n        result = run_indexing_test(i)\n        if result:\n            results.append(result)\n    \n    if len(results) < 2:\n        print(\"\u274c Not enough successful runs to compare\")\n        return\n    \n    print(f\"\\n\ud83d\udcca Consistency Analysis ({len(results)} runs):\")\n    print(\"=\" * 40)\n    \n    # Compare total counts\n    chunk_counts = [r['total_chunks'] for r in results]\n    file_counts = [r['total_files'] for r in results]\n    \n    print(f\"\ud83d\udce6 Total chunks: {chunk_counts}\")\n    print(f\"\ud83d\udcc1 Total files: {file_counts}\")\n    \n    if len(set(chunk_counts)) == 1:"}, {"id": "test_files/test_consistent_indexing.py_7", "file": "test_files/test_consistent_indexing.py", "content": "print(f\"\ud83d\udcc1 Total files: {file_counts}\")\n    \n    if len(set(chunk_counts)) == 1:\n        print(\"\u2705 Chunk counts are consistent\")\n    else:\n        print(\"\u26a0\ufe0f  Chunk counts vary between runs\")\n    \n    if len(set(file_counts)) == 1:\n        print(\"\u2705 File counts are consistent\")\n    else:\n        print(\"\u26a0\ufe0f  File counts vary between runs\")\n    \n    # Compare file type distributions\n    print(f\"\\n\ud83d\udcc1 File Type Consistency:\")\n    all_extensions = set()\n    for result in results:\n        all_extensions.update(result['file_types'].keys())\n    \n    for ext in sorted(all_extensions):\n        counts = [result['file_types'].get(ext, 0) for result in results]\n        if len(set(counts)) == 1:\n            print(f\"   {ext}: {counts[0]} \u2705\")\n        else:\n            print(f\"   {ext}: {counts} \u26a0\ufe0f\")"}, {"id": "test_files/test_consistent_indexing.py_8", "file": "test_files/test_consistent_indexing.py", "content": "else:\n            print(f\"   {ext}: {counts} \u26a0\ufe0f\")\n    \n    # Compare Python file detection\n    print(f\"\\n\ud83d\udc0d Python File Detection:\")\n    py_file_counts = [len(r['python_files']) for r in results]\n    print(f\"Python chunks found: {py_file_counts}\")\n    \n    if len(set(py_file_counts)) == 1:\n        print(\"\u2705 Python file detection is consistent\")\n    else:\n        print(\"\u26a0\ufe0f  Python file detection varies\")\n        \n        # Show what Python files were found in each run\n        for i, result in enumerate(results, 1):\n            print(f\"  Run {i} Python files:\")\n            for py_file in result['python_files']:\n                print(f\"    - {py_file['file']} ({py_file['type']})\")\n\n\nif __name__ == \"__main__\":\n    test_consistency()"}, {"id": "test_files/test_deep_analysis.py_0", "file": "test_files/test_deep_analysis.py", "content": "================================================\n#!/usr/bin/env python3\n\"\"\"\nTest script for deep repository analysis - fetches all files with their content\n\"\"\"\n\nimport requests\nimport json\nimport os\n\nBASE_URL = \"http://localhost:5000\""}, {"id": "test_files/test_deep_analysis.py_1", "file": "test_files/test_deep_analysis.py", "content": "def test_deep_analysis():\n    \"\"\"Test deep analysis of HazMapApp repository\"\"\"\n    print(\"\ud83d\udd0d Starting deep analysis of HazMapApp repository...\")\n    print(\"=\" * 60)\n    \n    url = f\"{BASE_URL}/api/repositories/deep-analyze\"\n    data = {\n        \"url\": \"https://github.com/Redomic/NeuThera-Drug-Discovery-Toolkit\",\n        \"max_file_size\": 1024 * 1024  # 512KB limit for demo\n    }\n    \n    response = requests.post(url, json=data)\n    print(f\"Status: {response.status_code}\")\n    \n    if response.status_code == 200:\n        result = response.json()\n        deep_analysis = result['deep_analysis']\n        \n        # Repository info\n        repo_info = deep_analysis['repository_info']\n        print(f\"\\n\ud83d\udcc1 Repository: {repo_info['full_name']}\")"}, {"id": "test_files/test_deep_analysis.py_2", "file": "test_files/test_deep_analysis.py", "content": "print(f\"\\n\ud83d\udcc1 Repository: {repo_info['full_name']}\")\n        print(f\"\ud83d\udcdd Description: {repo_info['description']}\")\n        print(f\"\ud83d\udd24 Language: {repo_info['language']}\")\n        print(f\"\ud83d\udcca Size: {repo_info['size']} KB\")\n        print(f\"\u2b50 Stars: {repo_info['stargazers_count']}\")\n        \n        # Structure stats\n        structure = deep_analysis['structure']\n        stats = structure['processing_stats']\n        \n        print(f\"\\n\ud83d\udcc8 Processing Statistics:\")\n        print(f\"  \u2705 Files processed: {stats['processed']}\")\n        print(f\"  \u26a0\ufe0f  Files skipped (too large): {stats['skipped_large']}\")\n        print(f\"  \ud83d\udeab Files skipped (binary): {stats['skipped_binary']}\")\n        print(f\"  \u274c Errors: {stats['errors']}\")\n        print(f\"  \ud83d\udcc2 Total directories: {structure['total_directories']}\")"}, {"id": "test_files/test_deep_analysis.py_3", "file": "test_files/test_deep_analysis.py", "content": "print(f\"  \ud83d\udcc2 Total directories: {structure['total_directories']}\")\n        print(f\"  \ud83d\udcc4 Total files: {structure['total_files']}\")\n        \n        # Display timing information\n        if 'processing_time' in result:\n            timing = result['processing_time']\n            print(f\"\\n\u23f1\ufe0f  Performance Metrics:\")\n            print(f\"  \ud83d\udd50 Processing time: {timing['formatted']} ({timing['seconds']}s)\")\n            print(f\"  \ud83d\ude80 Files per second: {stats.get('files_per_second', 0)}\")\n            print(f\"  \ud83d\udcca Average time per file: {round(timing['seconds'] / max(stats['processed'], 1), 3)}s\")\n        \n        # Show directory structure\n        print(f\"\\n\ud83d\udcc2 Directory Structure:\")\n        for directory in structure['directories'][:10]:\n            print(f\"  \ud83d\udcc1 {directory['path']}\")"}, {"id": "test_files/test_deep_analysis.py_4", "file": "test_files/test_deep_analysis.py", "content": "print(f\"  \ud83d\udcc1 {directory['path']}\")\n        if len(structure['directories']) > 10:\n            print(f\"  ... and {len(structure['directories']) - 10} more directories\")\n        \n        # Show files with content\n        print(f\"\\n\ud83d\udcc4 Files with Content ({len(structure['files_with_content'])}):\")\n        for i, file_info in enumerate(structure['files_with_content'][:5]):\n            print(f\"\\n  {i+1}. \ud83d\udcc4 {file_info['path']}\")\n            print(f\"     Size: {file_info['size']} bytes\")\n            print(f\"     Lines: {file_info['lines']}\")\n            print(f\"     Extension: {file_info['extension']}\")\n            \n            # Show first few lines of content\n            content = file_info['content']\n            if content:\n                lines = content.split('\\n')"}, {"id": "test_files/test_deep_analysis.py_5", "file": "test_files/test_deep_analysis.py", "content": "if content:\n                lines = content.split('\\n')\n                print(f\"     Content preview (first 3 lines):\")\n                for j, line in enumerate(lines[:3]):\n                    print(f\"       {j+1}: {line[:80]}{'...' if len(line) > 80 else ''}\")\n            else:\n                print(f\"     Content: [Empty file]\")\n        \n        if len(structure['files_with_content']) > 5:\n            print(f\"\\n  ... and {len(structure['files_with_content']) - 5} more files with content\")\n        \n        # Show skipped files\n        if structure['skipped_files']:\n            print(f\"\\n\u26a0\ufe0f  Skipped Files ({len(structure['skipped_files'])}):\")\n            for skip_info in structure['skipped_files'][:5]:\n                reason = skip_info['reason']"}, {"id": "test_files/test_deep_analysis.py_6", "file": "test_files/test_deep_analysis.py", "content": "reason = skip_info['reason']\n                path = skip_info['path']\n                if reason == 'file_too_large':\n                    print(f\"  \ud83d\udccf {path} (too large: {skip_info['size']} bytes)\")\n                elif reason == 'binary_file':\n                    print(f\"  \ud83d\udd27 {path} (binary: {skip_info['extension']})\")\n                else:\n                    print(f\"  \u274c {path} ({reason})\")\n            \n            if len(structure['skipped_files']) > 5:\n                print(f\"  ... and {len(structure['skipped_files']) - 5} more skipped files\")\n        \n        # Save detailed results to file\n        output_file = \"hazmap_deep_analysis.json\"\n        with open(output_file, 'w', encoding='utf-8') as f:\n            json.dump(result, f, indent=2, ensure_ascii=False)"}, {"id": "test_files/test_deep_analysis.py_7", "file": "test_files/test_deep_analysis.py", "content": "json.dump(result, f, indent=2, ensure_ascii=False)\n        \n        print(f\"\\n\ud83d\udcbe Full analysis saved to: {output_file}\")\n        print(f\"\ud83d\udcca Analysis completed at: {result['analyzed_at']}\")\n        \n        if 'processing_time' in result:\n            print(f\"\u26a1 Total processing time: {result['processing_time']['formatted']}\")\n        \n    else:\n        print(f\"\u274c Error: {response.json()}\")"}, {"id": "test_files/test_deep_analysis.py_8", "file": "test_files/test_deep_analysis.py", "content": "def test_explore_endpoint():\n    \"\"\"Test the alternative explore endpoint\"\"\"\n    print(\"\\n\ud83d\udd0d Testing explore endpoint...\")\n    print(\"=\" * 40)\n    \n    url = f\"{BASE_URL}/api/repositories/Redomic/NeuThera-Drug-Discovery-Toolkit/explore?max_file_size=102400\"  # 100KB limit\n    \n    response = requests.get(url)\n    print(f\"Status: {response.status_code}\")\n    \n    if response.status_code == 200:\n        result = response.json()\n        stats = result['deep_analysis']['structure']['processing_stats']\n        print(f\"\u2705 Processed {stats['processed']} files\")\n        print(f\"\u26a0\ufe0f  Skipped {stats['skipped_large'] + stats['skipped_binary']} files\")\n    else:\n        print(f\"\u274c Error: {response.json()}\")\n\nif __name__ == \"__main__\":\n    try:\n        test_deep_analysis()\n        test_explore_endpoint()"}, {"id": "test_files/test_deep_analysis.py_9", "file": "test_files/test_deep_analysis.py", "content": "if __name__ == \"__main__\":\n    try:\n        test_deep_analysis()\n        test_explore_endpoint()\n        \n        print(\"\\n\ud83c\udf89 Deep analysis testing completed!\")\n        \n    except requests.exceptions.ConnectionError:\n        print(\"\u274c Error: Could not connect to Flask server.\")\n        print(\"Make sure the server is running with: python app.py\")\n    except Exception as e:\n        print(f\"\u274c Error: {e}\")"}, {"id": "test_files/test_final.py_0", "file": "test_files/test_final.py", "content": "================================================\n#!/usr/bin/env python3\n\"\"\"\nFinal clean RAG test - no warnings, no Unicode issues\n\"\"\"\n\nimport os\nimport sys\nimport warnings\n\n# Suppress everything\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nos.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\nos.environ['PYTHONWARNINGS'] = 'ignore'\nwarnings.filterwarnings('ignore')\n\nfrom pathlib import Path\nimport logging\nlogging.disable(logging.CRITICAL)\n\nsys.path.append(str(Path(__file__).parent))"}, {"id": "test_files/test_final.py_1", "file": "test_files/test_final.py", "content": "def main():\n    print(\"Running Clean RAG Test\")\n    print(\"=\" * 30)\n    \n    try:\n        from services.rag_system import CPUOptimizedRAGSystem\n        \n        gitingest_file = \"gitingest_outputs/Emon69420_HazMapApp_20250905_194000.txt\"\n        \n        if not os.path.exists(gitingest_file):\n            print(f\"File not found: {gitingest_file}\")\n            return\n        \n        print(\"Building RAG index...\")\n        \n        # Silent build\n        with open(os.devnull, 'w') as devnull:\n            old_stdout = sys.stdout\n            old_stderr = sys.stderr\n            sys.stdout = devnull\n            sys.stderr = devnull\n            \n            try:\n                rag = CPUOptimizedRAGSystem(storage_path=\"./final_rag\")"}, {"id": "test_files/test_final.py_2", "file": "test_files/test_final.py", "content": "try:\n                rag = CPUOptimizedRAGSystem(storage_path=\"./final_rag\")\n                metrics = rag.build_rag_from_gitingest(gitingest_file, \"final_test\")\n            finally:\n                sys.stdout = old_stdout\n                sys.stderr = old_stderr\n        \n        print(f\"SUCCESS: {metrics.total_chunks} chunks from {metrics.total_files} files\")\n        \n        # Test searches\n        searches = [\n            (\"login authentication\", \"Login\"),\n            (\"wildfire prediction\", \"Wildfire\"),\n            (\"location GPS\", \"Location\"),\n            (\"map component\", \"Map\"),\n            (\"background task\", \"Background\"),\n            (\"user profile\", \"Profile\")\n        ]\n        \n        print(f\"\\nTesting {len(searches)} searches:\")"}, {"id": "test_files/test_final.py_3", "file": "test_files/test_final.py", "content": "]\n        \n        print(f\"\\nTesting {len(searches)} searches:\")\n        \n        for query, desc in searches:\n            # Silent query\n            with open(os.devnull, 'w') as devnull:\n                old_stderr = sys.stderr\n                sys.stderr = devnull\n                try:\n                    result = rag.query(query, max_results=1, collection_name=\"final_test\")\n                finally:\n                    sys.stderr = old_stderr\n            \n            if result.chunks:\n                chunk = result.chunks[0]\n                file_name = Path(chunk.file_path).name\n                func_name = chunk.metadata.get('function_name', 'N/A')\n                print(f\"  {desc}: {func_name} in {file_name}\")"}, {"id": "test_files/test_final.py_4", "file": "test_files/test_final.py", "content": "print(f\"  {desc}: {func_name} in {file_name}\")\n        \n        print(f\"\\nSummary: {metrics.total_files} files, {metrics.total_chunks} chunks\")\n        print(\"Test complete!\")\n        \n        # Cleanup\n        try:\n            rag.chroma_client = None\n            rag.collection = None\n            import shutil\n            import time\n            time.sleep(0.5)\n            if os.path.exists(\"./final_rag\"):\n                shutil.rmtree(\"./final_rag\")\n        except:\n            pass\n            \n    except Exception as e:\n        print(f\"Error: {e}\")\n\nif __name__ == \"__main__\":\n    main()"}, {"id": "test_files/test_find_functions.py_0", "file": "test_files/test_find_functions.py", "content": "================================================\n#!/usr/bin/env python3\n\"\"\"\n\n\"\"\"\n\nimport sys\nimport os\nfrom pathlib import Path\n\n# Add services to path\nsys.path.append(str(Path(__file__).parent))\n\ntry:\n    from services.rag_system import CPUOptimizedRAGSystem\nexcept ImportError as e:\n    print(f\"\u274c Import error: {e}\")\n    sys.exit(1)"}, {"id": "test_files/test_find_functions.py_1", "file": "test_files/test_find_functions.py", "content": "def test_find_specific_functions():\n    \"\"\"Test finding specific functions and components\"\"\"\n    print(\"\ud83d\udd0d Testing Function & Component Discovery\")\n    print(\"=\" * 50)\n    \n    gitingest_file = \"https://github.com/Emon69420/MedMint\"\n    \n    if not os.path.exists(gitingest_file):\n        print(f\"\u274c Gitingest file not found: {gitingest_file}\")\n        return\n    \n    try:\n        # Initialize RAG system\n        print(\"\ud83d\udd27 Building RAG index...\")\n        rag = CPUOptimizedRAGSystem(storage_path=\"./temp_rag_storage\")\n        \n        # Build RAG system\n        metrics = rag.build_rag_from_gitingest(gitingest_file, \"find_functions_test\")\n        print(f\"\u2705 Indexed {metrics.total_chunks} chunks from {metrics.total_files} files\")\n        \n        # Test specific function/component searches"}, {"id": "test_files/test_find_functions.py_2", "file": "test_files/test_find_functions.py", "content": "# Test specific function/component searches\n        searches = [\n            {\n                \"query\": \"authentication login function\",\n                \"expect\": \"Should find login-related code\"\n            },\n            {\n                \"query\": \"wildfire risk prediction algorithm\",\n                \"expect\": \"Should find prediction functions in Flask backend\"\n            },\n            {\n                \"query\": \"Flask backend get_wildfire_risk_prediction function\",\n                \"expect\": \"Should find the main Python prediction function\"\n            },\n            {\n                \"query\": \"gee_data Google Earth Engine API\",\n                \"expect\": \"Should find the GEE data processing function\"\n            },\n            {"}, {"id": "test_files/test_find_functions.py_3", "file": "test_files/test_find_functions.py", "content": "},\n            {\n                \"query\": \"Python Flask route handler\",\n                \"expect\": \"Should find Flask route functions like home and about\"\n            },\n            {\n                \"query\": \"environmental data processing Python\",\n                \"expect\": \"Should find Python functions that process environmental data\"\n            },\n            {\n                \"query\": \"location tracking GPS coordinates\",\n                \"expect\": \"Should find LocationContext and location services\"\n            },\n            {\n                \"query\": \"air quality monitoring API calls\",\n                \"expect\": \"Should find air quality related functions\"\n            },\n            {\n                \"query\": \"React Native map component MapView\","}, {"id": "test_files/test_find_functions.py_4", "file": "test_files/test_find_functions.py", "content": "},\n            {\n                \"query\": \"React Native map component MapView\",\n                \"expect\": \"Should find map implementation\"\n            },\n            {\n                \"query\": \"background task notification system\",\n                \"expect\": \"Should find background task services\"\n            },\n            {\n                \"query\": \"user profile management settings\",\n                \"expect\": \"Should find profile screen and user management\"\n            },\n            {\n                \"query\": \"evacuation route planning emergency\",\n                \"expect\": \"Should find evacuation-related components\"\n            },\n            {\n                \"query\": \"Python test functions pytest\",\n                \"expect\": \"Should find test functions in test_app.py\""}, {"id": "test_files/test_find_functions.py_5", "file": "test_files/test_find_functions.py", "content": "\"expect\": \"Should find test functions in test_app.py\"\n            },\n            {\n                \"query\": \"Flask app configuration setup\",\n                \"expect\": \"Should find Flask app initialization and config\"\n            }\n        ]\n        \n        print(f\"\\n\ud83c\udfaf Testing {len(searches)} specific searches:\")\n        print(\"=\" * 50)\n        \n        for i, search in enumerate(searches, 1):\n            print(f\"\\n\ud83d\udd0e Search {i}: '{search['query']}'\")\n            print(f\"   Expected: {search['expect']}\")\n            \n            # Query the RAG system\n            result = rag.query(search['query'], max_results=3, collection_name=\"find_functions_test\")\n            \n            print(f\"   \u26a1 Found {len(result.chunks)} results:\")"}, {"id": "test_files/test_find_functions.py_6", "file": "test_files/test_find_functions.py", "content": "print(f\"   \u26a1 Found {len(result.chunks)} results:\")\n            \n            # Show results with confidence scores\n            for j, (chunk, confidence) in enumerate(zip(result.chunks, result.confidence_scores)):\n                confidence_emoji = \"\ud83c\udfaf\" if confidence > 0.1 else \"\ud83d\udccd\" if confidence > 0.05 else \"\ud83d\udccc\"\n                print(f\"     {confidence_emoji} {chunk.chunk_type} in {chunk.file_path}\")\n                print(f\"        Confidence: {confidence:.3f}\")\n                \n                # Show content preview\n                preview = chunk.content.replace('\\n', ' ')[:80]\n                print(f\"        Preview: {preview}...\")\n                \n                # Show metadata if available\n                if chunk.metadata:"}, {"id": "test_files/test_find_functions.py_7", "file": "test_files/test_find_functions.py", "content": "# Show metadata if available\n                if chunk.metadata:\n                    relevant_meta = {}\n                    for key in ['function_name', 'class_name', 'method_name']:\n                        if key in chunk.metadata and chunk.metadata[key]:\n                            relevant_meta[key] = chunk.metadata[key]\n                    if relevant_meta:\n                        print(f\"        Metadata: {relevant_meta}\")\n            \n            # Show relationships if found\n            if result.relationships and any(result.relationships.values()):\n                related_info = []\n                for rel_type, items in result.relationships.items():\n                    if items:"}, {"id": "test_files/test_find_functions.py_8", "file": "test_files/test_find_functions.py", "content": "for rel_type, items in result.relationships.items():\n                    if items:\n                        related_info.append(f\"{rel_type}: {len(items)}\")\n                if related_info:\n                    print(f\"   \ud83d\udd17 Related: {', '.join(related_info)}\")\n        \n        # Test finding specific code patterns\n        print(f\"\\n\ud83e\udde9 Testing Code Pattern Discovery:\")\n        print(\"=\" * 30)\n        \n        pattern_searches = [\n            \"async function with await\",\n            \"React useState hook\",\n            \"API fetch request\",\n            \"error handling try catch\",\n            \"TypeScript interface definition\",\n            \"Python Flask route decorator\",\n            \"Python function with parameters\",\n            \"Python import statement\","}, {"id": "test_files/test_find_functions.py_9", "file": "test_files/test_find_functions.py", "content": "\"Python function with parameters\",\n            \"Python import statement\",\n            \"Python class definition\",\n            \"Python exception handling try except\"\n        ]\n        \n        for pattern in pattern_searches:\n            print(f\"\\n\ud83d\udd0d Pattern: '{pattern}'\")\n            result = rag.query(pattern, max_results=2, collection_name=\"find_functions_test\")\n            \n            for chunk, confidence in zip(result.chunks[:2], result.confidence_scores[:2]):\n                if confidence > 0.01:  # Only show if there's some relevance\n                    print(f\"   \ud83d\udcc4 {chunk.file_path} (confidence: {confidence:.3f})\")\n                    # Show a longer preview for code patterns\n                    preview = chunk.content.replace('\\n', ' ')[:120]"}, {"id": "test_files/test_find_functions.py_10", "file": "test_files/test_find_functions.py", "content": "preview = chunk.content.replace('\\n', ' ')[:120]\n                    print(f\"      {preview}...\")\n        \n        # Summary of what we found\n        print(f\"\\n\ud83d\udcca Discovery Summary:\")\n        print(\"=\" * 20)\n        \n        # Get all chunks to analyze what we have\n        all_results = rag.query(\"*\", max_results=50, collection_name=\"find_functions_test\")\n        \n        # Count by file type\n        file_types = {}\n        chunk_types = {}\n        \n        for chunk in all_results.chunks:\n            # File extension\n            ext = Path(chunk.file_path).suffix or 'no-ext'\n            file_types[ext] = file_types.get(ext, 0) + 1\n            \n            # Chunk type\n            chunk_types[chunk.chunk_type] = chunk_types.get(chunk.chunk_type, 0) + 1"}, {"id": "test_files/test_find_functions.py_11", "file": "test_files/test_find_functions.py", "content": "chunk_types[chunk.chunk_type] = chunk_types.get(chunk.chunk_type, 0) + 1\n        \n        print(\"\ud83d\udcc1 File types indexed:\")\n        for ext, count in sorted(file_types.items(), key=lambda x: x[1], reverse=True):\n            print(f\"   {ext}: {count} chunks\")\n        \n        print(\"\\n\ud83e\udde9 Chunk types created:\")\n        for chunk_type, count in sorted(chunk_types.items(), key=lambda x: x[1], reverse=True):\n            print(f\"   {chunk_type}: {count} chunks\")\n        \n        print(f\"\\n\ud83c\udf89 Function discovery test complete!\")\n        \n    except Exception as e:\n        print(f\"\\n\u274c Test failed: {str(e)}\")\n        import traceback\n        traceback.print_exc()\n        return 1\n    \n    finally:\n        # Clean up\n        try:\n            if 'rag' in locals():"}, {"id": "test_files/test_find_functions.py_12", "file": "test_files/test_find_functions.py", "content": "finally:\n        # Clean up\n        try:\n            if 'rag' in locals():\n                rag.chroma_client = None\n                rag.collection = None\n            \n            import shutil\n            import time\n            time.sleep(1)\n            if os.path.exists(\"./temp_rag_storage\"):\n                print(\"\ud83e\uddf9 Cleaning up...\")\n                shutil.rmtree(\"./temp_rag_storage\")\n        except Exception as e:\n            print(f\"\u26a0\ufe0f  Warning: Could not clean up: {e}\")\n    \n    return 0\n\n\nif __name__ == \"__main__\":\n    exit_code = test_find_specific_functions()\n    sys.exit(exit_code)"}, {"id": "test_files/test_find_functions_clean.py_0", "file": "test_files/test_find_functions_clean.py", "content": "================================================\nError reading file with 'cp1252': 'charmap' codec can't decode byte 0x9d in position 1034: character maps to <undefined>"}, {"id": "test_files/test_github_auth.py_0", "file": "test_files/test_github_auth.py", "content": "================================================\nimport unittest\nfrom unittest.mock import patch, MagicMock\nimport json\nfrom app import app, GitHubService"}, {"id": "test_files/test_github_auth.py_1", "file": "test_files/test_github_auth.py", "content": "class TestGitHubService(unittest.TestCase):\n    \n    def setUp(self):\n        self.app = app.test_client()\n        self.app.testing = True\n        self.github_service = GitHubService()\n    \n    @patch('requests.get')\n    def test_validate_token_success(self, mock_get):\n        \"\"\"Test successful token validation\"\"\"\n        # Mock successful GitHub API response\n        mock_response = MagicMock()\n        mock_response.status_code = 200\n        mock_response.json.return_value = {\n            'login': 'testuser',\n            'id': 12345,\n            'name': 'Test User',\n            'email': 'test@example.com'\n        }\n        mock_response.headers = {'X-OAuth-Scopes': 'repo, user:email'}\n        mock_get.return_value = mock_response"}, {"id": "test_files/test_github_auth.py_2", "file": "test_files/test_github_auth.py", "content": "mock_get.return_value = mock_response\n        \n        result = self.github_service.validate_token('valid_token')\n        \n        self.assertTrue(result['valid'])\n        self.assertEqual(result['user']['login'], 'testuser')\n        self.assertIn('repo', result['scopes'])\n    \n    @patch('requests.get')\n    def test_validate_token_invalid(self, mock_get):\n        \"\"\"Test invalid token validation\"\"\"\n        # Mock failed GitHub API response\n        mock_response = MagicMock()\n        mock_response.status_code = 401\n        mock_get.return_value = mock_response\n        \n        result = self.github_service.validate_token('invalid_token')\n        \n        self.assertFalse(result['valid'])\n        self.assertIn('error', result)\n    \n    def test_get_oauth_url(self):"}, {"id": "test_files/test_github_auth.py_3", "file": "test_files/test_github_auth.py", "content": "self.assertIn('error', result)\n    \n    def test_get_oauth_url(self):\n        \"\"\"Test OAuth URL generation\"\"\"\n        with patch.dict('os.environ', {'GITHUB_CLIENT_ID': 'test_client_id'}):\n            url = self.github_service.get_oauth_url('test_state')\n            \n            self.assertIn('github.com/login/oauth/authorize', url)\n            self.assertIn('client_id=test_client_id', url)\n            self.assertIn('state=test_state', url)\n    \n    def test_login_with_token(self):\n        \"\"\"Test login endpoint with personal access token\"\"\"\n        with patch.object(self.github_service, 'validate_token') as mock_validate:\n            mock_validate.return_value = {\n                'valid': True,\n                'user': {'login': 'testuser', 'id': 12345},"}, {"id": "test_files/test_github_auth.py_4", "file": "test_files/test_github_auth.py", "content": "'valid': True,\n                'user': {'login': 'testuser', 'id': 12345},\n                'scopes': ['repo', 'user:email']\n            }\n            \n            response = self.app.post('/auth/github/login',\n                                   data=json.dumps({'token': 'test_token'}),\n                                   content_type='application/json')\n            \n            self.assertEqual(response.status_code, 200)\n            data = json.loads(response.data)\n            self.assertTrue(data['success'])\n            self.assertEqual(data['user']['login'], 'testuser')\n    \n    def test_login_with_oauth(self):\n        \"\"\"Test login endpoint OAuth flow initiation\"\"\"\n        with patch.dict('os.environ', {'GITHUB_CLIENT_ID': 'test_client_id'}):"}, {"id": "test_files/test_github_auth.py_5", "file": "test_files/test_github_auth.py", "content": "with patch.dict('os.environ', {'GITHUB_CLIENT_ID': 'test_client_id'}):\n            response = self.app.post('/auth/github/login',\n                                   data=json.dumps({'oauth': True}),\n                                   content_type='application/json')\n            \n            self.assertEqual(response.status_code, 200)\n            data = json.loads(response.data)\n            self.assertTrue(data['success'])\n            self.assertIn('oauth_url', data)\n    \n    def test_auth_status_authenticated(self):\n        \"\"\"Test auth status when user is authenticated\"\"\"\n        with self.app.session_transaction() as sess:\n            sess['github_token'] = 'test_token'\n            sess['github_user'] = {'login': 'testuser', 'id': 12345}"}, {"id": "test_files/test_github_auth.py_6", "file": "test_files/test_github_auth.py", "content": "sess['github_user'] = {'login': 'testuser', 'id': 12345}\n        \n        response = self.app.get('/auth/status')\n        \n        self.assertEqual(response.status_code, 200)\n        data = json.loads(response.data)\n        self.assertTrue(data['authenticated'])\n        self.assertEqual(data['user']['login'], 'testuser')\n    \n    def test_auth_status_not_authenticated(self):\n        \"\"\"Test auth status when user is not authenticated\"\"\"\n        response = self.app.get('/auth/status')\n        \n        self.assertEqual(response.status_code, 200)\n        data = json.loads(response.data)\n        self.assertFalse(data['authenticated'])\n    \n    def test_logout(self):\n        \"\"\"Test logout functionality\"\"\"\n        with self.app.session_transaction() as sess:"}, {"id": "test_files/test_github_auth.py_7", "file": "test_files/test_github_auth.py", "content": "\"\"\"Test logout functionality\"\"\"\n        with self.app.session_transaction() as sess:\n            sess['github_token'] = 'test_token'\n            sess['github_user'] = {'login': 'testuser'}\n        \n        response = self.app.post('/auth/logout')\n        \n        self.assertEqual(response.status_code, 200)\n        data = json.loads(response.data)\n        self.assertTrue(data['success'])\n    \n    def test_parse_github_url(self):\n        \"\"\"Test GitHub URL parsing\"\"\"\n        # Test various URL formats\n        test_cases = [\n            ('https://github.com/owner/repo', {'owner': 'owner', 'repo': 'repo'}),\n            ('https://github.com/owner/repo.git', {'owner': 'owner', 'repo': 'repo'}),\n            ('git@github.com:owner/repo.git', {'owner': 'owner', 'repo': 'repo'}),"}, {"id": "test_files/test_github_auth.py_8", "file": "test_files/test_github_auth.py", "content": "('git@github.com:owner/repo.git', {'owner': 'owner', 'repo': 'repo'}),\n            ('https://github.com/owner/repo/', {'owner': 'owner', 'repo': 'repo'}),\n            ('invalid-url', None)\n        ]\n        \n        for url, expected in test_cases:\n            result = self.github_service.parse_github_url(url)\n            self.assertEqual(result, expected)\n    \n    @patch('requests.get')\n    def test_validate_repository_access_public(self, mock_get):\n        \"\"\"Test repository validation for public repo\"\"\"\n        mock_response = MagicMock()\n        mock_response.status_code = 200\n        mock_response.json.return_value = {\n            'name': 'test-repo',\n            'full_name': 'owner/test-repo',\n            'private': False,\n            'description': 'Test repository'"}, {"id": "test_files/test_github_auth.py_9", "file": "test_files/test_github_auth.py", "content": "'private': False,\n            'description': 'Test repository'\n        }\n        mock_get.return_value = mock_response\n        \n        result = self.github_service.validate_repository_access('owner', 'test-repo')\n        \n        self.assertTrue(result['accessible'])\n        self.assertEqual(result['repo_info']['name'], 'test-repo')\n        self.assertFalse(result['repo_info']['private'])\n    \n    def test_validate_repository_endpoint(self):\n        \"\"\"Test repository validation endpoint\"\"\"\n        with patch.object(self.github_service, 'parse_github_url') as mock_parse, \\\n             patch.object(self.github_service, 'validate_repository_access') as mock_validate:\n            \n            mock_parse.return_value = {'owner': 'owner', 'repo': 'repo'}"}, {"id": "test_files/test_github_auth.py_10", "file": "test_files/test_github_auth.py", "content": "mock_parse.return_value = {'owner': 'owner', 'repo': 'repo'}\n            mock_validate.return_value = {\n                'accessible': True,\n                'repo_info': {'name': 'repo', 'private': False}\n            }\n            \n            response = self.app.post('/api/repositories/validate',\n                                   data=json.dumps({'url': 'https://github.com/owner/repo'}),\n                                   content_type='application/json')\n            \n            self.assertEqual(response.status_code, 200)\n            data = json.loads(response.data)\n            self.assertTrue(data['success'])\n            self.assertEqual(data['repository']['name'], 'repo')\n    \n    def test_analyze_repository_endpoint(self):"}, {"id": "test_files/test_github_auth.py_11", "file": "test_files/test_github_auth.py", "content": "def test_analyze_repository_endpoint(self):\n        \"\"\"Test repository analysis endpoint\"\"\"\n        with patch.object(self.github_service, 'parse_github_url') as mock_parse, \\\n             patch.object(self.github_service, 'validate_repository_access') as mock_validate, \\\n             patch.object(self.github_service, 'get_repository_tree') as mock_tree:\n            \n            mock_parse.return_value = {'owner': 'owner', 'repo': 'repo'}\n            mock_validate.return_value = {\n                'accessible': True,\n                'repo_info': {'name': 'repo', 'private': False}\n            }\n            mock_tree.return_value = {\n                'success': True,\n                'tree': {'files': [], 'directories': [], 'total_files': 0}\n            }"}, {"id": "test_files/test_github_auth.py_12", "file": "test_files/test_github_auth.py", "content": "}\n            \n            response = self.app.post('/api/repositories/analyze',\n                                   data=json.dumps({'url': 'https://github.com/owner/repo'}),\n                                   content_type='application/json')\n            \n            self.assertEqual(response.status_code, 200)\n            data = json.loads(response.data)\n            self.assertTrue(data['success'])\n            self.assertIn('analysis', data)\n\nif __name__ == '__main__':\n    unittest.main()"}, {"id": "test_files/test_gitingest.py_0", "file": "test_files/test_gitingest.py", "content": "================================================\nError reading file with 'cp1252': 'charmap' codec can't decode byte 0x81 in position 1533: character maps to <undefined>"}, {"id": "test_files/test_gitingest_simple.py_0", "file": "test_files/test_gitingest_simple.py", "content": "================================================\n#!/usr/bin/env python3\n\"\"\"\nSimple direct test of gitingest command to debug encoding issues.\n\"\"\"\n\nimport subprocess\nimport sys"}, {"id": "test_files/test_gitingest_simple.py_1", "file": "test_files/test_gitingest_simple.py", "content": "def test_direct_gitingest():\n    \"\"\"Test gitingest directly with a simple repo\"\"\"\n    \n    print(\"\ud83e\uddea Testing gitingest directly...\")\n    \n    # Test with a very simple repo\n    repo_url = \"https://github.com/octocat/Hello-World\"\n    \n    try:\n        # Simple gitingest command\n        cmd = ['gitingest', repo_url, '--output', '-']\n        \n        print(f\"\ud83d\udd27 Running: {' '.join(cmd)}\")\n        \n        # Try with UTF-8 encoding\n        result = subprocess.run(\n            cmd,\n            capture_output=True,\n            text=True,\n            timeout=60,\n            encoding='utf-8',\n            errors='replace'\n        )\n        \n        print(f\"\ud83d\udcca Return code: {result.returncode}\")\n        print(f\"\ud83d\udccf Stdout length: {len(result.stdout)} chars\")"}, {"id": "test_files/test_gitingest_simple.py_2", "file": "test_files/test_gitingest_simple.py", "content": "print(f\"\ud83d\udccf Stdout length: {len(result.stdout)} chars\")\n        print(f\"\ud83d\udccf Stderr length: {len(result.stderr)} chars\")\n        \n        if result.returncode == 0:\n            print(\"\u2705 Success! Here's the first 500 chars of output:\")\n            print(\"-\" * 50)\n            print(result.stdout[:500])\n            print(\"-\" * 50)\n            if len(result.stdout) > 500:\n                print(f\"... and {len(result.stdout) - 500} more characters\")\n        else:\n            print(\"\u274c Failed!\")\n            print(\"STDERR:\")\n            print(result.stderr)\n            \n    except subprocess.TimeoutExpired:\n        print(\"\u23f0 Command timed out\")\n    except Exception as e:\n        print(f\"\ud83d\udca5 Error: {e}\")"}, {"id": "test_files/test_gitingest_simple.py_3", "file": "test_files/test_gitingest_simple.py", "content": "def test_gitingest_to_file():\n    \"\"\"Test gitingest with file output instead of stdout\"\"\"\n    \n    print(\"\\n\ud83e\uddea Testing gitingest with file output...\")\n    \n    repo_url = \"https://github.com/octocat/Hello-World\"\n    output_file = \"test_output.txt\"\n    \n    try:\n        # Output to file instead of stdout\n        cmd = ['gitingest', repo_url, '--output', output_file]\n        \n        print(f\"\ud83d\udd27 Running: {' '.join(cmd)}\")\n        \n        result = subprocess.run(\n            cmd,\n            capture_output=True,\n            text=True,\n            timeout=60,\n            encoding='utf-8',\n            errors='replace'\n        )\n        \n        print(f\"\ud83d\udcca Return code: {result.returncode}\")\n        \n        if result.returncode == 0:\n            print(\"\u2705 Success! Checking output file...\")"}, {"id": "test_files/test_gitingest_simple.py_4", "file": "test_files/test_gitingest_simple.py", "content": "if result.returncode == 0:\n            print(\"\u2705 Success! Checking output file...\")\n            try:\n                with open(output_file, 'r', encoding='utf-8') as f:\n                    content = f.read()\n                    print(f\"\ud83d\udccf File size: {len(content)} chars\")\n                    print(\"\ud83d\udcc4 First 500 chars:\")\n                    print(\"-\" * 50)\n                    print(content[:500])\n                    print(\"-\" * 50)\n                    \n                # Clean up\n                import os\n                os.remove(output_file)\n                print(\"\ud83e\uddf9 Cleaned up output file\")\n                \n            except Exception as e:\n                print(f\"\u274c Error reading output file: {e}\")\n        else:\n            print(\"\u274c Failed!\")\n            print(\"STDERR:\")"}, {"id": "test_files/test_gitingest_simple.py_5", "file": "test_files/test_gitingest_simple.py", "content": "else:\n            print(\"\u274c Failed!\")\n            print(\"STDERR:\")\n            print(result.stderr)\n            \n    except subprocess.TimeoutExpired:\n        print(\"\u23f0 Command timed out\")\n    except Exception as e:\n        print(f\"\ud83d\udca5 Error: {e}\")\n\nif __name__ == \"__main__\":\n    test_direct_gitingest()\n    test_gitingest_to_file()"}, {"id": "test_files/test_gitingest_with_output.py_0", "file": "test_files/test_gitingest_with_output.py", "content": "================================================\nError reading file with 'cp1252': 'charmap' codec can't decode byte 0x81 in position 1276: character maps to <undefined>"}, {"id": "test_files/test_hazmap.py_0", "file": "test_files/test_hazmap.py", "content": "================================================\n#!/usr/bin/env python3\nimport requests\nimport json\n\nBASE_URL = \"http://localhost:5000\""}, {"id": "test_files/test_hazmap.py_1", "file": "test_files/test_hazmap.py", "content": "def test_hazmap_analysis():\n    print(\"Analyzing HazMapApp repository...\")\n    \n    url = f\"{BASE_URL}/api/repositories/analyze\"\n    data = {\"url\": \"https://github.com/Emon69420/HazMapApp\"}\n    \n    response = requests.post(url, json=data)\n    print(f\"Status: {response.status_code}\")\n    \n    if response.status_code == 200:\n        result = response.json()\n        analysis = result['analysis']\n        \n        print(f\"Repository: {analysis['repository']['full_name']}\")\n        print(f\"Description: {analysis['repository']['description']}\")\n        print(f\"Language: {analysis['repository']['language']}\")\n        print(f\"Size: {analysis['repository']['size']} KB\")\n        print(f\"Stars: {analysis['repository']['stargazers_count']}\")"}, {"id": "test_files/test_hazmap.py_2", "file": "test_files/test_hazmap.py", "content": "print(f\"Stars: {analysis['repository']['stargazers_count']}\")\n        print(f\"Default branch: {analysis['repository']['default_branch']}\")\n        print()\n        \n        structure = analysis['structure']\n        print(f\"Total files: {structure['total_files']}\")\n        print(f\"Total directories: {structure['total_directories']}\")\n        print()\n        \n        print(\"File structure (first 10 files):\")\n        for file in structure['files'][:10]:\n            print(f\"  - {file['path']} ({file['size']} bytes)\")\n        \n        if len(structure['files']) > 10:\n            print(f\"  ... and {len(structure['files']) - 10} more files\")\n        \n    else:\n        print(f\"Error: {response.json()}\")"}, {"id": "test_files/test_hazmap.py_3", "file": "test_files/test_hazmap.py", "content": "def test_get_readme():\n    print(\"\\nGetting README.md content...\")\n    \n    url = f\"{BASE_URL}/api/repositories/Emon69420/HazMapApp/files/README.md\"\n    \n    response = requests.get(url)\n    print(f\"Status: {response.status_code}\")\n    \n    if response.status_code == 200:\n        result = response.json()\n        file_info = result['file']\n        \n        print(f\"File: {file_info['name']}\")\n        print(f\"Size: {file_info['size']} bytes\")\n        print(f\"Encoding: {file_info['encoding']}\")\n        print(f\"Download URL: {file_info['download_url']}\")\n        \n        # Decode base64 content if available\n        if file_info['content'] and file_info['encoding'] == 'base64':\n            import base64\n            content = base64.b64decode(file_info['content']).decode('utf-8')"}, {"id": "test_files/test_hazmap.py_4", "file": "test_files/test_hazmap.py", "content": "content = base64.b64decode(file_info['content']).decode('utf-8')\n            print(\"\\nREADME content (first 500 chars):\")\n            print(content[:500] + \"...\" if len(content) > 500 else content)\n    else:\n        print(f\"Error: {response.json()}\")\n\nif __name__ == \"__main__\":\n    try:\n        test_hazmap_analysis()\n        test_get_readme()\n    except requests.exceptions.ConnectionError:\n        print(\"Error: Could not connect to Flask server.\")\n        print(\"Make sure the server is running with: python app.py\")\n    except Exception as e:\n        print(f\"Error: {e}\")"}, {"id": "test_files/test_hazmap_rag.py_0", "file": "test_files/test_hazmap_rag.py", "content": "================================================\n#!/usr/bin/env python3\n\"\"\"\nTest RAG system with HazMap app gitingest output\n\"\"\"\n\nimport sys\nimport os\nfrom pathlib import Path\nimport time\n\n# Add services to path\nsys.path.append(str(Path(__file__).parent))\n\ntry:\n    from services.rag_system import CPUOptimizedRAGSystem, GitingestParser\n    from services.code_analyzer import MultiLanguageCodeAnalyzer\nexcept ImportError as e:\n    print(f\"\u274c Import error: {e}\")\n    sys.exit(1)"}, {"id": "test_files/test_hazmap_rag.py_1", "file": "test_files/test_hazmap_rag.py", "content": "def test_hazmap_rag():\n    \"\"\"Test RAG system with HazMap app\"\"\"\n    print(\"\ud83d\ude80 Testing RAG System with HazMap App\")\n    print(\"=\" * 60)\n    \n    gitingest_file = \"gitingest_outputs/Emon69420_HazMapApp_20250905_194000.txt\"\n    \n    if not os.path.exists(gitingest_file):\n        print(f\"\u274c Gitingest file not found: {gitingest_file}\")\n        return\n    \n    try:\n        # Initialize RAG system\n        print(\"\ud83d\udd27 Initializing RAG system...\")\n        rag = CPUOptimizedRAGSystem(storage_path=\"./hazmap_rag_storage\")\n        \n        # Build RAG system from HazMap gitingest\n        print(\"\ud83d\udcca Building RAG system from HazMap codebase...\")\n        start_time = time.time()\n        \n        metrics = rag.build_rag_from_gitingest(gitingest_file, \"hazmap_collection\")"}, {"id": "test_files/test_hazmap_rag.py_2", "file": "test_files/test_hazmap_rag.py", "content": "metrics = rag.build_rag_from_gitingest(gitingest_file, \"hazmap_collection\")\n        \n        build_time = time.time() - start_time\n        \n        print(f\"\\n\u2705 RAG system built successfully!\")\n        print(f\"  \ud83d\udcc1 Total files: {metrics.total_files}\")\n        print(f\"  \ud83e\udde9 Total chunks: {metrics.total_chunks}\")\n        print(f\"  \ud83c\udf10 Languages: {', '.join(metrics.languages_detected)}\")\n        print(f\"  \u23f1\ufe0f  Build time: {build_time:.2f}s\")\n        print(f\"  \ud83d\udcbe Index size: {metrics.index_size_mb:.2f}MB\")\n        \n        # Test queries relevant to HazMap\n        test_queries = [\n            \"How do I implement location tracking?\",\n            \"Show me authentication code\",\n            \"How is the map component implemented?\",\n            \"Find air quality monitoring functions\","}, {"id": "test_files/test_hazmap_rag.py_3", "file": "test_files/test_hazmap_rag.py", "content": "\"Find air quality monitoring functions\",\n            \"How does wildfire risk prediction work?\",\n            \"Show me background task implementation\",\n            \"How is user profile managed?\",\n            \"Find evacuation route planning code\",\n            \"How are notifications handled?\",\n            \"Show me the database configuration\",\n            \"How is the Google Maps API integrated?\",\n            \"Find React Native navigation setup\",\n            \"How are environmental data fetched?\",\n            \"Show me TypeScript interfaces\",\n            \"How is the app styled?\"\n        ]\n        \n        print(f\"\\n\ud83d\udd0d Testing {len(test_queries)} queries...\")\n        print(\"=\" * 60)\n        \n        for i, query in enumerate(test_queries, 1):"}, {"id": "test_files/test_hazmap_rag.py_4", "file": "test_files/test_hazmap_rag.py", "content": "print(\"=\" * 60)\n        \n        for i, query in enumerate(test_queries, 1):\n            print(f\"\\n\ud83d\udd0e Query {i}: '{query}'\")\n            \n            query_start = time.time()\n            result = rag.query(query, max_results=5, collection_name=\"hazmap_collection\")\n            query_time = time.time() - query_start\n            \n            print(f\"  \u26a1 Found {len(result.chunks)} results in {query_time:.3f}s\")\n            \n            # Show top 3 results\n            for j, (chunk, confidence) in enumerate(zip(result.chunks[:3], result.confidence_scores[:3])):\n                print(f\"    {j+1}. {chunk.chunk_type} in {chunk.file_path} (confidence: {confidence:.2f})\")\n                # Show a snippet of the content"}, {"id": "test_files/test_hazmap_rag.py_5", "file": "test_files/test_hazmap_rag.py", "content": "# Show a snippet of the content\n                content_preview = chunk.content.replace('\\n', ' ')[:100]\n                print(f\"       Preview: {content_preview}...\")\n            \n            if result.relationships and any(result.relationships.values()):\n                print(f\"    \ud83d\udd17 Related: {', '.join([f'{k}: {len(v)}' for k, v in result.relationships.items() if v])}\")\n        \n        # Test context generation for LLM\n        print(f\"\\n\ud83d\udcdd Testing context generation...\")\n        test_context_query = \"How does the HazMap app handle real-time wildfire monitoring and user notifications?\"\n        \n        result = rag.query(test_context_query, max_results=8, collection_name=\"hazmap_collection\")\n        context = rag.get_context_for_llm(result, max_tokens=2000)"}, {"id": "test_files/test_hazmap_rag.py_6", "file": "test_files/test_hazmap_rag.py", "content": "context = rag.get_context_for_llm(result, max_tokens=2000)\n        \n        print(f\"  \ud83d\udcc4 Generated context ({len(context)} chars):\")\n        print(f\"  Preview: {context[:300]}...\")\n        \n        # Show some interesting statistics\n        print(f\"\\n\ud83d\udcca HazMap Codebase Analysis:\")\n        \n        # Parse the gitingest file to get file breakdown\n        files = GitingestParser.parse_gitingest_file(gitingest_file)\n        analyzer = MultiLanguageCodeAnalyzer()\n        project_structure = analyzer.analyze_project(files)\n        \n        # Language breakdown\n        lang_stats = {}\n        for structure in project_structure.values():\n            lang = structure.language.value\n            if lang not in lang_stats:"}, {"id": "test_files/test_hazmap_rag.py_7", "file": "test_files/test_hazmap_rag.py", "content": "lang = structure.language.value\n            if lang not in lang_stats:\n                lang_stats[lang] = {'files': 0, 'functions': 0, 'classes': 0, 'lines': 0}\n            lang_stats[lang]['files'] += 1\n            lang_stats[lang]['functions'] += len(structure.functions)\n            lang_stats[lang]['classes'] += len(structure.classes)\n            lang_stats[lang]['lines'] += structure.total_lines\n        \n        for lang, stats in sorted(lang_stats.items(), key=lambda x: x[1]['lines'], reverse=True):\n            if stats['files'] > 0:\n                print(f\"  \ud83d\udd24 {lang.upper()}: {stats['files']} files, {stats['functions']} functions, {stats['classes']} classes, {stats['lines']} lines\")\n        \n        # Find key components\n        key_files = []"}, {"id": "test_files/test_hazmap_rag.py_8", "file": "test_files/test_hazmap_rag.py", "content": "# Find key components\n        key_files = []\n        for file_path, structure in project_structure.items():\n            if any(keyword in file_path.lower() for keyword in ['map', 'auth', 'profile', 'air-quality', 'evacuation']):\n                key_files.append((file_path, len(structure.functions), len(structure.classes)))\n        \n        if key_files:\n            print(f\"\\n\ud83c\udfaf Key Components Found:\")\n            for file_path, func_count, class_count in sorted(key_files, key=lambda x: x[1] + x[2], reverse=True)[:10]:\n                print(f\"  \ud83d\udcc4 {file_path}: {func_count} functions, {class_count} classes\")\n        \n        print(f\"\\n\ud83c\udf89 HazMap RAG analysis complete!\")\n        \n    except Exception as e:\n        print(f\"\\n\u274c Test failed: {str(e)}\")\n        import traceback"}, {"id": "test_files/test_hazmap_rag.py_9", "file": "test_files/test_hazmap_rag.py", "content": "except Exception as e:\n        print(f\"\\n\u274c Test failed: {str(e)}\")\n        import traceback\n        traceback.print_exc()\n        return 1\n    \n    finally:\n        # Clean up\n        try:\n            if 'rag' in locals():\n                rag.chroma_client = None\n                rag.collection = None\n            \n            import shutil\n            time.sleep(1)\n            if os.path.exists(\"./hazmap_rag_storage\"):\n                print(\"\ud83e\uddf9 Cleaning up storage...\")\n                shutil.rmtree(\"./hazmap_rag_storage\")\n        except Exception as e:\n            print(f\"\u26a0\ufe0f  Warning: Could not clean up storage: {e}\")\n    \n    return 0\n\n\nif __name__ == \"__main__\":\n    exit_code = test_hazmap_rag()\n    sys.exit(exit_code)"}, {"id": "test_files/test_rag_simple.py_0", "file": "test_files/test_rag_simple.py", "content": "================================================\n#!/usr/bin/env python3\n\"\"\"\nSimple test for CPU-optimized RAG system.\n\"\"\"\n\nimport os\nimport sys\nimport tempfile\nimport time\nfrom pathlib import Path\n\n# Add services to path\nsys.path.append(str(Path(__file__).parent))\n\ntry:\n    from services.rag_system import CPUOptimizedRAGSystem, GitingestParser\n    from services.code_analyzer import MultiLanguageCodeAnalyzer\nexcept ImportError as e:\n    print(f\"\u274c Import error: {e}\")\n    sys.exit(1)"}, {"id": "test_files/test_rag_simple.py_1", "file": "test_files/test_rag_simple.py", "content": "def test_simple_rag():\n    \"\"\"Test basic RAG functionality\"\"\"\n    print(\"\ud83d\ude80 Testing CPU-Optimized RAG System\")\n    print(\"=\" * 50)\n    \n    # Sample gitingest content\n    sample_content = \"\"\"\nDirectory structure:\n\u251c\u2500\u2500 calculator.py\n\u2514\u2500\u2500 main.py\n\n================================================================================\n\nFILE: calculator.py"}, {"id": "test_files/test_rag_simple.py_2", "file": "test_files/test_rag_simple.py", "content": "class Calculator:\n    \\\"\\\"\\\"Simple calculator class\\\"\\\"\\\"\n    \n    def __init__(self):\n        self.history = []\n    \n    def add(self, a, b):\n        \\\"\\\"\\\"Add two numbers\\\"\\\"\\\"\n        result = a + b\n        self.history.append(f\"{a} + {b} = {result}\")\n        return result\n    \n    def multiply(self, a, b):\n        \\\"\\\"\\\"Multiply two numbers\\\"\\\"\\\"\n        result = a * b\n        self.history.append(f\"{a} * {b} = {result}\")\n        return result\n\n================================================================================\n\nFILE: main.py\nfrom calculator import Calculator"}, {"id": "test_files/test_rag_simple.py_3", "file": "test_files/test_rag_simple.py", "content": "def main():\n    \\\"\\\"\\\"Main function\\\"\\\"\\\"\n    calc = Calculator()\n    result = calc.add(5, 3)\n    print(f\"5 + 3 = {result}\")\n    \n    product = calc.multiply(4, 6)\n    print(f\"4 * 6 = {product}\")\n\nif __name__ == \"__main__\":\n    main()\n\"\"\"\n    \n    # Use a persistent directory instead of temp\n    storage_dir = \"./rag_test_storage\"\n    \n    try:\n        # Clean up any existing storage\n        if os.path.exists(storage_dir):\n            import shutil\n            try:\n                shutil.rmtree(storage_dir)\n            except:\n                pass\n        \n        # Create gitingest file\n        gitingest_file = \"test_sample.txt\"\n        with open(gitingest_file, 'w', encoding='utf-8') as f:\n            f.write(sample_content)\n        \n        print(\"\ud83d\udcdd Created sample gitingest file\")"}, {"id": "test_files/test_rag_simple.py_4", "file": "test_files/test_rag_simple.py", "content": "f.write(sample_content)\n        \n        print(\"\ud83d\udcdd Created sample gitingest file\")\n        \n        # Initialize RAG system\n        print(\"\ud83d\udd27 Initializing RAG system...\")\n        rag = CPUOptimizedRAGSystem(storage_path=storage_dir)\n        \n        # Build RAG system\n        print(\"\ud83c\udfd7\ufe0f Building RAG system...\")\n        metrics = rag.build_rag_from_gitingest(gitingest_file, \"test_collection\")\n        \n        print(f\"\u2705 RAG system built successfully!\")\n        print(f\"  - Total chunks: {metrics.total_chunks}\")\n        print(f\"  - Total files: {metrics.total_files}\")\n        print(f\"  - Languages: {', '.join(metrics.languages_detected)}\")\n        print(f\"  - Build time: {metrics.build_time:.2f}s\")\n        print(f\"  - Index size: {metrics.index_size_mb:.2f}MB\")"}, {"id": "test_files/test_rag_simple.py_5", "file": "test_files/test_rag_simple.py", "content": "print(f\"  - Index size: {metrics.index_size_mb:.2f}MB\")\n        \n        # Test queries\n        test_queries = [\n            \"How do I add two numbers?\",\n            \"Show me calculator methods\",\n            \"What is the main function?\",\n            \"Find multiplication function\"\n        ]\n        \n        print(f\"\\n\ud83d\udd0d Testing queries...\")\n        for query in test_queries:\n            print(f\"\\nQuery: '{query}'\")\n            result = rag.query(query, max_results=3, collection_name=\"test_collection\")\n            \n            print(f\"  Found {len(result.chunks)} results in {result.query_time:.3f}s\")\n            for i, (chunk, confidence) in enumerate(zip(result.chunks, result.confidence_scores)):"}, {"id": "test_files/test_rag_simple.py_6", "file": "test_files/test_rag_simple.py", "content": "for i, (chunk, confidence) in enumerate(zip(result.chunks, result.confidence_scores)):\n                print(f\"  {i+1}. {chunk.chunk_type} in {chunk.file_path} (confidence: {confidence:.2f})\")\n                print(f\"     {chunk.content[:80]}...\")\n        \n        # Test context generation\n        print(f\"\\n\ud83d\udcdd Testing context generation...\")\n        result = rag.query(\"calculator functions\", max_results=5, collection_name=\"test_collection\")\n        context = rag.get_context_for_llm(result, max_tokens=1000)\n        print(f\"Generated context ({len(context)} chars):\")\n        print(context[:300] + \"...\" if len(context) > 300 else context)\n        \n        print(f\"\\n\ud83c\udf89 All tests completed successfully!\")\n        return True\n        \n    except Exception as e:"}, {"id": "test_files/test_rag_simple.py_7", "file": "test_files/test_rag_simple.py", "content": "return True\n        \n    except Exception as e:\n        print(f\"\\n\u274c Test failed: {str(e)}\")\n        import traceback\n        traceback.print_exc()\n        return False\n        \n    finally:\n        # Clean up files\n        try:\n            if os.path.exists(gitingest_file):\n                os.remove(gitingest_file)\n        except:\n            pass\n        \n        # Note: We'll leave the storage directory for manual cleanup\n        # since Windows file locking makes automatic cleanup difficult\n        print(f\"\\n\ud83d\udca1 Note: Test storage left at '{storage_dir}' for manual cleanup if needed\")\n\n\nif __name__ == \"__main__\":\n    success = test_simple_rag()\n    sys.exit(0 if success else 1)"}, {"id": "test_files/test_rag_system.py_0", "file": "test_files/test_rag_system.py", "content": "================================================\n#!/usr/bin/env python3\n\"\"\"\nTest script for CPU-optimized RAG system.\nThis tests the complete pipeline from gitingest file to queryable RAG system.\n\"\"\"\n\nimport asyncio\nimport sys\nimport os\nfrom pathlib import Path\nimport time\n\n# Add services to path\nsys.path.append(str(Path(__file__).parent))\n\ntry:\n    from services.rag_system import CPUOptimizedRAGSystem, GitingestParser\n    from services.code_analyzer import MultiLanguageCodeAnalyzer\nexcept ImportError as e:\n    print(f\"\u274c Import error: {e}\")\n    print(\"\ud83d\udca1 Make sure to install dependencies: pip install chromadb sentence-transformers networkx\")\n    sys.exit(1)"}, {"id": "test_files/test_rag_system.py_1", "file": "test_files/test_rag_system.py", "content": "def test_gitingest_parsing():\n    \"\"\"Test parsing of gitingest files\"\"\"\n    print(\"\ud83e\uddea Testing gitingest parsing...\")\n    \n    # Create a sample gitingest content\n    sample_content = \"\"\"\nDirectory structure:\n\u251c\u2500\u2500 main.py\n\u251c\u2500\u2500 utils.py\n\u2514\u2500\u2500 README.md\n\n================================================================================\n\nFILE: main.py\ndef hello_world():\n    \\\"\\\"\\\"Simple hello world function\\\"\\\"\\\"\n    print(\"Hello, World!\")\n    return \"success\"\n\nif __name__ == \"__main__\":\n    hello_world()\n\n================================================================================\n\nFILE: utils.py\nimport os\nimport sys\n\ndef get_file_size(filepath):\n    \\\"\\\"\\\"Get file size in bytes\\\"\\\"\\\"\n    return os.path.getsize(filepath)"}, {"id": "test_files/test_rag_system.py_2", "file": "test_files/test_rag_system.py", "content": "class FileManager:\n    def __init__(self, base_path):\n        self.base_path = base_path\n    \n    def list_files(self):\n        return os.listdir(self.base_path)\n\n================================================================================\n\nFILE: README.md\n# Test Project\n\nThis is a test project for RAG system.\n\"\"\"\n    \n    files = GitingestParser.parse_gitingest_content(sample_content)\n    \n    print(f\"\u2705 Parsed {len(files)} files:\")\n    for file_path, content in files.items():\n        print(f\"  - {file_path} ({len(content)} chars)\")\n    \n    return files"}, {"id": "test_files/test_rag_system.py_3", "file": "test_files/test_rag_system.py", "content": "def test_code_analysis():\n    \"\"\"Test multi-language code analysis\"\"\"\n    print(\"\\n\ud83e\uddea Testing code analysis...\")\n    \n    # Get sample files from gitingest parsing\n    files = test_gitingest_parsing()\n    \n    analyzer = MultiLanguageCodeAnalyzer()\n    project_structure = analyzer.analyze_project(files)\n    \n    print(f\"\u2705 Analyzed {len(project_structure)} files:\")\n    for file_path, structure in project_structure.items():\n        print(f\"  - {file_path}: {structure.language.value}\")\n        print(f\"    Functions: {len(structure.functions)}\")\n        print(f\"    Classes: {len(structure.classes)}\")\n        print(f\"    Imports: {len(structure.imports)}\")\n    \n    return project_structure"}, {"id": "test_files/test_rag_system.py_4", "file": "test_files/test_rag_system.py", "content": "def test_rag_system():\n    \"\"\"Test complete RAG system\"\"\"\n    print(\"\\n\ud83e\uddea Testing RAG system...\")\n    \n    import tempfile\n    \n    # Use a temporary directory that gets cleaned up automatically\n    with tempfile.TemporaryDirectory() as temp_dir:\n        # Initialize RAG system\n        rag = CPUOptimizedRAGSystem(storage_path=temp_dir)\n    \n        # Create a temporary gitingest file\n        temp_file = \"temp_gitingest.txt\"\n    sample_content = \"\"\"\nDirectory structure:\n\u251c\u2500\u2500 main.py\n\u251c\u2500\u2500 utils.py\n\u2514\u2500\u2500 calculator.py\n\n================================================================================\n\nFILE: main.py\ndef hello_world():\n    \\\"\\\"\\\"Simple hello world function\\\"\\\"\\\"\n    print(\"Hello, World!\")\n    return \"success\""}, {"id": "test_files/test_rag_system.py_5", "file": "test_files/test_rag_system.py", "content": "def main():\n    \\\"\\\"\\\"Main entry point\\\"\\\"\\\"\n    result = hello_world()\n    calc = Calculator()\n    sum_result = calc.add(5, 3)\n    print(f\"5 + 3 = {sum_result}\")\n\nif __name__ == \"__main__\":\n    main()\n\n================================================================================\n\nFILE: utils.py\nimport os\nimport sys\nfrom pathlib import Path\n\ndef get_file_size(filepath):\n    \\\"\\\"\\\"Get file size in bytes\\\"\\\"\\\"\n    return os.path.getsize(filepath)\n\ndef read_config(config_path):\n    \\\"\\\"\\\"Read configuration file\\\"\\\"\\\"\n    with open(config_path, 'r') as f:\n        return f.read()"}, {"id": "test_files/test_rag_system.py_6", "file": "test_files/test_rag_system.py", "content": "class FileManager:\n    def __init__(self, base_path):\n        self.base_path = base_path\n    \n    def list_files(self):\n        \\\"\\\"\\\"List all files in base path\\\"\\\"\\\"\n        return os.listdir(self.base_path)\n    \n    def create_file(self, filename, content):\n        \\\"\\\"\\\"Create a new file\\\"\\\"\\\"\n        filepath = Path(self.base_path) / filename\n        with open(filepath, 'w') as f:\n            f.write(content)\n\n================================================================================\n\nFILE: calculator.py"}, {"id": "test_files/test_rag_system.py_7", "file": "test_files/test_rag_system.py", "content": "class Calculator:\n    \\\"\\\"\\\"Simple calculator class\\\"\\\"\\\"\n    \n    def __init__(self):\n        self.history = []\n    \n    def add(self, a, b):\n        \\\"\\\"\\\"Add two numbers\\\"\\\"\\\"\n        result = a + b\n        self.history.append(f\"{a} + {b} = {result}\")\n        return result\n    \n    def subtract(self, a, b):\n        \\\"\\\"\\\"Subtract two numbers\\\"\\\"\\\"\n        result = a - b\n        self.history.append(f\"{a} - {b} = {result}\")\n        return result\n    \n    def multiply(self, a, b):\n        \\\"\\\"\\\"Multiply two numbers\\\"\\\"\\\"\n        result = a * b\n        self.history.append(f\"{a} * {b} = {result}\")\n        return result\n    \n    def get_history(self):\n        \\\"\\\"\\\"Get calculation history\\\"\\\"\\\"\n        return self.history.copy()\n\"\"\"\n    \n    # Write temporary file"}, {"id": "test_files/test_rag_system.py_8", "file": "test_files/test_rag_system.py", "content": "return self.history.copy()\n\"\"\"\n    \n    # Write temporary file\n    with open(temp_file, 'w', encoding='utf-8') as f:\n        f.write(sample_content)\n    \n    try:\n        # Build RAG system\n        print(\"Building RAG system...\")\n        metrics = rag.build_rag_from_gitingest(temp_file, \"test_collection\")\n        \n        print(f\"\u2705 RAG system built successfully!\")\n        print(f\"  - Total chunks: {metrics.total_chunks}\")\n        print(f\"  - Total files: {metrics.total_files}\")\n        print(f\"  - Languages: {', '.join(metrics.languages_detected)}\")\n        print(f\"  - Build time: {metrics.build_time:.2f}s\")\n        print(f\"  - Index size: {metrics.index_size_mb:.2f}MB\")\n        \n        # Test queries\n        test_queries = [\n            \"How do I add two numbers?\","}, {"id": "test_files/test_rag_system.py_9", "file": "test_files/test_rag_system.py", "content": "# Test queries\n        test_queries = [\n            \"How do I add two numbers?\",\n            \"Show me file management functions\",\n            \"What is the main entry point?\",\n            \"Find calculator methods\"\n        ]\n        \n        print(f\"\\n\ud83d\udd0d Testing queries...\")\n        for query in test_queries:\n            print(f\"\\nQuery: '{query}'\")\n            result = rag.query(query, max_results=3, collection_name=\"test_collection\")\n            \n            print(f\"  Found {len(result.chunks)} results in {result.query_time:.3f}s\")\n            for i, (chunk, confidence) in enumerate(zip(result.chunks, result.confidence_scores)):\n                print(f\"  {i+1}. {chunk.chunk_type} in {chunk.file_path} (confidence: {confidence:.2f})\")"}, {"id": "test_files/test_rag_system.py_10", "file": "test_files/test_rag_system.py", "content": "print(f\"     {chunk.content[:100]}...\")\n        \n        # Test context generation\n        print(f\"\\n\ud83d\udcdd Testing context generation...\")\n        result = rag.query(\"calculator functions\", max_results=5, collection_name=\"test_collection\")\n        context = rag.get_context_for_llm(result, max_tokens=1000)\n        print(f\"Generated context ({len(context)} chars):\")\n        print(context[:500] + \"...\" if len(context) > 500 else context)\n        \n    finally:\n        # Clean up\n        if os.path.exists(temp_file):\n            os.remove(temp_file)\n        \n        # Clean up test storage - close ChromaDB first\n        try:\n            if 'rag' in locals():\n                rag.cleanup()\n            \n            import shutil\n            import time\n            import gc"}, {"id": "test_files/test_rag_system.py_11", "file": "test_files/test_rag_system.py", "content": "import shutil\n            import time\n            import gc\n            \n            # Force garbage collection to release file handles\n            gc.collect()\n            time.sleep(2)  # Give more time for file handles to close\n            \n            if os.path.exists(\"./test_rag_storage\"):\n                shutil.rmtree(\"./test_rag_storage\")\n        except Exception as e:\n            print(f\"Warning: Could not clean up test storage: {e}\")\n            print(\"You may need to manually delete the ./test_rag_storage folder\")"}, {"id": "test_files/test_rag_system.py_12", "file": "test_files/test_rag_system.py", "content": "def main():\n    \"\"\"Run all tests\"\"\"\n    print(\"\ud83d\ude80 Starting RAG System Tests\")\n    print(\"=\" * 50)\n    \n    try:\n        # Test individual components\n        test_gitingest_parsing()\n        test_code_analysis()\n        \n        # Test complete system\n        test_rag_system()\n        \n        print(\"\\n\" + \"=\" * 50)\n        print(\"\ud83c\udf89 All tests completed successfully!\")\n        \n    except Exception as e:\n        print(f\"\\n\u274c Test failed: {str(e)}\")\n        import traceback\n        traceback.print_exc()\n        return 1\n    \n    return 0\n\n\nif __name__ == \"__main__\":\n    exit_code = main()\n    sys.exit(exit_code)"}, {"id": "test_files/test_silent.py_0", "file": "test_files/test_silent.py", "content": "================================================\n#!/usr/bin/env python3\n\"\"\"\nUltra-clean test with maximum warning suppression\n\"\"\"\n\nimport os\nimport sys\nimport warnings\nimport subprocess\n\n# Maximum suppression\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nos.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\nos.environ['ORT_DISABLE_ALL_LOGS'] = '1'\nos.environ['CUDA_VISIBLE_DEVICES'] = ''\nos.environ['PYTHONWARNINGS'] = 'ignore'\nwarnings.filterwarnings('ignore')\n\nfrom pathlib import Path\nimport logging\n\n# Suppress all logging\nlogging.disable(logging.CRITICAL)\n\nsys.path.append(str(Path(__file__).parent))"}, {"id": "test_files/test_silent.py_1", "file": "test_files/test_silent.py", "content": "def run_silent_test():\n    \"\"\"Run the test with maximum output suppression\"\"\"\n    print(\"\ud83d\udd07 Running SILENT RAG test...\")\n    print(\"=\" * 40)\n    \n    try:\n        from services.rag_system import CPUOptimizedRAGSystem\n        \n        gitingest_file = \"gitingest_outputs/Emon69420_HazMapApp_20250905_194000.txt\"\n        \n        if not os.path.exists(gitingest_file):\n            print(f\"\u274c File not found: {gitingest_file}\")\n            return\n        \n        print(\"\ud83d\udd27 Building index (silent)...\")\n        \n        # Redirect ALL output during initialization\n        with open(os.devnull, 'w') as devnull:\n            old_stdout = sys.stdout\n            old_stderr = sys.stderr\n            sys.stdout = devnull\n            sys.stderr = devnull\n            \n            try:"}, {"id": "test_files/test_silent.py_2", "file": "test_files/test_silent.py", "content": "sys.stdout = devnull\n            sys.stderr = devnull\n            \n            try:\n                rag = CPUOptimizedRAGSystem(storage_path=\"./silent_rag\")\n                metrics = rag.build_rag_from_gitingest(gitingest_file, \"silent_test\")\n            finally:\n                sys.stdout = old_stdout\n                sys.stderr = old_stderr\n        \n        print(f\"\u2705 Success! {metrics.total_chunks} chunks from {metrics.total_files} files\")\n        \n        # Test key searches silently\n        searches = [\n            (\"login authentication\", \"\ud83d\udd10 Login\"),\n            (\"wildfire prediction\", \"\ud83d\udd25 Wildfire\"),\n            (\"location GPS\", \"\ud83d\udccd Location\"),\n            (\"map component\", \"\ud83d\uddfa\ufe0f  Map\"),\n            (\"background task\", \"\u23f0 Background\"),"}, {"id": "test_files/test_silent.py_3", "file": "test_files/test_silent.py", "content": "(\"map component\", \"\ud83d\uddfa\ufe0f  Map\"),\n            (\"background task\", \"\u23f0 Background\"),\n            (\"user profile\", \"\ud83d\udc64 Profile\")\n        ]\n        \n        print(f\"\\n\ud83c\udfaf Testing {len(searches)} searches:\")\n        \n        for query, emoji_desc in searches:\n            # Silent query\n            with open(os.devnull, 'w') as devnull:\n                old_stderr = sys.stderr\n                sys.stderr = devnull\n                try:\n                    result = rag.query(query, max_results=1, collection_name=\"silent_test\")\n                finally:\n                    sys.stderr = old_stderr\n            \n            if result.chunks:\n                chunk = result.chunks[0]\n                confidence = result.confidence_scores[0]\n                \n                # Clean output"}, {"id": "test_files/test_silent.py_4", "file": "test_files/test_silent.py", "content": "# Clean output\n                file_name = Path(chunk.file_path).name\n                func_name = chunk.metadata.get('function_name', 'N/A')\n                \n                status = \"\ud83c\udfaf\" if confidence > 0.05 else \"\u2705\" if confidence > 0.01 else \"\ud83d\udccc\"\n                print(f\"   {status} {emoji_desc}: {func_name} in {file_name}\")\n        \n        print(f\"\\n\ud83d\udcca Index: {metrics.total_files} files, {metrics.total_chunks} chunks, {metrics.index_size_mb:.1f}MB\")\n        print(\"\ud83c\udf89 Silent test complete!\")\n        \n        # Silent cleanup\n        try:\n            rag.chroma_client = None\n            rag.collection = None\n            import shutil\n            import time\n            time.sleep(0.5)\n            if os.path.exists(\"./silent_rag\"):"}, {"id": "test_files/test_silent.py_5", "file": "test_files/test_silent.py", "content": "import time\n            time.sleep(0.5)\n            if os.path.exists(\"./silent_rag\"):\n                shutil.rmtree(\"./silent_rag\")\n        except:\n            pass\n            \n    except Exception as e:\n        print(f\"\u274c Error: {e}\")\n\nif __name__ == \"__main__\":\n    run_silent_test()"}, {"id": "test_files/test_timing_small.py_0", "file": "test_files/test_timing_small.py", "content": "================================================\n#!/usr/bin/env python3\n\"\"\"\nTest timing with a very small repository to minimize API calls\n\"\"\"\n\nimport requests\nimport json\n\nBASE_URL = \"http://localhost:5000\""}, {"id": "test_files/test_timing_small.py_1", "file": "test_files/test_timing_small.py", "content": "def test_small_repo_timing():\n    \"\"\"Test with a very small repository\"\"\"\n    print(\"\ud83d\udd0d Testing timing with small repository...\")\n    print(\"Note: This might still fail due to rate limits\")\n    \n    # Try with a very small, well-known repo\n    url = f\"{BASE_URL}/api/repositories/deep-analyze\"\n    data = {\n        \"url\": \"https://github.com/octocat/Hello-World\",  # Very small repo\n        \"max_file_size\": 1024 * 1024  # 1MB limit\n    }\n    \n    response = requests.post(url, json=data)\n    print(f\"Status: {response.status_code}\")\n    \n    if response.status_code == 200:\n        result = response.json()\n        print(\"\u2705 Analysis successful!\")\n        \n        # Show timing information\n        if 'processing_time' in result:\n            timing = result['processing_time']"}, {"id": "test_files/test_timing_small.py_2", "file": "test_files/test_timing_small.py", "content": "if 'processing_time' in result:\n            timing = result['processing_time']\n            print(f\"\\n\u23f1\ufe0f  Timing Results:\")\n            print(f\"  \ud83d\udd50 Total time: {timing['formatted']} ({timing['seconds']}s)\")\n            print(f\"  \ud83d\udcca Minutes: {timing['minutes']}\")\n        \n        stats = result['deep_analysis']['structure']['processing_stats']\n        print(f\"\\n\ud83d\udcc8 Performance:\")\n        print(f\"  \u2705 Files processed: {stats['processed']}\")\n        print(f\"  \ud83d\ude80 Files per second: {stats.get('files_per_second', 0)}\")\n        print(f\"  \u23f1\ufe0f  Start: {stats.get('start_time', 'N/A')}\")\n        print(f\"  \ud83c\udfc1 End: {stats.get('end_time', 'N/A')}\")\n        \n    else:\n        error = response.json()\n        if 'rate limited' in error.get('error', '').lower():"}, {"id": "test_files/test_timing_small.py_3", "file": "test_files/test_timing_small.py", "content": "error = response.json()\n        if 'rate limited' in error.get('error', '').lower():\n            print(\"\u274c Still rate limited. Try one of these:\")\n            print(\"1. Use GitHub token: python test_with_token.py\")\n            print(\"2. Wait until 00:39:17 for rate limit reset\")\n        else:\n            print(f\"\u274c Error: {error}\")\n\nif __name__ == \"__main__\":\n    test_small_repo_timing()"}, {"id": ".kiro/specs/ai-project-analyzer/design.md_0", "file": ".kiro/specs/ai-project-analyzer/design.md", "content": "================================================\nError reading file with 'cp1252': 'charmap' codec can't decode byte 0x9d in position 1179: character maps to <undefined>"}, {"id": ".kiro/specs/ai-project-analyzer/requirements.md_0", "file": ".kiro/specs/ai-project-analyzer/requirements.md", "content": "================================================\n# Requirements Document\n\n## Introduction\n\nThe AI Project Analyzer is a web application that enables developers to analyze GitHub repositories using AI-powered insights. The system ingests public or private repositories, creates a RAG (Retrieval-Augmented Generation) knowledge base, and provides both visual flowcharts and conversational AI interfaces for exploring codebases. The application integrates with GPT OSS via Hugging Face to deliver semantic search capabilities and intelligent code analysis."}, {"id": ".kiro/specs/ai-project-analyzer/requirements.md_1", "file": ".kiro/specs/ai-project-analyzer/requirements.md", "content": "## Requirements"}, {"id": ".kiro/specs/ai-project-analyzer/requirements.md_2", "file": ".kiro/specs/ai-project-analyzer/requirements.md", "content": "### Requirement 1\n\n**User Story:** As a developer, I want to input a GitHub repository URL and have the system analyze the entire codebase, so that I can understand the project structure and relationships.\n\n#### Acceptance Criteria\n\n1. WHEN a user provides a public GitHub repository URL THEN the system SHALL clone and parse the repository content\n2. WHEN a user provides a private GitHub repository URL THEN the system SHALL prompt for authentication credentials (token or SSH key)\n3. WHEN repository ingestion begins THEN the system SHALL display progress indicators showing parsing status\n4. WHEN ingestion completes THEN the system SHALL confirm successful analysis and display available features"}, {"id": ".kiro/specs/ai-project-analyzer/requirements.md_3", "file": ".kiro/specs/ai-project-analyzer/requirements.md", "content": "5. IF a repository URL is invalid or inaccessible THEN the system SHALL display clear error messages with suggested corrections"}, {"id": ".kiro/specs/ai-project-analyzer/requirements.md_4", "file": ".kiro/specs/ai-project-analyzer/requirements.md", "content": "### Requirement 2\n\n**User Story:** As a project maintainer, I want to ask natural language questions about my repository and receive AI-generated answers, so that I can quickly understand code functionality and architecture.\n\n#### Acceptance Criteria\n\n1. WHEN a repository has been analyzed THEN the system SHALL create a RAG knowledge base from all code files and documentation\n2. WHEN a user submits a natural language question THEN the system SHALL use GPT OSS via Hugging Face to generate contextual answers\n3. WHEN answering questions THEN the system SHALL reference specific files, functions, or code sections in the response\n4. WHEN no relevant information is found THEN the system SHALL indicate the limitation and suggest alternative queries"}, {"id": ".kiro/specs/ai-project-analyzer/requirements.md_5", "file": ".kiro/specs/ai-project-analyzer/requirements.md", "content": "5. WHEN multiple relevant code sections exist THEN the system SHALL provide comprehensive answers referencing all applicable parts"}, {"id": ".kiro/specs/ai-project-analyzer/requirements.md_6", "file": ".kiro/specs/ai-project-analyzer/requirements.md", "content": "### Requirement 3\n\n**User Story:** As a team member, I want to securely analyze private repositories without exposing sensitive credentials, so that I can maintain security while gaining insights.\n\n#### Acceptance Criteria\n\n1. WHEN handling private repositories THEN the system SHALL accept GitHub personal access tokens through secure input fields\n2. WHEN credentials are provided THEN the system SHALL store them only in memory or secure environment variables\n3. WHEN analysis completes THEN the system SHALL clear all authentication data from memory\n4. WHEN invalid credentials are provided THEN the system SHALL display authentication errors without exposing credential details\n5. IF SSH key authentication is used THEN the system SHALL support standard SSH key formats and secure key handling"}, {"id": ".kiro/specs/ai-project-analyzer/requirements.md_7", "file": ".kiro/specs/ai-project-analyzer/requirements.md", "content": "### Requirement 4\n\n**User Story:** As a new contributor, I want to see an interactive visual flowchart of the repository structure, so that I can understand how files and components relate to each other.\n\n#### Acceptance Criteria\n\n1. WHEN repository analysis completes THEN the system SHALL generate an interactive flowchart showing file and module relationships\n2. WHEN a user clicks on a flowchart node THEN the system SHALL display the corresponding source code or file content\n3. WHEN hovering over nodes THEN the system SHALL show AI-generated summaries of the component's purpose\n4. WHEN the flowchart is complex THEN the system SHALL provide zoom, pan, and filtering capabilities"}, {"id": ".kiro/specs/ai-project-analyzer/requirements.md_8", "file": ".kiro/specs/ai-project-analyzer/requirements.md", "content": "5. WHEN displaying relationships THEN the system SHALL show imports, dependencies, function calls, and class inheritance"}, {"id": ".kiro/specs/ai-project-analyzer/requirements.md_9", "file": ".kiro/specs/ai-project-analyzer/requirements.md", "content": "### Requirement 5\n\n**User Story:** As a developer, I want the analysis to stay current with repository changes, so that the insights remain accurate over time.\n\n#### Acceptance Criteria\n\n1. WHEN a user requests re-analysis THEN the system SHALL update the RAG knowledge base with current repository state\n2. WHEN repository changes are detected THEN the system SHALL offer automatic re-analysis options\n3. WHEN re-analysis occurs THEN the system SHALL preserve user session data and preferences\n4. WHEN updates complete THEN the system SHALL refresh the flowchart and knowledge base automatically\n5. IF webhook integration is configured THEN the system SHALL trigger re-analysis on repository push events"}, {"id": ".kiro/specs/ai-project-analyzer/requirements.md_10", "file": ".kiro/specs/ai-project-analyzer/requirements.md", "content": "### Requirement 6\n\n**User Story:** As a user, I want a clean web interface to interact with both the AI chat and visual flowchart, so that I can efficiently explore repositories.\n\n#### Acceptance Criteria\n\n1. WHEN accessing the application THEN the system SHALL provide a responsive web interface compatible with modern browsers\n2. WHEN using the chat interface THEN the system SHALL display conversation history and allow follow-up questions\n3. WHEN viewing flowcharts THEN the system SHALL provide intuitive navigation controls and clear visual hierarchy\n4. WHEN switching between features THEN the system SHALL maintain context and allow seamless transitions\n5. WHEN on mobile devices THEN the system SHALL adapt the interface for touch interaction and smaller screens"}, {"id": ".kiro/specs/ai-project-analyzer/requirements.md_11", "file": ".kiro/specs/ai-project-analyzer/requirements.md", "content": "### Requirement 7\n\n**User Story:** As a security-conscious user, I want all sensitive data handled according to industry standards, so that my credentials and code remain protected.\n\n#### Acceptance Criteria\n\n1. WHEN handling authentication THEN the system SHALL use HTTPS for all credential transmission\n2. WHEN storing temporary data THEN the system SHALL encrypt sensitive information at rest\n3. WHEN processing private repositories THEN the system SHALL not log or persist repository content unnecessarily\n4. WHEN errors occur THEN the system SHALL not expose sensitive information in error messages or logs\n5. WHEN sessions end THEN the system SHALL clear all authentication tokens and temporary repository data"}, {"id": ".kiro/specs/ai-project-analyzer/tasks.md_0", "file": ".kiro/specs/ai-project-analyzer/tasks.md", "content": "================================================\n# Implementation Plan\n\n- [ ] 1. Set up project dependencies and core infrastructure\n\n\n\n\n\n  - Install required npm packages: @octokit/rest (GitHub API), @huggingface/inference, Redis, D3.js\n  - Configure environment variables for GitHub API, Hugging Face API keys\n  - Create service directory structure optimized for API-only processing (no file storage)\n  - _Requirements: 7.1, 7.2_\n\n- [ ] 2. Implement GitHub authentication and repository access\n- [x] 2.1 Create GitHub authentication service\n\n\n\n  - Write GitHubAuthService class with token validation and SSH key support\n  - Implement secure credential handling with in-memory storage only\n  - Create unit tests for authentication flows and error handling\n  - _Requirements: 1.2, 3.1, 3.2, 3.3_"}, {"id": ".kiro/specs/ai-project-analyzer/tasks.md_1", "file": ".kiro/specs/ai-project-analyzer/tasks.md", "content": "- _Requirements: 1.2, 3.1, 3.2, 3.3_\n\n- [x] 2.2 Implement repository validation and access checking\n\n\n\n\n  - Code repository URL validation and accessibility verification\n  - Write functions to check public/private repository permissions\n  - Create unit tests for various repository access scenarios\n\n\n\n  - _Requirements: 1.1, 1.5_\n\n- [ ] 3. Build repository ingestion and parsing system\n- [ ] 3.1 Create GitHub API streaming service\n  - Implement GitHub API client with rate limiting and error handling\n  - Write file streaming functions that fetch content directly from GitHub API\n  - Create progress tracking for API-based repository analysis\n  - _Requirements: 1.1, 1.3, 7.3_\n\n- [ ] 3.2 Implement code structure parsing from API"}, {"id": ".kiro/specs/ai-project-analyzer/tasks.md_2", "file": ".kiro/specs/ai-project-analyzer/tasks.md", "content": "- _Requirements: 1.1, 1.3, 7.3_\n\n- [ ] 3.2 Implement code structure parsing from API\n\n\n  - Write AST parsers that work with streamed file content from GitHub API\n  - Create dependency mapping by parsing package.json, requirements.txt via API\n  - Implement repository tree analysis using GitHub's tree API endpoint\n  - _Requirements: 4.5, 1.1_\n\n- [ ] 3.3 Build repository analysis orchestrator\n  - Create RepositoryService class that coordinates API streaming and parsing\n  - Implement parallel file processing with GitHub API rate limit management\n  - Write integration tests for complete API-based repository analysis workflow\n  - _Requirements: 1.3, 1.4_\n\n- [ ] 4. Implement AI processing and RAG system\n- [ ] 4.1 Create Hugging Face GPT OSS integration"}, {"id": ".kiro/specs/ai-project-analyzer/tasks.md_3", "file": ".kiro/specs/ai-project-analyzer/tasks.md", "content": "- [ ] 4. Implement AI processing and RAG system\n- [ ] 4.1 Create Hugging Face GPT OSS integration\n  - Write AIService class with Hugging Face API client\n  - Implement error handling and retry logic for API failures\n  - Create unit tests for AI service integration\n  - _Requirements: 2.2, 2.4_\n\n- [ ] 4.2 Build RAG knowledge base creation from GitHub API\n  - Implement streaming document embedding generation from GitHub API responses\n  - Create vector storage and indexing system that processes files as they stream\n  - Write functions to intelligently chunk files during API streaming\n  - _Requirements: 2.1, 2.5_\n\n- [ ] 4.3 Implement semantic query processing\n  - Create natural language query handler with context retrieval\n  - Write response generation with source code references"}, {"id": ".kiro/specs/ai-project-analyzer/tasks.md_4", "file": ".kiro/specs/ai-project-analyzer/tasks.md", "content": "- Write response generation with source code references\n  - Implement confidence scoring and fallback responses\n  - _Requirements: 2.2, 2.3, 2.4_\n\n- [ ] 5. Build interactive flowchart visualization system\n- [ ] 5.1 Create flowchart data generation\n  - Write VisualizationService to convert AST data to flowchart nodes and edges\n  - Implement relationship mapping for imports, function calls, and inheritance\n  - Create layout algorithms for optimal node positioning\n  - _Requirements: 4.1, 4.5_\n\n- [ ] 5.2 Implement AI-powered node summaries\n  - Integrate AI service to generate component summaries for flowchart nodes\n  - Create caching system for generated summaries\n  - Write functions to update summaries when code changes\n  - _Requirements: 4.3_"}, {"id": ".kiro/specs/ai-project-analyzer/tasks.md_5", "file": ".kiro/specs/ai-project-analyzer/tasks.md", "content": "- Write functions to update summaries when code changes\n  - _Requirements: 4.3_\n\n- [ ] 5.3 Build interactive flowchart features\n  - Implement zoom, pan, and filtering capabilities for complex graphs\n  - Create click handlers for node navigation to source code\n  - Write hover functionality for displaying AI summaries\n  - _Requirements: 4.2, 4.3, 4.4_\n\n- [ ] 6. Create web API endpoints\n- [ ] 6.1 Implement repository analysis endpoints\n  - Create POST /api/repositories/analyze endpoint for repository submission\n  - Write GET /api/repositories/:id/status for analysis progress tracking\n  - Implement DELETE /api/repositories/:id for cleanup operations\n  - _Requirements: 1.1, 1.3, 1.4_\n\n- [ ] 6.2 Build AI query endpoints"}, {"id": ".kiro/specs/ai-project-analyzer/tasks.md_6", "file": ".kiro/specs/ai-project-analyzer/tasks.md", "content": "- _Requirements: 1.1, 1.3, 1.4_\n\n- [ ] 6.2 Build AI query endpoints\n  - Create POST /api/repositories/:id/query for natural language questions\n  - Write GET /api/repositories/:id/summaries for component summaries\n  - Implement caching middleware for frequently asked questions\n  - _Requirements: 2.2, 2.3_\n\n- [ ] 6.3 Create visualization endpoints\n  - Write GET /api/repositories/:id/flowchart for flowchart data\n  - Implement PUT /api/repositories/:id/flowchart for layout updates\n  - Create WebSocket endpoints for real-time flowchart updates\n  - _Requirements: 4.1, 4.2_\n\n- [ ] 7. Build frontend user interface\n- [ ] 7.1 Create repository input interface\n  - Build React components for repository URL input and credential forms\n  - Implement secure credential input with no browser storage"}, {"id": ".kiro/specs/ai-project-analyzer/tasks.md_7", "file": ".kiro/specs/ai-project-analyzer/tasks.md", "content": "- Implement secure credential input with no browser storage\n  - Create progress indicators and status displays for analysis\n  - _Requirements: 1.1, 1.2, 1.3, 3.1, 3.2_\n\n- [ ] 7.2 Implement AI chat interface\n  - Create conversational UI components for natural language queries\n  - Build chat history display with source code references\n  - Implement follow-up question suggestions and context preservation\n  - _Requirements: 2.2, 2.3, 6.2_\n\n- [ ] 7.3 Build interactive flowchart viewer\n  - Create React components for flowchart rendering using D3.js or similar\n  - Implement navigation controls, zoom, and filtering UI\n  - Build click handlers for source code navigation and summary display\n  - _Requirements: 4.1, 4.2, 4.3, 4.4, 6.1_\n\n- [ ] 8. Implement repository update and re-analysis features"}, {"id": ".kiro/specs/ai-project-analyzer/tasks.md_8", "file": ".kiro/specs/ai-project-analyzer/tasks.md", "content": "- [ ] 8. Implement repository update and re-analysis features\n- [ ] 8.1 Create manual re-analysis functionality\n  - Build UI controls for triggering repository re-analysis\n  - Implement incremental update detection and processing\n  - Create functions to preserve user session data during updates\n  - _Requirements: 5.1, 5.3_\n\n- [ ] 8.2 Implement automatic update detection\n  - Create webhook endpoint for GitHub repository change notifications\n  - Write scheduled job system for periodic repository checking\n  - Implement smart update triggers based on change significance\n  - _Requirements: 5.2, 5.5_\n\n- [ ] 8.3 Build update notification system\n  - Create real-time notifications for completed re-analysis\n  - Implement UI updates for refreshed flowcharts and knowledge base"}, {"id": ".kiro/specs/ai-project-analyzer/tasks.md_9", "file": ".kiro/specs/ai-project-analyzer/tasks.md", "content": "- Implement UI updates for refreshed flowcharts and knowledge base\n  - Write functions to maintain user context across updates\n  - _Requirements: 5.4_\n\n- [ ] 9. Implement security and performance optimizations\n- [ ] 9.1 Add comprehensive security measures\n  - Implement HTTPS enforcement and secure header middleware\n  - Create input validation and sanitization for all endpoints\n  - Write rate limiting and authentication middleware\n  - _Requirements: 7.1, 7.4, 7.5_\n\n- [ ] 9.2 Optimize performance and caching\n  - Implement Redis caching for GitHub API responses and AI-generated content\n  - Create intelligent batching for GitHub API requests to maximize rate limits\n  - Write memory-efficient streaming processors that don't accumulate file content\n  - _Requirements: 6.4_"}, {"id": ".kiro/specs/ai-project-analyzer/tasks.md_10", "file": ".kiro/specs/ai-project-analyzer/tasks.md", "content": "- _Requirements: 6.4_\n\n- [ ] 9.3 Add monitoring and error handling\n  - Create comprehensive error handling with user-friendly messages\n  - Implement logging system that excludes sensitive information\n  - Write health check endpoints and performance monitoring\n  - _Requirements: 7.4, 7.5_\n\n- [ ] 10. Create comprehensive testing suite\n- [ ] 10.1 Write unit tests for all services\n  - Create test suites for RepositoryService, AIService, and VisualizationService\n  - Write mock implementations for external APIs (GitHub, Hugging Face)\n  - Implement test fixtures with sample repositories and expected outputs\n  - _Requirements: All requirements_\n\n- [ ] 10.2 Build integration tests\n  - Create end-to-end tests for complete repository analysis workflows"}, {"id": ".kiro/specs/ai-project-analyzer/tasks.md_11", "file": ".kiro/specs/ai-project-analyzer/tasks.md", "content": "- Create end-to-end tests for complete repository analysis workflows\n  - Write API endpoint tests with authentication and error scenarios\n  - Implement frontend component tests with user interaction simulation\n  - _Requirements: All requirements_\n\n- [ ] 10.3 Add performance and security tests\n  - Create load tests for concurrent repository analysis\n  - Write security tests for credential handling and data protection\n  - Implement memory usage and cleanup validation tests\n  - _Requirements: 3.3, 7.1, 7.2, 7.3, 7.4, 7.5_"}, {"id": ".kiro/specs/gitingest-integration/design.md_0", "file": ".kiro/specs/gitingest-integration/design.md", "content": "================================================\n# Design Document\n\n## Overview\n\nThe Gitingest Integration replaces the complex GitHub API streaming approach in the AI Project Analyzer with gitingest, a Python tool that converts Git repositories into LLM-optimized text format. This design maintains the existing system architecture while significantly simplifying repository ingestion and improving AI analysis quality through better structured input."}, {"id": ".kiro/specs/gitingest-integration/design.md_1", "file": ".kiro/specs/gitingest-integration/design.md", "content": "## Architecture"}, {"id": ".kiro/specs/gitingest-integration/design.md_2", "file": ".kiro/specs/gitingest-integration/design.md", "content": "### High-Level Architecture\n\nThe integration modifies the existing system by replacing the GitHub API streaming layer with a gitingest processing service, while maintaining all other components:\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Web Frontend  \u2502\u2500\u2500\u2500\u2500\u2502   API Gateway    \u2502\u2500\u2500\u2500\u2500\u2502  Auth Service   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                \u2502\n                                \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Repository Service                           \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                  \u2502\n\u2502  \u2502 GitHub API      \u2502\u2500\u2500\u2500\u2500\u2502 Gitingest        \u2502                  \u2502"}, {"id": ".kiro/specs/gitingest-integration/design.md_3", "file": ".kiro/specs/gitingest-integration/design.md", "content": "\u2502  \u2502 GitHub API      \u2502\u2500\u2500\u2500\u2500\u2502 Gitingest        \u2502                  \u2502\n\u2502  \u2502 (validation)    \u2502    \u2502 Processing       \u2502                  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                \u2502\n                                \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   AI Service    \u2502\u2500\u2500\u2500\u2500\u2502   RAG System     \u2502\u2500\u2500\u2500\u2500\u2502 Vector Storage  \u2502\n\u2502 (Hugging Face)  \u2502    \u2502                  \u2502    \u2502                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                \u2502\n                                \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510"}, {"id": ".kiro/specs/gitingest-integration/design.md_4", "file": ".kiro/specs/gitingest-integration/design.md", "content": "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                 Visualization Service                           \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                  \u2502\n\u2502  \u2502 Flowchart       \u2502\u2500\u2500\u2500\u2500\u2502 Interactive      \u2502                  \u2502\n\u2502  \u2502 Generator       \u2502    \u2502 Components       \u2502                  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```"}, {"id": ".kiro/specs/gitingest-integration/design.md_5", "file": ".kiro/specs/gitingest-integration/design.md", "content": "### Integration Points\n\n1. **Repository Service Enhancement**: Replaces GitHub API streaming with gitingest processing\n2. **RAG System Optimization**: Leverages gitingest's structured output for better chunking\n3. **Visualization Improvement**: Uses gitingest's comprehensive file mapping for accurate dependency graphs\n4. **Security Preservation**: Maintains existing authentication and credential handling patterns"}, {"id": ".kiro/specs/gitingest-integration/design.md_6", "file": ".kiro/specs/gitingest-integration/design.md", "content": "## Components and Interfaces\n\n### GitingestProcessor\n\n**Purpose**: Core service that handles gitingest execution and output processing\n\n**Key Methods**:\n```python"}, {"id": ".kiro/specs/gitingest-integration/design.md_7", "file": ".kiro/specs/gitingest-integration/design.md", "content": "class GitingestProcessor:\n    async def process_repository(self, repo_url: str, auth_config: AuthConfig) -> GitingestOutput\n    async def validate_repository(self, repo_url: str) -> ValidationResult\n    def parse_gitingest_output(self, raw_output: str) -> StructuredRepository\n    def cleanup_temporary_files(self, process_id: str) -> None\n```\n\n**Interfaces**:\n- Input: Repository URL, authentication credentials\n- Output: Structured repository representation with file hierarchy and content\n- Dependencies: gitingest Python package, subprocess management, temporary file handling\n\n### RepositoryService (Enhanced)\n\n**Purpose**: Orchestrates repository analysis using gitingest instead of GitHub API streaming\n\n**Key Methods**:\n```python"}, {"id": ".kiro/specs/gitingest-integration/design.md_8", "file": ".kiro/specs/gitingest-integration/design.md", "content": "class RepositoryService:\n    async def analyze_repository(self, repo_url: str, auth_config: AuthConfig) -> AnalysisResult\n    async def get_analysis_progress(self, analysis_id: str) -> ProgressStatus\n    def create_rag_documents(self, structured_repo: StructuredRepository) -> List[Document]\n```\n\n**Changes from Current Design**:\n- Replaces GitHub API client with GitingestProcessor\n- Simplifies file streaming logic\n- Improves error handling for repository access issues\n- Maintains existing progress tracking and caching mechanisms\n\n### AuthenticationService (Unchanged)\n\n**Purpose**: Handles GitHub authentication for both public and private repositories\n\n**Integration**: Passes credentials to gitingest through environment variables or command-line arguments securely"}, {"id": ".kiro/specs/gitingest-integration/design.md_9", "file": ".kiro/specs/gitingest-integration/design.md", "content": "### RAGService (Enhanced)\n\n**Purpose**: Creates knowledge base from gitingest's structured output\n\n**Key Enhancements**:\n```python"}, {"id": ".kiro/specs/gitingest-integration/design.md_10", "file": ".kiro/specs/gitingest-integration/design.md", "content": "class RAGService:\n    def chunk_gitingest_output(self, structured_repo: StructuredRepository) -> List[Chunk]\n    def create_embeddings_batch(self, chunks: List[Chunk]) -> List[Embedding]\n    def build_file_hierarchy_index(self, structured_repo: StructuredRepository) -> HierarchyIndex\n```\n\n**Improvements**:\n- Better chunking strategy using gitingest's file boundaries\n- Improved context preservation through structured file hierarchy\n- Enhanced metadata extraction from gitingest's comprehensive output\n\n## Data Models\n\n### GitingestOutput\n\n```python\n@dataclass"}, {"id": ".kiro/specs/gitingest-integration/design.md_11", "file": ".kiro/specs/gitingest-integration/design.md", "content": "class GitingestOutput:\n    repository_info: RepositoryInfo\n    file_tree: FileTree\n    content_blocks: List[ContentBlock]\n    metadata: GitingestMetadata\n    processing_stats: ProcessingStats\n```\n\n### StructuredRepository\n\n```python\n@dataclass\nclass StructuredRepository:\n    repo_url: str\n    files: Dict[str, FileContent]\n    dependencies: List[Dependency]\n    file_hierarchy: FileHierarchy\n    language_stats: LanguageStats\n    gitingest_metadata: GitingestMetadata\n```\n\n### ContentBlock\n\n```python\n@dataclass\nclass ContentBlock:\n    file_path: str\n    content: str\n    language: str\n    line_count: int\n    size_bytes: int\n    file_type: FileType\n```\n\n### ProcessingConfig\n\n```python\n@dataclass"}, {"id": ".kiro/specs/gitingest-integration/design.md_12", "file": ".kiro/specs/gitingest-integration/design.md", "content": "class ProcessingConfig:\n    include_patterns: List[str]\n    exclude_patterns: List[str]\n    max_file_size: int\n    respect_gitignore: bool\n    include_binary_files: bool\n    auth_method: AuthMethod\n```"}, {"id": ".kiro/specs/gitingest-integration/design.md_13", "file": ".kiro/specs/gitingest-integration/design.md", "content": "## Error Handling\n\n### Gitingest-Specific Errors\n\n1. **Repository Access Errors**\n   - Invalid repository URLs\n   - Authentication failures\n   - Network connectivity issues\n   - Repository not found or private access denied\n\n2. **Processing Errors**\n   - Gitingest execution failures\n   - Large repository timeout handling\n   - Memory limitations for massive repositories\n   - Corrupted or incomplete output\n\n3. **Integration Errors**\n   - Python environment issues\n   - Gitingest package version conflicts\n   - Temporary file system errors\n   - Output parsing failures\n\n### Error Recovery Strategies\n\n```python"}, {"id": ".kiro/specs/gitingest-integration/design.md_14", "file": ".kiro/specs/gitingest-integration/design.md", "content": "class ErrorRecoveryService:\n    async def retry_with_smaller_scope(self, repo_url: str, config: ProcessingConfig) -> GitingestOutput\n    async def fallback_to_api_streaming(self, repo_url: str) -> RepositoryData\n    def diagnose_gitingest_failure(self, error: Exception) -> DiagnosticReport\n```"}, {"id": ".kiro/specs/gitingest-integration/design.md_15", "file": ".kiro/specs/gitingest-integration/design.md", "content": "## Testing Strategy\n\n### Unit Testing\n\n1. **GitingestProcessor Tests**\n   - Mock gitingest execution with sample outputs\n   - Test various repository types and sizes\n   - Validate error handling for different failure scenarios\n   - Test authentication credential passing\n\n2. **Output Parsing Tests**\n   - Test parsing of gitingest output format\n   - Validate file hierarchy reconstruction\n   - Test content extraction and metadata handling\n   - Verify language detection and statistics"}, {"id": ".kiro/specs/gitingest-integration/design.md_16", "file": ".kiro/specs/gitingest-integration/design.md", "content": "### Integration Testing\n\n1. **End-to-End Repository Processing**\n   - Test complete workflow from URL input to structured output\n   - Validate with both public and private repositories\n   - Test different authentication methods\n   - Verify cleanup of temporary files and credentials\n\n2. **RAG System Integration**\n   - Test improved chunking with gitingest output\n   - Validate embedding generation from structured content\n   - Test query performance improvements\n   - Verify file reference accuracy in AI responses"}, {"id": ".kiro/specs/gitingest-integration/design.md_17", "file": ".kiro/specs/gitingest-integration/design.md", "content": "### Performance Testing\n\n1. **Repository Size Scaling**\n   - Test with repositories of varying sizes (small, medium, large)\n   - Measure processing time improvements over GitHub API approach\n   - Validate memory usage patterns\n   - Test concurrent repository processing\n\n2. **Comparison Benchmarks**\n   - Compare gitingest vs GitHub API streaming performance\n   - Measure AI analysis quality improvements\n   - Test flowchart generation accuracy\n   - Validate user experience improvements"}, {"id": ".kiro/specs/gitingest-integration/design.md_18", "file": ".kiro/specs/gitingest-integration/design.md", "content": "## Security Considerations\n\n### Credential Handling\n\n1. **Environment Variable Management**\n   - Pass GitHub tokens through secure environment variables\n   - Clear environment variables after gitingest execution\n   - Validate credential format before passing to gitingest\n\n2. **Temporary File Security**\n   - Create temporary directories with restricted permissions\n   - Encrypt temporary files containing sensitive repository content\n   - Implement secure cleanup procedures for all temporary artifacts"}, {"id": ".kiro/specs/gitingest-integration/design.md_19", "file": ".kiro/specs/gitingest-integration/design.md", "content": "### Repository Content Protection\n\n1. **Memory Management**\n   - Process gitingest output in streaming fashion when possible\n   - Avoid keeping complete repository content in memory longer than necessary\n   - Implement secure memory clearing for sensitive content\n\n2. **Logging and Monitoring**\n   - Exclude repository content from application logs\n   - Log only metadata and processing statistics\n   - Implement audit trails for repository access without content exposure"}, {"id": ".kiro/specs/gitingest-integration/design.md_20", "file": ".kiro/specs/gitingest-integration/design.md", "content": "## Deployment Considerations\n\n### Python Environment\n\n1. **Dependency Management**\n   - Add gitingest to requirements.txt with version pinning\n   - Ensure Python environment compatibility\n   - Handle potential conflicts with existing dependencies\n\n2. **System Requirements**\n   - Ensure Git is available in the deployment environment\n   - Configure appropriate disk space for temporary repository processing\n   - Set up proper file system permissions for temporary directories"}, {"id": ".kiro/specs/gitingest-integration/design.md_21", "file": ".kiro/specs/gitingest-integration/design.md", "content": "### Configuration\n\n1. **Environment Variables**\n   ```\n   GITINGEST_MAX_FILE_SIZE=10MB\n   GITINGEST_TIMEOUT=300\n   GITINGEST_TEMP_DIR=/tmp/gitingest\n   GITINGEST_INCLUDE_PATTERNS=*.py,*.js,*.md,*.json\n   GITINGEST_EXCLUDE_PATTERNS=node_modules,__pycache__,.git\n   ```\n\n2. **Runtime Configuration**\n   - Configurable processing timeouts\n   - Adjustable file size limits\n   - Customizable include/exclude patterns\n   - Flexible authentication method selection"}, {"id": ".kiro/specs/gitingest-integration/requirements.md_0", "file": ".kiro/specs/gitingest-integration/requirements.md", "content": "================================================\n# Requirements Document\n\n## Introduction\n\nThe Gitingest Integration enhances the existing AI Project Analyzer by replacing the complex GitHub API streaming approach with gitingest, a Python tool that converts Git repositories into LLM-optimized text format. This integration will simplify repository ingestion, improve parsing accuracy, and provide better context for AI analysis while maintaining all existing security and functionality requirements."}, {"id": ".kiro/specs/gitingest-integration/requirements.md_1", "file": ".kiro/specs/gitingest-integration/requirements.md", "content": "## Requirements"}, {"id": ".kiro/specs/gitingest-integration/requirements.md_2", "file": ".kiro/specs/gitingest-integration/requirements.md", "content": "### Requirement 1\n\n**User Story:** As a developer, I want the system to use gitingest to efficiently convert any Git repository into a structured text format, so that AI analysis becomes faster and more comprehensive.\n\n#### Acceptance Criteria\n\n1. WHEN a user provides a repository URL THEN the system SHALL use gitingest to convert the repository into structured text format\n2. WHEN gitingest processes a repository THEN the system SHALL capture the complete codebase structure including file paths, content, and metadata\n3. WHEN ingestion completes THEN the system SHALL have a single text representation optimized for LLM consumption\n4. WHEN processing large repositories THEN the system SHALL handle gitingest output efficiently without memory overflow"}, {"id": ".kiro/specs/gitingest-integration/requirements.md_3", "file": ".kiro/specs/gitingest-integration/requirements.md", "content": "5. IF gitingest fails to process a repository THEN the system SHALL provide clear error messages and fallback options"}, {"id": ".kiro/specs/gitingest-integration/requirements.md_4", "file": ".kiro/specs/gitingest-integration/requirements.md", "content": "### Requirement 2\n\n**User Story:** As a project maintainer, I want gitingest integration to preserve all file types and relationships, so that AI analysis covers the complete project ecosystem including documentation, configuration, and code files.\n\n#### Acceptance Criteria\n\n1. WHEN gitingest processes a repository THEN the system SHALL include all relevant file types (code, docs, configs, tests)\n2. WHEN analyzing the gitingest output THEN the system SHALL maintain file hierarchy and relationship information\n3. WHEN creating the RAG knowledge base THEN the system SHALL use gitingest's structured format for better context chunking\n4. WHEN generating responses THEN the system SHALL reference specific files and line numbers from the gitingest output"}, {"id": ".kiro/specs/gitingest-integration/requirements.md_5", "file": ".kiro/specs/gitingest-integration/requirements.md", "content": "5. WHEN filtering files THEN the system SHALL respect gitignore rules and exclude binary/irrelevant files automatically"}, {"id": ".kiro/specs/gitingest-integration/requirements.md_6", "file": ".kiro/specs/gitingest-integration/requirements.md", "content": "### Requirement 3\n\n**User Story:** As a security-conscious user, I want gitingest integration to work with both public and private repositories while maintaining the same security standards, so that sensitive code remains protected.\n\n#### Acceptance Criteria\n\n1. WHEN processing private repositories THEN the system SHALL pass authentication credentials securely to gitingest\n2. WHEN gitingest accesses repositories THEN the system SHALL ensure credentials are handled only in memory\n3. WHEN processing completes THEN the system SHALL clear all temporary files and authentication data\n4. WHEN errors occur THEN the system SHALL not expose repository content or credentials in logs\n5. IF gitingest creates temporary files THEN the system SHALL clean them up immediately after processing"}, {"id": ".kiro/specs/gitingest-integration/requirements.md_7", "file": ".kiro/specs/gitingest-integration/requirements.md", "content": "### Requirement 4\n\n**User Story:** As a team member, I want gitingest integration to be faster than the current GitHub API approach, so that I can analyze repositories more efficiently.\n\n#### Acceptance Criteria\n\n1. WHEN comparing to GitHub API streaming THEN gitingest integration SHALL complete repository ingestion faster\n2. WHEN processing repositories THEN the system SHALL show progress indicators for gitingest operations\n3. WHEN gitingest runs THEN the system SHALL provide real-time status updates to users\n4. WHEN analysis completes THEN the system SHALL transition seamlessly to AI processing and visualization\n5. IF gitingest takes longer than expected THEN the system SHALL provide estimated completion times"}, {"id": ".kiro/specs/gitingest-integration/requirements.md_8", "file": ".kiro/specs/gitingest-integration/requirements.md", "content": "### Requirement 5\n\n**User Story:** As a developer, I want the gitingest integration to enhance the existing flowchart and AI chat features, so that I get better insights from the improved repository representation.\n\n#### Acceptance Criteria\n\n1. WHEN gitingest output is processed THEN the system SHALL generate more accurate dependency graphs for flowcharts\n2. WHEN AI answers questions THEN the system SHALL leverage gitingest's structured format for better context retrieval\n3. WHEN displaying code references THEN the system SHALL use gitingest's file path information for precise navigation\n4. WHEN generating summaries THEN the system SHALL benefit from gitingest's comprehensive file inclusion\n5. WHEN updating repositories THEN the system SHALL re-run gitingest to maintain current analysis"}, {"id": ".kiro/specs/gitingest-integration/requirements.md_9", "file": ".kiro/specs/gitingest-integration/requirements.md", "content": "### Requirement 6\n\n**User Story:** As a system administrator, I want gitingest integration to be configurable and maintainable, so that the system can adapt to different repository types and requirements.\n\n#### Acceptance Criteria\n\n1. WHEN installing the system THEN gitingest SHALL be included as a Python dependency with proper version management\n2. WHEN configuring gitingest THEN the system SHALL allow customization of file inclusion/exclusion patterns\n3. WHEN running gitingest THEN the system SHALL handle different Git authentication methods (HTTPS, SSH, tokens)\n4. WHEN processing fails THEN the system SHALL provide detailed diagnostic information for troubleshooting\n5. IF gitingest updates are available THEN the system SHALL support easy upgrades without breaking existing functionality"}, {"id": ".kiro/specs/gitingest-integration/requirements.md_10", "file": ".kiro/specs/gitingest-integration/requirements.md", "content": "### Requirement 7\n\n**User Story:** As a user, I want gitingest integration to work seamlessly with the existing web interface, so that the improved backend processing is transparent to my workflow.\n\n#### Acceptance Criteria\n\n1. WHEN using the repository input interface THEN the system SHALL show gitingest processing status alongside existing progress indicators\n2. WHEN gitingest completes THEN the system SHALL automatically proceed to AI processing and flowchart generation\n3. WHEN errors occur during gitingest processing THEN the system SHALL display user-friendly error messages\n4. WHEN switching between repositories THEN the system SHALL manage gitingest operations efficiently"}, {"id": ".kiro/specs/gitingest-integration/requirements.md_11", "file": ".kiro/specs/gitingest-integration/requirements.md", "content": "5. IF gitingest processing is interrupted THEN the system SHALL allow users to retry or cancel operations gracefully"}, {"id": ".kiro/specs/gitingest-integration/tasks.md_0", "file": ".kiro/specs/gitingest-integration/tasks.md", "content": "================================================\n# Implementation Plan\n\n- [x] 1. Set up gitingest dependency and core infrastructure\n\n\n\n\n\n\n  - Add gitingest to requirements.txt with version pinning\n  - Create GitingestProcessor service class with basic structure\n  - Set up environment configuration for gitingest processing\n  - _Requirements: 6.1, 6.2_\n\n- [ ] 2. Implement GitingestProcessor core functionality\n- [ ] 2.1 Create repository processing method\n  - Write async process_repository method that executes gitingest command\n  - Implement secure credential passing through environment variables\n  - Add subprocess management with timeout and error handling\n  - _Requirements: 1.1, 3.1, 3.2_\n\n- [ ] 2.2 Implement gitingest output parsing"}, {"id": ".kiro/specs/gitingest-integration/tasks.md_1", "file": ".kiro/specs/gitingest-integration/tasks.md", "content": "- _Requirements: 1.1, 3.1, 3.2_\n\n- [ ] 2.2 Implement gitingest output parsing\n  - Write parse_gitingest_output method to convert raw text to structured data\n  - Create file hierarchy reconstruction from gitingest output\n  - Implement content block extraction with metadata preservation\n  - _Requirements: 1.2, 1.3, 2.2_\n\n- [ ] 2.3 Add repository validation and cleanup\n  - Write validate_repository method for URL and access checking\n  - Implement cleanup_temporary_files for secure file management\n  - Create error handling for gitingest execution failures\n  - _Requirements: 1.5, 3.3, 3.4_\n\n- [ ] 3. Enhance RepositoryService with gitingest integration\n- [ ] 3.1 Replace GitHub API streaming with gitingest processing\n  - Modify analyze_repository method to use GitingestProcessor"}, {"id": ".kiro/specs/gitingest-integration/tasks.md_2", "file": ".kiro/specs/gitingest-integration/tasks.md", "content": "- Modify analyze_repository method to use GitingestProcessor\n  - Update progress tracking for gitingest operations\n  - Maintain existing caching and session management\n  - _Requirements: 4.1, 4.3, 7.2_\n\n- [ ] 3.2 Implement improved error handling and diagnostics\n  - Create gitingest-specific error types and messages\n  - Add fallback mechanisms for gitingest failures\n  - Implement diagnostic reporting for troubleshooting\n  - _Requirements: 1.5, 6.4, 7.3_\n\n- [ ] 4. Optimize RAGService for gitingest output\n- [ ] 4.1 Create enhanced chunking strategy\n  - Write chunk_gitingest_output method using file boundaries\n  - Implement improved context preservation through structured hierarchy\n  - Create metadata extraction from gitingest's comprehensive output\n  - _Requirements: 2.1, 2.3, 5.2_"}, {"id": ".kiro/specs/gitingest-integration/tasks.md_3", "file": ".kiro/specs/gitingest-integration/tasks.md", "content": "- _Requirements: 2.1, 2.3, 5.2_\n\n- [ ] 4.2 Build file hierarchy indexing\n  - Write build_file_hierarchy_index for better navigation\n  - Implement dependency mapping from gitingest structure\n  - Create enhanced embedding generation with file context\n  - _Requirements: 2.2, 2.4, 5.3_\n\n- [ ] 5. Update VisualizationService for improved flowcharts\n- [ ] 5.1 Enhance dependency graph generation\n  - Modify flowchart data generation to use gitingest's structured output\n  - Improve relationship mapping accuracy with comprehensive file inclusion\n  - Update layout algorithms for better node positioning with more complete data\n  - _Requirements: 5.1, 5.4_\n\n- [ ] 5.2 Implement better source code navigation\n  - Update click handlers to use gitingest's precise file path information"}, {"id": ".kiro/specs/gitingest-integration/tasks.md_4", "file": ".kiro/specs/gitingest-integration/tasks.md", "content": "- Update click handlers to use gitingest's precise file path information\n  - Enhance code reference display with line number accuracy\n  - Create improved hover functionality with comprehensive summaries\n  - _Requirements: 5.3, 5.4_\n\n- [ ] 6. Create gitingest-specific API endpoints\n- [ ] 6.1 Add gitingest processing status endpoints\n  - Create GET /api/gitingest/:id/status for processing progress\n  - Write POST /api/gitingest/process for repository submission\n  - Implement DELETE /api/gitingest/:id for cleanup operations\n  - _Requirements: 4.2, 7.1, 7.4_\n\n- [ ] 6.2 Update existing repository endpoints\n  - Modify existing repository analysis endpoints to use gitingest\n  - Update response formats to include gitingest metadata\n  - Maintain backward compatibility with existing frontend"}, {"id": ".kiro/specs/gitingest-integration/tasks.md_5", "file": ".kiro/specs/gitingest-integration/tasks.md", "content": "- Maintain backward compatibility with existing frontend\n  - _Requirements: 7.2, 7.5_\n\n- [ ] 7. Enhance frontend for gitingest integration\n- [ ] 7.1 Update repository input interface\n  - Add gitingest processing indicators to existing progress displays\n  - Create configuration options for gitingest include/exclude patterns\n  - Implement better error messaging for gitingest-specific failures\n  - _Requirements: 6.2, 7.1, 7.3_\n\n- [ ] 7.2 Improve AI chat interface with better context\n  - Update chat components to leverage improved file references\n  - Enhance source code navigation with gitingest's precise paths\n  - Create better context display using gitingest's structured format\n  - _Requirements: 5.2, 5.3, 7.2_\n\n- [ ] 8. Implement configuration and customization features"}, {"id": ".kiro/specs/gitingest-integration/tasks.md_6", "file": ".kiro/specs/gitingest-integration/tasks.md", "content": "- _Requirements: 5.2, 5.3, 7.2_\n\n- [ ] 8. Implement configuration and customization features\n- [ ] 8.1 Create gitingest configuration management\n  - Write configuration service for include/exclude patterns\n  - Implement file size limits and processing timeout settings\n  - Create authentication method selection for different Git providers\n  - _Requirements: 6.2, 6.3_\n\n- [ ] 8.2 Add processing optimization controls\n  - Implement configurable memory usage limits\n  - Create batch processing options for multiple repositories\n  - Write performance monitoring and metrics collection\n  - _Requirements: 4.1, 4.4, 6.5_\n\n- [ ] 9. Build comprehensive testing suite\n- [ ] 9.1 Create GitingestProcessor unit tests\n  - Write tests for repository processing with mock gitingest execution"}, {"id": ".kiro/specs/gitingest-integration/tasks.md_7", "file": ".kiro/specs/gitingest-integration/tasks.md", "content": "- Write tests for repository processing with mock gitingest execution\n  - Create output parsing tests with sample gitingest outputs\n  - Implement error handling tests for various failure scenarios\n  - _Requirements: 1.1, 1.2, 1.5_\n\n- [ ] 9.2 Write integration tests for enhanced services\n  - Create end-to-end tests for complete gitingest workflow\n  - Write RAG system tests with gitingest output\n  - Implement visualization tests with improved dependency graphs\n  - _Requirements: 2.1, 4.1, 5.1_\n\n- [ ] 9.3 Add performance and security tests\n  - Create performance comparison tests between gitingest and GitHub API\n  - Write security tests for credential handling and cleanup\n  - Implement load tests for concurrent gitingest processing\n  - _Requirements: 3.1, 3.2, 3.3, 4.1_"}, {"id": ".kiro/specs/gitingest-integration/tasks.md_8", "file": ".kiro/specs/gitingest-integration/tasks.md", "content": "- _Requirements: 3.1, 3.2, 3.3, 4.1_\n\n- [ ] 10. Create migration and deployment utilities\n- [ ] 10.1 Build migration tools for existing repositories\n  - Write scripts to re-process existing repositories with gitingest\n  - Create data migration utilities for RAG knowledge base updates\n  - Implement rollback mechanisms for deployment safety\n  - _Requirements: 5.5, 6.5_\n\n- [ ] 10.2 Add monitoring and maintenance features\n  - Create health check endpoints for gitingest functionality\n  - Implement logging and metrics for gitingest operations\n  - Write maintenance scripts for cleanup and optimization\n  - _Requirements: 6.4, 6.5_"}, {"id": ".kiro/specs/self-configuring-ai-agents/requirements.md_0", "file": ".kiro/specs/self-configuring-ai-agents/requirements.md", "content": "================================================\n[Empty file]"}, {"id": ".kiro/specs/streamlit-frontend/design.md_0", "file": ".kiro/specs/streamlit-frontend/design.md", "content": "================================================\nError reading file with 'cp1252': 'charmap' codec can't decode byte 0x90 in position 4761: character maps to <undefined>"}, {"id": ".kiro/specs/streamlit-frontend/requirements.md_0", "file": ".kiro/specs/streamlit-frontend/requirements.md", "content": "================================================\n# Requirements Document\n\n## Introduction\n\nThis feature creates a beautiful, dark-mode Streamlit frontend for the AI Project Analyzer Flask backend. The frontend will provide an intuitive interface for users to view their existing repositories and add new ones by providing GitHub repository URLs. The interface will communicate with the Flask backend to clone repositories and display analysis results."}, {"id": ".kiro/specs/streamlit-frontend/requirements.md_1", "file": ".kiro/specs/streamlit-frontend/requirements.md", "content": "## Requirements\n\n### Requirement 1\n\n**User Story:** As a user, I want to see a list of my existing repositories in a clean, organized interface, so that I can quickly browse and select repositories I've already analyzed.\n\n#### Acceptance Criteria\n\n1. WHEN the application loads THEN the system SHALL display all repositories from the my_repos directory\n2. WHEN repositories are displayed THEN the system SHALL show repository name, description, and last modified date\n3. WHEN no repositories exist THEN the system SHALL display a friendly message indicating no repositories are available\n4. WHEN repositories are listed THEN the system SHALL use a dark theme with good contrast and readability"}, {"id": ".kiro/specs/streamlit-frontend/requirements.md_2", "file": ".kiro/specs/streamlit-frontend/requirements.md", "content": "### Requirement 2\n\n**User Story:** As a user, I want to input a GitHub repository URL and have it cloned automatically, so that I can analyze new repositories without manual setup.\n\n#### Acceptance Criteria\n\n1. WHEN I enter a valid GitHub repository URL THEN the system SHALL validate the URL format\n2. WHEN I submit a repository URL THEN the system SHALL call the Flask backend to clone the repository\n3. WHEN cloning is successful THEN the system SHALL display a success message and refresh the repository list\n4. WHEN cloning fails THEN the system SHALL display a clear error message explaining what went wrong\n5. WHEN cloning is in progress THEN the system SHALL show a loading indicator"}, {"id": ".kiro/specs/streamlit-frontend/requirements.md_3", "file": ".kiro/specs/streamlit-frontend/requirements.md", "content": "### Requirement 3\n\n**User Story:** As a user, I want the interface to have a beautiful dark mode design, so that I can work comfortably in low-light environments and have a modern user experience.\n\n#### Acceptance Criteria\n\n1. WHEN the application loads THEN the system SHALL use a dark color scheme as the default theme\n2. WHEN displaying content THEN the system SHALL use high contrast colors for good readability\n3. WHEN showing interactive elements THEN the system SHALL provide clear visual feedback on hover and click\n4. WHEN displaying status messages THEN the system SHALL use appropriate colors (green for success, red for errors, blue for info)"}, {"id": ".kiro/specs/streamlit-frontend/requirements.md_4", "file": ".kiro/specs/streamlit-frontend/requirements.md", "content": "### Requirement 4\n\n**User Story:** As a user, I want real-time feedback on repository operations, so that I understand what's happening and can track progress.\n\n#### Acceptance Criteria\n\n1. WHEN a repository operation starts THEN the system SHALL display a progress indicator\n2. WHEN operations complete THEN the system SHALL show success/failure notifications\n3. WHEN errors occur THEN the system SHALL display detailed error messages with suggested actions\n4. WHEN the repository list changes THEN the system SHALL automatically refresh the display"}, {"id": ".kiro/specs/streamlit-frontend/requirements.md_5", "file": ".kiro/specs/streamlit-frontend/requirements.md", "content": "### Requirement 5\n\n**User Story:** As a user, I want the interface to be responsive and intuitive, so that I can efficiently manage my repositories regardless of screen size.\n\n#### Acceptance Criteria\n\n1. WHEN using different screen sizes THEN the system SHALL adapt the layout appropriately\n2. WHEN interacting with form elements THEN the system SHALL provide clear labels and validation feedback\n3. WHEN navigating the interface THEN the system SHALL maintain consistent styling and behavior\n4. WHEN performing actions THEN the system SHALL provide keyboard shortcuts where appropriate"}, {"id": ".kiro/specs/streamlit-frontend/tasks.md_0", "file": ".kiro/specs/streamlit-frontend/tasks.md", "content": "================================================\n# Implementation Plan\n\n- [x] 1. Set up Streamlit application structure and dependencies\n\n\n\n\n  - Create streamlit_app.py as main entry point\n  - Create requirements.txt with Streamlit, requests, and other dependencies\n  - Set up basic Streamlit configuration and page setup\n  - _Requirements: 3.1, 3.3_\n\n- [ ] 2. Implement dark theme styling system\n  - Create custom CSS for dark theme with specified color palette\n  - Implement load_custom_css() function to inject styles\n  - Style all UI components for consistent dark theme appearance\n  - _Requirements: 3.1, 3.2, 3.3_\n\n- [ ] 3. Create API client module for Flask backend communication\n  - Implement get_local_repositories() function to fetch repository list"}, {"id": ".kiro/specs/streamlit-frontend/tasks.md_1", "file": ".kiro/specs/streamlit-frontend/tasks.md", "content": "- Implement get_local_repositories() function to fetch repository list\n  - Create clone_repository() function to call Flask clone endpoint\n  - Add validate_github_url() function for client-side URL validation\n  - Implement handle_api_response() function for consistent error handling\n  - _Requirements: 2.2, 2.3, 4.2, 4.3_\n\n- [ ] 4. Build repository list display component\n  - Create render_repository_list() function to display repository cards\n  - Implement repository card layout with metadata display\n  - Add file statistics, language breakdown, and last modified info\n  - Style repository cards with hover effects and responsive design\n  - _Requirements: 1.1, 1.2, 1.4, 5.3_\n\n- [ ] 5. Implement add repository form component"}, {"id": ".kiro/specs/streamlit-frontend/tasks.md_2", "file": ".kiro/specs/streamlit-frontend/tasks.md", "content": "- _Requirements: 1.1, 1.2, 1.4, 5.3_\n\n- [ ] 5. Implement add repository form component\n  - Create render_add_repository_form() function with URL input field\n  - Add optional GitHub token input with secure handling\n  - Implement form validation and submission logic\n  - Add clone and analyze button functionality\n  - _Requirements: 2.1, 2.2, 2.4, 5.2_\n\n- [ ] 6. Create notification and status system\n  - Implement render_notifications() function for user feedback\n  - Add loading indicators for repository operations\n  - Create success, error, and info notification types with appropriate colors\n  - Implement progress tracking for clone operations\n  - _Requirements: 2.3, 2.5, 4.1, 4.2, 4.3_\n\n- [ ] 7. Add session state management and initialization"}, {"id": ".kiro/specs/streamlit-frontend/tasks.md_3", "file": ".kiro/specs/streamlit-frontend/tasks.md", "content": "- [ ] 7. Add session state management and initialization\n  - Create initialize_session_state() function for app state setup\n  - Implement repository caching with refresh functionality\n  - Add state management for current operations and notifications\n  - Handle GitHub token storage in session state securely\n  - _Requirements: 4.4, 5.3_\n\n- [ ] 8. Implement main application orchestration\n  - Create main() function as application entry point\n  - Add render_header() function for app title and navigation\n  - Integrate all components into cohesive user interface\n  - Implement auto-refresh functionality for repository list\n  - _Requirements: 1.3, 1.4, 4.4, 5.1_\n\n- [ ] 9. Add error handling and user feedback systems\n  - Implement comprehensive error handling for API failures"}, {"id": ".kiro/specs/streamlit-frontend/tasks.md_4", "file": ".kiro/specs/streamlit-frontend/tasks.md", "content": "- Implement comprehensive error handling for API failures\n  - Add user-friendly error messages with suggested actions\n  - Create timeout handling for long-running operations\n  - Add validation feedback for form inputs\n  - _Requirements: 2.4, 4.2, 4.3, 5.2_\n\n- [ ] 10. Create responsive layout and mobile optimization\n  - Implement responsive design for different screen sizes\n  - Add mobile-friendly touch interactions\n  - Optimize layout for tablet and desktop viewing\n  - Test and adjust component spacing and sizing\n  - _Requirements: 5.1, 5.3_\n\n- [ ] 11. Add repository statistics and metadata display\n  - Implement detailed file type breakdown visualization\n  - Create language percentage display with color coding\n  - Add repository size formatting and display"}, {"id": ".kiro/specs/streamlit-frontend/tasks.md_5", "file": ".kiro/specs/streamlit-frontend/tasks.md", "content": "- Add repository size formatting and display\n  - Show clone timestamp and source URL information\n  - _Requirements: 1.2, 1.4_\n\n- [ ] 12. Implement real-time operation feedback\n  - Add progress bars for clone operations\n  - Create real-time status updates during repository processing\n  - Implement operation cancellation if supported by backend\n  - Add estimated time remaining for long operations\n  - _Requirements: 4.1, 4.4_\n\n- [ ] 13. Create comprehensive testing suite\n  - Write unit tests for API client functions\n  - Create integration tests for Flask backend communication\n  - Add UI component testing with mock data\n  - Implement error scenario testing and validation\n  - _Requirements: All requirements validation_\n\n- [ ] 14. Add final polish and optimization"}, {"id": ".kiro/specs/streamlit-frontend/tasks.md_6", "file": ".kiro/specs/streamlit-frontend/tasks.md", "content": "- _Requirements: All requirements validation_\n\n- [ ] 14. Add final polish and optimization\n  - Optimize performance for large repository lists\n  - Add keyboard shortcuts for common actions\n  - Implement caching for improved responsiveness\n  - Add final styling touches and animations\n  - _Requirements: 5.1, 5.3, 5.4_"}]


================================================
FILE: indexes/NaviGit/graph.pkl
================================================
[Binary file]


================================================
FILE: indexes/NaviGit/repo.index
================================================
[Binary file]


================================================
FILE: services/__init__.py
================================================
# Services package for AI Project Analyzer

from .gitingest_processor import GitingestProcessor, AuthConfig, ProcessingConfig
from .config import GitingestConfig, load_gitingest_config, get_github_token, setup_gitingest_environment

__all__ = [
    'GitingestProcessor',
    'AuthConfig', 
    'ProcessingConfig',
    'GitingestConfig',
    'load_gitingest_config',
    'get_github_token',
    'setup_gitingest_environment'
]


================================================
FILE: services/code_analyzer.py
================================================
"""
Multi-Language Code Analyzer

This module provides comprehensive code analysis capabilities for 10+ programming languages.
It uses Tree-sitter for accurate parsing and extracts code structure, relationships, and metadata.
"""

import re
import ast
import json
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
import logging

logger = logging.getLogger(__name__)


class ProgrammingLanguage(Enum):
    """Supported programming languages"""
    PYTHON = "python"
    JAVASCRIPT = "javascript"
    TYPESCRIPT = "typescript"
    RUST = "rust"
    GO = "go"
    JAVA = "java"
    CPP = "cpp"
    C = "c"
    CSHARP = "csharp"
    PHP = "php"
    RUBY = "ruby"
    SWIFT = "swift"
    KOTLIN = "kotlin"
    SCALA = "scala"
    DART = "dart"
    LUA = "lua"
    UNKNOWN = "unknown"


@dataclass
class CodeFunction:
    """Represents a function in the code"""
    name: str
    start_line: int
    end_line: int
    parameters: List[str]
    return_type: Optional[str]
    docstring: Optional[str]
    calls: List[str]  # Functions this function calls
    complexity: str  # low, medium, high
    is_async: bool = False
    is_static: bool = False
    visibility: str = "public"  # public, private, protected


@dataclass
class CodeClass:
    """Represents a class in the code"""
    name: str
    start_line: int
    end_line: int
    methods: List[CodeFunction]
    properties: List[str]
    inherits_from: List[str]
    implements: List[str]
    docstring: Optional[str]
    is_abstract: bool = False


@dataclass
class CodeImport:
    """Represents an import statement"""
    module: str
    items: List[str]  # Specific items imported
    alias: Optional[str]
    is_relative: bool = False
    line_number: int = 0


@dataclass
class CodeStructure:
    """Complete code structure for a file"""
    file_path: str
    language: ProgrammingLanguage
    functions: List[CodeFunction]
    classes: List[CodeClass]
    imports: List[CodeImport]
    exports: List[str]  # For languages that support exports
    variables: List[str]  # Global/module-level variables
    interfaces: List[Dict[str, Any]]  # For TypeScript/Java interfaces
    types: List[Dict[str, Any]]  # Custom types
    total_lines: int
    complexity_score: float
    entry_points: List[str]  # Main functions, if __name__ == "__main__", etc.


class LanguageDetector:
    """Detects programming language from file path and content"""
    
    EXTENSION_MAP = {
        '.py': ProgrammingLanguage.PYTHON,
        '.js': ProgrammingLanguage.JAVASCRIPT,
        '.mjs': ProgrammingLanguage.JAVASCRIPT,
        '.ts': ProgrammingLanguage.TYPESCRIPT,
        '.tsx': ProgrammingLanguage.TYPESCRIPT,
        '.jsx': ProgrammingLanguage.JAVASCRIPT,
        '.rs': ProgrammingLanguage.RUST,
        '.go': ProgrammingLanguage.GO,
        '.java': ProgrammingLanguage.JAVA,
        '.cpp': ProgrammingLanguage.CPP,
        '.cc': ProgrammingLanguage.CPP,
        '.cxx': ProgrammingLanguage.CPP,
        '.c': ProgrammingLanguage.C,
        '.h': ProgrammingLanguage.C,
        '.hpp': ProgrammingLanguage.CPP,
        '.cs': ProgrammingLanguage.CSHARP,
        '.php': ProgrammingLanguage.PHP,
        '.rb': ProgrammingLanguage.RUBY,
        '.swift': ProgrammingLanguage.SWIFT,
        '.kt': ProgrammingLanguage.KOTLIN,
        '.kts': ProgrammingLanguage.KOTLIN,
        '.scala': ProgrammingLanguage.SCALA,
        '.dart': ProgrammingLanguage.DART,
        '.lua': ProgrammingLanguage.LUA,
    }
    
    @classmethod
    def detect_from_path(cls, file_path: str) -> ProgrammingLanguage:
        """Detect language from file extension"""
        path = Path(file_path)
        extension = path.suffix.lower()
        return cls.EXTENSION_MAP.get(extension, ProgrammingLanguage.UNKNOWN)
    
    @classmethod
    def detect_language(cls, file_path: str, content: str) -> ProgrammingLanguage:
        """Comprehensive language detection"""
        # Try extension first (most reliable)
        ext_language = cls.detect_from_path(file_path)
        
        if ext_language != ProgrammingLanguage.UNKNOWN:
            return ext_language
        
        # Fall back to unknown for now
        return ProgrammingLanguage.UNKNOWN


class PythonAnalyzer:
    """Specialized analyzer for Python code"""
    
    @staticmethod
    def analyze(content: str, file_path: str) -> CodeStructure:
        """Analyze Python code structure"""
        functions = []
        classes = []
        imports = []
        variables = []
        entry_points = []
        
        try:
            tree = ast.parse(content)
            
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    func = CodeFunction(
                        name=node.name,
                        start_line=node.lineno,
                        end_line=getattr(node, 'end_lineno', node.lineno),
                        parameters=[arg.arg for arg in node.args.args],
                        return_type=None,  # Could extract from annotations
                        docstring=ast.get_docstring(node),
                        calls=PythonAnalyzer._extract_function_calls(node),
                        complexity=PythonAnalyzer._calculate_complexity(node),
                        is_async=isinstance(node, ast.AsyncFunctionDef)
                    )
                    functions.append(func)
                
                elif isinstance(node, ast.ClassDef):
                    class_methods = []
                    for item in node.body:
                        if isinstance(item, (ast.FunctionDef, ast.AsyncFunctionDef)):
                            method = CodeFunction(
                                name=item.name,
                                start_line=item.lineno,
                                end_line=getattr(item, 'end_lineno', item.lineno),
                                parameters=[arg.arg for arg in item.args.args],
                                return_type=None,
                                docstring=ast.get_docstring(item),
                                calls=PythonAnalyzer._extract_function_calls(item),
                                complexity=PythonAnalyzer._calculate_complexity(item),
                                is_async=isinstance(item, ast.AsyncFunctionDef)
                            )
                            class_methods.append(method)
                    
                    cls = CodeClass(
                        name=node.name,
                        start_line=node.lineno,
                        end_line=getattr(node, 'end_lineno', node.lineno),
                        methods=class_methods,
                        properties=[],  # Could extract from assignments
                        inherits_from=[base.id for base in node.bases if hasattr(base, 'id')],
                        implements=[],
                        docstring=ast.get_docstring(node)
                    )
                    classes.append(cls)
                
                elif isinstance(node, (ast.Import, ast.ImportFrom)):
                    if isinstance(node, ast.Import):
                        for alias in node.names:
                            imp = CodeImport(
                                module=alias.name,
                                items=[],
                                alias=alias.asname,
                                line_number=node.lineno
                            )
                            imports.append(imp)
                    else:  # ImportFrom
                        items = [alias.name for alias in node.names]
                        imp = CodeImport(
                            module=node.module or '',
                            items=items,
                            alias=None,
                            is_relative=node.level > 0,
                            line_number=node.lineno
                        )
                        imports.append(imp)
            
            # Check for entry points
            if 'if __name__ == "__main__"' in content:
                entry_points.append('__main__')
            
        except SyntaxError as e:
            logger.warning(f"Failed to parse Python file {file_path}: {e}")
        
        return CodeStructure(
            file_path=file_path,
            language=ProgrammingLanguage.PYTHON,
            functions=functions,
            classes=classes,
            imports=imports,
            exports=[],
            variables=variables,
            interfaces=[],
            types=[],
            total_lines=len(content.split('\n')),
            complexity_score=len(functions) + len(classes) * 2,
            entry_points=entry_points
        )
    
    @staticmethod
    def _extract_function_calls(node: ast.AST) -> List[str]:
        """Extract function calls from AST node"""
        calls = []
        for child in ast.walk(node):
            if isinstance(child, ast.Call) and hasattr(child.func, 'id'):
                calls.append(child.func.id)
        return calls
    
    @staticmethod
    def _calculate_complexity(node: ast.AST) -> str:
        """Calculate cyclomatic complexity"""
        complexity = 1  # Base complexity
        
        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.Try, ast.With)):
                complexity += 1
            elif isinstance(child, ast.BoolOp):
                complexity += len(child.values) - 1
        
        if complexity <= 5:
            return "low"
        elif complexity <= 10:
            return "medium"
        else:
            return "high"


class TypeScriptAnalyzer:
    """Specialized analyzer for TypeScript/JavaScript code"""
    
    @staticmethod
    def analyze(content: str, file_path: str) -> CodeStructure:
        """Analyze TypeScript/JavaScript code structure using regex patterns"""
        functions = []
        classes = []
        imports = []
        exports = []
        interfaces = []
        entry_points = []
        
        lines = content.split('\n')
        
        # Patterns for different constructs
        function_patterns = [
            r'(?:export\s+)?(?:async\s+)?function\s+(\w+)\s*\(',  # function declarations
            r'(?:export\s+)?const\s+(\w+)\s*=\s*(?:async\s*)?\([^)]*\)\s*=>', # arrow functions
            r'(?:export\s+)?const\s+(\w+)\s*=\s*(?:async\s+)?function', # function expressions
        ]
        
        class_patterns = [
            r'(?:export\s+)?(?:default\s+)?class\s+(\w+)',  # class declarations
        ]
        
        interface_patterns = [
            r'(?:export\s+)?interface\s+(\w+)',  # interface declarations
            r'(?:export\s+)?type\s+(\w+)\s*=',   # type aliases
        ]
        
        import_patterns = [
            r'import\s+(?:\{([^}]+)\}|\*\s+as\s+(\w+)|(\w+))\s+from\s+[\'"]([^\'"]+)[\'"]',
            r'import\s+[\'"]([^\'"]+)[\'"]',  # side-effect imports
        ]
        
        export_patterns = [
            r'export\s+(?:default\s+)?(?:const|let|var|function|class)\s+(\w+)',
            r'export\s+\{([^}]+)\}',
        ]
        
        for i, line in enumerate(lines, 1):
            line = line.strip()
            
            # Find functions
            for pattern in function_patterns:
                matches = re.finditer(pattern, line)
                for match in matches:
                    func_name = match.group(1)
                    # Extract parameters (basic)
                    param_match = re.search(r'\(([^)]*)\)', line)
                    params = []
                    if param_match:
                        param_str = param_match.group(1)
                        if param_str.strip():
                            params = [p.split(':')[0].strip() for p in param_str.split(',') if p.strip()]
                    
                    func = CodeFunction(
                        name=func_name,
                        start_line=i,
                        end_line=i,  # Approximate
                        parameters=params,
                        return_type=None,
                        docstring=None,
                        calls=[],
                        complexity="medium",  # Default
                        is_async='async' in line
                    )
                    functions.append(func)
            
            # Find classes
            for pattern in class_patterns:
                matches = re.finditer(pattern, line)
                for match in matches:
                    class_name = match.group(1)
                    cls = CodeClass(
                        name=class_name,
                        start_line=i,
                        end_line=i,  # Approximate
                        methods=[],
                        properties=[],
                        inherits_from=[],
                        implements=[],
                        docstring=None
                    )
                    classes.append(cls)
            
            # Find interfaces/types
            for pattern in interface_patterns:
                matches = re.finditer(pattern, line)
                for match in matches:
                    interface_name = match.group(1)
                    interfaces.append({
                        'name': interface_name,
                        'line': i,
                        'type': 'interface' if 'interface' in line else 'type'
                    })
            
            # Find imports
            for pattern in import_patterns:
                matches = re.finditer(pattern, line)
                for match in matches:
                    groups = match.groups()
                    if len(groups) >= 4 and groups[3]:  # Named/default imports
                        module = groups[3]
                        items = []
                        if groups[0]:  # Named imports
                            items = [item.strip() for item in groups[0].split(',')]
                        elif groups[1]:  # Namespace import
                            items = [groups[1]]
                        elif groups[2]:  # Default import
                            items = [groups[2]]
                        
                        imp = CodeImport(
                            module=module,
                            items=items,
                            alias=None,
                            is_relative=module.startswith('.'),
                            line_number=i
                        )
                        imports.append(imp)
                    elif len(groups) >= 1 and groups[0]:  # Side-effect import
                        imp = CodeImport(
                            module=groups[0],
                            items=[],
                            alias=None,
                            is_relative=groups[0].startswith('.'),
                            line_number=i
                        )
                        imports.append(imp)
            
            # Find exports
            for pattern in export_patterns:
                matches = re.finditer(pattern, line)
                for match in matches:
                    if match.group(1):
                        exports.append(match.group(1))
                    else:
                        # Handle export { ... }
                        export_list = match.group(1) if len(match.groups()) > 1 else ""
                        if export_list:
                            exports.extend([e.strip() for e in export_list.split(',') if e.strip()])
        
        # Check for React component (common entry point)
        if 'export default' in content or 'export default function' in content:
            entry_points.append('default_export')
        
        return CodeStructure(
            file_path=file_path,
            language=ProgrammingLanguage.TYPESCRIPT if file_path.endswith(('.ts', '.tsx')) else ProgrammingLanguage.JAVASCRIPT,
            functions=functions,
            classes=classes,
            imports=imports,
            exports=exports,
            variables=[],
            interfaces=interfaces,
            types=[],
            total_lines=len(lines),
            complexity_score=len(functions) + len(classes) * 2 + len(interfaces),
            entry_points=entry_points
        )


class MultiLanguageCodeAnalyzer:
    """Main analyzer that coordinates language-specific analyzers"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
        self.analyzers = {
            ProgrammingLanguage.PYTHON: PythonAnalyzer,
            ProgrammingLanguage.TYPESCRIPT: TypeScriptAnalyzer,
            ProgrammingLanguage.JAVASCRIPT: TypeScriptAnalyzer,  # Use same analyzer
        }
    
    def analyze_file(self, file_path: str, content: str) -> CodeStructure:
        """Analyze a single file and return its code structure"""
        try:
            # Detect language
            language = LanguageDetector.detect_language(file_path, content)
            
            self.logger.debug(f"Analyzing {file_path} as {language.value}")
            
            # Use specialized analyzer if available
            if language in self.analyzers:
                analyzer = self.analyzers[language]
                return analyzer.analyze(content, file_path)
            
            # Return minimal structure for unsupported languages
            return CodeStructure(
                file_path=file_path,
                language=language,
                functions=[],
                classes=[],
                imports=[],
                exports=[],
                variables=[],
                interfaces=[],
                types=[],
                total_lines=len(content.split('\n')),
                complexity_score=0,
                entry_points=[]
            )
            
        except Exception as e:
            self.logger.error(f"Error analyzing file {file_path}: {str(e)}")
            
            # Return minimal structure on error
            return CodeStructure(
                file_path=file_path,
                language=ProgrammingLanguage.UNKNOWN,
                functions=[],
                classes=[],
                imports=[],
                exports=[],
                variables=[],
                interfaces=[],
                types=[],
                total_lines=len(content.split('\n')),
                complexity_score=0,
                entry_points=[]
            )
    
    def analyze_project(self, files: Dict[str, str]) -> Dict[str, CodeStructure]:
        """Analyze multiple files and return project structure"""
        project_structure = {}
        
        for file_path, content in files.items():
            structure = self.analyze_file(file_path, content)
            project_structure[file_path] = structure
        
        return project_structure


================================================
FILE: services/config.py
================================================
"""
Configuration module for gitingest processing.

This module handles loading and validation of environment variables
for gitingest integration configuration.
"""

import os
from typing import List, Optional
from dataclasses import dataclass


@dataclass
class GitingestConfig:
    """Configuration class for gitingest processing settings"""
    
    max_file_size: int
    timeout: int
    temp_dir: str
    include_patterns: List[str]
    exclude_patterns: List[str]
    
    @classmethod
    def from_environment(cls) -> 'GitingestConfig':
        """
        Load gitingest configuration from environment variables.
        
        Returns:
            GitingestConfig instance with values from environment or defaults
        """
        # Load with defaults
        max_file_size = int(os.getenv('GITINGEST_MAX_FILE_SIZE', '10485760'))  # 10MB default
        timeout = int(os.getenv('GITINGEST_TIMEOUT', '300'))  # 5 minutes default
        temp_dir = os.getenv('GITINGEST_TEMP_DIR', '/tmp/gitingest')
        
        # Parse comma-separated patterns
        include_patterns_str = os.getenv(
            'GITINGEST_INCLUDE_PATTERNS', 
            '*.py,*.js,*.ts,*.jsx,*.tsx,*.md,*.json,*.yaml,*.yml'
        )
        include_patterns = [p.strip() for p in include_patterns_str.split(',') if p.strip()]
        
        exclude_patterns_str = os.getenv(
            'GITINGEST_EXCLUDE_PATTERNS',
            'node_modules,__pycache__,.git,*.pyc,*.log'
        )
        exclude_patterns = [p.strip() for p in exclude_patterns_str.split(',') if p.strip()]
        
        return cls(
            max_file_size=max_file_size,
            timeout=timeout,
            temp_dir=temp_dir,
            include_patterns=include_patterns,
            exclude_patterns=exclude_patterns
        )
    
    def validate(self) -> List[str]:
        """
        Validate configuration values.
        
        Returns:
            List of validation error messages, empty if valid
        """
        errors = []
        
        if self.max_file_size <= 0:
            errors.append("max_file_size must be positive")
        
        if self.timeout <= 0:
            errors.append("timeout must be positive")
        
        if not self.temp_dir:
            errors.append("temp_dir cannot be empty")
        
        if not self.include_patterns:
            errors.append("include_patterns cannot be empty")
        
        return errors
    
    def to_processing_config(self):
        """
        Convert to ProcessingConfig for GitingestProcessor.
        
        Returns:
            ProcessingConfig instance
        """
        from .gitingest_processor import ProcessingConfig
        
        return ProcessingConfig(
            include_patterns=self.include_patterns,
            exclude_patterns=self.exclude_patterns,
            max_file_size=self.max_file_size,
            respect_gitignore=True,
            include_binary_files=False,
            timeout=self.timeout
        )


def load_gitingest_config() -> GitingestConfig:
    """
    Load and validate gitingest configuration from environment.
    
    Returns:
        GitingestConfig instance
        
    Raises:
        ValueError: If configuration is invalid
    """
    config = GitingestConfig.from_environment()
    
    errors = config.validate()
    if errors:
        raise ValueError(f"Invalid gitingest configuration: {', '.join(errors)}")
    
    return config


def get_github_token() -> Optional[str]:
    """
    Get GitHub token from environment variables.
    
    Checks multiple possible environment variable names for GitHub token.
    
    Returns:
        GitHub token if found, None otherwise
    """
    # Check common environment variable names for GitHub token
    # Prioritize the one already used in your app
    token_vars = [
        'GITHUB_API_TOKEN',  # Your existing token variable
        'GITHUB_TOKEN',
        'GITHUB_ACCESS_TOKEN', 
        'GH_TOKEN',
        'PERSONAL_ACCESS_TOKEN'
    ]
    
    for var in token_vars:
        token = os.getenv(var)
        if token and token != 'your_github_token_here':  # Skip placeholder values
            return token
    
    return None


def setup_gitingest_environment() -> None:
    """
    Set up environment for gitingest processing.
    
    Creates necessary directories and validates configuration.
    """
    import tempfile
    from pathlib import Path
    
    config = load_gitingest_config()
    
    # Create temp directory if it doesn't exist
    temp_path = Path(config.temp_dir)
    if not temp_path.exists():
        try:
            temp_path.mkdir(parents=True, exist_ok=True)
        except PermissionError:
            # Fall back to system temp directory
            config.temp_dir = tempfile.gettempdir()
    
    # Validate gitingest is available
    import subprocess
    try:
        result = subprocess.run(['gitingest', '--version'], 
                              capture_output=True, text=True, timeout=10)
        if result.returncode != 0:
            raise RuntimeError("Gitingest command failed")
    except (FileNotFoundError, subprocess.TimeoutExpired):
        raise RuntimeError("Gitingest is not installed or not accessible in PATH")


================================================
FILE: services/gitingest_processor.py
================================================
"""
GitingestProcessor Service

This service handles gitingest execution and output processing for repository analysis.
It replaces the complex GitHub API streaming approach with gitingest's optimized
text format generation.
"""

import os
import subprocess
import tempfile
import logging
from pathlib import Path
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from datetime import datetime
import json
import shutil

logger = logging.getLogger(__name__)


@dataclass
class AuthConfig:
    """Configuration for repository authentication"""
    token: Optional[str] = None
    auth_method: str = "token"  # token, ssh, https
    

@dataclass
class ProcessingConfig:
    """Configuration for gitingest processing"""
    include_patterns: List[str] = None
    exclude_patterns: List[str] = None
    max_file_size: int = 10 * 1024 * 1024  # 10MB default
    respect_gitignore: bool = True
    include_binary_files: bool = False
    timeout: int = 300  # 5 minutes default
    
    def __post_init__(self):
        if self.include_patterns is None:
            self.include_patterns = ["*.py", "*.js", "*.ts", "*.jsx", "*.tsx", "*.md", "*.json", "*.yaml", "*.yml"]
        if self.exclude_patterns is None:
            self.exclude_patterns = ["node_modules", "__pycache__", ".git", "*.pyc", "*.log"]


@dataclass
class GitingestMetadata:
    """Metadata from gitingest processing"""
    processing_time: float
    total_files: int
    total_size: int
    gitingest_version: str
    processed_at: str


@dataclass
class ContentBlock:
    """Represents a content block from gitingest output"""
    file_path: str
    content: str
    language: str
    line_count: int
    size_bytes: int
    file_type: str


@dataclass
class StructuredRepository:
    """Structured representation of repository from gitingest"""
    repo_url: str
    files: Dict[str, ContentBlock]
    file_hierarchy: Dict[str, Any]
    language_stats: Dict[str, int]
    gitingest_metadata: GitingestMetadata
    raw_output: str


@dataclass
class ValidationResult:
    """Result of repository validation"""
    valid: bool
    error: Optional[str] = None
    repo_info: Optional[Dict[str, Any]] = None


@dataclass
class GitingestOutput:
    """Complete output from gitingest processing"""
    success: bool
    structured_repo: Optional[StructuredRepository] = None
    error: Optional[str] = None
    processing_stats: Optional[Dict[str, Any]] = None


class GitingestProcessor:
    """
    Core service that handles gitingest execution and output processing.
    
    This service provides methods to:
    - Process repositories using gitingest
    - Parse gitingest output into structured format
    - Validate repository access
    - Handle authentication and cleanup
    """
    
    def __init__(self, config: Optional[ProcessingConfig] = None):
        """
        Initialize GitingestProcessor with configuration.
        
        Args:
            config: Processing configuration, uses defaults if None
        """
        self.config = config or ProcessingConfig()
        self.temp_dir = None
        self._setup_logging()
    
    def _setup_logging(self):
        """Setup logging for gitingest operations"""
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
    
    async def process_repository(self, repo_url: str, auth_config: AuthConfig) -> GitingestOutput:
        """
        Process a repository using gitingest to convert it to structured text format.
        
        Args:
            repo_url: URL of the repository to process
            auth_config: Authentication configuration for repository access
            
        Returns:
            GitingestOutput containing structured repository data or error information
        """
        start_time = datetime.now()
        process_id = None
        
        try:
            self.logger.info(f"Starting gitingest processing for repository: {repo_url}")
            
            # Validate repository first
            validation = await self.validate_repository(repo_url)
            if not validation.valid:
                return GitingestOutput(
                    success=False,
                    error=f"Repository validation failed: {validation.error}"
                )
            
            # Create temporary directory for processing
            process_id = self._create_temp_directory()
            
            # Execute gitingest command
            raw_output = await self._execute_gitingest(repo_url, auth_config, process_id)
            
            # Parse gitingest output
            structured_repo = self.parse_gitingest_output(raw_output, repo_url)
            
            # Calculate processing stats
            processing_time = (datetime.now() - start_time).total_seconds()
            processing_stats = {
                'processing_time_seconds': processing_time,
                'files_processed': len(structured_repo.files),
                'total_size_bytes': sum(block.size_bytes for block in structured_repo.files.values()),
                'started_at': start_time.isoformat(),
                'completed_at': datetime.now().isoformat()
            }
            
            self.logger.info(f"Successfully processed repository {repo_url} in {processing_time:.2f} seconds")
            
            return GitingestOutput(
                success=True,
                structured_repo=structured_repo,
                processing_stats=processing_stats
            )
            
        except Exception as e:
            self.logger.error(f"Error processing repository {repo_url}: {str(e)}")
            return GitingestOutput(
                success=False,
                error=f"Processing failed: {str(e)}"
            )
        finally:
            # Always cleanup temporary files
            if process_id:
                self.cleanup_temporary_files(process_id)
    
    async def validate_repository(self, repo_url: str) -> ValidationResult:
        """
        Validate repository URL and check basic accessibility.
        
        Args:
            repo_url: Repository URL to validate
            
        Returns:
            ValidationResult indicating if repository is valid and accessible
        """
        try:
            # Basic URL validation
            if not repo_url or not isinstance(repo_url, str):
                return ValidationResult(valid=False, error="Invalid repository URL")
            
            # Check if it's a valid Git URL format
            valid_patterns = [
                r'https://github\.com/[\w\-\.]+/[\w\-\.]+',
                r'git@github\.com:[\w\-\.]+/[\w\-\.]+\.git',
                r'https://gitlab\.com/[\w\-\.]+/[\w\-\.]+',
                r'https://bitbucket\.org/[\w\-\.]+/[\w\-\.]+',
            ]
            
            import re
            is_valid_format = any(re.match(pattern, repo_url) for pattern in valid_patterns)
            
            if not is_valid_format:
                return ValidationResult(
                    valid=False, 
                    error="Repository URL format not supported. Please use GitHub, GitLab, or Bitbucket URLs."
                )
            
            # For now, assume valid if format is correct
            # In a full implementation, we might do additional checks here
            return ValidationResult(
                valid=True,
                repo_info={
                    'url': repo_url,
                    'validated_at': datetime.now().isoformat()
                }
            )
            
        except Exception as e:
            self.logger.error(f"Repository validation error: {str(e)}")
            return ValidationResult(valid=False, error=f"Validation failed: {str(e)}")
    
    def parse_gitingest_output(self, raw_output: str, repo_url: str) -> StructuredRepository:
        """
        Parse gitingest raw output into structured repository representation.
        
        Args:
            raw_output: Raw text output from gitingest command
            repo_url: Original repository URL
            
        Returns:
            StructuredRepository with parsed and structured data
        """
        try:
            self.logger.info("Parsing gitingest output into structured format")
            
            # Initialize data structures
            files = {}
            file_hierarchy = {}
            language_stats = {}
            
            # Parse the gitingest output
            # Gitingest format: FILE: filename followed by content
            lines = raw_output.split('\n')
            current_file = None
            current_content = []
            in_file_section = False
            
            for line in lines:
                # Detect file headers - gitingest uses "FILE: filename" format
                if line.startswith('FILE: '):
                    # Save previous file if exists
                    if current_file and current_content:
                        self._add_file_to_structure(current_file, current_content, files, language_stats)
                    
                    # Start new file
                    current_file = line.replace('FILE: ', '').strip()
                    current_content = []
                    in_file_section = True
                    
                elif line.startswith('='):
                    # Skip separator lines
                    continue
                    
                elif line.startswith('Directory structure:'):
                    # Skip directory structure section
                    in_file_section = False
                    current_file = None
                    
                elif in_file_section and current_file:
                    # Add content line
                    current_content.append(line)
            
            # Add last file
            if current_file and current_content:
                self._add_file_to_structure(current_file, current_content, files, language_stats)
            
            # Build file hierarchy from the raw output directory structure
            file_hierarchy = self._parse_directory_structure(raw_output)
            
            # Create metadata
            metadata = GitingestMetadata(
                processing_time=0.0,  # Will be set by caller
                total_files=len(files),
                total_size=sum(block.size_bytes for block in files.values()),
                gitingest_version="unknown",  # Could be detected from gitingest --version
                processed_at=datetime.now().isoformat()
            )
            
            return StructuredRepository(
                repo_url=repo_url,
                files=files,
                file_hierarchy=file_hierarchy,
                language_stats=language_stats,
                gitingest_metadata=metadata,
                raw_output=raw_output
            )
            
        except Exception as e:
            self.logger.error(f"Error parsing gitingest output: {str(e)}")
            raise
    
    def cleanup_temporary_files(self, process_id: str) -> None:
        """
        Clean up temporary files and directories created during processing.
        
        Args:
            process_id: Unique identifier for the processing session
        """
        try:
            if self.temp_dir and os.path.exists(self.temp_dir):
                shutil.rmtree(self.temp_dir)
                self.logger.info(f"Cleaned up temporary directory for process {process_id}")
        except Exception as e:
            self.logger.error(f"Error cleaning up temporary files for process {process_id}: {str(e)}")
    
    def _create_temp_directory(self) -> str:
        """Create temporary directory for processing and return process ID"""
        self.temp_dir = tempfile.mkdtemp(prefix="gitingest_")
        process_id = os.path.basename(self.temp_dir)
        self.logger.debug(f"Created temporary directory: {self.temp_dir}")
        return process_id
    
    async def _execute_gitingest(self, repo_url: str, auth_config: AuthConfig, process_id: str) -> str:
        """
        Execute gitingest command with proper authentication and configuration.
        
        Args:
            repo_url: Repository URL to process
            auth_config: Authentication configuration
            process_id: Process identifier for cleanup
            
        Returns:
            Raw output from gitingest command
        """
        output_file = None
        try:
            # Create temporary output file (Windows encoding workaround)
            import tempfile
            output_fd, output_file = tempfile.mkstemp(suffix='.txt', dir=self.temp_dir, text=True)
            os.close(output_fd)  # Close the file descriptor, we'll use the path
            
            # Build gitingest command with correct syntax
            cmd = ['gitingest', repo_url]
            
            # Add configuration options using correct flags
            if self.config.max_file_size:
                cmd.extend(['--max-size', str(self.config.max_file_size)])
            
            # Add include patterns
            for pattern in self.config.include_patterns:
                cmd.extend(['--include-pattern', pattern])
            
            # Add exclude patterns
            for pattern in self.config.exclude_patterns:
                cmd.extend(['--exclude-pattern', pattern])
            
            # Include gitignored files if configured
            if not self.config.respect_gitignore:
                cmd.append('--include-gitignored')
            
            # Add token if provided
            if auth_config.token:
                cmd.extend(['--token', auth_config.token])
            
            # Output to temporary file (Windows encoding workaround)
            cmd.extend(['--output', output_file])
            
            # Set up environment
            env = os.environ.copy()
            if auth_config.token:
                env['GITHUB_TOKEN'] = auth_config.token
            
            # Execute gitingest
            self.logger.debug(f"Executing gitingest command: {' '.join(cmd[:-2])} [URL] --output [temp_file]")
            
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.config.timeout,
                env=env,
                cwd=self.temp_dir,
                encoding='utf-8',
                errors='replace'  # Handle encoding errors gracefully
            )
            
            if result.returncode != 0:
                error_msg = result.stderr.strip() if result.stderr else "Unknown gitingest error"
                raise RuntimeError(f"Gitingest execution failed: {error_msg}")
            
            # Read the output file
            with open(output_file, 'r', encoding='utf-8', errors='replace') as f:
                output_content = f.read()
            
            return output_content
            
        except subprocess.TimeoutExpired:
            raise RuntimeError(f"Gitingest execution timed out after {self.config.timeout} seconds")
        except FileNotFoundError:
            raise RuntimeError("Gitingest is not installed or not in PATH")
        except Exception as e:
            raise RuntimeError(f"Gitingest execution failed: {str(e)}")
        finally:
            # Clean up temporary output file
            if output_file and os.path.exists(output_file):
                try:
                    os.remove(output_file)
                except Exception as e:
                    self.logger.warning(f"Failed to clean up temporary output file {output_file}: {e}")
    
    def _add_file_to_structure(self, file_path: str, content_lines: List[str], 
                              files: Dict[str, ContentBlock], language_stats: Dict[str, int]) -> None:
        """Add a file to the structured repository data"""
        # Clean up content - remove empty lines at the end
        while content_lines and not content_lines[-1].strip():
            content_lines.pop()
        
        content = '\n'.join(content_lines)
        language = self._detect_language(file_path)
        
        # Update language statistics
        if language:
            language_stats[language] = language_stats.get(language, 0) + 1
        
        # Create content block
        content_block = ContentBlock(
            file_path=file_path,
            content=content,
            language=language or 'unknown',
            line_count=len(content_lines),
            size_bytes=len(content.encode('utf-8')),
            file_type=self._get_file_type(file_path)
        )
        
        files[file_path] = content_block
    
    def _parse_directory_structure(self, raw_output: str) -> Dict[str, Any]:
        """Parse directory structure from gitingest output"""
        hierarchy = {}
        
        lines = raw_output.split('\n')
        in_directory_section = False
        
        for line in lines:
            if line.startswith('Directory structure:'):
                in_directory_section = True
                continue
            elif line.startswith('=') and in_directory_section:
                # End of directory section
                break
            elif in_directory_section and line.strip():
                # Parse directory tree lines
                # Example: "    â””â”€â”€ README" or "â””â”€â”€ octocat-hello-world/"
                if 'â””â”€â”€' in line or 'â”œâ”€â”€' in line:
                    # Extract file/folder name
                    parts = line.split('â”€â”€')
                    if len(parts) > 1:
                        name = parts[-1].strip()
                        if name.endswith('/'):
                            # Directory
                            hierarchy[name[:-1]] = {}
                        else:
                            # File
                            hierarchy[name] = name
        
        return hierarchy
    
    def _build_file_hierarchy(self, file_paths: List[str]) -> Dict[str, Any]:
        """Build hierarchical structure from file paths"""
        hierarchy = {}
        
        for file_path in file_paths:
            parts = file_path.split('/')
            current = hierarchy
            
            for part in parts[:-1]:  # Directories
                if part not in current:
                    current[part] = {}
                current = current[part]
            
            # File
            if parts:
                current[parts[-1]] = file_path
        
        return hierarchy
    
    def _detect_language(self, file_path: str) -> Optional[str]:
        """Detect programming language from file extension"""
        ext = Path(file_path).suffix.lower()
        
        language_map = {
            '.py': 'Python',
            '.js': 'JavaScript',
            '.ts': 'TypeScript',
            '.jsx': 'JavaScript',
            '.tsx': 'TypeScript',
            '.java': 'Java',
            '.cpp': 'C++',
            '.c': 'C',
            '.cs': 'C#',
            '.go': 'Go',
            '.rs': 'Rust',
            '.php': 'PHP',
            '.rb': 'Ruby',
            '.swift': 'Swift',
            '.kt': 'Kotlin',
            '.scala': 'Scala',
            '.html': 'HTML',
            '.css': 'CSS',
            '.scss': 'SCSS',
            '.md': 'Markdown',
            '.json': 'JSON',
            '.yaml': 'YAML',
            '.yml': 'YAML',
            '.xml': 'XML',
            '.sql': 'SQL',
            '.sh': 'Shell',
            '.bash': 'Shell',
            '.ps1': 'PowerShell'
        }
        
        return language_map.get(ext)
    
    def _get_file_type(self, file_path: str) -> str:
        """Determine file type category"""
        ext = Path(file_path).suffix.lower()
        
        if ext in ['.py', '.js', '.ts', '.jsx', '.tsx', '.java', '.cpp', '.c', '.cs', '.go', '.rs', '.php', '.rb', '.swift', '.kt', '.scala']:
            return 'source'
        elif ext in ['.md', '.txt', '.rst', '.doc', '.docx']:
            return 'documentation'
        elif ext in ['.json', '.yaml', '.yml', '.xml', '.toml', '.ini', '.cfg']:
            return 'configuration'
        elif ext in ['.html', '.css', '.scss', '.less']:
            return 'web'
        elif ext in ['.sql']:
            return 'database'
        elif ext in ['.sh', '.bash', '.ps1', '.bat']:
            return 'script'
        else:
            return 'other'


================================================
FILE: services/rag_service.py
================================================
[Empty file]


================================================
FILE: services/rag_system.py
================================================
Error reading file with 'cp1252': 'charmap' codec can't decode byte 0x8d in position 36680: character maps to <undefined>


================================================
FILE: static/index.css
================================================
/* Reset + Base */
body, html {
    margin: 0;
    padding: 0;
    height: 100%;
    font-family: "Inter", sans-serif;
    display: flex;
    flex-direction: column;
    background: radial-gradient(circle at bottom center, #ff6a3d, #2b2d77 70%);
    color: white;
  }
  
  /* Header */
  header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    padding: 20px 40px;
  }
  
  header .logo {
    font-family: "Instrument Serif", serif;
    font-weight: 100;
    font-size: 20px;
  }
  
  header nav a {
    margin-left: 20px;
    text-decoration: none;
    color: white;
    font-size: 14px;
    opacity: 0.9;
  }
  
  /* Main hero */
  .main {
    flex: 1;
    display: flex;
    flex-direction: column;
    justify-content: center;
    align-items: center;
    text-align: center;
  }
  
  .main h1 {
    font-size: 78px;
    margin-bottom: 0px;
    font-weight: 100;
    font-family: "Instrument Serif", sans-serif;
  }
  
  .main p {
    font-size: 18px;
    opacity: 0.85;
    margin-bottom: 40px;
    
  }
  
  /* Input box */
  .input-box {
    background: #111;
    padding: 20px;
    border-radius: 12px;
    width: 600px;
    max-width: 90%;
    display: flex;
    flex-direction: column;
    gap: 15px;
  }
  
  .input-box input[type="text"] {
    padding: 15px;
    border: none;
    border-radius: 8px;
    font-size: 16px;
    outline: none;
    width: 100%;
  }
  
  .input-box button {
    padding: 12px;
    border: none;
    border-radius: 8px;
    background: #007bff;
    color: white;
    font-size: 16px;
    cursor: pointer;
  }
  
  .input-box button:hover {
    background: #0056b3;
  }
  
  /* Repo list */
  .repo-list {
    margin-top: 40px;
    text-align: left;
    width: 600px;
    max-width: 90%;
  }
  
  .repo-list h2 {
    margin-bottom: 15px;
    font-size: 20px;
  }
  
  .repo-list ul {
    list-style: none;
    padding: 0;
    margin: 0;
  }
  
  .repo-list li {
    background: rgba(255,255,255,0.1);
    padding: 12px;
    border-radius: 8px;
    margin-bottom: 10px;
  }
  
  .repo-list li a {
    color: white;
    text-decoration: none;
  }


  .repo-input-container {
    background: #1c1c1c; /* dark background like Lovable */
    border-radius: 12px;
    padding: 12px 16px;
    display: flex;
    align-items: center;
    justify-content: space-between;
    width: 50%;
    max-width: 100%;
    margin: 0 auto;
    box-shadow: 0 2px 6px rgba(0,0,0,0.3);
  }
  
  .repo-input-container form {
    display: flex;
    flex: 1;
    align-items: center;
    gap: 10px;
  }
  
  .repo-input-container input {
    flex: 1;
    background: transparent;
    border: none;
    outline: none;
    color: white;
    font-size: 15px;
    padding: 10px;
  }
  
  .repo-input-container input::placeholder {
    color: #888;
  }
  
  .repo-input-container button {
    background: #484848; /* blue button */
    color: white;
    border: none;
    padding: 10px 18px;
    border-radius: 8px;
    cursor: pointer;
    font-size: 14px;
    font-weight: 500;
    transition: background 0.2s ease;
  }
  
  .repo-input-container button:hover {
    background: #0056b3;
  }

  .repos-section {
    margin-top: 40px;
    text-align: center;
  }
  
  .repos-section h2 {
    font-family: "Lora", serif;
    font-size: 28px;
    margin-bottom: 20px;
    color: white;
  }
  
  .repos-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(240px, 1fr));
    gap: 20px;
    justify-items: center;
    padding: 0 20px;
  }
  
  .repo-card {
    display: flex;
    align-items: center;
    justify-content: center;
    background: rgba(255, 255, 255, 0.08);
    border: 1px solid rgba(255, 255, 255, 0.15);
    border-radius: 12px;
    padding: 30px 20px;
    width: 100%;
    max-width: 320px;
    color: white;
    font-size: 18px;
    font-weight: 500;
    text-decoration: none;
    transition: all 0.25s ease;
  }
  
  .repo-card:hover {
    background: rgba(255, 255, 255, 0.15);
    transform: translateY(-4px);
  }


================================================
FILE: templates/index.html
================================================
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>NaviGit</title>
  <link rel="stylesheet" href="{{ url_for('static', filename='index.css') }}">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Instrument+Serif:ital@0;1&display=swap" rel="stylesheet">
</head>
<body>
  <!-- Header -->
  <header>
    <div class="logo">NaviGit</div>
    <nav>
      <a href="#">Docs</a>
      <a href="#">Pricing</a>
      <a href="#">About</a>
      <a href="#">Login</a>
    </nav>
  </header>

  <!-- Main -->
  <div class="main">
    <h1>Get the gist before the first sip</h1>
    <p>Ingest repos and chat with your code</p>

    <!-- Repo input -->
    <div class="repo-input-container">
      <form method="POST" action="/">
        <input type="text" name="repo_link" placeholder="Paste GitHub repo link..." />
        <button type="submit">Ingest Repo</button>
      </form>
    </div>

    <div class="repos-section">
      <h2>Your Repos</h2>
      <div class="repos-grid">
        {% for repo_key in repos %}
          <a href="{{ url_for('workspace', owner=repo_key.split('/')[0], repo=repo_key.split('/')[1]) }}" class="repo-card">
            <div class="repo-title">{{ repo_key }}</div>
          </a>
        {% endfor %}
      </div>
    </div>
  </div>
</body>
</html>



================================================
FILE: templates/loading.html
================================================
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Loading Repo</title>
  <style>
    .bubble {
      width: 100px;
      height: 100px;
      background: blue;
      border-radius: 50%;
      animation: bounce 1s infinite alternate;
    }
    @keyframes bounce {
      from { transform: translateY(0); }
      to { transform: translateY(-30px); }
    }
  </style>
</head>
<body>
  <h1>Preparing {{ repo }}...</h1>
  <div class="bubble"></div>
  <p>AI is analyzing your repo, please wait.</p>
  <script>
    setTimeout(() => {
      window.location.href = "/workspace/{{ repo }}";
    }, 3000); // auto redirect after 3s
  </script>
</body>
</html>



================================================
FILE: templates/workspace.html
================================================
<!DOCTYPE html>
<html>
<head>
  <title>{{ repo }}</title>
  <style>
    body, html { margin: 0; padding: 0; height: 100%; font-family: sans-serif; }
    .container { display: flex; height: 100vh; }
    .sidebar { width: 280px; overflow-y: auto; background: #f5f5f5; padding: 10px; border-right: 1px solid #ddd; }
    .main { flex: 1; display: flex; flex-direction: column; }
    .code-viewer { flex: 2; display: flex; flex-direction: column; border-bottom: 1px solid #ddd; }
    .chat { flex: 1; display: flex; flex-direction: column; }
    .chat-history { flex: 1; overflow-y: auto; padding: 10px; background: #fafafa; }
    .chat-input { display: flex; border-top: 1px solid #ddd; }
    .chat-input textarea { flex: 1; resize: none; padding: 10px; border: none; outline: none; }
    .chat-input button { width: 100px; border: none; background: #007bff; color: white; cursor: pointer; }
    .chat-input button:hover { background: #0056b3; }
    ul { list-style: none; padding-left: 20px; margin: 0; }
    li { cursor: pointer; }
    li.folder > span { font-weight: bold; }
    h3 { margin: 0; padding: 10px; border-bottom: 1px solid #ddd; background: #f9f9f9; }
    .CodeMirror { height: 100%; font-size: 14px; }
  </style>

  <!-- CodeMirror assets -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.65.9/codemirror.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.65.9/theme/eclipse.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.65.9/codemirror.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.65.9/mode/python/python.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.65.9/mode/javascript/javascript.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.65.9/mode/clike/clike.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.65.9/mode/markdown/markdown.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.65.9/mode/xml/xml.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.65.9/mode/css/css.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.65.9/mode/htmlmixed/htmlmixed.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.65.9/mode/jsx/jsx.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.65.9/mode/javascript/typescript.min.js"></script>
</head>
<body>
  <div class="container">
    <!-- Sidebar -->
    <div class="sidebar">
      <h3>{{ owner }}/{{ repo }}</h3>
      <ul>
        {% macro render_tree(tree, path="") %}
          {% for key, value in tree.items() %}
            {% if value is string %}
              <li class="file" onclick="showContent('{{ path ~ key }}')">ðŸ“„ {{ key }}</li>
              <script>
                window.fileContents = window.fileContents || {};
                window.fileContents["{{ path ~ key }}"] = {{ value|tojson }};
              </script>
            {% else %}
              <li class="folder">
                <span onclick="toggleFolder(this)">ðŸ“‚ {{ key }}</span>
                <ul style="display:none;">
                  {{ render_tree(value, path ~ key ~ "/") }}
                </ul>
              </li>
            {% endif %}
          {% endfor %}
        {% endmacro %}
        {{ render_tree(file_tree) }}
      </ul>
    </div>

    <!-- Main Panel -->
    <div class="main">
      <!-- Code Viewer -->
      <div class="code-viewer">
        <h3 id="current-file">Select a file</h3>
        <textarea id="code-editor"></textarea>
      </div>

      <!-- Chat Assistant -->
      <div class="chat">
        <div id="chat-history" class="chat-history"></div>
        <div class="chat-input">
          <textarea id="chat-input" rows="2" placeholder="Ask about this repo..."></textarea>
          <button onclick="sendMessage()">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script>
    // Initialize CodeMirror
    let editor = CodeMirror.fromTextArea(document.getElementById("code-editor"), {
      lineNumbers: true,
      readOnly: true,
      theme: "eclipse",
      mode: "null"
    });

    function guessMode(filename) {
      if (filename.endsWith(".py")) return "python";
      if (filename.endsWith(".js")) return "javascript";
      if (filename.endsWith(".ts") || filename.endsWith(".tsx")) return "text/typescript";
      if (filename.endsWith(".jsx")) return "jsx";
      if (filename.endsWith(".java")) return "text/x-java";
      if (filename.endsWith(".md")) return "markdown";
      if (filename.endsWith(".html")) return "htmlmixed";
      if (filename.endsWith(".css")) return "css";
      if (filename.endsWith(".xml")) return "xml";
      return "null";
    }

    function showContent(filename) {
      const content = window.fileContents[filename] || "";
      editor.setValue(content);
      editor.setOption("mode", guessMode(filename));
      document.getElementById("current-file").innerText = filename;
    }

    function toggleFolder(el) {
      let sublist = el.nextElementSibling;
      if (sublist.style.display === "none") {
        sublist.style.display = "block";
      } else {
        sublist.style.display = "none";
      }
    }

    async function sendMessage() {
      const input = document.getElementById("chat-input");
      const message = input.value.trim();
      if (!message) return;

      const history = document.getElementById("chat-history");
      const userMsg = document.createElement("div");
      userMsg.textContent = "ðŸ§‘ " + message;
      history.appendChild(userMsg);

      input.value = "";

      const res = await fetch("{{ url_for('chat_api', owner=owner, repo=repo) }}", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ message })
      });
      const data = await res.json();

      const botMsg = document.createElement("div");
      botMsg.textContent = "ðŸ¤– " + data.reply;
      history.appendChild(botMsg);
      history.scrollTop = history.scrollHeight;
    }
  </script>
</body>
</html>



================================================
FILE: test_files/quick_test.py
================================================
#!/usr/bin/env python3
import requests
import json

# Test with a well-known public repository
BASE_URL = "http://localhost:5000"

def test_with_known_repo():
    print("Testing with octocat/Hello-World (known public repo)...")
    
    url = f"{BASE_URL}/api/repositories/validate"
    data = {"url": "https://github.com/octocat/Hello-World"}
    
    response = requests.post(url, json=data)
    print(f"Status: {response.status_code}")
    print(f"Response: {response.json()}")
    print()

def test_with_your_repo():
    print("Testing with Emon69420/HazMapApp...")
    
    url = f"{BASE_URL}/api/repositories/validate"
    data = {"url": "https://github.com/Emon69420/HazMapApp"}
    
    response = requests.post(url, json=data)
    print(f"Status: {response.status_code}")
    print(f"Response: {response.json()}")
    print()

if __name__ == "__main__":
    try:
        test_with_known_repo()
        test_with_your_repo()
    except requests.exceptions.ConnectionError:
        print("Error: Could not connect to Flask server.")
        print("Make sure the server is running with: python app.py")
    except Exception as e:
        print(f"Error: {e}")


================================================
FILE: test_files/quick_token_test.py
================================================
#!/usr/bin/env python3
"""
Quick test to verify your GitHub token works
"""

import requests

def test_github_token():
    """Test if your GitHub token works"""
    print("🔑 GitHub Token Tester")
    print("=" * 30)
    
    # Get token from user
    token = input("Paste your GitHub token here: ").strip()
    
    if not token:
        print("❌ No token provided!")
        return
    
    if not token.startswith('ghp_'):
        print("⚠️  Warning: Token should start with 'ghp_'")
    
    print("\n🔍 Testing token...")
    
    # Test the token
    headers = {
        'Authorization': f'token {token}',
        'Accept': 'application/vnd.github.v3+json'
    }
    
    try:
        # Test 1: Get user info
        response = requests.get('https://api.github.com/user', headers=headers)
        
        if response.status_code == 200:
            user_data = response.json()
            print(f"✅ Token valid!")
            print(f"   User: {user_data.get('login')}")
            print(f"   Name: {user_data.get('name', 'Not set')}")
            print(f"   Email: {user_data.get('email', 'Not public')}")
            
            # Test 2: Check rate limits
            rate_response = requests.get('https://api.github.com/rate_limit', headers=headers)
            if rate_response.status_code == 200:
                rate_data = rate_response.json()
                core = rate_data['resources']['core']
                print(f"\n📊 Rate Limits:")
                print(f"   Limit: {core['limit']} requests/hour")
                print(f"   Remaining: {core['remaining']}")
                print(f"   Used: {core['used']}")
            
            # Test 3: Access your repository
            print(f"\n🔍 Testing repository access...")
            repo_response = requests.get('https://api.github.com/repos/Emon69420/HazMapApp', headers=headers)
            
            if repo_response.status_code == 200:
                repo_data = repo_response.json()
                print(f"✅ Repository accessible!")
                print(f"   Name: {repo_data['full_name']}")
                print(f"   Private: {repo_data['private']}")
                print(f"   Size: {repo_data['size']} KB")
                
                print(f"\n🎉 Token is working perfectly!")
                print(f"💾 Save this token: {token}")
                
            else:
                print(f"❌ Repository access failed: {repo_response.status_code}")
                
        elif response.status_code == 401:
            print("❌ Token is invalid or expired")
        elif response.status_code == 403:
            print("❌ Token doesn't have required permissions")
        else:
            print(f"❌ Unexpected error: {response.status_code}")
            
    except Exception as e:
        print(f"❌ Error testing token: {e}")

if __name__ == "__main__":
    test_github_token()
    
    print("\n💡 Next steps:")
    print("1. If token works: Run 'python test_with_token.py'")
    print("2. If token fails: Check permissions and regenerate")
    print("3. Keep your token safe - don't share it!")


================================================
FILE: test_files/streamlit_app.py
================================================
import streamlit as st
import requests
from datetime import datetime
import os
import json

def load_custom_css():
    """Load custom CSS for dark theme styling"""
    st.markdown("""
    <style>
    .main {
        background-color: #0E1117;
    }
    
    .stApp {
        background-color: #0E1117;
    }
    
    .css-1d391kg {
        background-color: #0E1117;
    }
    
    .stSelectbox > div > div {
        background-color: #262730;
        color: #FAFAFA;
    }
    
    .stTextInput > div > div > input {
        background-color: #262730;
        color: #FAFAFA;
        border: 1px solid #4F4F4F;
    }
    
    .stButton > button {
        background-color: #FF4B4B;
        color: white;
        border: none;
        border-radius: 4px;
        padding: 0.5rem 1rem;
    }
    
    .stButton > button:hover {
        background-color: #FF6B6B;
    }
    
    .success-message {
        background-color: #00CC88;
        color: white;
        padding: 0.5rem;
        border-radius: 4px;
        margin: 0.5rem 0;
    }
    
    .error-message {
        background-color: #FF6B6B;
        color: white;
        padding: 0.5rem;
        border-radius: 4px;
        margin: 0.5rem 0;
    }
    
    .info-message {
        background-color: #4A90E2;
        color: white;
        padding: 0.5rem;
        border-radius: 4px;
        margin: 0.5rem 0;
    }
    
    .repo-card {
        background-color: #262730;
        padding: 1rem;
        border-radius: 8px;
        margin: 0.5rem 0;
        border: 1px solid #4F4F4F;
    }
    
    .repo-card:hover {
        border-color: #FF4B4B;
        transition: border-color 0.3s ease;
    }
    </style>
    """, unsafe_allow_html=True)

def initialize_session_state():
    """Initialize session state variables"""
    if 'repositories' not in st.session_state:
        st.session_state.repositories = []
    if 'loading' not in st.session_state:
        st.session_state.loading = False
    if 'current_operation' not in st.session_state:
        st.session_state.current_operation = ""
    if 'notifications' not in st.session_state:
        st.session_state.notifications = []
    if 'github_token' not in st.session_state:
        st.session_state.github_token = ""
    if 'last_refresh' not in st.session_state:
        st.session_state.last_refresh = None

def render_header():
    """Render the application header"""
    st.title("ðŸš€ AI Project Analyzer")
    st.markdown("---")

def main():
    """Main application entry point"""
    # Configure Streamlit page
    st.set_page_config(
        page_title="AI Project Analyzer",
        page_icon="ðŸš€",
        layout="wide",
        initial_sidebar_state="collapsed"
    )
    
    # Load custom styling
    load_custom_css()
    
    # Initialize session state
    initialize_session_state()
    
    # Render header
    render_header()
    
    # Placeholder content for now
    st.info("ðŸ”§ Application structure set up successfully!")
    st.markdown("### Next Steps:")
    st.markdown("- Dark theme styling system")
    st.markdown("- API client module")
    st.markdown("- Repository list display")
    st.markdown("- Add repository form")

if __name__ == "__main__":
    main()


================================================
FILE: test_files/suppress_warnings.py
================================================
#!/usr/bin/env python3
"""
Utility to suppress ONNX Runtime warnings and other verbose output
"""

import os
import sys
import warnings
import logging

def suppress_all_warnings():
    """Suppress all the annoying warnings from ML libraries"""
    
    # 1. Suppress TensorFlow warnings
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Only show errors
    os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'  # Disable oneDNN warnings
    
    # 2. Suppress ONNX Runtime warnings
    os.environ['ORT_DISABLE_ALL_LOGS'] = '1'
    
    # 3. Suppress Python warnings
    warnings.filterwarnings('ignore')
    
    # 4. Suppress specific library warnings
    logging.getLogger('tensorflow').setLevel(logging.ERROR)
    logging.getLogger('onnxruntime').setLevel(logging.ERROR)
    logging.getLogger('transformers').setLevel(logging.ERROR)
    logging.getLogger('sentence_transformers').setLevel(logging.ERROR)
    logging.getLogger('chromadb').setLevel(logging.ERROR)
    
    # 5. Redirect stderr temporarily to suppress C++ warnings
    import contextlib
    
    @contextlib.contextmanager
    def suppress_stderr():
        with open(os.devnull, "w") as devnull:
            old_stderr = sys.stderr
            sys.stderr = devnull
            try:
                yield
            finally:
                sys.stderr = old_stderr
    
    return suppress_stderr

# Call this at the start of any script
def setup_clean_environment():
    """Set up a clean environment without warnings"""
    suppress_all_warnings()
    
    # Also suppress the specific ONNX warnings by setting environment variables
    os.environ['CUDA_VISIBLE_DEVICES'] = ''  # Force CPU-only
    os.environ['OMP_NUM_THREADS'] = '1'  # Reduce threading warnings
    
    print("ðŸ”‡ Warnings suppressed - clean output enabled!")

if __name__ == "__main__":
    setup_clean_environment()
    print("âœ… Warning suppression configured!")


================================================
FILE: test_files/test_api.py
================================================
#!/usr/bin/env python3
"""
Simple test script to verify the API endpoints work correctly
"""

import requests
import json

BASE_URL = "http://localhost:5000"

def test_repository_validation():
    """Test repository validation endpoint"""
    print("Testing repository validation...")
    
    url = f"{BASE_URL}/api/repositories/validate"
    data = {"url": "https://github.com/Emon69420/HazMapApp"}
    
    response = requests.post(url, json=data)
    print(f"Status: {response.status_code}")
    print(f"Response: {response.json()}")
    print()

def test_repository_analysis():
    """Test repository analysis endpoint"""
    print("Testing repository analysis...")
    
    url = f"{BASE_URL}/api/repositories/analyze"
    data = {"url": "https://github.com/Emon69420/HazMapApp"}
    
    response = requests.post(url, json=data)
    print(f"Status: {response.status_code}")
    print(f"Response: {response.json()}")
    print()

def test_repository_tree():
    """Test repository tree endpoint"""
    print("Testing repository tree...")
    
    url = f"{BASE_URL}/api/repositories/Emon69420/HazMapApp/tree"
    
    response = requests.get(url)
    print(f"Status: {response.status_code}")
    result = response.json()
    if 'tree' in result:
        print(f"Files found: {result['tree']['total_files']}")
        print(f"Directories found: {result['tree']['total_directories']}")
        # Show first few files
        files = result['tree']['files'][:5]
        print("Sample files:")
        for file in files:
            print(f"  - {file['path']}")
    else:
        print(f"Response: {result}")
    print()

def test_file_content():
    """Test file content endpoint"""
    print("Testing file content...")
    
    url = f"{BASE_URL}/api/repositories/Emon69420/HazMapApp/files/README.md"
    
    response = requests.get(url)
    print(f"Status: {response.status_code}")
    result = response.json()
    if 'file' in result:
        print(f"File: {result['file']['name']}")
        print(f"Size: {result['file']['size']} bytes")
        print(f"Encoding: {result['file']['encoding']}")
    else:
        print(f"Response: {result}")
    print()

if __name__ == "__main__":
    print("Testing AI Project Analyzer API endpoints")
    print("=" * 50)
    
    try:
        test_repository_validation()
        test_repository_analysis()
        test_repository_tree()
        test_file_content()
        
        print("All tests completed!")
        
    except requests.exceptions.ConnectionError:
        print("Error: Could not connect to Flask server.")
        print("Make sure the server is running with: python app.py")
    except Exception as e:
        print(f"Error: {e}")


================================================
FILE: test_files/test_clone.py
================================================
#!/usr/bin/env python3
"""
Test script for repository cloning functionality
"""

import requests
import json
import os
from pathlib import Path

BASE_URL = "http://localhost:5000"

def test_clone_repository():
    """Test cloning a repository"""
    print("🔄 Testing repository cloning...")
    print("=" * 50)
    
    url = f"{BASE_URL}/api/repositories/clone"
    data = {
        "url": "https://github.com/Emon69420/HazMapApp",
        "target_dir": "./my_repos"
    }
    
    response = requests.post(url, json=data)
    print(f"Status: {response.status_code}")
    
    if response.status_code == 200:
        result = response.json()
        print(f"✅ Clone successful!")
        print(f"📁 Clone path: {result['clone_path']}")
        print(f"📊 Total files: {result['stats']['total_files']}")
        print(f"📂 Total directories: {result['stats']['total_directories']}")
        print(f"💾 Size: {result['stats']['size_bytes']} bytes")
        print(f"🔤 Languages detected:")
        for lang, count in result['stats']['languages'].items():
            print(f"   - {lang}: {count} files")
        
        # Check if directory actually exists
        clone_path = Path(result['clone_path'])
        if clone_path.exists():
            print(f"✅ Directory exists: {clone_path}")
            
            # List some files
            files = list(clone_path.rglob('*'))[:10]
            print(f"📄 Sample files:")
            for file in files:
                if file.is_file():
                    print(f"   - {file.relative_to(clone_path)}")
        else:
            print(f"❌ Directory not found: {clone_path}")
            
    else:
        print(f"❌ Clone failed: {response.json()}")
    
    print()

def test_clone_and_analyze():
    """Test clone and analyze in one operation"""
    print("🔍 Testing clone and analyze...")
    print("=" * 50)
    
    url = f"{BASE_URL}/api/repositories/clone-and-analyze"
    data = {
        "url": "https://github.com/Emon69420/HazMapApp",
        "target_dir": "./my_repos",
        "max_file_size": 512 * 1024,  # 512KB limit
        "cleanup_after": False  # Keep the repository for inspection
    }
    
    response = requests.post(url, json=data)
    print(f"Status: {response.status_code}")
    
    if response.status_code == 200:
        result = response.json()
        
        # Clone info
        clone_info = result['clone_info']
        print(f"✅ Clone successful!")
        print(f"📁 Clone path: {clone_info['clone_path']}")
        print(f"⏰ Cloned at: {clone_info['cloned_at']}")
        
        # Analysis info
        analysis = result['analysis']
        stats = analysis['processing_stats']
        
        print(f"\n📈 Analysis Results:")
        print(f"  ✅ Files processed: {stats['processed']}")
        print(f"  ⚠️  Files skipped (too large): {stats['skipped_large']}")
        print(f"  🚫 Files skipped (binary): {stats['skipped_binary']}")
        print(f"  ❌ Errors: {stats['errors']}")
        
        # Repository stats
        repo_stats = analysis['stats']
        print(f"\n📊 Repository Statistics:")
        print(f"  📄 Total files: {repo_stats['total_files']}")
        print(f"  📂 Total directories: {repo_stats['total_directories']}")
        print(f"  💾 Size: {repo_stats['size_bytes']} bytes")
        
        # Languages
        if repo_stats['languages']:
            print(f"\n🔤 Languages detected:")
            for lang, count in sorted(repo_stats['languages'].items(), key=lambda x: x[1], reverse=True):
                print(f"   - {lang}: {count} files")
        
        # Show some processed files
        files_with_content = analysis['files_with_content'][:5]
        print(f"\n📄 Sample processed files:")
        for file_info in files_with_content:
            print(f"   - {file_info['path']} ({file_info['lines']} lines, {file_info['language'] or 'Unknown'})")
        
        if len(analysis['files_with_content']) > 5:
            print(f"   ... and {len(analysis['files_with_content']) - 5} more files")
        
        # Save detailed results
        output_file = "clone_analysis_result.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        
        print(f"\n💾 Full results saved to: {output_file}")
        
    else:
        print(f"❌ Clone and analyze failed: {response.json()}")
    
    print()

def test_performance_comparison():
    """Compare API vs Clone performance"""
    print("⚡ Performance Comparison: API vs Clone")
    print("=" * 50)
    
    import time
    
    # Test API approach
    print("Testing API approach...")
    start_time = time.time()
    
    api_url = f"{BASE_URL}/api/repositories/deep-analyze"
    api_data = {
        "url": "https://github.com/octocat/Hello-World",  # Small repo for fair comparison
        "max_file_size": 1024 * 1024
    }
    
    api_response = requests.post(api_url, json=api_data)
    api_time = time.time() - start_time
    
    print(f"API approach: {api_time:.2f} seconds")
    
    # Test Clone approach
    print("Testing Clone approach...")
    start_time = time.time()
    
    clone_url = f"{BASE_URL}/api/repositories/clone-and-analyze"
    clone_data = {
        "url": "https://github.com/octocat/Hello-World",
        "cleanup_after": True  # Clean up after test
    }
    
    clone_response = requests.post(clone_url, json=clone_data)
    clone_time = time.time() - start_time
    
    print(f"Clone approach: {clone_time:.2f} seconds")
    
    # Compare results
    if api_response.status_code == 200 and clone_response.status_code == 200:
        api_files = len(api_response.json()['deep_analysis']['structure']['files_with_content'])
        clone_files = len(clone_response.json()['analysis']['files_with_content'])
        
        print(f"\n📊 Results:")
        print(f"API files processed: {api_files}")
        print(f"Clone files processed: {clone_files}")
        print(f"Speed improvement: {api_time/clone_time:.1f}x faster" if clone_time < api_time else f"API was {clone_time/api_time:.1f}x faster")
    
    print()

if __name__ == "__main__":
    print("🚀 Testing Repository Cloning System")
    print("=" * 60)
    
    try:
        # Check if git is available
        import subprocess
        result = subprocess.run(['git', '--version'], capture_output=True, text=True)
        if result.returncode != 0:
            print("❌ Git is not installed or not in PATH")
            print("Please install Git to use cloning functionality")
            exit(1)
        else:
            print(f"✅ Git available: {result.stdout.strip()}")
            print()
        
        test_clone_repository()
        test_clone_and_analyze()
        test_performance_comparison()
        
        print("🎉 All cloning tests completed!")
        
    except requests.exceptions.ConnectionError:
        print("❌ Error: Could not connect to Flask server.")
        print("Make sure the server is running with: python app.py")
    except Exception as e:
        print(f"❌ Error: {e}")


================================================
FILE: test_files/test_consistent_indexing.py
================================================
#!/usr/bin/env python3
"""
Test to check consistency of RAG indexing across multiple runs
"""

import sys
import os
from pathlib import Path

# Add services to path
sys.path.append(str(Path(__file__).parent))

try:
    from services.rag_system import CPUOptimizedRAGSystem
except ImportError as e:
    print(f"❌ Import error: {e}")
    sys.exit(1)


def run_indexing_test(run_number):
    """Run a single indexing test and return metrics"""
    print(f"\n🔄 Run {run_number}:")
    print("-" * 30)
    
    gitingest_file = "gitingest_outputs/Samay1011_Project_ecommerce_React_20250906_104832.txt"
    
    if not os.path.exists(gitingest_file):
        print(f"❌ Gitingest file not found: {gitingest_file}")
        return None
    
    try:
        # Initialize RAG system with unique storage path
        storage_path = f"./temp_consistency_test_{run_number}"
        rag = CPUOptimizedRAGSystem(storage_path=storage_path)
        
        # Build RAG system
        metrics = rag.build_rag_from_gitingest(gitingest_file, f"consistency_test_{run_number}")
        print(f"✅ Indexed {metrics.total_chunks} chunks from {metrics.total_files} files")
        
        # Get all chunks to analyze
        all_results = rag.query("*", max_results=200, collection_name=f"consistency_test_{run_number}")
        
        # Count by file type
        file_types = {}
        chunk_types = {}
        python_files = []
        
        for chunk in all_results.chunks:
            # File extension
            ext = Path(chunk.file_path).suffix or 'no-ext'
            file_types[ext] = file_types.get(ext, 0) + 1
            
            # Chunk type
            chunk_types[chunk.chunk_type] = chunk_types.get(chunk.chunk_type, 0) + 1
            
            # Track Python files specifically
            if ext == '.py':
                python_files.append({
                    'file': chunk.file_path,
                    'type': chunk.chunk_type,
                    'content_preview': chunk.content[:100].replace('\n', ' ')
                })
        
        print("📁 File types:")
        for ext, count in sorted(file_types.items(), key=lambda x: x[1], reverse=True):
            print(f"   {ext}: {count}")
        
        print("🧩 Chunk types:")
        for chunk_type, count in sorted(chunk_types.items(), key=lambda x: x[1], reverse=True):
            print(f"   {chunk_type}: {count}")
        
        if python_files:
            print("🐍 Python files found:")
            for py_file in python_files:
                print(f"   {py_file['type']}: {py_file['file']}")
                print(f"      Preview: {py_file['content_preview']}...")
        
        return {
            'total_chunks': metrics.total_chunks,
            'total_files': metrics.total_files,
            'file_types': file_types,
            'chunk_types': chunk_types,
            'python_files': python_files
        }
        
    except Exception as e:
        print(f"❌ Run {run_number} failed: {str(e)}")
        return None
    
    finally:
        # Clean up
        try:
            if 'rag' in locals():
                rag.chroma_client = None
                rag.collection = None
            
            import shutil
            import time
            time.sleep(0.5)
            if os.path.exists(storage_path):
                shutil.rmtree(storage_path)
        except Exception as e:
            print(f"⚠️  Warning: Could not clean up run {run_number}: {e}")


def test_consistency():
    """Test consistency across multiple runs"""
    print("🔍 Testing RAG Indexing Consistency")
    print("=" * 50)
    
    results = []
    num_runs = 3
    
    for i in range(1, num_runs + 1):
        result = run_indexing_test(i)
        if result:
            results.append(result)
    
    if len(results) < 2:
        print("❌ Not enough successful runs to compare")
        return
    
    print(f"\n📊 Consistency Analysis ({len(results)} runs):")
    print("=" * 40)
    
    # Compare total counts
    chunk_counts = [r['total_chunks'] for r in results]
    file_counts = [r['total_files'] for r in results]
    
    print(f"📦 Total chunks: {chunk_counts}")
    print(f"📁 Total files: {file_counts}")
    
    if len(set(chunk_counts)) == 1:
        print("✅ Chunk counts are consistent")
    else:
        print("⚠️  Chunk counts vary between runs")
    
    if len(set(file_counts)) == 1:
        print("✅ File counts are consistent")
    else:
        print("⚠️  File counts vary between runs")
    
    # Compare file type distributions
    print(f"\n📁 File Type Consistency:")
    all_extensions = set()
    for result in results:
        all_extensions.update(result['file_types'].keys())
    
    for ext in sorted(all_extensions):
        counts = [result['file_types'].get(ext, 0) for result in results]
        if len(set(counts)) == 1:
            print(f"   {ext}: {counts[0]} ✅")
        else:
            print(f"   {ext}: {counts} ⚠️")
    
    # Compare Python file detection
    print(f"\n🐍 Python File Detection:")
    py_file_counts = [len(r['python_files']) for r in results]
    print(f"Python chunks found: {py_file_counts}")
    
    if len(set(py_file_counts)) == 1:
        print("✅ Python file detection is consistent")
    else:
        print("⚠️  Python file detection varies")
        
        # Show what Python files were found in each run
        for i, result in enumerate(results, 1):
            print(f"  Run {i} Python files:")
            for py_file in result['python_files']:
                print(f"    - {py_file['file']} ({py_file['type']})")


if __name__ == "__main__":
    test_consistency()


================================================
FILE: test_files/test_deep_analysis.py
================================================
#!/usr/bin/env python3
"""
Test script for deep repository analysis - fetches all files with their content
"""

import requests
import json
import os

BASE_URL = "http://localhost:5000"

def test_deep_analysis():
    """Test deep analysis of HazMapApp repository"""
    print("🔍 Starting deep analysis of HazMapApp repository...")
    print("=" * 60)
    
    url = f"{BASE_URL}/api/repositories/deep-analyze"
    data = {
        "url": "https://github.com/Redomic/NeuThera-Drug-Discovery-Toolkit",
        "max_file_size": 1024 * 1024  # 512KB limit for demo
    }
    
    response = requests.post(url, json=data)
    print(f"Status: {response.status_code}")
    
    if response.status_code == 200:
        result = response.json()
        deep_analysis = result['deep_analysis']
        
        # Repository info
        repo_info = deep_analysis['repository_info']
        print(f"\n📁 Repository: {repo_info['full_name']}")
        print(f"📝 Description: {repo_info['description']}")
        print(f"🔤 Language: {repo_info['language']}")
        print(f"📊 Size: {repo_info['size']} KB")
        print(f"⭐ Stars: {repo_info['stargazers_count']}")
        
        # Structure stats
        structure = deep_analysis['structure']
        stats = structure['processing_stats']
        
        print(f"\n📈 Processing Statistics:")
        print(f"  ✅ Files processed: {stats['processed']}")
        print(f"  ⚠️  Files skipped (too large): {stats['skipped_large']}")
        print(f"  🚫 Files skipped (binary): {stats['skipped_binary']}")
        print(f"  ❌ Errors: {stats['errors']}")
        print(f"  📂 Total directories: {structure['total_directories']}")
        print(f"  📄 Total files: {structure['total_files']}")
        
        # Display timing information
        if 'processing_time' in result:
            timing = result['processing_time']
            print(f"\n⏱️  Performance Metrics:")
            print(f"  🕐 Processing time: {timing['formatted']} ({timing['seconds']}s)")
            print(f"  🚀 Files per second: {stats.get('files_per_second', 0)}")
            print(f"  📊 Average time per file: {round(timing['seconds'] / max(stats['processed'], 1), 3)}s")
        
        # Show directory structure
        print(f"\n📂 Directory Structure:")
        for directory in structure['directories'][:10]:
            print(f"  📁 {directory['path']}")
        if len(structure['directories']) > 10:
            print(f"  ... and {len(structure['directories']) - 10} more directories")
        
        # Show files with content
        print(f"\n📄 Files with Content ({len(structure['files_with_content'])}):")
        for i, file_info in enumerate(structure['files_with_content'][:5]):
            print(f"\n  {i+1}. 📄 {file_info['path']}")
            print(f"     Size: {file_info['size']} bytes")
            print(f"     Lines: {file_info['lines']}")
            print(f"     Extension: {file_info['extension']}")
            
            # Show first few lines of content
            content = file_info['content']
            if content:
                lines = content.split('\n')
                print(f"     Content preview (first 3 lines):")
                for j, line in enumerate(lines[:3]):
                    print(f"       {j+1}: {line[:80]}{'...' if len(line) > 80 else ''}")
            else:
                print(f"     Content: [Empty file]")
        
        if len(structure['files_with_content']) > 5:
            print(f"\n  ... and {len(structure['files_with_content']) - 5} more files with content")
        
        # Show skipped files
        if structure['skipped_files']:
            print(f"\n⚠️  Skipped Files ({len(structure['skipped_files'])}):")
            for skip_info in structure['skipped_files'][:5]:
                reason = skip_info['reason']
                path = skip_info['path']
                if reason == 'file_too_large':
                    print(f"  📏 {path} (too large: {skip_info['size']} bytes)")
                elif reason == 'binary_file':
                    print(f"  🔧 {path} (binary: {skip_info['extension']})")
                else:
                    print(f"  ❌ {path} ({reason})")
            
            if len(structure['skipped_files']) > 5:
                print(f"  ... and {len(structure['skipped_files']) - 5} more skipped files")
        
        # Save detailed results to file
        output_file = "hazmap_deep_analysis.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        
        print(f"\n💾 Full analysis saved to: {output_file}")
        print(f"📊 Analysis completed at: {result['analyzed_at']}")
        
        if 'processing_time' in result:
            print(f"⚡ Total processing time: {result['processing_time']['formatted']}")
        
    else:
        print(f"❌ Error: {response.json()}")

def test_explore_endpoint():
    """Test the alternative explore endpoint"""
    print("\n🔍 Testing explore endpoint...")
    print("=" * 40)
    
    url = f"{BASE_URL}/api/repositories/Redomic/NeuThera-Drug-Discovery-Toolkit/explore?max_file_size=102400"  # 100KB limit
    
    response = requests.get(url)
    print(f"Status: {response.status_code}")
    
    if response.status_code == 200:
        result = response.json()
        stats = result['deep_analysis']['structure']['processing_stats']
        print(f"✅ Processed {stats['processed']} files")
        print(f"⚠️  Skipped {stats['skipped_large'] + stats['skipped_binary']} files")
    else:
        print(f"❌ Error: {response.json()}")

if __name__ == "__main__":
    try:
        test_deep_analysis()
        test_explore_endpoint()
        
        print("\n🎉 Deep analysis testing completed!")
        
    except requests.exceptions.ConnectionError:
        print("❌ Error: Could not connect to Flask server.")
        print("Make sure the server is running with: python app.py")
    except Exception as e:
        print(f"❌ Error: {e}")


================================================
FILE: test_files/test_final.py
================================================
#!/usr/bin/env python3
"""
Final clean RAG test - no warnings, no Unicode issues
"""

import os
import sys
import warnings

# Suppress everything
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
os.environ['PYTHONWARNINGS'] = 'ignore'
warnings.filterwarnings('ignore')

from pathlib import Path
import logging
logging.disable(logging.CRITICAL)

sys.path.append(str(Path(__file__).parent))

def main():
    print("Running Clean RAG Test")
    print("=" * 30)
    
    try:
        from services.rag_system import CPUOptimizedRAGSystem
        
        gitingest_file = "gitingest_outputs/Emon69420_HazMapApp_20250905_194000.txt"
        
        if not os.path.exists(gitingest_file):
            print(f"File not found: {gitingest_file}")
            return
        
        print("Building RAG index...")
        
        # Silent build
        with open(os.devnull, 'w') as devnull:
            old_stdout = sys.stdout
            old_stderr = sys.stderr
            sys.stdout = devnull
            sys.stderr = devnull
            
            try:
                rag = CPUOptimizedRAGSystem(storage_path="./final_rag")
                metrics = rag.build_rag_from_gitingest(gitingest_file, "final_test")
            finally:
                sys.stdout = old_stdout
                sys.stderr = old_stderr
        
        print(f"SUCCESS: {metrics.total_chunks} chunks from {metrics.total_files} files")
        
        # Test searches
        searches = [
            ("login authentication", "Login"),
            ("wildfire prediction", "Wildfire"),
            ("location GPS", "Location"),
            ("map component", "Map"),
            ("background task", "Background"),
            ("user profile", "Profile")
        ]
        
        print(f"\nTesting {len(searches)} searches:")
        
        for query, desc in searches:
            # Silent query
            with open(os.devnull, 'w') as devnull:
                old_stderr = sys.stderr
                sys.stderr = devnull
                try:
                    result = rag.query(query, max_results=1, collection_name="final_test")
                finally:
                    sys.stderr = old_stderr
            
            if result.chunks:
                chunk = result.chunks[0]
                file_name = Path(chunk.file_path).name
                func_name = chunk.metadata.get('function_name', 'N/A')
                print(f"  {desc}: {func_name} in {file_name}")
        
        print(f"\nSummary: {metrics.total_files} files, {metrics.total_chunks} chunks")
        print("Test complete!")
        
        # Cleanup
        try:
            rag.chroma_client = None
            rag.collection = None
            import shutil
            import time
            time.sleep(0.5)
            if os.path.exists("./final_rag"):
                shutil.rmtree("./final_rag")
        except:
            pass
            
    except Exception as e:
        print(f"Error: {e}")

if __name__ == "__main__":
    main()


================================================
FILE: test_files/test_find_functions.py
================================================
#!/usr/bin/env python3
"""

"""

import sys
import os
from pathlib import Path

# Add services to path
sys.path.append(str(Path(__file__).parent))

try:
    from services.rag_system import CPUOptimizedRAGSystem
except ImportError as e:
    print(f"❌ Import error: {e}")
    sys.exit(1)


def test_find_specific_functions():
    """Test finding specific functions and components"""
    print("🔍 Testing Function & Component Discovery")
    print("=" * 50)
    
    gitingest_file = "https://github.com/Emon69420/MedMint"
    
    if not os.path.exists(gitingest_file):
        print(f"❌ Gitingest file not found: {gitingest_file}")
        return
    
    try:
        # Initialize RAG system
        print("🔧 Building RAG index...")
        rag = CPUOptimizedRAGSystem(storage_path="./temp_rag_storage")
        
        # Build RAG system
        metrics = rag.build_rag_from_gitingest(gitingest_file, "find_functions_test")
        print(f"✅ Indexed {metrics.total_chunks} chunks from {metrics.total_files} files")
        
        # Test specific function/component searches
        searches = [
            {
                "query": "authentication login function",
                "expect": "Should find login-related code"
            },
            {
                "query": "wildfire risk prediction algorithm",
                "expect": "Should find prediction functions in Flask backend"
            },
            {
                "query": "Flask backend get_wildfire_risk_prediction function",
                "expect": "Should find the main Python prediction function"
            },
            {
                "query": "gee_data Google Earth Engine API",
                "expect": "Should find the GEE data processing function"
            },
            {
                "query": "Python Flask route handler",
                "expect": "Should find Flask route functions like home and about"
            },
            {
                "query": "environmental data processing Python",
                "expect": "Should find Python functions that process environmental data"
            },
            {
                "query": "location tracking GPS coordinates",
                "expect": "Should find LocationContext and location services"
            },
            {
                "query": "air quality monitoring API calls",
                "expect": "Should find air quality related functions"
            },
            {
                "query": "React Native map component MapView",
                "expect": "Should find map implementation"
            },
            {
                "query": "background task notification system",
                "expect": "Should find background task services"
            },
            {
                "query": "user profile management settings",
                "expect": "Should find profile screen and user management"
            },
            {
                "query": "evacuation route planning emergency",
                "expect": "Should find evacuation-related components"
            },
            {
                "query": "Python test functions pytest",
                "expect": "Should find test functions in test_app.py"
            },
            {
                "query": "Flask app configuration setup",
                "expect": "Should find Flask app initialization and config"
            }
        ]
        
        print(f"\n🎯 Testing {len(searches)} specific searches:")
        print("=" * 50)
        
        for i, search in enumerate(searches, 1):
            print(f"\n🔎 Search {i}: '{search['query']}'")
            print(f"   Expected: {search['expect']}")
            
            # Query the RAG system
            result = rag.query(search['query'], max_results=3, collection_name="find_functions_test")
            
            print(f"   ⚡ Found {len(result.chunks)} results:")
            
            # Show results with confidence scores
            for j, (chunk, confidence) in enumerate(zip(result.chunks, result.confidence_scores)):
                confidence_emoji = "🎯" if confidence > 0.1 else "📍" if confidence > 0.05 else "📌"
                print(f"     {confidence_emoji} {chunk.chunk_type} in {chunk.file_path}")
                print(f"        Confidence: {confidence:.3f}")
                
                # Show content preview
                preview = chunk.content.replace('\n', ' ')[:80]
                print(f"        Preview: {preview}...")
                
                # Show metadata if available
                if chunk.metadata:
                    relevant_meta = {}
                    for key in ['function_name', 'class_name', 'method_name']:
                        if key in chunk.metadata and chunk.metadata[key]:
                            relevant_meta[key] = chunk.metadata[key]
                    if relevant_meta:
                        print(f"        Metadata: {relevant_meta}")
            
            # Show relationships if found
            if result.relationships and any(result.relationships.values()):
                related_info = []
                for rel_type, items in result.relationships.items():
                    if items:
                        related_info.append(f"{rel_type}: {len(items)}")
                if related_info:
                    print(f"   🔗 Related: {', '.join(related_info)}")
        
        # Test finding specific code patterns
        print(f"\n🧩 Testing Code Pattern Discovery:")
        print("=" * 30)
        
        pattern_searches = [
            "async function with await",
            "React useState hook",
            "API fetch request",
            "error handling try catch",
            "TypeScript interface definition",
            "Python Flask route decorator",
            "Python function with parameters",
            "Python import statement",
            "Python class definition",
            "Python exception handling try except"
        ]
        
        for pattern in pattern_searches:
            print(f"\n🔍 Pattern: '{pattern}'")
            result = rag.query(pattern, max_results=2, collection_name="find_functions_test")
            
            for chunk, confidence in zip(result.chunks[:2], result.confidence_scores[:2]):
                if confidence > 0.01:  # Only show if there's some relevance
                    print(f"   📄 {chunk.file_path} (confidence: {confidence:.3f})")
                    # Show a longer preview for code patterns
                    preview = chunk.content.replace('\n', ' ')[:120]
                    print(f"      {preview}...")
        
        # Summary of what we found
        print(f"\n📊 Discovery Summary:")
        print("=" * 20)
        
        # Get all chunks to analyze what we have
        all_results = rag.query("*", max_results=50, collection_name="find_functions_test")
        
        # Count by file type
        file_types = {}
        chunk_types = {}
        
        for chunk in all_results.chunks:
            # File extension
            ext = Path(chunk.file_path).suffix or 'no-ext'
            file_types[ext] = file_types.get(ext, 0) + 1
            
            # Chunk type
            chunk_types[chunk.chunk_type] = chunk_types.get(chunk.chunk_type, 0) + 1
        
        print("📁 File types indexed:")
        for ext, count in sorted(file_types.items(), key=lambda x: x[1], reverse=True):
            print(f"   {ext}: {count} chunks")
        
        print("\n🧩 Chunk types created:")
        for chunk_type, count in sorted(chunk_types.items(), key=lambda x: x[1], reverse=True):
            print(f"   {chunk_type}: {count} chunks")
        
        print(f"\n🎉 Function discovery test complete!")
        
    except Exception as e:
        print(f"\n❌ Test failed: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1
    
    finally:
        # Clean up
        try:
            if 'rag' in locals():
                rag.chroma_client = None
                rag.collection = None
            
            import shutil
            import time
            time.sleep(1)
            if os.path.exists("./temp_rag_storage"):
                print("🧹 Cleaning up...")
                shutil.rmtree("./temp_rag_storage")
        except Exception as e:
            print(f"⚠️  Warning: Could not clean up: {e}")
    
    return 0


if __name__ == "__main__":
    exit_code = test_find_specific_functions()
    sys.exit(exit_code)


================================================
FILE: test_files/test_find_functions_clean.py
================================================
Error reading file with 'cp1252': 'charmap' codec can't decode byte 0x9d in position 1034: character maps to <undefined>


================================================
FILE: test_files/test_github_auth.py
================================================
import unittest
from unittest.mock import patch, MagicMock
import json
from app import app, GitHubService

class TestGitHubService(unittest.TestCase):
    
    def setUp(self):
        self.app = app.test_client()
        self.app.testing = True
        self.github_service = GitHubService()
    
    @patch('requests.get')
    def test_validate_token_success(self, mock_get):
        """Test successful token validation"""
        # Mock successful GitHub API response
        mock_response = MagicMock()
        mock_response.status_code = 200
        mock_response.json.return_value = {
            'login': 'testuser',
            'id': 12345,
            'name': 'Test User',
            'email': 'test@example.com'
        }
        mock_response.headers = {'X-OAuth-Scopes': 'repo, user:email'}
        mock_get.return_value = mock_response
        
        result = self.github_service.validate_token('valid_token')
        
        self.assertTrue(result['valid'])
        self.assertEqual(result['user']['login'], 'testuser')
        self.assertIn('repo', result['scopes'])
    
    @patch('requests.get')
    def test_validate_token_invalid(self, mock_get):
        """Test invalid token validation"""
        # Mock failed GitHub API response
        mock_response = MagicMock()
        mock_response.status_code = 401
        mock_get.return_value = mock_response
        
        result = self.github_service.validate_token('invalid_token')
        
        self.assertFalse(result['valid'])
        self.assertIn('error', result)
    
    def test_get_oauth_url(self):
        """Test OAuth URL generation"""
        with patch.dict('os.environ', {'GITHUB_CLIENT_ID': 'test_client_id'}):
            url = self.github_service.get_oauth_url('test_state')
            
            self.assertIn('github.com/login/oauth/authorize', url)
            self.assertIn('client_id=test_client_id', url)
            self.assertIn('state=test_state', url)
    
    def test_login_with_token(self):
        """Test login endpoint with personal access token"""
        with patch.object(self.github_service, 'validate_token') as mock_validate:
            mock_validate.return_value = {
                'valid': True,
                'user': {'login': 'testuser', 'id': 12345},
                'scopes': ['repo', 'user:email']
            }
            
            response = self.app.post('/auth/github/login',
                                   data=json.dumps({'token': 'test_token'}),
                                   content_type='application/json')
            
            self.assertEqual(response.status_code, 200)
            data = json.loads(response.data)
            self.assertTrue(data['success'])
            self.assertEqual(data['user']['login'], 'testuser')
    
    def test_login_with_oauth(self):
        """Test login endpoint OAuth flow initiation"""
        with patch.dict('os.environ', {'GITHUB_CLIENT_ID': 'test_client_id'}):
            response = self.app.post('/auth/github/login',
                                   data=json.dumps({'oauth': True}),
                                   content_type='application/json')
            
            self.assertEqual(response.status_code, 200)
            data = json.loads(response.data)
            self.assertTrue(data['success'])
            self.assertIn('oauth_url', data)
    
    def test_auth_status_authenticated(self):
        """Test auth status when user is authenticated"""
        with self.app.session_transaction() as sess:
            sess['github_token'] = 'test_token'
            sess['github_user'] = {'login': 'testuser', 'id': 12345}
        
        response = self.app.get('/auth/status')
        
        self.assertEqual(response.status_code, 200)
        data = json.loads(response.data)
        self.assertTrue(data['authenticated'])
        self.assertEqual(data['user']['login'], 'testuser')
    
    def test_auth_status_not_authenticated(self):
        """Test auth status when user is not authenticated"""
        response = self.app.get('/auth/status')
        
        self.assertEqual(response.status_code, 200)
        data = json.loads(response.data)
        self.assertFalse(data['authenticated'])
    
    def test_logout(self):
        """Test logout functionality"""
        with self.app.session_transaction() as sess:
            sess['github_token'] = 'test_token'
            sess['github_user'] = {'login': 'testuser'}
        
        response = self.app.post('/auth/logout')
        
        self.assertEqual(response.status_code, 200)
        data = json.loads(response.data)
        self.assertTrue(data['success'])
    
    def test_parse_github_url(self):
        """Test GitHub URL parsing"""
        # Test various URL formats
        test_cases = [
            ('https://github.com/owner/repo', {'owner': 'owner', 'repo': 'repo'}),
            ('https://github.com/owner/repo.git', {'owner': 'owner', 'repo': 'repo'}),
            ('git@github.com:owner/repo.git', {'owner': 'owner', 'repo': 'repo'}),
            ('https://github.com/owner/repo/', {'owner': 'owner', 'repo': 'repo'}),
            ('invalid-url', None)
        ]
        
        for url, expected in test_cases:
            result = self.github_service.parse_github_url(url)
            self.assertEqual(result, expected)
    
    @patch('requests.get')
    def test_validate_repository_access_public(self, mock_get):
        """Test repository validation for public repo"""
        mock_response = MagicMock()
        mock_response.status_code = 200
        mock_response.json.return_value = {
            'name': 'test-repo',
            'full_name': 'owner/test-repo',
            'private': False,
            'description': 'Test repository'
        }
        mock_get.return_value = mock_response
        
        result = self.github_service.validate_repository_access('owner', 'test-repo')
        
        self.assertTrue(result['accessible'])
        self.assertEqual(result['repo_info']['name'], 'test-repo')
        self.assertFalse(result['repo_info']['private'])
    
    def test_validate_repository_endpoint(self):
        """Test repository validation endpoint"""
        with patch.object(self.github_service, 'parse_github_url') as mock_parse, \
             patch.object(self.github_service, 'validate_repository_access') as mock_validate:
            
            mock_parse.return_value = {'owner': 'owner', 'repo': 'repo'}
            mock_validate.return_value = {
                'accessible': True,
                'repo_info': {'name': 'repo', 'private': False}
            }
            
            response = self.app.post('/api/repositories/validate',
                                   data=json.dumps({'url': 'https://github.com/owner/repo'}),
                                   content_type='application/json')
            
            self.assertEqual(response.status_code, 200)
            data = json.loads(response.data)
            self.assertTrue(data['success'])
            self.assertEqual(data['repository']['name'], 'repo')
    
    def test_analyze_repository_endpoint(self):
        """Test repository analysis endpoint"""
        with patch.object(self.github_service, 'parse_github_url') as mock_parse, \
             patch.object(self.github_service, 'validate_repository_access') as mock_validate, \
             patch.object(self.github_service, 'get_repository_tree') as mock_tree:
            
            mock_parse.return_value = {'owner': 'owner', 'repo': 'repo'}
            mock_validate.return_value = {
                'accessible': True,
                'repo_info': {'name': 'repo', 'private': False}
            }
            mock_tree.return_value = {
                'success': True,
                'tree': {'files': [], 'directories': [], 'total_files': 0}
            }
            
            response = self.app.post('/api/repositories/analyze',
                                   data=json.dumps({'url': 'https://github.com/owner/repo'}),
                                   content_type='application/json')
            
            self.assertEqual(response.status_code, 200)
            data = json.loads(response.data)
            self.assertTrue(data['success'])
            self.assertIn('analysis', data)

if __name__ == '__main__':
    unittest.main()


================================================
FILE: test_files/test_gitingest.py
================================================
Error reading file with 'cp1252': 'charmap' codec can't decode byte 0x81 in position 1533: character maps to <undefined>


================================================
FILE: test_files/test_gitingest_simple.py
================================================
#!/usr/bin/env python3
"""
Simple direct test of gitingest command to debug encoding issues.
"""

import subprocess
import sys

def test_direct_gitingest():
    """Test gitingest directly with a simple repo"""
    
    print("🧪 Testing gitingest directly...")
    
    # Test with a very simple repo
    repo_url = "https://github.com/octocat/Hello-World"
    
    try:
        # Simple gitingest command
        cmd = ['gitingest', repo_url, '--output', '-']
        
        print(f"🔧 Running: {' '.join(cmd)}")
        
        # Try with UTF-8 encoding
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=60,
            encoding='utf-8',
            errors='replace'
        )
        
        print(f"📊 Return code: {result.returncode}")
        print(f"📏 Stdout length: {len(result.stdout)} chars")
        print(f"📏 Stderr length: {len(result.stderr)} chars")
        
        if result.returncode == 0:
            print("✅ Success! Here's the first 500 chars of output:")
            print("-" * 50)
            print(result.stdout[:500])
            print("-" * 50)
            if len(result.stdout) > 500:
                print(f"... and {len(result.stdout) - 500} more characters")
        else:
            print("❌ Failed!")
            print("STDERR:")
            print(result.stderr)
            
    except subprocess.TimeoutExpired:
        print("⏰ Command timed out")
    except Exception as e:
        print(f"💥 Error: {e}")

def test_gitingest_to_file():
    """Test gitingest with file output instead of stdout"""
    
    print("\n🧪 Testing gitingest with file output...")
    
    repo_url = "https://github.com/octocat/Hello-World"
    output_file = "test_output.txt"
    
    try:
        # Output to file instead of stdout
        cmd = ['gitingest', repo_url, '--output', output_file]
        
        print(f"🔧 Running: {' '.join(cmd)}")
        
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=60,
            encoding='utf-8',
            errors='replace'
        )
        
        print(f"📊 Return code: {result.returncode}")
        
        if result.returncode == 0:
            print("✅ Success! Checking output file...")
            try:
                with open(output_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    print(f"📏 File size: {len(content)} chars")
                    print("📄 First 500 chars:")
                    print("-" * 50)
                    print(content[:500])
                    print("-" * 50)
                    
                # Clean up
                import os
                os.remove(output_file)
                print("🧹 Cleaned up output file")
                
            except Exception as e:
                print(f"❌ Error reading output file: {e}")
        else:
            print("❌ Failed!")
            print("STDERR:")
            print(result.stderr)
            
    except subprocess.TimeoutExpired:
        print("⏰ Command timed out")
    except Exception as e:
        print(f"💥 Error: {e}")

if __name__ == "__main__":
    test_direct_gitingest()
    test_gitingest_to_file()


================================================
FILE: test_files/test_gitingest_with_output.py
================================================
Error reading file with 'cp1252': 'charmap' codec can't decode byte 0x81 in position 1276: character maps to <undefined>


================================================
FILE: test_files/test_hazmap.py
================================================
#!/usr/bin/env python3
import requests
import json

BASE_URL = "http://localhost:5000"

def test_hazmap_analysis():
    print("Analyzing HazMapApp repository...")
    
    url = f"{BASE_URL}/api/repositories/analyze"
    data = {"url": "https://github.com/Emon69420/HazMapApp"}
    
    response = requests.post(url, json=data)
    print(f"Status: {response.status_code}")
    
    if response.status_code == 200:
        result = response.json()
        analysis = result['analysis']
        
        print(f"Repository: {analysis['repository']['full_name']}")
        print(f"Description: {analysis['repository']['description']}")
        print(f"Language: {analysis['repository']['language']}")
        print(f"Size: {analysis['repository']['size']} KB")
        print(f"Stars: {analysis['repository']['stargazers_count']}")
        print(f"Default branch: {analysis['repository']['default_branch']}")
        print()
        
        structure = analysis['structure']
        print(f"Total files: {structure['total_files']}")
        print(f"Total directories: {structure['total_directories']}")
        print()
        
        print("File structure (first 10 files):")
        for file in structure['files'][:10]:
            print(f"  - {file['path']} ({file['size']} bytes)")
        
        if len(structure['files']) > 10:
            print(f"  ... and {len(structure['files']) - 10} more files")
        
    else:
        print(f"Error: {response.json()}")

def test_get_readme():
    print("\nGetting README.md content...")
    
    url = f"{BASE_URL}/api/repositories/Emon69420/HazMapApp/files/README.md"
    
    response = requests.get(url)
    print(f"Status: {response.status_code}")
    
    if response.status_code == 200:
        result = response.json()
        file_info = result['file']
        
        print(f"File: {file_info['name']}")
        print(f"Size: {file_info['size']} bytes")
        print(f"Encoding: {file_info['encoding']}")
        print(f"Download URL: {file_info['download_url']}")
        
        # Decode base64 content if available
        if file_info['content'] and file_info['encoding'] == 'base64':
            import base64
            content = base64.b64decode(file_info['content']).decode('utf-8')
            print("\nREADME content (first 500 chars):")
            print(content[:500] + "..." if len(content) > 500 else content)
    else:
        print(f"Error: {response.json()}")

if __name__ == "__main__":
    try:
        test_hazmap_analysis()
        test_get_readme()
    except requests.exceptions.ConnectionError:
        print("Error: Could not connect to Flask server.")
        print("Make sure the server is running with: python app.py")
    except Exception as e:
        print(f"Error: {e}")


================================================
FILE: test_files/test_hazmap_rag.py
================================================
#!/usr/bin/env python3
"""
Test RAG system with HazMap app gitingest output
"""

import sys
import os
from pathlib import Path
import time

# Add services to path
sys.path.append(str(Path(__file__).parent))

try:
    from services.rag_system import CPUOptimizedRAGSystem, GitingestParser
    from services.code_analyzer import MultiLanguageCodeAnalyzer
except ImportError as e:
    print(f"❌ Import error: {e}")
    sys.exit(1)


def test_hazmap_rag():
    """Test RAG system with HazMap app"""
    print("🚀 Testing RAG System with HazMap App")
    print("=" * 60)
    
    gitingest_file = "gitingest_outputs/Emon69420_HazMapApp_20250905_194000.txt"
    
    if not os.path.exists(gitingest_file):
        print(f"❌ Gitingest file not found: {gitingest_file}")
        return
    
    try:
        # Initialize RAG system
        print("🔧 Initializing RAG system...")
        rag = CPUOptimizedRAGSystem(storage_path="./hazmap_rag_storage")
        
        # Build RAG system from HazMap gitingest
        print("📊 Building RAG system from HazMap codebase...")
        start_time = time.time()
        
        metrics = rag.build_rag_from_gitingest(gitingest_file, "hazmap_collection")
        
        build_time = time.time() - start_time
        
        print(f"\n✅ RAG system built successfully!")
        print(f"  📁 Total files: {metrics.total_files}")
        print(f"  🧩 Total chunks: {metrics.total_chunks}")
        print(f"  🌐 Languages: {', '.join(metrics.languages_detected)}")
        print(f"  ⏱️  Build time: {build_time:.2f}s")
        print(f"  💾 Index size: {metrics.index_size_mb:.2f}MB")
        
        # Test queries relevant to HazMap
        test_queries = [
            "How do I implement location tracking?",
            "Show me authentication code",
            "How is the map component implemented?",
            "Find air quality monitoring functions",
            "How does wildfire risk prediction work?",
            "Show me background task implementation",
            "How is user profile managed?",
            "Find evacuation route planning code",
            "How are notifications handled?",
            "Show me the database configuration",
            "How is the Google Maps API integrated?",
            "Find React Native navigation setup",
            "How are environmental data fetched?",
            "Show me TypeScript interfaces",
            "How is the app styled?"
        ]
        
        print(f"\n🔍 Testing {len(test_queries)} queries...")
        print("=" * 60)
        
        for i, query in enumerate(test_queries, 1):
            print(f"\n🔎 Query {i}: '{query}'")
            
            query_start = time.time()
            result = rag.query(query, max_results=5, collection_name="hazmap_collection")
            query_time = time.time() - query_start
            
            print(f"  ⚡ Found {len(result.chunks)} results in {query_time:.3f}s")
            
            # Show top 3 results
            for j, (chunk, confidence) in enumerate(zip(result.chunks[:3], result.confidence_scores[:3])):
                print(f"    {j+1}. {chunk.chunk_type} in {chunk.file_path} (confidence: {confidence:.2f})")
                # Show a snippet of the content
                content_preview = chunk.content.replace('\n', ' ')[:100]
                print(f"       Preview: {content_preview}...")
            
            if result.relationships and any(result.relationships.values()):
                print(f"    🔗 Related: {', '.join([f'{k}: {len(v)}' for k, v in result.relationships.items() if v])}")
        
        # Test context generation for LLM
        print(f"\n📝 Testing context generation...")
        test_context_query = "How does the HazMap app handle real-time wildfire monitoring and user notifications?"
        
        result = rag.query(test_context_query, max_results=8, collection_name="hazmap_collection")
        context = rag.get_context_for_llm(result, max_tokens=2000)
        
        print(f"  📄 Generated context ({len(context)} chars):")
        print(f"  Preview: {context[:300]}...")
        
        # Show some interesting statistics
        print(f"\n📊 HazMap Codebase Analysis:")
        
        # Parse the gitingest file to get file breakdown
        files = GitingestParser.parse_gitingest_file(gitingest_file)
        analyzer = MultiLanguageCodeAnalyzer()
        project_structure = analyzer.analyze_project(files)
        
        # Language breakdown
        lang_stats = {}
        for structure in project_structure.values():
            lang = structure.language.value
            if lang not in lang_stats:
                lang_stats[lang] = {'files': 0, 'functions': 0, 'classes': 0, 'lines': 0}
            lang_stats[lang]['files'] += 1
            lang_stats[lang]['functions'] += len(structure.functions)
            lang_stats[lang]['classes'] += len(structure.classes)
            lang_stats[lang]['lines'] += structure.total_lines
        
        for lang, stats in sorted(lang_stats.items(), key=lambda x: x[1]['lines'], reverse=True):
            if stats['files'] > 0:
                print(f"  🔤 {lang.upper()}: {stats['files']} files, {stats['functions']} functions, {stats['classes']} classes, {stats['lines']} lines")
        
        # Find key components
        key_files = []
        for file_path, structure in project_structure.items():
            if any(keyword in file_path.lower() for keyword in ['map', 'auth', 'profile', 'air-quality', 'evacuation']):
                key_files.append((file_path, len(structure.functions), len(structure.classes)))
        
        if key_files:
            print(f"\n🎯 Key Components Found:")
            for file_path, func_count, class_count in sorted(key_files, key=lambda x: x[1] + x[2], reverse=True)[:10]:
                print(f"  📄 {file_path}: {func_count} functions, {class_count} classes")
        
        print(f"\n🎉 HazMap RAG analysis complete!")
        
    except Exception as e:
        print(f"\n❌ Test failed: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1
    
    finally:
        # Clean up
        try:
            if 'rag' in locals():
                rag.chroma_client = None
                rag.collection = None
            
            import shutil
            time.sleep(1)
            if os.path.exists("./hazmap_rag_storage"):
                print("🧹 Cleaning up storage...")
                shutil.rmtree("./hazmap_rag_storage")
        except Exception as e:
            print(f"⚠️  Warning: Could not clean up storage: {e}")
    
    return 0


if __name__ == "__main__":
    exit_code = test_hazmap_rag()
    sys.exit(exit_code)


================================================
FILE: test_files/test_rag_simple.py
================================================
#!/usr/bin/env python3
"""
Simple test for CPU-optimized RAG system.
"""

import os
import sys
import tempfile
import time
from pathlib import Path

# Add services to path
sys.path.append(str(Path(__file__).parent))

try:
    from services.rag_system import CPUOptimizedRAGSystem, GitingestParser
    from services.code_analyzer import MultiLanguageCodeAnalyzer
except ImportError as e:
    print(f"❌ Import error: {e}")
    sys.exit(1)


def test_simple_rag():
    """Test basic RAG functionality"""
    print("🚀 Testing CPU-Optimized RAG System")
    print("=" * 50)
    
    # Sample gitingest content
    sample_content = """
Directory structure:
├── calculator.py
└── main.py

================================================================================

FILE: calculator.py
class Calculator:
    \"\"\"Simple calculator class\"\"\"
    
    def __init__(self):
        self.history = []
    
    def add(self, a, b):
        \"\"\"Add two numbers\"\"\"
        result = a + b
        self.history.append(f"{a} + {b} = {result}")
        return result
    
    def multiply(self, a, b):
        \"\"\"Multiply two numbers\"\"\"
        result = a * b
        self.history.append(f"{a} * {b} = {result}")
        return result

================================================================================

FILE: main.py
from calculator import Calculator

def main():
    \"\"\"Main function\"\"\"
    calc = Calculator()
    result = calc.add(5, 3)
    print(f"5 + 3 = {result}")
    
    product = calc.multiply(4, 6)
    print(f"4 * 6 = {product}")

if __name__ == "__main__":
    main()
"""
    
    # Use a persistent directory instead of temp
    storage_dir = "./rag_test_storage"
    
    try:
        # Clean up any existing storage
        if os.path.exists(storage_dir):
            import shutil
            try:
                shutil.rmtree(storage_dir)
            except:
                pass
        
        # Create gitingest file
        gitingest_file = "test_sample.txt"
        with open(gitingest_file, 'w', encoding='utf-8') as f:
            f.write(sample_content)
        
        print("📝 Created sample gitingest file")
        
        # Initialize RAG system
        print("🔧 Initializing RAG system...")
        rag = CPUOptimizedRAGSystem(storage_path=storage_dir)
        
        # Build RAG system
        print("🏗️ Building RAG system...")
        metrics = rag.build_rag_from_gitingest(gitingest_file, "test_collection")
        
        print(f"✅ RAG system built successfully!")
        print(f"  - Total chunks: {metrics.total_chunks}")
        print(f"  - Total files: {metrics.total_files}")
        print(f"  - Languages: {', '.join(metrics.languages_detected)}")
        print(f"  - Build time: {metrics.build_time:.2f}s")
        print(f"  - Index size: {metrics.index_size_mb:.2f}MB")
        
        # Test queries
        test_queries = [
            "How do I add two numbers?",
            "Show me calculator methods",
            "What is the main function?",
            "Find multiplication function"
        ]
        
        print(f"\n🔍 Testing queries...")
        for query in test_queries:
            print(f"\nQuery: '{query}'")
            result = rag.query(query, max_results=3, collection_name="test_collection")
            
            print(f"  Found {len(result.chunks)} results in {result.query_time:.3f}s")
            for i, (chunk, confidence) in enumerate(zip(result.chunks, result.confidence_scores)):
                print(f"  {i+1}. {chunk.chunk_type} in {chunk.file_path} (confidence: {confidence:.2f})")
                print(f"     {chunk.content[:80]}...")
        
        # Test context generation
        print(f"\n📝 Testing context generation...")
        result = rag.query("calculator functions", max_results=5, collection_name="test_collection")
        context = rag.get_context_for_llm(result, max_tokens=1000)
        print(f"Generated context ({len(context)} chars):")
        print(context[:300] + "..." if len(context) > 300 else context)
        
        print(f"\n🎉 All tests completed successfully!")
        return True
        
    except Exception as e:
        print(f"\n❌ Test failed: {str(e)}")
        import traceback
        traceback.print_exc()
        return False
        
    finally:
        # Clean up files
        try:
            if os.path.exists(gitingest_file):
                os.remove(gitingest_file)
        except:
            pass
        
        # Note: We'll leave the storage directory for manual cleanup
        # since Windows file locking makes automatic cleanup difficult
        print(f"\n💡 Note: Test storage left at '{storage_dir}' for manual cleanup if needed")


if __name__ == "__main__":
    success = test_simple_rag()
    sys.exit(0 if success else 1)


================================================
FILE: test_files/test_rag_system.py
================================================
#!/usr/bin/env python3
"""
Test script for CPU-optimized RAG system.
This tests the complete pipeline from gitingest file to queryable RAG system.
"""

import asyncio
import sys
import os
from pathlib import Path
import time

# Add services to path
sys.path.append(str(Path(__file__).parent))

try:
    from services.rag_system import CPUOptimizedRAGSystem, GitingestParser
    from services.code_analyzer import MultiLanguageCodeAnalyzer
except ImportError as e:
    print(f"❌ Import error: {e}")
    print("💡 Make sure to install dependencies: pip install chromadb sentence-transformers networkx")
    sys.exit(1)


def test_gitingest_parsing():
    """Test parsing of gitingest files"""
    print("🧪 Testing gitingest parsing...")
    
    # Create a sample gitingest content
    sample_content = """
Directory structure:
├── main.py
├── utils.py
└── README.md

================================================================================

FILE: main.py
def hello_world():
    \"\"\"Simple hello world function\"\"\"
    print("Hello, World!")
    return "success"

if __name__ == "__main__":
    hello_world()

================================================================================

FILE: utils.py
import os
import sys

def get_file_size(filepath):
    \"\"\"Get file size in bytes\"\"\"
    return os.path.getsize(filepath)

class FileManager:
    def __init__(self, base_path):
        self.base_path = base_path
    
    def list_files(self):
        return os.listdir(self.base_path)

================================================================================

FILE: README.md
# Test Project

This is a test project for RAG system.
"""
    
    files = GitingestParser.parse_gitingest_content(sample_content)
    
    print(f"✅ Parsed {len(files)} files:")
    for file_path, content in files.items():
        print(f"  - {file_path} ({len(content)} chars)")
    
    return files


def test_code_analysis():
    """Test multi-language code analysis"""
    print("\n🧪 Testing code analysis...")
    
    # Get sample files from gitingest parsing
    files = test_gitingest_parsing()
    
    analyzer = MultiLanguageCodeAnalyzer()
    project_structure = analyzer.analyze_project(files)
    
    print(f"✅ Analyzed {len(project_structure)} files:")
    for file_path, structure in project_structure.items():
        print(f"  - {file_path}: {structure.language.value}")
        print(f"    Functions: {len(structure.functions)}")
        print(f"    Classes: {len(structure.classes)}")
        print(f"    Imports: {len(structure.imports)}")
    
    return project_structure


def test_rag_system():
    """Test complete RAG system"""
    print("\n🧪 Testing RAG system...")
    
    import tempfile
    
    # Use a temporary directory that gets cleaned up automatically
    with tempfile.TemporaryDirectory() as temp_dir:
        # Initialize RAG system
        rag = CPUOptimizedRAGSystem(storage_path=temp_dir)
    
        # Create a temporary gitingest file
        temp_file = "temp_gitingest.txt"
    sample_content = """
Directory structure:
├── main.py
├── utils.py
└── calculator.py

================================================================================

FILE: main.py
def hello_world():
    \"\"\"Simple hello world function\"\"\"
    print("Hello, World!")
    return "success"

def main():
    \"\"\"Main entry point\"\"\"
    result = hello_world()
    calc = Calculator()
    sum_result = calc.add(5, 3)
    print(f"5 + 3 = {sum_result}")

if __name__ == "__main__":
    main()

================================================================================

FILE: utils.py
import os
import sys
from pathlib import Path

def get_file_size(filepath):
    \"\"\"Get file size in bytes\"\"\"
    return os.path.getsize(filepath)

def read_config(config_path):
    \"\"\"Read configuration file\"\"\"
    with open(config_path, 'r') as f:
        return f.read()

class FileManager:
    def __init__(self, base_path):
        self.base_path = base_path
    
    def list_files(self):
        \"\"\"List all files in base path\"\"\"
        return os.listdir(self.base_path)
    
    def create_file(self, filename, content):
        \"\"\"Create a new file\"\"\"
        filepath = Path(self.base_path) / filename
        with open(filepath, 'w') as f:
            f.write(content)

================================================================================

FILE: calculator.py
class Calculator:
    \"\"\"Simple calculator class\"\"\"
    
    def __init__(self):
        self.history = []
    
    def add(self, a, b):
        \"\"\"Add two numbers\"\"\"
        result = a + b
        self.history.append(f"{a} + {b} = {result}")
        return result
    
    def subtract(self, a, b):
        \"\"\"Subtract two numbers\"\"\"
        result = a - b
        self.history.append(f"{a} - {b} = {result}")
        return result
    
    def multiply(self, a, b):
        \"\"\"Multiply two numbers\"\"\"
        result = a * b
        self.history.append(f"{a} * {b} = {result}")
        return result
    
    def get_history(self):
        \"\"\"Get calculation history\"\"\"
        return self.history.copy()
"""
    
    # Write temporary file
    with open(temp_file, 'w', encoding='utf-8') as f:
        f.write(sample_content)
    
    try:
        # Build RAG system
        print("Building RAG system...")
        metrics = rag.build_rag_from_gitingest(temp_file, "test_collection")
        
        print(f"✅ RAG system built successfully!")
        print(f"  - Total chunks: {metrics.total_chunks}")
        print(f"  - Total files: {metrics.total_files}")
        print(f"  - Languages: {', '.join(metrics.languages_detected)}")
        print(f"  - Build time: {metrics.build_time:.2f}s")
        print(f"  - Index size: {metrics.index_size_mb:.2f}MB")
        
        # Test queries
        test_queries = [
            "How do I add two numbers?",
            "Show me file management functions",
            "What is the main entry point?",
            "Find calculator methods"
        ]
        
        print(f"\n🔍 Testing queries...")
        for query in test_queries:
            print(f"\nQuery: '{query}'")
            result = rag.query(query, max_results=3, collection_name="test_collection")
            
            print(f"  Found {len(result.chunks)} results in {result.query_time:.3f}s")
            for i, (chunk, confidence) in enumerate(zip(result.chunks, result.confidence_scores)):
                print(f"  {i+1}. {chunk.chunk_type} in {chunk.file_path} (confidence: {confidence:.2f})")
                print(f"     {chunk.content[:100]}...")
        
        # Test context generation
        print(f"\n📝 Testing context generation...")
        result = rag.query("calculator functions", max_results=5, collection_name="test_collection")
        context = rag.get_context_for_llm(result, max_tokens=1000)
        print(f"Generated context ({len(context)} chars):")
        print(context[:500] + "..." if len(context) > 500 else context)
        
    finally:
        # Clean up
        if os.path.exists(temp_file):
            os.remove(temp_file)
        
        # Clean up test storage - close ChromaDB first
        try:
            if 'rag' in locals():
                rag.cleanup()
            
            import shutil
            import time
            import gc
            
            # Force garbage collection to release file handles
            gc.collect()
            time.sleep(2)  # Give more time for file handles to close
            
            if os.path.exists("./test_rag_storage"):
                shutil.rmtree("./test_rag_storage")
        except Exception as e:
            print(f"Warning: Could not clean up test storage: {e}")
            print("You may need to manually delete the ./test_rag_storage folder")


def main():
    """Run all tests"""
    print("🚀 Starting RAG System Tests")
    print("=" * 50)
    
    try:
        # Test individual components
        test_gitingest_parsing()
        test_code_analysis()
        
        # Test complete system
        test_rag_system()
        
        print("\n" + "=" * 50)
        print("🎉 All tests completed successfully!")
        
    except Exception as e:
        print(f"\n❌ Test failed: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)


================================================
FILE: test_files/test_silent.py
================================================
#!/usr/bin/env python3
"""
Ultra-clean test with maximum warning suppression
"""

import os
import sys
import warnings
import subprocess

# Maximum suppression
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
os.environ['ORT_DISABLE_ALL_LOGS'] = '1'
os.environ['CUDA_VISIBLE_DEVICES'] = ''
os.environ['PYTHONWARNINGS'] = 'ignore'
warnings.filterwarnings('ignore')

from pathlib import Path
import logging

# Suppress all logging
logging.disable(logging.CRITICAL)

sys.path.append(str(Path(__file__).parent))

def run_silent_test():
    """Run the test with maximum output suppression"""
    print("🔇 Running SILENT RAG test...")
    print("=" * 40)
    
    try:
        from services.rag_system import CPUOptimizedRAGSystem
        
        gitingest_file = "gitingest_outputs/Emon69420_HazMapApp_20250905_194000.txt"
        
        if not os.path.exists(gitingest_file):
            print(f"❌ File not found: {gitingest_file}")
            return
        
        print("🔧 Building index (silent)...")
        
        # Redirect ALL output during initialization
        with open(os.devnull, 'w') as devnull:
            old_stdout = sys.stdout
            old_stderr = sys.stderr
            sys.stdout = devnull
            sys.stderr = devnull
            
            try:
                rag = CPUOptimizedRAGSystem(storage_path="./silent_rag")
                metrics = rag.build_rag_from_gitingest(gitingest_file, "silent_test")
            finally:
                sys.stdout = old_stdout
                sys.stderr = old_stderr
        
        print(f"✅ Success! {metrics.total_chunks} chunks from {metrics.total_files} files")
        
        # Test key searches silently
        searches = [
            ("login authentication", "🔐 Login"),
            ("wildfire prediction", "🔥 Wildfire"),
            ("location GPS", "📍 Location"),
            ("map component", "🗺️  Map"),
            ("background task", "⏰ Background"),
            ("user profile", "👤 Profile")
        ]
        
        print(f"\n🎯 Testing {len(searches)} searches:")
        
        for query, emoji_desc in searches:
            # Silent query
            with open(os.devnull, 'w') as devnull:
                old_stderr = sys.stderr
                sys.stderr = devnull
                try:
                    result = rag.query(query, max_results=1, collection_name="silent_test")
                finally:
                    sys.stderr = old_stderr
            
            if result.chunks:
                chunk = result.chunks[0]
                confidence = result.confidence_scores[0]
                
                # Clean output
                file_name = Path(chunk.file_path).name
                func_name = chunk.metadata.get('function_name', 'N/A')
                
                status = "🎯" if confidence > 0.05 else "✅" if confidence > 0.01 else "📌"
                print(f"   {status} {emoji_desc}: {func_name} in {file_name}")
        
        print(f"\n📊 Index: {metrics.total_files} files, {metrics.total_chunks} chunks, {metrics.index_size_mb:.1f}MB")
        print("🎉 Silent test complete!")
        
        # Silent cleanup
        try:
            rag.chroma_client = None
            rag.collection = None
            import shutil
            import time
            time.sleep(0.5)
            if os.path.exists("./silent_rag"):
                shutil.rmtree("./silent_rag")
        except:
            pass
            
    except Exception as e:
        print(f"❌ Error: {e}")

if __name__ == "__main__":
    run_silent_test()


================================================
FILE: test_files/test_timing_small.py
================================================
#!/usr/bin/env python3
"""
Test timing with a very small repository to minimize API calls
"""

import requests
import json

BASE_URL = "http://localhost:5000"

def test_small_repo_timing():
    """Test with a very small repository"""
    print("🔍 Testing timing with small repository...")
    print("Note: This might still fail due to rate limits")
    
    # Try with a very small, well-known repo
    url = f"{BASE_URL}/api/repositories/deep-analyze"
    data = {
        "url": "https://github.com/octocat/Hello-World",  # Very small repo
        "max_file_size": 1024 * 1024  # 1MB limit
    }
    
    response = requests.post(url, json=data)
    print(f"Status: {response.status_code}")
    
    if response.status_code == 200:
        result = response.json()
        print("✅ Analysis successful!")
        
        # Show timing information
        if 'processing_time' in result:
            timing = result['processing_time']
            print(f"\n⏱️  Timing Results:")
            print(f"  🕐 Total time: {timing['formatted']} ({timing['seconds']}s)")
            print(f"  📊 Minutes: {timing['minutes']}")
        
        stats = result['deep_analysis']['structure']['processing_stats']
        print(f"\n📈 Performance:")
        print(f"  ✅ Files processed: {stats['processed']}")
        print(f"  🚀 Files per second: {stats.get('files_per_second', 0)}")
        print(f"  ⏱️  Start: {stats.get('start_time', 'N/A')}")
        print(f"  🏁 End: {stats.get('end_time', 'N/A')}")
        
    else:
        error = response.json()
        if 'rate limited' in error.get('error', '').lower():
            print("❌ Still rate limited. Try one of these:")
            print("1. Use GitHub token: python test_with_token.py")
            print("2. Wait until 00:39:17 for rate limit reset")
        else:
            print(f"❌ Error: {error}")

if __name__ == "__main__":
    test_small_repo_timing()


================================================
FILE: test_files/test_token.py
================================================
#!/usr/bin/env python3
"""
Test script to validate your GitHub token with the Flask API
"""

import requests
import json

BASE_URL = "http://localhost:5000"

def test_github_token():
    """Test GitHub token authentication"""
    
    # Get token from user
    print("🔑 GitHub Token Tester")
    print("=" * 30)
    
    token = input("Enter your GitHub Personal Access Token: ").strip()
    
    if not token:
        print("❌ No token provided!")
        return
    
    print(f"\n🔍 Testing token: {token[:8]}...")
    
    # Test token with login endpoint
    url = f"{BASE_URL}/auth/github/login"
    data = {"token": token}
    
    try:
        response = requests.post(url, json=data)
        print(f"Status: {response.status_code}")
        
        if response.status_code == 200:
            result = response.json()
            user = result['user']
            
            print("✅ Token is valid!")
            print(f"👤 User: {user['login']}")
            print(f"📧 Email: {user.get('email', 'Not provided')}")
            print(f"🔐 Scopes: {', '.join(result['scopes'])}")
            
            # Test repository access with token
            print(f"\n🔍 Testing repository access...")
            test_repo_with_token()
            
        else:
            error = response.json()
            print(f"❌ Token validation failed: {error.get('error')}")
            
    except requests.exceptions.ConnectionError:
        print("❌ Error: Could not connect to Flask server.")
        print("Make sure the server is running with: python app.py")
    except Exception as e:
        print(f"❌ Error: {e}")

def test_repo_with_token():
    """Test repository access with authenticated token"""
    
    # Test with your repository
    url = f"{BASE_URL}/api/repositories/validate"
    data = {"url": "https://github.com/Emon69420/HazMapApp"}
    
    response = requests.post(url, json=data)
    
    if response.status_code == 200:
        result = response.json()
        repo = result['repository']
        print(f"✅ Repository access successful!")
        print(f"📁 Repo: {repo['full_name']}")
        print(f"🔒 Private: {repo['private']}")
        print(f"⭐ Stars: {repo['stargazers_count']}")
    else:
        print(f"⚠️  Repository access issue: {response.json()}")

def show_token_info():
    """Show information about GitHub tokens"""
    print("\n📋 GitHub Token Information:")
    print("=" * 40)
    print("🔗 Get token at: https://github.com/settings/tokens")
    print("\n📝 Required scopes:")
    print("  ✅ repo (for private repositories)")
    print("  ✅ public_repo (for public repositories)")
    print("  ✅ user:email (for user information)")
    print("\n⚠️  Security tips:")
    print("  • Never share your token publicly")
    print("  • Set appropriate expiration dates")
    print("  • Use environment variables in production")
    print("  • Revoke tokens you no longer need")

if __name__ == "__main__":
    show_token_info()
    test_github_token()


================================================
FILE: test_files/test_with_token.py
================================================
#!/usr/bin/env python3
"""
Test with GitHub token to bypass rate limits
"""

import requests
import json

BASE_URL = "http://localhost:5000"

def login_with_token():
    """Login with GitHub token first"""
    # Replace with your actual GitHub token
    github_token = input("Enter your GitHub Personal Access Token: ").strip()
    
    if not github_token:
        print("❌ No token provided")
        return False
    
    print("🔐 Logging in with GitHub token...")
    
    url = f"{BASE_URL}/auth/github/login"
    data = {"token": github_token}
    
    response = requests.post(url, json=data)
    
    if response.status_code == 200:
        result = response.json()
        print(f"✅ Logged in as: {result['user']['login']}")
        return True
    else:
        print(f"❌ Login failed: {response.json()}")
        return False

def test_deep_analysis_with_auth():
    """Test deep analysis with authentication"""
    print("\n🔍 Testing deep analysis with authentication...")
    
    url = f"{BASE_URL}/api/repositories/deep-analyze"
    data = {
        "url": "https://github.com/Emon69420/HazMapApp",
        "max_file_size": 512 * 1024
    }
    
    # Use session to maintain login
    session = requests.Session()
    
    response = session.post(url, json=data)
    print(f"Status: {response.status_code}")
    
    if response.status_code == 200:
        result = response.json()
        print("✅ Deep analysis successful!")
        
        if 'processing_time' in result:
            timing = result['processing_time']
            print(f"⏱️  Processing time: {timing['formatted']}")
        
        stats = result['deep_analysis']['structure']['processing_stats']
        print(f"📊 Files processed: {stats['processed']}")
        
    else:
        print(f"❌ Error: {response.json()}")

if __name__ == "__main__":
    print("🚀 Testing with GitHub Authentication")
    print("=" * 50)
    
    if login_with_token():
        test_deep_analysis_with_auth()
    else:
        print("\n💡 To get a GitHub token:")
        print("1. Go to https://github.com/settings/tokens")
        print("2. Generate new token (classic)")
        print("3. Select 'repo' scope")
        print("4. Copy the token and paste it here")


================================================
FILE: .kiro/specs/ai-project-analyzer/design.md
================================================
Error reading file with 'cp1252': 'charmap' codec can't decode byte 0x9d in position 1179: character maps to <undefined>


================================================
FILE: .kiro/specs/ai-project-analyzer/requirements.md
================================================
# Requirements Document

## Introduction

The AI Project Analyzer is a web application that enables developers to analyze GitHub repositories using AI-powered insights. The system ingests public or private repositories, creates a RAG (Retrieval-Augmented Generation) knowledge base, and provides both visual flowcharts and conversational AI interfaces for exploring codebases. The application integrates with GPT OSS via Hugging Face to deliver semantic search capabilities and intelligent code analysis.

## Requirements

### Requirement 1

**User Story:** As a developer, I want to input a GitHub repository URL and have the system analyze the entire codebase, so that I can understand the project structure and relationships.

#### Acceptance Criteria

1. WHEN a user provides a public GitHub repository URL THEN the system SHALL clone and parse the repository content
2. WHEN a user provides a private GitHub repository URL THEN the system SHALL prompt for authentication credentials (token or SSH key)
3. WHEN repository ingestion begins THEN the system SHALL display progress indicators showing parsing status
4. WHEN ingestion completes THEN the system SHALL confirm successful analysis and display available features
5. IF a repository URL is invalid or inaccessible THEN the system SHALL display clear error messages with suggested corrections

### Requirement 2

**User Story:** As a project maintainer, I want to ask natural language questions about my repository and receive AI-generated answers, so that I can quickly understand code functionality and architecture.

#### Acceptance Criteria

1. WHEN a repository has been analyzed THEN the system SHALL create a RAG knowledge base from all code files and documentation
2. WHEN a user submits a natural language question THEN the system SHALL use GPT OSS via Hugging Face to generate contextual answers
3. WHEN answering questions THEN the system SHALL reference specific files, functions, or code sections in the response
4. WHEN no relevant information is found THEN the system SHALL indicate the limitation and suggest alternative queries
5. WHEN multiple relevant code sections exist THEN the system SHALL provide comprehensive answers referencing all applicable parts

### Requirement 3

**User Story:** As a team member, I want to securely analyze private repositories without exposing sensitive credentials, so that I can maintain security while gaining insights.

#### Acceptance Criteria

1. WHEN handling private repositories THEN the system SHALL accept GitHub personal access tokens through secure input fields
2. WHEN credentials are provided THEN the system SHALL store them only in memory or secure environment variables
3. WHEN analysis completes THEN the system SHALL clear all authentication data from memory
4. WHEN invalid credentials are provided THEN the system SHALL display authentication errors without exposing credential details
5. IF SSH key authentication is used THEN the system SHALL support standard SSH key formats and secure key handling

### Requirement 4

**User Story:** As a new contributor, I want to see an interactive visual flowchart of the repository structure, so that I can understand how files and components relate to each other.

#### Acceptance Criteria

1. WHEN repository analysis completes THEN the system SHALL generate an interactive flowchart showing file and module relationships
2. WHEN a user clicks on a flowchart node THEN the system SHALL display the corresponding source code or file content
3. WHEN hovering over nodes THEN the system SHALL show AI-generated summaries of the component's purpose
4. WHEN the flowchart is complex THEN the system SHALL provide zoom, pan, and filtering capabilities
5. WHEN displaying relationships THEN the system SHALL show imports, dependencies, function calls, and class inheritance

### Requirement 5

**User Story:** As a developer, I want the analysis to stay current with repository changes, so that the insights remain accurate over time.

#### Acceptance Criteria

1. WHEN a user requests re-analysis THEN the system SHALL update the RAG knowledge base with current repository state
2. WHEN repository changes are detected THEN the system SHALL offer automatic re-analysis options
3. WHEN re-analysis occurs THEN the system SHALL preserve user session data and preferences
4. WHEN updates complete THEN the system SHALL refresh the flowchart and knowledge base automatically
5. IF webhook integration is configured THEN the system SHALL trigger re-analysis on repository push events

### Requirement 6

**User Story:** As a user, I want a clean web interface to interact with both the AI chat and visual flowchart, so that I can efficiently explore repositories.

#### Acceptance Criteria

1. WHEN accessing the application THEN the system SHALL provide a responsive web interface compatible with modern browsers
2. WHEN using the chat interface THEN the system SHALL display conversation history and allow follow-up questions
3. WHEN viewing flowcharts THEN the system SHALL provide intuitive navigation controls and clear visual hierarchy
4. WHEN switching between features THEN the system SHALL maintain context and allow seamless transitions
5. WHEN on mobile devices THEN the system SHALL adapt the interface for touch interaction and smaller screens

### Requirement 7

**User Story:** As a security-conscious user, I want all sensitive data handled according to industry standards, so that my credentials and code remain protected.

#### Acceptance Criteria

1. WHEN handling authentication THEN the system SHALL use HTTPS for all credential transmission
2. WHEN storing temporary data THEN the system SHALL encrypt sensitive information at rest
3. WHEN processing private repositories THEN the system SHALL not log or persist repository content unnecessarily
4. WHEN errors occur THEN the system SHALL not expose sensitive information in error messages or logs
5. WHEN sessions end THEN the system SHALL clear all authentication tokens and temporary repository data


================================================
FILE: .kiro/specs/ai-project-analyzer/tasks.md
================================================
# Implementation Plan

- [ ] 1. Set up project dependencies and core infrastructure





  - Install required npm packages: @octokit/rest (GitHub API), @huggingface/inference, Redis, D3.js
  - Configure environment variables for GitHub API, Hugging Face API keys
  - Create service directory structure optimized for API-only processing (no file storage)
  - _Requirements: 7.1, 7.2_

- [ ] 2. Implement GitHub authentication and repository access
- [x] 2.1 Create GitHub authentication service



  - Write GitHubAuthService class with token validation and SSH key support
  - Implement secure credential handling with in-memory storage only
  - Create unit tests for authentication flows and error handling
  - _Requirements: 1.2, 3.1, 3.2, 3.3_

- [x] 2.2 Implement repository validation and access checking




  - Code repository URL validation and accessibility verification
  - Write functions to check public/private repository permissions
  - Create unit tests for various repository access scenarios



  - _Requirements: 1.1, 1.5_

- [ ] 3. Build repository ingestion and parsing system
- [ ] 3.1 Create GitHub API streaming service
  - Implement GitHub API client with rate limiting and error handling
  - Write file streaming functions that fetch content directly from GitHub API
  - Create progress tracking for API-based repository analysis
  - _Requirements: 1.1, 1.3, 7.3_

- [ ] 3.2 Implement code structure parsing from API


  - Write AST parsers that work with streamed file content from GitHub API
  - Create dependency mapping by parsing package.json, requirements.txt via API
  - Implement repository tree analysis using GitHub's tree API endpoint
  - _Requirements: 4.5, 1.1_

- [ ] 3.3 Build repository analysis orchestrator
  - Create RepositoryService class that coordinates API streaming and parsing
  - Implement parallel file processing with GitHub API rate limit management
  - Write integration tests for complete API-based repository analysis workflow
  - _Requirements: 1.3, 1.4_

- [ ] 4. Implement AI processing and RAG system
- [ ] 4.1 Create Hugging Face GPT OSS integration
  - Write AIService class with Hugging Face API client
  - Implement error handling and retry logic for API failures
  - Create unit tests for AI service integration
  - _Requirements: 2.2, 2.4_

- [ ] 4.2 Build RAG knowledge base creation from GitHub API
  - Implement streaming document embedding generation from GitHub API responses
  - Create vector storage and indexing system that processes files as they stream
  - Write functions to intelligently chunk files during API streaming
  - _Requirements: 2.1, 2.5_

- [ ] 4.3 Implement semantic query processing
  - Create natural language query handler with context retrieval
  - Write response generation with source code references
  - Implement confidence scoring and fallback responses
  - _Requirements: 2.2, 2.3, 2.4_

- [ ] 5. Build interactive flowchart visualization system
- [ ] 5.1 Create flowchart data generation
  - Write VisualizationService to convert AST data to flowchart nodes and edges
  - Implement relationship mapping for imports, function calls, and inheritance
  - Create layout algorithms for optimal node positioning
  - _Requirements: 4.1, 4.5_

- [ ] 5.2 Implement AI-powered node summaries
  - Integrate AI service to generate component summaries for flowchart nodes
  - Create caching system for generated summaries
  - Write functions to update summaries when code changes
  - _Requirements: 4.3_

- [ ] 5.3 Build interactive flowchart features
  - Implement zoom, pan, and filtering capabilities for complex graphs
  - Create click handlers for node navigation to source code
  - Write hover functionality for displaying AI summaries
  - _Requirements: 4.2, 4.3, 4.4_

- [ ] 6. Create web API endpoints
- [ ] 6.1 Implement repository analysis endpoints
  - Create POST /api/repositories/analyze endpoint for repository submission
  - Write GET /api/repositories/:id/status for analysis progress tracking
  - Implement DELETE /api/repositories/:id for cleanup operations
  - _Requirements: 1.1, 1.3, 1.4_

- [ ] 6.2 Build AI query endpoints
  - Create POST /api/repositories/:id/query for natural language questions
  - Write GET /api/repositories/:id/summaries for component summaries
  - Implement caching middleware for frequently asked questions
  - _Requirements: 2.2, 2.3_

- [ ] 6.3 Create visualization endpoints
  - Write GET /api/repositories/:id/flowchart for flowchart data
  - Implement PUT /api/repositories/:id/flowchart for layout updates
  - Create WebSocket endpoints for real-time flowchart updates
  - _Requirements: 4.1, 4.2_

- [ ] 7. Build frontend user interface
- [ ] 7.1 Create repository input interface
  - Build React components for repository URL input and credential forms
  - Implement secure credential input with no browser storage
  - Create progress indicators and status displays for analysis
  - _Requirements: 1.1, 1.2, 1.3, 3.1, 3.2_

- [ ] 7.2 Implement AI chat interface
  - Create conversational UI components for natural language queries
  - Build chat history display with source code references
  - Implement follow-up question suggestions and context preservation
  - _Requirements: 2.2, 2.3, 6.2_

- [ ] 7.3 Build interactive flowchart viewer
  - Create React components for flowchart rendering using D3.js or similar
  - Implement navigation controls, zoom, and filtering UI
  - Build click handlers for source code navigation and summary display
  - _Requirements: 4.1, 4.2, 4.3, 4.4, 6.1_

- [ ] 8. Implement repository update and re-analysis features
- [ ] 8.1 Create manual re-analysis functionality
  - Build UI controls for triggering repository re-analysis
  - Implement incremental update detection and processing
  - Create functions to preserve user session data during updates
  - _Requirements: 5.1, 5.3_

- [ ] 8.2 Implement automatic update detection
  - Create webhook endpoint for GitHub repository change notifications
  - Write scheduled job system for periodic repository checking
  - Implement smart update triggers based on change significance
  - _Requirements: 5.2, 5.5_

- [ ] 8.3 Build update notification system
  - Create real-time notifications for completed re-analysis
  - Implement UI updates for refreshed flowcharts and knowledge base
  - Write functions to maintain user context across updates
  - _Requirements: 5.4_

- [ ] 9. Implement security and performance optimizations
- [ ] 9.1 Add comprehensive security measures
  - Implement HTTPS enforcement and secure header middleware
  - Create input validation and sanitization for all endpoints
  - Write rate limiting and authentication middleware
  - _Requirements: 7.1, 7.4, 7.5_

- [ ] 9.2 Optimize performance and caching
  - Implement Redis caching for GitHub API responses and AI-generated content
  - Create intelligent batching for GitHub API requests to maximize rate limits
  - Write memory-efficient streaming processors that don't accumulate file content
  - _Requirements: 6.4_

- [ ] 9.3 Add monitoring and error handling
  - Create comprehensive error handling with user-friendly messages
  - Implement logging system that excludes sensitive information
  - Write health check endpoints and performance monitoring
  - _Requirements: 7.4, 7.5_

- [ ] 10. Create comprehensive testing suite
- [ ] 10.1 Write unit tests for all services
  - Create test suites for RepositoryService, AIService, and VisualizationService
  - Write mock implementations for external APIs (GitHub, Hugging Face)
  - Implement test fixtures with sample repositories and expected outputs
  - _Requirements: All requirements_

- [ ] 10.2 Build integration tests
  - Create end-to-end tests for complete repository analysis workflows
  - Write API endpoint tests with authentication and error scenarios
  - Implement frontend component tests with user interaction simulation
  - _Requirements: All requirements_

- [ ] 10.3 Add performance and security tests
  - Create load tests for concurrent repository analysis
  - Write security tests for credential handling and data protection
  - Implement memory usage and cleanup validation tests
  - _Requirements: 3.3, 7.1, 7.2, 7.3, 7.4, 7.5_


================================================
FILE: .kiro/specs/gitingest-integration/design.md
================================================
# Design Document

## Overview

The Gitingest Integration replaces the complex GitHub API streaming approach in the AI Project Analyzer with gitingest, a Python tool that converts Git repositories into LLM-optimized text format. This design maintains the existing system architecture while significantly simplifying repository ingestion and improving AI analysis quality through better structured input.

## Architecture

### High-Level Architecture

The integration modifies the existing system by replacing the GitHub API streaming layer with a gitingest processing service, while maintaining all other components:

```
┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐
│   Web Frontend  │────│   API Gateway    │────│  Auth Service   │
└─────────────────┘    └──────────────────┘    └─────────────────┘
                                │
                                ▼
┌─────────────────────────────────────────────────────────────────┐
│                    Repository Service                           │
│  ┌─────────────────┐    ┌──────────────────┐                  │
│  │ GitHub API      │────│ Gitingest        │                  │
│  │ (validation)    │    │ Processing       │                  │
│  └─────────────────┘    └──────────────────┘                  │
└─────────────────────────────────────────────────────────────────┘
                                │
                                ▼
┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐
│   AI Service    │────│   RAG System     │────│ Vector Storage  │
│ (Hugging Face)  │    │                  │    │                 │
└─────────────────┘    └──────────────────┘    └─────────────────┘
                                │
                                ▼
┌─────────────────────────────────────────────────────────────────┐
│                 Visualization Service                           │
│  ┌─────────────────┐    ┌──────────────────┐                  │
│  │ Flowchart       │────│ Interactive      │                  │
│  │ Generator       │    │ Components       │                  │
│  └─────────────────┘    └──────────────────┘                  │
└─────────────────────────────────────────────────────────────────┘
```

### Integration Points

1. **Repository Service Enhancement**: Replaces GitHub API streaming with gitingest processing
2. **RAG System Optimization**: Leverages gitingest's structured output for better chunking
3. **Visualization Improvement**: Uses gitingest's comprehensive file mapping for accurate dependency graphs
4. **Security Preservation**: Maintains existing authentication and credential handling patterns

## Components and Interfaces

### GitingestProcessor

**Purpose**: Core service that handles gitingest execution and output processing

**Key Methods**:
```python
class GitingestProcessor:
    async def process_repository(self, repo_url: str, auth_config: AuthConfig) -> GitingestOutput
    async def validate_repository(self, repo_url: str) -> ValidationResult
    def parse_gitingest_output(self, raw_output: str) -> StructuredRepository
    def cleanup_temporary_files(self, process_id: str) -> None
```

**Interfaces**:
- Input: Repository URL, authentication credentials
- Output: Structured repository representation with file hierarchy and content
- Dependencies: gitingest Python package, subprocess management, temporary file handling

### RepositoryService (Enhanced)

**Purpose**: Orchestrates repository analysis using gitingest instead of GitHub API streaming

**Key Methods**:
```python
class RepositoryService:
    async def analyze_repository(self, repo_url: str, auth_config: AuthConfig) -> AnalysisResult
    async def get_analysis_progress(self, analysis_id: str) -> ProgressStatus
    def create_rag_documents(self, structured_repo: StructuredRepository) -> List[Document]
```

**Changes from Current Design**:
- Replaces GitHub API client with GitingestProcessor
- Simplifies file streaming logic
- Improves error handling for repository access issues
- Maintains existing progress tracking and caching mechanisms

### AuthenticationService (Unchanged)

**Purpose**: Handles GitHub authentication for both public and private repositories

**Integration**: Passes credentials to gitingest through environment variables or command-line arguments securely

### RAGService (Enhanced)

**Purpose**: Creates knowledge base from gitingest's structured output

**Key Enhancements**:
```python
class RAGService:
    def chunk_gitingest_output(self, structured_repo: StructuredRepository) -> List[Chunk]
    def create_embeddings_batch(self, chunks: List[Chunk]) -> List[Embedding]
    def build_file_hierarchy_index(self, structured_repo: StructuredRepository) -> HierarchyIndex
```

**Improvements**:
- Better chunking strategy using gitingest's file boundaries
- Improved context preservation through structured file hierarchy
- Enhanced metadata extraction from gitingest's comprehensive output

## Data Models

### GitingestOutput

```python
@dataclass
class GitingestOutput:
    repository_info: RepositoryInfo
    file_tree: FileTree
    content_blocks: List[ContentBlock]
    metadata: GitingestMetadata
    processing_stats: ProcessingStats
```

### StructuredRepository

```python
@dataclass
class StructuredRepository:
    repo_url: str
    files: Dict[str, FileContent]
    dependencies: List[Dependency]
    file_hierarchy: FileHierarchy
    language_stats: LanguageStats
    gitingest_metadata: GitingestMetadata
```

### ContentBlock

```python
@dataclass
class ContentBlock:
    file_path: str
    content: str
    language: str
    line_count: int
    size_bytes: int
    file_type: FileType
```

### ProcessingConfig

```python
@dataclass
class ProcessingConfig:
    include_patterns: List[str]
    exclude_patterns: List[str]
    max_file_size: int
    respect_gitignore: bool
    include_binary_files: bool
    auth_method: AuthMethod
```

## Error Handling

### Gitingest-Specific Errors

1. **Repository Access Errors**
   - Invalid repository URLs
   - Authentication failures
   - Network connectivity issues
   - Repository not found or private access denied

2. **Processing Errors**
   - Gitingest execution failures
   - Large repository timeout handling
   - Memory limitations for massive repositories
   - Corrupted or incomplete output

3. **Integration Errors**
   - Python environment issues
   - Gitingest package version conflicts
   - Temporary file system errors
   - Output parsing failures

### Error Recovery Strategies

```python
class ErrorRecoveryService:
    async def retry_with_smaller_scope(self, repo_url: str, config: ProcessingConfig) -> GitingestOutput
    async def fallback_to_api_streaming(self, repo_url: str) -> RepositoryData
    def diagnose_gitingest_failure(self, error: Exception) -> DiagnosticReport
```

## Testing Strategy

### Unit Testing

1. **GitingestProcessor Tests**
   - Mock gitingest execution with sample outputs
   - Test various repository types and sizes
   - Validate error handling for different failure scenarios
   - Test authentication credential passing

2. **Output Parsing Tests**
   - Test parsing of gitingest output format
   - Validate file hierarchy reconstruction
   - Test content extraction and metadata handling
   - Verify language detection and statistics

### Integration Testing

1. **End-to-End Repository Processing**
   - Test complete workflow from URL input to structured output
   - Validate with both public and private repositories
   - Test different authentication methods
   - Verify cleanup of temporary files and credentials

2. **RAG System Integration**
   - Test improved chunking with gitingest output
   - Validate embedding generation from structured content
   - Test query performance improvements
   - Verify file reference accuracy in AI responses

### Performance Testing

1. **Repository Size Scaling**
   - Test with repositories of varying sizes (small, medium, large)
   - Measure processing time improvements over GitHub API approach
   - Validate memory usage patterns
   - Test concurrent repository processing

2. **Comparison Benchmarks**
   - Compare gitingest vs GitHub API streaming performance
   - Measure AI analysis quality improvements
   - Test flowchart generation accuracy
   - Validate user experience improvements

## Security Considerations

### Credential Handling

1. **Environment Variable Management**
   - Pass GitHub tokens through secure environment variables
   - Clear environment variables after gitingest execution
   - Validate credential format before passing to gitingest

2. **Temporary File Security**
   - Create temporary directories with restricted permissions
   - Encrypt temporary files containing sensitive repository content
   - Implement secure cleanup procedures for all temporary artifacts

### Repository Content Protection

1. **Memory Management**
   - Process gitingest output in streaming fashion when possible
   - Avoid keeping complete repository content in memory longer than necessary
   - Implement secure memory clearing for sensitive content

2. **Logging and Monitoring**
   - Exclude repository content from application logs
   - Log only metadata and processing statistics
   - Implement audit trails for repository access without content exposure

## Deployment Considerations

### Python Environment

1. **Dependency Management**
   - Add gitingest to requirements.txt with version pinning
   - Ensure Python environment compatibility
   - Handle potential conflicts with existing dependencies

2. **System Requirements**
   - Ensure Git is available in the deployment environment
   - Configure appropriate disk space for temporary repository processing
   - Set up proper file system permissions for temporary directories

### Configuration

1. **Environment Variables**
   ```
   GITINGEST_MAX_FILE_SIZE=10MB
   GITINGEST_TIMEOUT=300
   GITINGEST_TEMP_DIR=/tmp/gitingest
   GITINGEST_INCLUDE_PATTERNS=*.py,*.js,*.md,*.json
   GITINGEST_EXCLUDE_PATTERNS=node_modules,__pycache__,.git
   ```

2. **Runtime Configuration**
   - Configurable processing timeouts
   - Adjustable file size limits
   - Customizable include/exclude patterns
   - Flexible authentication method selection


================================================
FILE: .kiro/specs/gitingest-integration/requirements.md
================================================
# Requirements Document

## Introduction

The Gitingest Integration enhances the existing AI Project Analyzer by replacing the complex GitHub API streaming approach with gitingest, a Python tool that converts Git repositories into LLM-optimized text format. This integration will simplify repository ingestion, improve parsing accuracy, and provide better context for AI analysis while maintaining all existing security and functionality requirements.

## Requirements

### Requirement 1

**User Story:** As a developer, I want the system to use gitingest to efficiently convert any Git repository into a structured text format, so that AI analysis becomes faster and more comprehensive.

#### Acceptance Criteria

1. WHEN a user provides a repository URL THEN the system SHALL use gitingest to convert the repository into structured text format
2. WHEN gitingest processes a repository THEN the system SHALL capture the complete codebase structure including file paths, content, and metadata
3. WHEN ingestion completes THEN the system SHALL have a single text representation optimized for LLM consumption
4. WHEN processing large repositories THEN the system SHALL handle gitingest output efficiently without memory overflow
5. IF gitingest fails to process a repository THEN the system SHALL provide clear error messages and fallback options

### Requirement 2

**User Story:** As a project maintainer, I want gitingest integration to preserve all file types and relationships, so that AI analysis covers the complete project ecosystem including documentation, configuration, and code files.

#### Acceptance Criteria

1. WHEN gitingest processes a repository THEN the system SHALL include all relevant file types (code, docs, configs, tests)
2. WHEN analyzing the gitingest output THEN the system SHALL maintain file hierarchy and relationship information
3. WHEN creating the RAG knowledge base THEN the system SHALL use gitingest's structured format for better context chunking
4. WHEN generating responses THEN the system SHALL reference specific files and line numbers from the gitingest output
5. WHEN filtering files THEN the system SHALL respect gitignore rules and exclude binary/irrelevant files automatically

### Requirement 3

**User Story:** As a security-conscious user, I want gitingest integration to work with both public and private repositories while maintaining the same security standards, so that sensitive code remains protected.

#### Acceptance Criteria

1. WHEN processing private repositories THEN the system SHALL pass authentication credentials securely to gitingest
2. WHEN gitingest accesses repositories THEN the system SHALL ensure credentials are handled only in memory
3. WHEN processing completes THEN the system SHALL clear all temporary files and authentication data
4. WHEN errors occur THEN the system SHALL not expose repository content or credentials in logs
5. IF gitingest creates temporary files THEN the system SHALL clean them up immediately after processing

### Requirement 4

**User Story:** As a team member, I want gitingest integration to be faster than the current GitHub API approach, so that I can analyze repositories more efficiently.

#### Acceptance Criteria

1. WHEN comparing to GitHub API streaming THEN gitingest integration SHALL complete repository ingestion faster
2. WHEN processing repositories THEN the system SHALL show progress indicators for gitingest operations
3. WHEN gitingest runs THEN the system SHALL provide real-time status updates to users
4. WHEN analysis completes THEN the system SHALL transition seamlessly to AI processing and visualization
5. IF gitingest takes longer than expected THEN the system SHALL provide estimated completion times

### Requirement 5

**User Story:** As a developer, I want the gitingest integration to enhance the existing flowchart and AI chat features, so that I get better insights from the improved repository representation.

#### Acceptance Criteria

1. WHEN gitingest output is processed THEN the system SHALL generate more accurate dependency graphs for flowcharts
2. WHEN AI answers questions THEN the system SHALL leverage gitingest's structured format for better context retrieval
3. WHEN displaying code references THEN the system SHALL use gitingest's file path information for precise navigation
4. WHEN generating summaries THEN the system SHALL benefit from gitingest's comprehensive file inclusion
5. WHEN updating repositories THEN the system SHALL re-run gitingest to maintain current analysis

### Requirement 6

**User Story:** As a system administrator, I want gitingest integration to be configurable and maintainable, so that the system can adapt to different repository types and requirements.

#### Acceptance Criteria

1. WHEN installing the system THEN gitingest SHALL be included as a Python dependency with proper version management
2. WHEN configuring gitingest THEN the system SHALL allow customization of file inclusion/exclusion patterns
3. WHEN running gitingest THEN the system SHALL handle different Git authentication methods (HTTPS, SSH, tokens)
4. WHEN processing fails THEN the system SHALL provide detailed diagnostic information for troubleshooting
5. IF gitingest updates are available THEN the system SHALL support easy upgrades without breaking existing functionality

### Requirement 7

**User Story:** As a user, I want gitingest integration to work seamlessly with the existing web interface, so that the improved backend processing is transparent to my workflow.

#### Acceptance Criteria

1. WHEN using the repository input interface THEN the system SHALL show gitingest processing status alongside existing progress indicators
2. WHEN gitingest completes THEN the system SHALL automatically proceed to AI processing and flowchart generation
3. WHEN errors occur during gitingest processing THEN the system SHALL display user-friendly error messages
4. WHEN switching between repositories THEN the system SHALL manage gitingest operations efficiently
5. IF gitingest processing is interrupted THEN the system SHALL allow users to retry or cancel operations gracefully


================================================
FILE: .kiro/specs/gitingest-integration/tasks.md
================================================
# Implementation Plan

- [x] 1. Set up gitingest dependency and core infrastructure






  - Add gitingest to requirements.txt with version pinning
  - Create GitingestProcessor service class with basic structure
  - Set up environment configuration for gitingest processing
  - _Requirements: 6.1, 6.2_

- [ ] 2. Implement GitingestProcessor core functionality
- [ ] 2.1 Create repository processing method
  - Write async process_repository method that executes gitingest command
  - Implement secure credential passing through environment variables
  - Add subprocess management with timeout and error handling
  - _Requirements: 1.1, 3.1, 3.2_

- [ ] 2.2 Implement gitingest output parsing
  - Write parse_gitingest_output method to convert raw text to structured data
  - Create file hierarchy reconstruction from gitingest output
  - Implement content block extraction with metadata preservation
  - _Requirements: 1.2, 1.3, 2.2_

- [ ] 2.3 Add repository validation and cleanup
  - Write validate_repository method for URL and access checking
  - Implement cleanup_temporary_files for secure file management
  - Create error handling for gitingest execution failures
  - _Requirements: 1.5, 3.3, 3.4_

- [ ] 3. Enhance RepositoryService with gitingest integration
- [ ] 3.1 Replace GitHub API streaming with gitingest processing
  - Modify analyze_repository method to use GitingestProcessor
  - Update progress tracking for gitingest operations
  - Maintain existing caching and session management
  - _Requirements: 4.1, 4.3, 7.2_

- [ ] 3.2 Implement improved error handling and diagnostics
  - Create gitingest-specific error types and messages
  - Add fallback mechanisms for gitingest failures
  - Implement diagnostic reporting for troubleshooting
  - _Requirements: 1.5, 6.4, 7.3_

- [ ] 4. Optimize RAGService for gitingest output
- [ ] 4.1 Create enhanced chunking strategy
  - Write chunk_gitingest_output method using file boundaries
  - Implement improved context preservation through structured hierarchy
  - Create metadata extraction from gitingest's comprehensive output
  - _Requirements: 2.1, 2.3, 5.2_

- [ ] 4.2 Build file hierarchy indexing
  - Write build_file_hierarchy_index for better navigation
  - Implement dependency mapping from gitingest structure
  - Create enhanced embedding generation with file context
  - _Requirements: 2.2, 2.4, 5.3_

- [ ] 5. Update VisualizationService for improved flowcharts
- [ ] 5.1 Enhance dependency graph generation
  - Modify flowchart data generation to use gitingest's structured output
  - Improve relationship mapping accuracy with comprehensive file inclusion
  - Update layout algorithms for better node positioning with more complete data
  - _Requirements: 5.1, 5.4_

- [ ] 5.2 Implement better source code navigation
  - Update click handlers to use gitingest's precise file path information
  - Enhance code reference display with line number accuracy
  - Create improved hover functionality with comprehensive summaries
  - _Requirements: 5.3, 5.4_

- [ ] 6. Create gitingest-specific API endpoints
- [ ] 6.1 Add gitingest processing status endpoints
  - Create GET /api/gitingest/:id/status for processing progress
  - Write POST /api/gitingest/process for repository submission
  - Implement DELETE /api/gitingest/:id for cleanup operations
  - _Requirements: 4.2, 7.1, 7.4_

- [ ] 6.2 Update existing repository endpoints
  - Modify existing repository analysis endpoints to use gitingest
  - Update response formats to include gitingest metadata
  - Maintain backward compatibility with existing frontend
  - _Requirements: 7.2, 7.5_

- [ ] 7. Enhance frontend for gitingest integration
- [ ] 7.1 Update repository input interface
  - Add gitingest processing indicators to existing progress displays
  - Create configuration options for gitingest include/exclude patterns
  - Implement better error messaging for gitingest-specific failures
  - _Requirements: 6.2, 7.1, 7.3_

- [ ] 7.2 Improve AI chat interface with better context
  - Update chat components to leverage improved file references
  - Enhance source code navigation with gitingest's precise paths
  - Create better context display using gitingest's structured format
  - _Requirements: 5.2, 5.3, 7.2_

- [ ] 8. Implement configuration and customization features
- [ ] 8.1 Create gitingest configuration management
  - Write configuration service for include/exclude patterns
  - Implement file size limits and processing timeout settings
  - Create authentication method selection for different Git providers
  - _Requirements: 6.2, 6.3_

- [ ] 8.2 Add processing optimization controls
  - Implement configurable memory usage limits
  - Create batch processing options for multiple repositories
  - Write performance monitoring and metrics collection
  - _Requirements: 4.1, 4.4, 6.5_

- [ ] 9. Build comprehensive testing suite
- [ ] 9.1 Create GitingestProcessor unit tests
  - Write tests for repository processing with mock gitingest execution
  - Create output parsing tests with sample gitingest outputs
  - Implement error handling tests for various failure scenarios
  - _Requirements: 1.1, 1.2, 1.5_

- [ ] 9.2 Write integration tests for enhanced services
  - Create end-to-end tests for complete gitingest workflow
  - Write RAG system tests with gitingest output
  - Implement visualization tests with improved dependency graphs
  - _Requirements: 2.1, 4.1, 5.1_

- [ ] 9.3 Add performance and security tests
  - Create performance comparison tests between gitingest and GitHub API
  - Write security tests for credential handling and cleanup
  - Implement load tests for concurrent gitingest processing
  - _Requirements: 3.1, 3.2, 3.3, 4.1_

- [ ] 10. Create migration and deployment utilities
- [ ] 10.1 Build migration tools for existing repositories
  - Write scripts to re-process existing repositories with gitingest
  - Create data migration utilities for RAG knowledge base updates
  - Implement rollback mechanisms for deployment safety
  - _Requirements: 5.5, 6.5_

- [ ] 10.2 Add monitoring and maintenance features
  - Create health check endpoints for gitingest functionality
  - Implement logging and metrics for gitingest operations
  - Write maintenance scripts for cleanup and optimization
  - _Requirements: 6.4, 6.5_


================================================
FILE: .kiro/specs/self-configuring-ai-agents/requirements.md
================================================
[Empty file]


================================================
FILE: .kiro/specs/streamlit-frontend/design.md
================================================
Error reading file with 'cp1252': 'charmap' codec can't decode byte 0x90 in position 4761: character maps to <undefined>


================================================
FILE: .kiro/specs/streamlit-frontend/requirements.md
================================================
# Requirements Document

## Introduction

This feature creates a beautiful, dark-mode Streamlit frontend for the AI Project Analyzer Flask backend. The frontend will provide an intuitive interface for users to view their existing repositories and add new ones by providing GitHub repository URLs. The interface will communicate with the Flask backend to clone repositories and display analysis results.

## Requirements

### Requirement 1

**User Story:** As a user, I want to see a list of my existing repositories in a clean, organized interface, so that I can quickly browse and select repositories I've already analyzed.

#### Acceptance Criteria

1. WHEN the application loads THEN the system SHALL display all repositories from the my_repos directory
2. WHEN repositories are displayed THEN the system SHALL show repository name, description, and last modified date
3. WHEN no repositories exist THEN the system SHALL display a friendly message indicating no repositories are available
4. WHEN repositories are listed THEN the system SHALL use a dark theme with good contrast and readability

### Requirement 2

**User Story:** As a user, I want to input a GitHub repository URL and have it cloned automatically, so that I can analyze new repositories without manual setup.

#### Acceptance Criteria

1. WHEN I enter a valid GitHub repository URL THEN the system SHALL validate the URL format
2. WHEN I submit a repository URL THEN the system SHALL call the Flask backend to clone the repository
3. WHEN cloning is successful THEN the system SHALL display a success message and refresh the repository list
4. WHEN cloning fails THEN the system SHALL display a clear error message explaining what went wrong
5. WHEN cloning is in progress THEN the system SHALL show a loading indicator

### Requirement 3

**User Story:** As a user, I want the interface to have a beautiful dark mode design, so that I can work comfortably in low-light environments and have a modern user experience.

#### Acceptance Criteria

1. WHEN the application loads THEN the system SHALL use a dark color scheme as the default theme
2. WHEN displaying content THEN the system SHALL use high contrast colors for good readability
3. WHEN showing interactive elements THEN the system SHALL provide clear visual feedback on hover and click
4. WHEN displaying status messages THEN the system SHALL use appropriate colors (green for success, red for errors, blue for info)

### Requirement 4

**User Story:** As a user, I want real-time feedback on repository operations, so that I understand what's happening and can track progress.

#### Acceptance Criteria

1. WHEN a repository operation starts THEN the system SHALL display a progress indicator
2. WHEN operations complete THEN the system SHALL show success/failure notifications
3. WHEN errors occur THEN the system SHALL display detailed error messages with suggested actions
4. WHEN the repository list changes THEN the system SHALL automatically refresh the display

### Requirement 5

**User Story:** As a user, I want the interface to be responsive and intuitive, so that I can efficiently manage my repositories regardless of screen size.

#### Acceptance Criteria

1. WHEN using different screen sizes THEN the system SHALL adapt the layout appropriately
2. WHEN interacting with form elements THEN the system SHALL provide clear labels and validation feedback
3. WHEN navigating the interface THEN the system SHALL maintain consistent styling and behavior
4. WHEN performing actions THEN the system SHALL provide keyboard shortcuts where appropriate


================================================
FILE: .kiro/specs/streamlit-frontend/tasks.md
================================================
# Implementation Plan

- [x] 1. Set up Streamlit application structure and dependencies




  - Create streamlit_app.py as main entry point
  - Create requirements.txt with Streamlit, requests, and other dependencies
  - Set up basic Streamlit configuration and page setup
  - _Requirements: 3.1, 3.3_

- [ ] 2. Implement dark theme styling system
  - Create custom CSS for dark theme with specified color palette
  - Implement load_custom_css() function to inject styles
  - Style all UI components for consistent dark theme appearance
  - _Requirements: 3.1, 3.2, 3.3_

- [ ] 3. Create API client module for Flask backend communication
  - Implement get_local_repositories() function to fetch repository list
  - Create clone_repository() function to call Flask clone endpoint
  - Add validate_github_url() function for client-side URL validation
  - Implement handle_api_response() function for consistent error handling
  - _Requirements: 2.2, 2.3, 4.2, 4.3_

- [ ] 4. Build repository list display component
  - Create render_repository_list() function to display repository cards
  - Implement repository card layout with metadata display
  - Add file statistics, language breakdown, and last modified info
  - Style repository cards with hover effects and responsive design
  - _Requirements: 1.1, 1.2, 1.4, 5.3_

- [ ] 5. Implement add repository form component
  - Create render_add_repository_form() function with URL input field
  - Add optional GitHub token input with secure handling
  - Implement form validation and submission logic
  - Add clone and analyze button functionality
  - _Requirements: 2.1, 2.2, 2.4, 5.2_

- [ ] 6. Create notification and status system
  - Implement render_notifications() function for user feedback
  - Add loading indicators for repository operations
  - Create success, error, and info notification types with appropriate colors
  - Implement progress tracking for clone operations
  - _Requirements: 2.3, 2.5, 4.1, 4.2, 4.3_

- [ ] 7. Add session state management and initialization
  - Create initialize_session_state() function for app state setup
  - Implement repository caching with refresh functionality
  - Add state management for current operations and notifications
  - Handle GitHub token storage in session state securely
  - _Requirements: 4.4, 5.3_

- [ ] 8. Implement main application orchestration
  - Create main() function as application entry point
  - Add render_header() function for app title and navigation
  - Integrate all components into cohesive user interface
  - Implement auto-refresh functionality for repository list
  - _Requirements: 1.3, 1.4, 4.4, 5.1_

- [ ] 9. Add error handling and user feedback systems
  - Implement comprehensive error handling for API failures
  - Add user-friendly error messages with suggested actions
  - Create timeout handling for long-running operations
  - Add validation feedback for form inputs
  - _Requirements: 2.4, 4.2, 4.3, 5.2_

- [ ] 10. Create responsive layout and mobile optimization
  - Implement responsive design for different screen sizes
  - Add mobile-friendly touch interactions
  - Optimize layout for tablet and desktop viewing
  - Test and adjust component spacing and sizing
  - _Requirements: 5.1, 5.3_

- [ ] 11. Add repository statistics and metadata display
  - Implement detailed file type breakdown visualization
  - Create language percentage display with color coding
  - Add repository size formatting and display
  - Show clone timestamp and source URL information
  - _Requirements: 1.2, 1.4_

- [ ] 12. Implement real-time operation feedback
  - Add progress bars for clone operations
  - Create real-time status updates during repository processing
  - Implement operation cancellation if supported by backend
  - Add estimated time remaining for long operations
  - _Requirements: 4.1, 4.4_

- [ ] 13. Create comprehensive testing suite
  - Write unit tests for API client functions
  - Create integration tests for Flask backend communication
  - Add UI component testing with mock data
  - Implement error scenario testing and validation
  - _Requirements: All requirements validation_

- [ ] 14. Add final polish and optimization
  - Optimize performance for large repository lists
  - Add keyboard shortcuts for common actions
  - Implement caching for improved responsiveness
  - Add final styling touches and animations
  - _Requirements: 5.1, 5.3, 5.4_

